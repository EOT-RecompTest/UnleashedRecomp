#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_82127B5C"))) PPC_WEAK_FUNC(sub_82127B5C);
PPC_FUNC_IMPL(__imp__sub_82127B5C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82127B60"))) PPC_WEAK_FUNC(sub_82127B60);
PPC_FUNC_IMPL(__imp__sub_82127B60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e450
	ctx.lr = 0x82127B68;
	__restfpr_22(ctx, base);
	// stfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -104, ctx.f30.u64);
	// stfd f31,-96(r1)
	PPC_STORE_U64(ctx.r1.u32 + -96, ctx.f31.u64);
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x82127B8C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82127B98;
	sub_82111340(ctx, base);
	// lbz r11,1152(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1152);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82127bb0
	if (ctx.cr6.eq) goto loc_82127BB0;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82127558
	ctx.lr = 0x82127BB0;
	sub_82127558(ctx, base);
loc_82127BB0:
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82127868
	ctx.lr = 0x82127BB8;
	sub_82127868(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x82127BC4;
	sub_82111340(ctx, base);
	// li r24,0
	ctx.r24.s64 = 0;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r24,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r24.u32);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// stw r24,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r24.u32);
	// lwz r25,356(r30)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r30.u32 + 356);
	// rlwinm r11,r25,1,0,30
	ctx.r11.u64 = rotl64(ctx.r25.u32 | (ctx.r25.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r25,r11
	ctx.r11.u64 = ctx.r25.u64 + ctx.r11.u64;
	// rlwinm r29,r11,4,0,27
	ctx.r29.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8210b178
	ctx.lr = 0x82127BF0;
	sub_8210B178(ctx, base);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// lfs f30,48(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,36(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// beq cr6,0x82127c80
	if (ctx.cr6.eq) goto loc_82127C80;
	// addi r9,r25,-1
	ctx.r9.s64 = ctx.r25.s64 + -1;
	// mtctr r25
	ctx.ctr.u64 = ctx.r25.u64;
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// clrldi r8,r9,32
	ctx.r8.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// std r8,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r8.u64);
	// lfd f0,96(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f0
	ctx.f13.f64 = double(ctx.f0.s64);
	// frsp f0,f13
	ctx.f0.f64 = double(float(ctx.f13.f64));
loc_82127C2C:
	// clrldi r9,r10,32
	ctx.r9.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// stfs f30,4(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + 4, temp.u32);
	// stfs f31,8(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 8, temp.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// std r9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r9.u64);
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f12,f13
	ctx.f12.f64 = double(ctx.f13.s64);
	// frsp f11,f12
	ctx.f11.f64 = double(float(ctx.f12.f64));
	// fdivs f10,f11,f0
	ctx.f10.f64 = double(float(ctx.f11.f64 / ctx.f0.f64));
	// fsubs f9,f31,f10
	ctx.f9.f64 = static_cast<float>(ctx.f31.f64 - ctx.f10.f64);
	// stfs f9,12(r11)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + 12, temp.u32);
	// stfs f30,16(r11)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + 16, temp.u32);
	// stfs f30,20(r11)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + 20, temp.u32);
	// stfs f9,24(r11)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + 24, temp.u32);
	// stfs f31,28(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 28, temp.u32);
	// stfs f30,32(r11)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + 32, temp.u32);
	// stfs f9,36(r11)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// stfs f31,40(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stfs f31,44(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// stfsu f9,48(r11)
	temp.f32 = float(ctx.f9.f64);
	ea = 48 + ctx.r11.u32;
	PPC_STORE_U32(ea, temp.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x82127c2c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82127C2C;
loc_82127C80:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r9,r24
	ctx.r9.u64 = ctx.r24.u64;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r8,r11,200
	ctx.r8.s64 = ctx.r11.s64 + 200;
	// lwz r10,272(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	// stb r24,264(r11)
	PPC_STORE_U8(ctx.r11.u32 + 264, ctx.r24.u8);
	// add r9,r29,r10
	ctx.r9.u64 = ctx.r29.u64 + ctx.r10.u64;
	// lwz r10,268(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// addi r7,r9,31
	ctx.r7.s64 = ctx.r9.s64 + 31;
	// rlwinm r6,r10,2,0,29
	ctx.r6.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r7,0,0,26
	ctx.r10.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFE0;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// lwzx r3,r6,r8
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r8.u32);
	// lwz r4,24(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r4,r4,0,0,29
	ctx.r4.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFC;
	// bl 0x8222ee68
	ctx.lr = 0x82127CC4;
	sub_8222EE68(ctx, base);
	// lbz r3,1152(r30)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1152);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r26,3
	ctx.r26.s64 = 3;
	// li r27,1
	ctx.r27.s64 = 1;
	// addi r29,r11,28184
	ctx.r29.s64 = ctx.r11.s64 + 28184;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82127e88
	if (ctx.cr6.eq) goto loc_82127E88;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lis r22,-32178
	ctx.r22.s64 = -2108817408;
	// lwz r28,25880(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25880);
	// lwz r3,25592(r22)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r22.u32 + 25592);
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// stw r10,12216(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r3)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82127D0C;
	sub_82238728(ctx, base);
	// lwz r3,25592(r22)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r22.u32 + 25592);
	// lwz r4,0(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82127D18;
	sub_82238380(ctx, base);
	// lis r7,-32178
	ctx.r7.s64 = -2108817408;
	// lwz r11,296(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 296);
	// lwz r28,25916(r7)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r7.u32 + 25916);
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82127d44
	if (ctx.cr6.eq) goto loc_82127D44;
	// lis r6,16384
	ctx.r6.s64 = 1073741824;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82237a38
	ctx.lr = 0x82127D40;
	sub_82237A38(ctx, base);
	// stw r28,296(r29)
	PPC_STORE_U32(ctx.r29.u32 + 296, ctx.r28.u32);
loc_82127D44:
	// lwz r11,2292(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2292);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82127d78
	if (ctx.cr6.eq) goto loc_82127D78;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r26,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r26.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2292, ctx.r10.u32);
loc_82127D78:
	// lwz r11,2308(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2308);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82127dac
	if (ctx.cr6.eq) goto loc_82127DAC;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r26,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r26.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2308, ctx.r10.u32);
loc_82127DAC:
	// lwz r11,2356(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2356);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82127dd0
	if (ctx.cr6.eq) goto loc_82127DD0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82127DC8;
	sub_8222C248(ctx, base);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// stw r24,2356(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2356, ctx.r24.u32);
loc_82127DD0:
	// lwz r11,2372(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2372);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82127df4
	if (ctx.cr6.eq) goto loc_82127DF4;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x82127DEC;
	sub_8222C0A0(ctx, base);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// stw r24,2372(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2372, ctx.r24.u32);
loc_82127DF4:
	// lwz r11,2388(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2388);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82127e28
	if (ctx.cr6.eq) goto loc_82127E28;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// lwz r9,1164(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r9,r27,24,7,8
	ctx.r9.u64 = (rotl32(ctx.r27.u32, 24) & 0x1800000) | (ctx.r9.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r9,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r9.u32);
	// ld r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// oris r7,r8,16384
	ctx.r7.u64 = ctx.r8.u64 | 1073741824;
	// std r7,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r7.u64);
	// stw r10,2388(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2388, ctx.r10.u32);
loc_82127E28:
	// lwz r11,2340(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2340);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x82127e5c
	if (ctx.cr6.eq) goto loc_82127E5C;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r10,-1
	ctx.r10.s64 = -1;
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// lwz r9,1172(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// rlwimi r9,r27,0,30,31
	ctx.r9.u64 = (rotl32(ctx.r27.u32, 0) & 0x3) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r9,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r9.u32);
	// ld r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// oris r7,r8,16384
	ctx.r7.u64 = ctx.r8.u64 | 1073741824;
	// std r7,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r7.u64);
	// stw r10,2340(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2340, ctx.r10.u32);
loc_82127E5C:
	// lbz r11,1068(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 1068);
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,4
	ctx.r6.s64 = 4;
	// rotlwi r11,r11,6
	ctx.r11.u64 = rotl32(ctx.r11.u32, 6);
	// rldicr r7,r7,32,31
	ctx.r7.u64 = rotl64(ctx.r7.u64, 32) & 0xFFFFFFFF00000000;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// li r4,122
	ctx.r4.s64 = 122;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r5,r11,520
	ctx.r5.s64 = ctx.r11.s64 + 520;
	// bl 0x82238048
	ctx.lr = 0x82127E84;
	sub_82238048(ctx, base);
	// b 0x82127e94
	goto loc_82127E94;
loc_82127E88:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25876(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25876);
	// bl 0x8211c5f0
	ctx.lr = 0x82127E94;
	sub_8211C5F0(ctx, base);
loc_82127E94:
	// stfs f30,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stfs f30,100(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// stfs f30,104(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stfs f30,108(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// li r4,15
	ctx.r4.s64 = 15;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82229fb8
	ctx.lr = 0x82127EC0;
	sub_82229FB8(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82127ECC;
	sub_82111340(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,12
	ctx.r7.s64 = 12;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x82127EE8;
	sub_8222CC48(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// li r6,4
	ctx.r6.s64 = 4;
	// rldicr r28,r11,36,63
	ctx.r28.u64 = rotl64(ctx.r11.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// addi r5,r30,16
	ctx.r5.s64 = ctx.r30.s64 + 16;
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// li r4,108
	ctx.r4.s64 = 108;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238048
	ctx.lr = 0x82127F08;
	sub_82238048(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,4
	ctx.r6.s64 = 4;
	// rldicr r7,r7,35,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 35) & 0xFFFFFFFFFFFFFFFF;
	// addi r5,r30,80
	ctx.r5.s64 = ctx.r30.s64 + 80;
	// li r4,112
	ctx.r4.s64 = 112;
	// bl 0x82238048
	ctx.lr = 0x82127F20;
	sub_82238048(ctx, base);
	// addi r4,r29,36
	ctx.r4.s64 = ctx.r29.s64 + 36;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// li r5,64
	ctx.r5.s64 = 64;
	// bl 0x8233e4e0
	ctx.lr = 0x82127F30;
	sub_8233E4E0(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82257a50
	ctx.lr = 0x82127F3C;
	sub_82257A50(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,4
	ctx.r6.s64 = 4;
	// rldicr r7,r7,63,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238048
	ctx.lr = 0x82127F58;
	sub_82238048(ctx, base);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r7,3
	ctx.r7.s64 = 3;
	// rldicr r11,r10,34,63
	ctx.r11.u64 = rotl64(ctx.r10.u64, 34) & 0xFFFFFFFFFFFFFFFF;
	// rldicr r7,r7,33,30
	ctx.r7.u64 = rotl64(ctx.r7.u64, 33) & 0xFFFFFFFE00000000;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r30,144
	ctx.r5.s64 = ctx.r30.s64 + 144;
	// li r4,118
	ctx.r4.s64 = 118;
	// lfs f0,208(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 208);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,3776(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3776, temp.u32);
	// lfs f13,212(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 212);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,3780(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3780, temp.u32);
	// lfs f12,216(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 216);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,3784(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3784, temp.u32);
	// lfs f11,220(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 220);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,3788(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3788, temp.u32);
	// ld r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r8,r9,r11
	ctx.r8.u64 = ctx.r9.u64 | ctx.r11.u64;
	// std r8,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r8.u64);
	// lfs f10,224(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 224);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,3792(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3792, temp.u32);
	// lfs f9,228(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 228);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,3796(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3796, temp.u32);
	// lfs f8,232(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 232);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,3800(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3800, temp.u32);
	// lfs f7,236(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 236);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,3804(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3804, temp.u32);
	// ld r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 | ctx.r11.u64;
	// std r9,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r9.u64);
	// bl 0x82238048
	ctx.lr = 0x82127FD0;
	sub_82238048(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82127FDC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82127FE8;
	sub_821112B0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,257
	ctx.r3.s64 = 257;
	// bl 0x82113bc0
	ctx.lr = 0x82127FF4;
	sub_82113BC0(ctx, base);
	// lwz r8,336(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 336);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r4,4(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// bl 0x82111400
	ctx.lr = 0x82128004;
	sub_82111400(ctx, base);
	// lwz r11,2052(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82128028
	if (ctx.cr6.eq) goto loc_82128028;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82128020;
	sub_8222C0A0(ctx, base);
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,2052(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2052, ctx.r27.u32);
loc_82128028:
	// lwz r11,2036(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212804c
	if (ctx.cr6.eq) goto loc_8212804C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82128044;
	sub_8222C248(ctx, base);
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,2036(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2036, ctx.r27.u32);
loc_8212804C:
	// lwz r11,2068(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2068);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82128080
	if (ctx.cr6.eq) goto loc_82128080;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1164(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r8,r27,23,7,8
	ctx.r8.u64 = (rotl32(ctx.r27.u32, 23) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r27,2068(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2068, ctx.r27.u32);
loc_82128080:
	// li r5,6
	ctx.r5.s64 = 6;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111390
	ctx.lr = 0x82128090;
	sub_82111390(ctx, base);
	// lwz r11,1988(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1988);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x821280c4
	if (ctx.cr6.eq) goto loc_821280C4;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r26,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r26.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1988, ctx.r10.u32);
loc_821280C4:
	// lwz r11,2020(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2020);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821280f8
	if (ctx.cr6.eq) goto loc_821280F8;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1172(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// rlwinm r7,r8,0,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFC;
	// stw r7,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r24,2020(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2020, ctx.r24.u32);
loc_821280F8:
	// lwz r10,240(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 240);
	// li r12,1
	ctx.r12.s64 = 1;
	// addi r11,r31,10272
	ctx.r11.s64 = ctx.r31.s64 + 10272;
	// rldicr r12,r12,54,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 54) & 0xFFFFFFFFFFFFFFFF;
	// addi r9,r30,240
	ctx.r9.s64 = ctx.r30.s64 + 240;
	// li r4,63
	ctx.r4.s64 = 63;
	// stw r10,10272(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10272, ctx.r10.u32);
	// li r3,172
	ctx.r3.s64 = 172;
	// lwz r8,244(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 244);
	// stw r8,10276(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10276, ctx.r8.u32);
	// lwz r7,248(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 248);
	// stw r7,10280(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10280, ctx.r7.u32);
	// lwz r6,252(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 252);
	// stw r6,10284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10284, ctx.r6.u32);
	// ld r5,32(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r11,r5,r12
	ctx.r11.u64 = ctx.r5.u64 | ctx.r12.u64;
	// std r11,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r11.u64);
	// li r12,1
	ctx.r12.s64 = 1;
	// lwz r10,256(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 256);
	// stw r10,10288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10288, ctx.r10.u32);
	// rldicr r12,r12,53,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 53) & 0xFFFFFFFFFFFFFFFF;
	// lwz r9,260(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 260);
	// stw r9,10292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10292, ctx.r9.u32);
	// lwz r8,264(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 264);
	// stw r8,10296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10296, ctx.r8.u32);
	// lwz r7,268(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 268);
	// stw r7,10300(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10300, ctx.r7.u32);
	// ld r6,32(r31)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r5,r6,r12
	ctx.r5.u64 = ctx.r6.u64 | ctx.r12.u64;
	// std r5,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r5.u64);
	// li r12,1
	ctx.r12.s64 = 1;
	// lwz r11,272(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 272);
	// stw r11,10304(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10304, ctx.r11.u32);
	// rldicr r12,r12,52,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 52) & 0xFFFFFFFFFFFFFFFF;
	// lwz r10,276(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 276);
	// stw r10,10308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10308, ctx.r10.u32);
	// lwz r9,280(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 280);
	// stw r9,10312(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10312, ctx.r9.u32);
	// lwz r8,284(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 284);
	// stw r8,10316(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10316, ctx.r8.u32);
	// ld r7,32(r31)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r6,r7,r12
	ctx.r6.u64 = ctx.r7.u64 | ctx.r12.u64;
	// std r6,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r6.u64);
	// li r12,1
	ctx.r12.s64 = 1;
	// lwz r5,288(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 288);
	// stw r5,10320(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10320, ctx.r5.u32);
	// rldicr r12,r12,51,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 51) & 0xFFFFFFFFFFFFFFFF;
	// lwz r11,292(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 292);
	// stw r11,10324(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10324, ctx.r11.u32);
	// lwz r10,296(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 296);
	// stw r10,10328(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10328, ctx.r10.u32);
	// lwz r9,300(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 300);
	// stw r9,10332(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10332, ctx.r9.u32);
	// ld r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r7,r8,r12
	ctx.r7.u64 = ctx.r8.u64 | ctx.r12.u64;
	// std r7,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r7.u64);
	// li r12,1
	ctx.r12.s64 = 1;
	// lwz r6,304(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 304);
	// stw r6,10336(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10336, ctx.r6.u32);
	// rldicr r12,r12,50,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 50) & 0xFFFFFFFFFFFFFFFF;
	// lwz r5,308(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 308);
	// stw r5,10340(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10340, ctx.r5.u32);
	// lwz r11,312(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 312);
	// stw r11,10344(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10344, ctx.r11.u32);
	// lwz r10,316(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 316);
	// stw r10,10348(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10348, ctx.r10.u32);
	// ld r9,32(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r8,r9,r12
	ctx.r8.u64 = ctx.r9.u64 | ctx.r12.u64;
	// std r8,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r8.u64);
	// li r12,1
	ctx.r12.s64 = 1;
	// lwz r7,320(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 320);
	// stw r7,10352(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10352, ctx.r7.u32);
	// rldicr r12,r12,49,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 49) & 0xFFFFFFFFFFFFFFFF;
	// lwz r6,324(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 324);
	// stw r6,10356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10356, ctx.r6.u32);
	// lwz r5,328(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 328);
	// stw r5,10360(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10360, ctx.r5.u32);
	// lwz r11,332(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 332);
	// stw r11,10364(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10364, ctx.r11.u32);
	// ld r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r9,r10,r12
	ctx.r9.u64 = ctx.r10.u64 | ctx.r12.u64;
	// std r9,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r9.u64);
	// bl 0x82111340
	ctx.lr = 0x82128244;
	sub_82111340(ctx, base);
	// lfs f0,340(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 340);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,7744(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7744, temp.u32);
	// rlwinm r6,r25,2,0,29
	ctx.r6.u64 = rotl64(ctx.r25.u32 | (ctx.r25.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,13
	ctx.r4.s64 = 13;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lfs f13,344(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 344);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,7748(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7748, temp.u32);
	// lfs f12,348(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 348);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,7752(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7752, temp.u32);
	// lfs f11,352(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 352);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,7756(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7756, temp.u32);
	// ld r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r7,r8,r28
	ctx.r7.u64 = ctx.r8.u64 | ctx.r28.u64;
	// std r7,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r7.u64);
	// bl 0x8222dfc8
	ctx.lr = 0x82128284;
	sub_8222DFC8(ctx, base);
	// lis r5,-32178
	ctx.r5.s64 = -2108817408;
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lis r3,11264
	ctx.r3.s64 = 738197504;
	// lwz r5,25912(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 25912);
	// bl 0x8210af50
	ctx.lr = 0x821282A8;
	sub_8210AF50(ctx, base);
	// lis r4,-32182
	ctx.r4.s64 = -2109079552;
	// addi r3,r4,-27800
	ctx.r3.s64 = ctx.r4.s64 + -27800;
	// bl 0x8211f958
	ctx.lr = 0x821282B4;
	sub_8211F958(ctx, base);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82128318
	ctx.lr = 0x821282BC;
	sub_82128318(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x821282D8;
	sub_8222CC48(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,172
	ctx.r3.s64 = 172;
	// bl 0x82111340
	ctx.lr = 0x821282E4;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x821282F0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x821282FC;
	sub_82111400(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82128308;
	sub_821112B0(ctx, base);
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x8233e4a0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82128318"))) PPC_WEAK_FUNC(sub_82128318);
PPC_FUNC_IMPL(__imp__sub_82128318) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82128320;
	__restfpr_27(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,0(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x82128338;
	sub_82113BC0(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82128344;
	sub_82111340(ctx, base);
	// lis r27,-32178
	ctx.r27.s64 = -2108817408;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// li r6,11
	ctx.r6.s64 = 11;
	// lwz r4,25912(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 25912);
	// lwz r5,25900(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25900);
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x8212e3b8
	ctx.lr = 0x82128360;
	sub_8212E3B8(ctx, base);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// li r11,257
	ctx.r11.s64 = 257;
	// addi r31,r10,28184
	ctx.r31.s64 = ctx.r10.s64 + 28184;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,100
	ctx.r3.s64 = 100;
	// stw r11,288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 288, ctx.r11.u32);
	// bl 0x82111340
	ctx.lr = 0x8212837C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82111340
	ctx.lr = 0x82128388;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x82128394;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x821283A0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x821283AC;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x821283B8;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x82111340
	ctx.lr = 0x821283C4;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x821283D0;
	sub_82111340(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// addi r29,r11,27648
	ctx.r29.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,1932
	ctx.r5.s64 = ctx.r10.s64 + 1932;
	// lwz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x821283fc
	if (ctx.cr6.eq) goto loc_821283FC;
	// stw r5,36(r29)
	PPC_STORE_U32(ctx.r29.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x821283FC;
	sub_8222CDF8(ctx, base);
loc_821283FC:
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// lwz r11,52(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 52);
	// addi r28,r10,1980
	ctx.r28.s64 = ctx.r10.s64 + 1980;
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212842c
	if (ctx.cr6.eq) goto loc_8212842C;
	// stw r28,52(r29)
	PPC_STORE_U32(ctx.r29.u32 + 52, ctx.r28.u32);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// bl 0x8222d188
	ctx.lr = 0x82128420;
	sub_8222D188(ctx, base);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x8212842c
	if (ctx.cr6.eq) goto loc_8212842C;
	// bl 0x82113790
	ctx.lr = 0x8212842C;
	sub_82113790(ctx, base);
loc_8212842C:
	// lis r11,-32179
	ctx.r11.s64 = -2108882944;
	// lis r8,-32250
	ctx.r8.s64 = -2113536000;
	// addi r9,r11,20000
	ctx.r9.s64 = ctx.r11.s64 + 20000;
	// addi r7,r8,31376
	ctx.r7.s64 = ctx.r8.s64 + 31376;
	// addis r11,r9,1
	ctx.r11.s64 = ctx.r9.s64 + 65536;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// li r12,1
	ctx.r12.s64 = 1;
	// addi r6,r11,768
	ctx.r6.s64 = ctx.r11.s64 + 768;
	// lfs f0,36(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// rldicr r12,r12,36,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// lfs f13,48(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// lwz r5,768(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 768);
	// lwz r9,772(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 772);
	// stfs f0,128(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lwz r8,776(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 776);
	// stfs f13,132(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lwz r7,780(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 780);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r5,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r5.u32);
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r8,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r8.u32);
	// stw r7,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r7.u32);
	// lfs f11,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,7744(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7744, temp.u32);
	// stfs f11,7748(r30)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7748, temp.u32);
	// stfs f0,7752(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7752, temp.u32);
	// stfs f13,7756(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7756, temp.u32);
	// ld r6,8(r30)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r5,r6,r12
	ctx.r5.u64 = ctx.r6.u64 | ctx.r12.u64;
	// std r5,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r5.u64);
	// lfs f10,13012(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 13012);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,13008(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 13008);
	ctx.f8.f64 = double(temp.f32);
	// lfs f4,13004(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 13004);
	ctx.f4.f64 = double(temp.f32);
	// lfs f9,13000(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 13000);
	ctx.f9.f64 = double(temp.f32);
	// fctidz f5,f9
	ctx.f5.s64 = (ctx.f9.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f9.f64);
	// stfd f5,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.f5.u64);
	// lwz r9,100(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f7,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f7.u64);
	// fctidz f6,f10
	ctx.f6.s64 = (ctx.f10.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f10.f64);
	// stfd f6,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f6.u64);
	// fctidz f3,f4
	ctx.f3.s64 = (ctx.f4.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f4.f64);
	// stfd f3,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.f3.u64);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r8,100(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stw r9,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r9.u32);
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r11.u32);
	// stw r10,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r10.u32);
	// stw r8,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r8.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x82128508;
	sub_8222CBC8(ctx, base);
	// lis r7,-32178
	ctx.r7.s64 = -2108817408;
	// lwz r3,25892(r7)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + 25892);
	// bl 0x8211c5f0
	ctx.lr = 0x82128514;
	sub_8211C5F0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82128520;
	sub_821112B0(ctx, base);
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// lwz r30,25912(r27)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r27.u32 + 25912);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x8212854c
	if (ctx.cr6.eq) goto loc_8212854C;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x82128548;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_8212854C:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82128574
	if (ctx.cr6.eq) goto loc_82128574;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8212856C;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_82128574:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82128598
	if (ctx.cr6.eq) goto loc_82128598;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82128590;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_82128598:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821285cc
	if (ctx.cr6.eq) goto loc_821285CC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1164(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r8,r30,23,7,8
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 23) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r30,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r30.u32);
loc_821285CC:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82128600
	if (ctx.cr6.eq) goto loc_82128600;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82128600:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82128634
	if (ctx.cr6.eq) goto loc_82128634;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_82128634:
	// bl 0x8210b0d8
	ctx.lr = 0x82128638;
	sub_8210B0D8(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82128640"))) PPC_WEAK_FUNC(sub_82128640);
PPC_FUNC_IMPL(__imp__sub_82128640) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,44
	ctx.r11.s64 = 2883584;
	// li r10,5
	ctx.r10.s64 = 5;
	// ori r11,r11,9125
	ctx.r11.u64 = ctx.r11.u64 | 9125;
	// li r9,0
	ctx.r9.s64 = 0;
	// stb r10,101(r1)
	PPC_STORE_U8(ctx.r1.u32 + 101, ctx.r10.u8);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// li r4,3
	ctx.r4.s64 = 3;
	// stb r9,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, ctx.r9.u8);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// bl 0x821160a8
	ctx.lr = 0x82128678;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8212867C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821286a8
	if (ctx.cr6.eq) goto loc_821286A8;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,31632
	ctx.r6.s64 = ctx.r11.s64 + 31632;
	// addi r5,r10,32376
	ctx.r5.s64 = ctx.r10.s64 + 32376;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212869C;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25924(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25924, ctx.r3.u32);
	// b 0x821286b4
	goto loc_821286B4;
loc_821286A8:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25924(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25924, ctx.r11.u32);
loc_821286B4:
	// bl 0x82116360
	ctx.lr = 0x821286B8;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821286f0
	if (ctx.cr6.eq) goto loc_821286F0;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,32696
	ctx.r6.s64 = ctx.r11.s64 + 32696;
	// addi r5,r10,-32344
	ctx.r5.s64 = ctx.r10.s64 + -32344;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x821286D8;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25920(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25920, ctx.r3.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_821286F0:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25920(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25920, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8212870C"))) PPC_WEAK_FUNC(sub_8212870C);
PPC_FUNC_IMPL(__imp__sub_8212870C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82128710"))) PPC_WEAK_FUNC(sub_82128710);
PPC_FUNC_IMPL(__imp__sub_82128710) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82128718;
	__restfpr_26(ctx, base);
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r26,0(r3)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82128734;
	sub_821112B0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x82128740;
	sub_82113BC0(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x8212874C;
	sub_82111340(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82128758;
	sub_82111340(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25920(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25920);
	// bl 0x8211c5f0
	ctx.lr = 0x82128764;
	sub_8211C5F0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// addi r30,r10,16
	ctx.r30.s64 = ctx.r10.s64 + 16;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x8212879c
	if (ctx.cr6.eq) goto loc_8212879C;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x82128798;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_8212879C:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// li r9,3
	ctx.r9.s64 = 3;
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x821287d4
	if (ctx.cr6.eq) goto loc_821287D4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,11,19,21
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 11) & 0x1C00) | (ctx.r7.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_821287D4:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82128808
	if (ctx.cr6.eq) goto loc_82128808;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,14,16,18
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 14) & 0xE000) | (ctx.r7.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_82128808:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212882c
	if (ctx.cr6.eq) goto loc_8212882C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82128824;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r11.u32);
loc_8212882C:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82128850
	if (ctx.cr6.eq) goto loc_82128850;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82128848;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
loc_82128850:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// li r9,1
	ctx.r9.s64 = 1;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82128888
	if (ctx.cr6.eq) goto loc_82128888;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1164(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r7,r9,24,7,8
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 24) & 0x1800000) | (ctx.r7.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r7,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r10.u32);
loc_82128888:
	// lwz r11,2020(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2020);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x821288bc
	if (ctx.cr6.eq) goto loc_821288BC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1172(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// rlwimi r7,r9,0,30,31
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 0) & 0x3) | (ctx.r7.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r7,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2020, ctx.r10.u32);
loc_821288BC:
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// addi r31,r10,27648
	ctx.r31.s64 = ctx.r10.s64 + 27648;
	// addi r5,r11,2220
	ctx.r5.s64 = ctx.r11.s64 + 2220;
	// addi r30,r11,2316
	ctx.r30.s64 = ctx.r11.s64 + 2316;
	// addi r28,r11,484
	ctx.r28.s64 = ctx.r11.s64 + 484;
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x821288f0
	if (ctx.cr6.eq) goto loc_821288F0;
	// stw r5,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x821288F0;
	sub_8222CDF8(ctx, base);
loc_821288F0:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8210b080
	ctx.lr = 0x821288F8;
	sub_8210B080(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x821288FC;
	sub_8210B0D8(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r27,r11,31376
	ctx.r27.s64 = ctx.r11.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lfs f31,36(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// li r3,20
	ctx.r3.s64 = 20;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x8210af50
	ctx.lr = 0x82128928;
	sub_8210AF50(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lbz r10,25549(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 25549);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212899c
	if (ctx.cr6.eq) goto loc_8212899C;
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// addi r5,r11,2268
	ctx.r5.s64 = ctx.r11.s64 + 2268;
	// addi r30,r11,2364
	ctx.r30.s64 = ctx.r11.s64 + 2364;
	// addi r29,r11,536
	ctx.r29.s64 = ctx.r11.s64 + 536;
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82128964
	if (ctx.cr6.eq) goto loc_82128964;
	// stw r5,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82128964;
	sub_8222CDF8(ctx, base);
loc_82128964:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8210b080
	ctx.lr = 0x8212896C;
	sub_8210B080(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x82128978;
	sub_82111400(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212897C;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,20
	ctx.r3.s64 = 20;
	// bl 0x8210af50
	ctx.lr = 0x8212899C;
	sub_8210AF50(ctx, base);
loc_8212899C:
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x821289A8;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x821289B4;
	sub_82111340(ctx, base);
	// lfs f0,48(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lfs f13,13012(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 13012);
	ctx.f13.f64 = double(temp.f32);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lfs f11,13000(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 13000);
	ctx.f11.f64 = double(temp.f32);
	// fctidz f10,f13
	ctx.f10.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// lfs f8,13004(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 13004);
	ctx.f8.f64 = double(temp.f32);
	// fctidz f9,f11
	ctx.f9.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f7,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f7.u64);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// stfs f31,112(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stw r10,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r10.u32);
	// lfs f0,13008(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 13008);
	ctx.f0.f64 = double(temp.f32);
	// fctidz f12,f0
	ctx.f12.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// stfd f12,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f12.u64);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfd f9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f9.u64);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r8,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r8.u32);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x82128A1C;
	sub_8222CBC8(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82128A28"))) PPC_WEAK_FUNC(sub_82128A28);
PPC_FUNC_IMPL(__imp__sub_82128A28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82128A30;
	__restfpr_28(ctx, base);
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r30,r11,27648
	ctx.r30.s64 = ctx.r11.s64 + 27648;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r5,r11,1932
	ctx.r5.s64 = ctx.r11.s64 + 1932;
	// addi r29,r11,1980
	ctx.r29.s64 = ctx.r11.s64 + 1980;
	// lwz r10,36(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82128a70
	if (ctx.cr6.eq) goto loc_82128A70;
	// stw r5,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82128A70;
	sub_8222CDF8(ctx, base);
loc_82128A70:
	// lwz r11,52(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82128a98
	if (ctx.cr6.eq) goto loc_82128A98;
	// stw r29,52(r30)
	PPC_STORE_U32(ctx.r30.u32 + 52, ctx.r29.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222d188
	ctx.lr = 0x82128A8C;
	sub_8222D188(ctx, base);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82128a98
	if (ctx.cr6.eq) goto loc_82128A98;
	// bl 0x82113790
	ctx.lr = 0x82128A98;
	sub_82113790(ctx, base);
loc_82128A98:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82128AA4;
	sub_821112B0(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r30,r11,31376
	ctx.r30.s64 = ctx.r11.s64 + 31376;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,32
	ctx.r3.s64 = 32;
	// lfs f31,36(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x8210afd8
	ctx.lr = 0x82128AC4;
	sub_8210AFD8(ctx, base);
	// lfs f0,48(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lfs f13,13012(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13012);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,13000(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13000);
	ctx.f11.f64 = double(temp.f32);
	// fctidz f10,f13
	ctx.f10.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// lfs f8,13004(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13004);
	ctx.f8.f64 = double(temp.f32);
	// fctidz f9,f11
	ctx.f9.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// lwz r9,92(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f7,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f7.u64);
	// lwz r7,92(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// stfs f31,112(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stw r9,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r9.u32);
	// lfs f0,13008(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13008);
	ctx.f0.f64 = double(temp.f32);
	// fctidz f12,f0
	ctx.f12.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// stfd f12,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f12.u64);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfd f9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f9.u64);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r7,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r7.u32);
	// stw r10,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r10.u32);
	// stw r8,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r8.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x82128B2C;
	sub_8222CBC8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82128B38;
	sub_821112B0(ctx, base);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// li r11,8449
	ctx.r11.s64 = 8449;
	// addi r31,r10,28184
	ctx.r31.s64 = ctx.r10.s64 + 28184;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,100
	ctx.r3.s64 = 100;
	// stw r11,288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 288, ctx.r11.u32);
	// bl 0x82111340
	ctx.lr = 0x82128B54;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82111340
	ctx.lr = 0x82128B60;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x82128B6C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x82128B78;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x82128B84;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x82128B90;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x82111340
	ctx.lr = 0x82128B9C;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82128BA8;
	sub_82111340(ctx, base);
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// addi r30,r10,432
	ctx.r30.s64 = ctx.r10.s64 + 432;
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82128bd8
	if (ctx.cr6.eq) goto loc_82128BD8;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x82128BD4;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_82128BD8:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82128bfc
	if (ctx.cr6.eq) goto loc_82128BFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82128BF4;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
loc_82128BFC:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82128c20
	if (ctx.cr6.eq) goto loc_82128C20;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82128C18;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r11.u32);
loc_82128C20:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82128c58
	if (ctx.cr6.eq) goto loc_82128C58;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1164(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r8,r30,24,7,8
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 24) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r10.u32);
loc_82128C58:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82128c8c
	if (ctx.cr6.eq) goto loc_82128C8C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82128C8C:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82128cc0
	if (ctx.cr6.eq) goto loc_82128CC0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_82128CC0:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r4,r11,16
	ctx.r4.s64 = ctx.r11.s64 + 16;
	// bl 0x82111400
	ctx.lr = 0x82128CD0;
	sub_82111400(ctx, base);
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82128cf4
	if (ctx.cr6.eq) goto loc_82128CF4;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82128CEC;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r11.u32);
loc_82128CF4:
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82128d18
	if (ctx.cr6.eq) goto loc_82128D18;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x82128D10;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r11.u32);
loc_82128D18:
	// lwz r11,2388(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2388);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82128d4c
	if (ctx.cr6.eq) goto loc_82128D4C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r9,2
	ctx.r9.s64 = 2;
	// addi r10,r11,24
	ctx.r10.s64 = ctx.r11.s64 + 24;
	// lwz r10,1188(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1188);
	// rlwimi r10,r30,24,7,8
	ctx.r10.u64 = (rotl32(ctx.r30.u32, 24) & 0x1800000) | (ctx.r10.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r10,1188(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1188, ctx.r10.u32);
	// ld r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r7,r8,16384
	ctx.r7.u64 = ctx.r8.u64 | 1073741824;
	// std r7,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r7.u64);
	// stw r9,2388(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2388, ctx.r9.u32);
loc_82128D4C:
	// lwz r11,2292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2292);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82128d80
	if (ctx.cr6.eq) goto loc_82128D80;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2292, ctx.r10.u32);
loc_82128D80:
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82128db4
	if (ctx.cr6.eq) goto loc_82128DB4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r10.u32);
loc_82128DB4:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// li r3,2
	ctx.r3.s64 = 2;
	// lbz r10,25549(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 25549);
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// addi r4,r11,536
	ctx.r4.s64 = ctx.r11.s64 + 536;
	// bne cr6,0x82128dd4
	if (!ctx.cr6.eq) goto loc_82128DD4;
	// addi r4,r11,484
	ctx.r4.s64 = ctx.r11.s64 + 484;
loc_82128DD4:
	// bl 0x82111400
	ctx.lr = 0x82128DD8;
	sub_82111400(ctx, base);
	// lwz r11,2676(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2676);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82128dfc
	if (ctx.cr6.eq) goto loc_82128DFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8222c248
	ctx.lr = 0x82128DF4;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2676(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2676, ctx.r11.u32);
loc_82128DFC:
	// lwz r11,2692(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2692);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82128e20
	if (ctx.cr6.eq) goto loc_82128E20;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8222c0a0
	ctx.lr = 0x82128E18;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2692(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2692, ctx.r11.u32);
loc_82128E20:
	// lwz r11,2708(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2708);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82128e54
	if (ctx.cr6.eq) goto loc_82128E54;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1212(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1212);
	// rlwimi r8,r30,24,7,8
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 24) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1212(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1212, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,8192
	ctx.r6.u64 = ctx.r7.u64 | 536870912;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2708(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2708, ctx.r10.u32);
loc_82128E54:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x82111390
	ctx.lr = 0x82128E64;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x82111390
	ctx.lr = 0x82128E74;
	sub_82111390(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25924(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25924);
	// bl 0x8211c5f0
	ctx.lr = 0x82128E80;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x82128E84;
	sub_8210B0D8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82128E90;
	sub_821112B0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,12545
	ctx.r3.s64 = 12545;
	// bl 0x82113bc0
	ctx.lr = 0x82128E9C;
	sub_82113BC0(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82128EA8"))) PPC_WEAK_FUNC(sub_82128EA8);
PPC_FUNC_IMPL(__imp__sub_82128EA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82128EB0;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r28,0(r3)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x82111340
	ctx.lr = 0x82128ECC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,92
	ctx.r3.s64 = 92;
	// bl 0x82111340
	ctx.lr = 0x82128ED8;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,84
	ctx.r3.s64 = 84;
	// bl 0x82111340
	ctx.lr = 0x82128EE4;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,88
	ctx.r3.s64 = 88;
	// bl 0x82111340
	ctx.lr = 0x82128EF0;
	sub_82111340(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82128EFC;
	sub_82111340(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lbz r10,25549(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 25549);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// beq cr6,0x82128f1c
	if (ctx.cr6.eq) goto loc_82128F1C;
	// addi r11,r11,536
	ctx.r11.s64 = ctx.r11.s64 + 536;
	// b 0x82128f20
	goto loc_82128F20;
loc_82128F1C:
	// addi r11,r11,484
	ctx.r11.s64 = ctx.r11.s64 + 484;
loc_82128F20:
	// stw r11,25928(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25928, ctx.r11.u32);
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// addi r4,r31,12
	ctx.r4.s64 = ctx.r31.s64 + 12;
	// addi r3,r11,-27800
	ctx.r3.s64 = ctx.r11.s64 + -27800;
	// bl 0x8211e968
	ctx.lr = 0x82128F34;
	sub_8211E968(ctx, base);
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// addi r31,r11,432
	ctx.r31.s64 = ctx.r11.s64 + 432;
	// lwz r11,464(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 464);
	// clrlwi r29,r11,26
	ctx.r29.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r29,50
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 50, ctx.xer);
	// bne cr6,0x82128f58
	if (!ctx.cr6.eq) goto loc_82128F58;
	// li r10,3
	ctx.r10.s64 = 3;
	// rlwimi r11,r10,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r10.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_82128F58:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// addi r6,r11,27648
	ctx.r6.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,31376
	ctx.r5.s64 = ctx.r10.s64 + 31376;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,188(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 188);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// lfs f1,36(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82227e30
	ctx.lr = 0x82128F8C;
	sub_82227E30(ctx, base);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// li r4,1
	ctx.r4.s64 = 1;
	// rlwimi r11,r29,0,26,31
	ctx.r11.u64 = (rotl32(ctx.r29.u32, 0) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// bl 0x82113bc0
	ctx.lr = 0x82128FA4;
	sub_82113BC0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,64
	ctx.r3.s64 = 64;
	// bl 0x82111340
	ctx.lr = 0x82128FB0;
	sub_82111340(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82128a28
	ctx.lr = 0x82128FB8;
	sub_82128A28(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x82128FC4;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x82128FD0;
	sub_82111340(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8222cc48
	ctx.lr = 0x82128FEC;
	sub_8222CC48(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82128FF8;
	sub_821112B0(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82129004;
	sub_82111340(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212900C"))) PPC_WEAK_FUNC(sub_8212900C);
PPC_FUNC_IMPL(__imp__sub_8212900C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82129010"))) PPC_WEAK_FUNC(sub_82129010);
PPC_FUNC_IMPL(__imp__sub_82129010) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x82129018;
	__restfpr_24(ctx, base);
	// stwu r1,-3040(r1)
	ea = -3040 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r9,0(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lwz r10,156(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 156);
	// addi r8,r5,4
	ctx.r8.s64 = ctx.r5.s64 + 4;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r7,r9,4,0,27
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// dcbt r7,r10
	// lwz r5,4(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// addi r7,r8,4
	ctx.r7.s64 = ctx.r8.s64 + 4;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r4,r5,4,0,27
	ctx.r4.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 4) & 0xFFFFFFF0;
	// dcbt r4,r10
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82129104
	if (ctx.cr6.eq) goto loc_82129104;
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// addi r4,r7,-4
	ctx.r4.s64 = ctx.r7.s64 + -4;
loc_8212905C:
	// rlwinm r31,r9,4,0,27
	ctx.r31.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// lwzu r7,4(r4)
	ea = 4 + ctx.r4.u32;
	ctx.r7.u64 = PPC_LOAD_U32(ea);
	ctx.r4.u32 = ea;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// add r30,r31,r10
	ctx.r30.u64 = ctx.r31.u64 + ctx.r10.u64;
	// rlwinm r31,r9,4,0,27
	ctx.r31.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// add r29,r31,r10
	ctx.r29.u64 = ctx.r31.u64 + ctx.r10.u64;
	// rlwinm r31,r9,4,0,27
	ctx.r31.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// lwz r28,0(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r9,r5
	ctx.r9.u64 = ctx.r5.u64;
	// lwz r27,4(r30)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// add r26,r31,r10
	ctx.r26.u64 = ctx.r31.u64 + ctx.r10.u64;
	// lwz r25,8(r30)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// rlwinm r5,r7,2,0,29
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r30,12(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// rlwinm r7,r7,6,0,25
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 6) & 0xFFFFFFC0;
	// lwz r24,0(r29)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// stw r28,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r28.u32);
	// stw r27,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r27.u32);
	// stw r25,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r25.u32);
	// stw r30,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r30.u32);
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// lwz r30,4(r29)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r28,8(r29)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// lwz r29,12(r29)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// lwzx r31,r31,r10
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r10.u32);
	// stw r24,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r24.u32);
	// stw r30,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r30.u32);
	// stw r28,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r28.u32);
	// stw r29,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r29.u32);
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// lwz r30,4(r26)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// lwz r29,8(r26)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// lwz r28,12(r26)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	// stw r31,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r31.u32);
	// stw r30,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r30.u32);
	// stw r29,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r29.u32);
	// stw r28,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r28.u32);
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// dcbt r7,r10
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// bne 0x8212905c
	if (!ctx.cr0.eq) goto loc_8212905C;
loc_82129104:
	// rlwinm r11,r6,1,0,30
	ctx.r11.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r10,1
	ctx.r10.s64 = 1;
	// add r6,r6,r11
	ctx.r6.u64 = ctx.r6.u64 + ctx.r11.u64;
	// rldicr r9,r10,63,63
	ctx.r9.u64 = rotl64(ctx.r10.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// addi r8,r6,65
	ctx.r8.s64 = ctx.r6.s64 + 65;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// rlwinm r11,r8,30,2,31
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 30) & 0x3FFFFFFF;
	// li r4,66
	ctx.r4.s64 = 66;
	// addi r7,r11,-16
	ctx.r7.s64 = ctx.r11.s64 + -16;
	// clrldi r11,r7,32
	ctx.r11.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// srad r10,r9,r11
	temp.u64 = ctx.r11.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r9.s64 < 0) & (((ctx.r9.s64 >> temp.u64) << temp.u64) != ctx.r9.s64);
	ctx.r10.s64 = ctx.r9.s64 >> temp.u64;
	// rldicl r7,r10,48,16
	ctx.r7.u64 = rotl64(ctx.r10.u64, 48) & 0xFFFFFFFFFFFF;
	// bl 0x82238048
	ctx.lr = 0x8212913C;
	sub_82238048(ctx, base);
	// addi r1,r1,3040
	ctx.r1.s64 = ctx.r1.s64 + 3040;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82129144"))) PPC_WEAK_FUNC(sub_82129144);
PPC_FUNC_IMPL(__imp__sub_82129144) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82129148"))) PPC_WEAK_FUNC(sub_82129148);
PPC_FUNC_IMPL(__imp__sub_82129148) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82129150;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r10,88(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 88);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,84(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 84);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mulli r10,r10,108
	ctx.r10.s64 = ctx.r10.s64 * 108;
	// lwz r28,0(r3)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// addi r29,r11,212
	ctx.r29.s64 = ctx.r11.s64 + 212;
	// addi r4,r29,60
	ctx.r4.s64 = ctx.r29.s64 + 60;
	// bl 0x8222cd68
	ctx.lr = 0x82129180;
	sub_8222CD68(ctx, base);
	// lis r9,-32182
	ctx.r9.s64 = -2109079552;
	// addi r8,r9,-27800
	ctx.r8.s64 = ctx.r9.s64 + -27800;
	// lwz r11,2120(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 2120);
	// rlwinm r7,r11,0,29,29
	ctx.r7.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// beq cr6,0x821291a4
	if (ctx.cr6.eq) goto loc_821291A4;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r4,r31,24
	ctx.r4.s64 = ctx.r31.s64 + 24;
	// b 0x821291e8
	goto loc_821291E8;
loc_821291A4:
	// lwz r11,72(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// addi r4,r31,72
	ctx.r4.s64 = ctx.r31.s64 + 72;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821291c4
	if (!ctx.cr6.eq) goto loc_821291C4;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// beq cr6,0x821291c8
	if (ctx.cr6.eq) goto loc_821291C8;
loc_821291C4:
	// li r11,0
	ctx.r11.s64 = 0;
loc_821291C8:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821291e0
	if (!ctx.cr6.eq) goto loc_821291E0;
	// addi r5,r29,28
	ctx.r5.s64 = ctx.r29.s64 + 28;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82129878
	ctx.lr = 0x821291E0;
	sub_82129878(ctx, base);
loc_821291E0:
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r4,r31,48
	ctx.r4.s64 = ctx.r31.s64 + 48;
loc_821291E8:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82129200
	if (!ctx.cr6.eq) goto loc_82129200;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// beq cr6,0x82129204
	if (ctx.cr6.eq) goto loc_82129204;
loc_82129200:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82129204:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212921c
	if (!ctx.cr6.eq) goto loc_8212921C;
	// addi r5,r29,28
	ctx.r5.s64 = ctx.r29.s64 + 28;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82129878
	ctx.lr = 0x8212921C;
	sub_82129878(ctx, base);
loc_8212921C:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f13,8(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// lfs f0,36(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// beq cr6,0x82129260
	if (ctx.cr6.eq) goto loc_82129260;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r12,1
	ctx.r12.s64 = 1;
	// stfs f0,8(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 8, temp.u32);
	// rldicr r12,r12,49,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 49) & 0xFFFFFFFFFFFFFFFF;
	// stfs f0,6944(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6944, temp.u32);
	// stfs f0,6948(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6948, temp.u32);
	// stfs f0,6952(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6952, temp.u32);
	// stfs f0,6956(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6956, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// or r9,r10,r12
	ctx.r9.u64 = ctx.r10.u64 | ctx.r12.u64;
	// std r9,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r9.u64);
loc_82129260:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8222cd68
	ctx.lr = 0x8212926C;
	sub_8222CD68(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8222cc48
	ctx.lr = 0x82129288;
	sub_8222CC48(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82129290"))) PPC_WEAK_FUNC(sub_82129290);
PPC_FUNC_IMPL(__imp__sub_82129290) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x82129298;
	__restfpr_24(ctx, base);
	// stfd f30,-88(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -88, ctx.f30.u64);
	// stfd f31,-80(r1)
	PPC_STORE_U64(ctx.r1.u32 + -80, ctx.f31.u64);
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x821292BC;
	sub_821112B0(ctx, base);
	// lfs f0,13004(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13004);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,13008(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13008);
	ctx.f13.f64 = double(temp.f32);
	// fctidz f12,f0
	ctx.f12.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// lfs f11,13012(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13012);
	ctx.f11.f64 = double(temp.f32);
	// fctidz f10,f13
	ctx.f10.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// lfs f8,13000(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13000);
	ctx.f8.f64 = double(temp.f32);
	// fctidz f9,f11
	ctx.f9.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// stfd f12,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f12.u64);
	// lwz r26,92(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// stfd f10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f10.u64);
	// lwz r25,84(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f9,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f9.u64);
	// stfd f7,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f7.u64);
	// lwz r24,92(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r27,84(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r11,6
	ctx.r11.s64 = 6;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stw r26,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r26.u32);
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// lfs f31,13016(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13016);
	ctx.f31.f64 = double(temp.f32);
	// lfs f30,13020(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13020);
	ctx.f30.f64 = double(temp.f32);
	// addi r8,r10,-4
	ctx.r8.s64 = ctx.r10.s64 + -4;
	// stfs f31,112(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// addi r10,r9,-4
	ctx.r10.s64 = ctx.r9.s64 + -4;
	// stfs f30,116(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r27.u32);
	// stw r25,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r25.u32);
	// stw r24,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r24.u32);
loc_82129334:
	// lwzu r11,4(r10)
	ea = 4 + ctx.r10.u32;
	ctx.r11.u64 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	// stwu r11,4(r8)
	ea = 4 + ctx.r8.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r8.u32 = ea;
	// bdnz 0x82129334
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82129334;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lfs f0,48(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,144(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f0,148(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x82129360;
	sub_8222CBC8(ctx, base);
	// lis r9,-32183
	ctx.r9.s64 = -2109145088;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// addi r29,r9,28184
	ctx.r29.s64 = ctx.r9.s64 + 28184;
	// li r5,64
	ctx.r5.s64 = 64;
	// addi r4,r29,164
	ctx.r4.s64 = ctx.r29.s64 + 164;
	// bl 0x8233e4e0
	ctx.lr = 0x82129378;
	sub_8233E4E0(ctx, base);
	// addi r4,r29,100
	ctx.r4.s64 = ctx.r29.s64 + 100;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// li r5,64
	ctx.r5.s64 = 64;
	// bl 0x8233e4e0
	ctx.lr = 0x82129388;
	sub_8233E4E0(ctx, base);
	// addi r4,r30,24
	ctx.r4.s64 = ctx.r30.s64 + 24;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x821139a8
	ctx.lr = 0x82129394;
	sub_821139A8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,172
	ctx.r3.s64 = 172;
	// bl 0x82111340
	ctx.lr = 0x821293A0;
	sub_82111340(ctx, base);
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// addi r29,r30,12
	ctx.r29.s64 = ctx.r30.s64 + 12;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,20(r30)
	PPC_STORE_U32(ctx.r30.u32 + 20, ctx.r11.u32);
	// beq cr6,0x821293f8
	if (ctx.cr6.eq) goto loc_821293F8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r10.u32);
loc_821293BC:
	// lwz r4,12(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// addi r10,r11,12
	ctx.r10.s64 = ctx.r11.s64 + 12;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// stw r4,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r4.u32);
	// beq cr6,0x821293e0
	if (ctx.cr6.eq) goto loc_821293E0;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r11,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r11.u32);
	// bl 0x82129148
	ctx.lr = 0x821293E0;
	sub_82129148(ctx, base);
loc_821293E0:
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821293f8
	if (ctx.cr6.eq) goto loc_821293F8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r10.u32);
	// bne cr6,0x821293bc
	if (!ctx.cr6.eq) goto loc_821293BC;
loc_821293F8:
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x821139a8
	ctx.lr = 0x82129404;
	sub_821139A8(ctx, base);
	// clrldi r11,r27,32
	ctx.r11.u64 = ctx.r27.u64 & 0xFFFFFFFF;
	// clrldi r9,r25,32
	ctx.r9.u64 = ctx.r25.u64 & 0xFFFFFFFF;
	// fmr f6,f30
	ctx.fpscr.disableFlushMode();
	ctx.f6.f64 = ctx.f30.f64;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// clrldi r10,r24,32
	ctx.r10.u64 = ctx.r24.u64 & 0xFFFFFFFF;
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// clrldi r8,r26,32
	ctx.r8.u64 = ctx.r26.u64 & 0xFFFFFFFF;
	// lfd f12,80(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f11,80(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f7,f0
	ctx.f7.f64 = double(ctx.f0.s64);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// fmr f5,f31
	ctx.f5.f64 = ctx.f31.f64;
	// fcfid f9,f12
	ctx.f9.f64 = double(ctx.f12.s64);
	// fcfid f8,f13
	ctx.f8.f64 = double(ctx.f13.s64);
	// fcfid f10,f11
	ctx.f10.f64 = double(ctx.f11.s64);
	// frsp f1,f7
	ctx.f1.f64 = double(float(ctx.f7.f64));
	// frsp f3,f9
	ctx.f3.f64 = double(float(ctx.f9.f64));
	// frsp f4,f8
	ctx.f4.f64 = double(float(ctx.f8.f64));
	// frsp f2,f10
	ctx.f2.f64 = double(float(ctx.f10.f64));
	// bl 0x8222a560
	ctx.lr = 0x82129464;
	sub_8222A560(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82129470;
	sub_821112B0(ctx, base);
	// lis r7,-32182
	ctx.r7.s64 = -2109079552;
	// addi r3,r7,-27800
	ctx.r3.s64 = ctx.r7.s64 + -27800;
	// bl 0x8211f958
	ctx.lr = 0x8212947C;
	sub_8211F958(ctx, base);
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// lfd f30,-88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// lfd f31,-80(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212948C"))) PPC_WEAK_FUNC(sub_8212948C);
PPC_FUNC_IMPL(__imp__sub_8212948C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82129490"))) PPC_WEAK_FUNC(sub_82129490);
PPC_FUNC_IMPL(__imp__sub_82129490) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x82129498;
	__restfpr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// std r5,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, ctx.r5.u64);
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// lwz r27,0(r3)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r25,r8
	ctx.r25.u64 = ctx.r8.u64;
	// std r6,184(r1)
	PPC_STORE_U64(ctx.r1.u32 + 184, ctx.r6.u64);
	// mr r26,r9
	ctx.r26.u64 = ctx.r9.u64;
	// cmpwi cr6,r4,8
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 8, ctx.xer);
	// beq cr6,0x821296b4
	if (ctx.cr6.eq) goto loc_821296B4;
	// cmpwi cr6,r4,5
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 5, ctx.xer);
	// beq cr6,0x821296b4
	if (ctx.cr6.eq) goto loc_821296B4;
	// cmpwi cr6,r4,6
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 6, ctx.xer);
	// beq cr6,0x821296b4
	if (ctx.cr6.eq) goto loc_821296B4;
	// cmpwi cr6,r4,10
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 10, ctx.xer);
	// beq cr6,0x821296b4
	if (ctx.cr6.eq) goto loc_821296B4;
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f0,176(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r27,8
	ctx.r11.s64 = ctx.r27.s64 + 8;
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// rldicr r12,r12,59,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 59) & 0xFFFFFFFFFFFFFFFF;
	// lfs f11,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f11.f64 = double(temp.f32);
	// cmpwi cr6,r4,9
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 9, ctx.xer);
	// stfs f0,6288(r27)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + 6288, temp.u32);
	// stfs f13,6292(r27)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r27.u32 + 6292, temp.u32);
	// stfs f12,6296(r27)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + 6296, temp.u32);
	// stfs f11,6300(r27)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r27.u32 + 6300, temp.u32);
	// ld r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r27.u32 + 8);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,8(r27)
	PPC_STORE_U64(ctx.r27.u32 + 8, ctx.r10.u64);
	// beq cr6,0x821296b4
	if (ctx.cr6.eq) goto loc_821296B4;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r30,1
	ctx.r30.s64 = 1;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,6772(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 6772);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82129554
	if (ctx.cr6.eq) goto loc_82129554;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1512(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1512);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1512(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1512, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,1
	ctx.r6.u64 = ctx.r7.u64 | 65536;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,6772(r31)
	PPC_STORE_U32(ctx.r31.u32 + 6772, ctx.r10.u32);
loc_82129554:
	// lwz r11,6788(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 6788);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82129588
	if (ctx.cr6.eq) goto loc_82129588;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1512(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1512);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1512(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1512, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,1
	ctx.r6.u64 = ctx.r7.u64 | 65536;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,6788(r31)
	PPC_STORE_U32(ctx.r31.u32 + 6788, ctx.r10.u32);
loc_82129588:
	// lwz r11,6836(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 6836);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821295ac
	if (ctx.cr6.eq) goto loc_821295AC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,15
	ctx.r4.s64 = 15;
	// bl 0x8222c248
	ctx.lr = 0x821295A4;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,6836(r31)
	PPC_STORE_U32(ctx.r31.u32 + 6836, ctx.r30.u32);
loc_821295AC:
	// lwz r11,6852(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 6852);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821295d0
	if (ctx.cr6.eq) goto loc_821295D0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,15
	ctx.r4.s64 = 15;
	// bl 0x8222c0a0
	ctx.lr = 0x821295C8;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,6852(r31)
	PPC_STORE_U32(ctx.r31.u32 + 6852, ctx.r30.u32);
loc_821295D0:
	// lwz r11,6868(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 6868);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82129604
	if (ctx.cr6.eq) goto loc_82129604;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1524(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1524);
	// rlwimi r8,r30,24,7,8
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 24) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1524(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1524, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,1
	ctx.r6.u64 = ctx.r7.u64 | 65536;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,6868(r31)
	PPC_STORE_U32(ctx.r31.u32 + 6868, ctx.r10.u32);
loc_82129604:
	// lwz r11,6820(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 6820);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x82129638
	if (ctx.cr6.eq) goto loc_82129638;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1532(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1532);
	// rlwimi r8,r30,0,30,31
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 0) & 0x3) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r8,1532(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1532, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,1
	ctx.r6.u64 = ctx.r7.u64 | 65536;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,6820(r31)
	PPC_STORE_U32(ctx.r31.u32 + 6820, ctx.r10.u32);
loc_82129638:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x821296b4
	if (ctx.cr6.eq) goto loc_821296B4;
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r29,r26
	ctx.r29.u64 = ctx.r26.u64;
	// addi r31,r25,4
	ctx.r31.s64 = ctx.r25.s64 + 4;
	// rldicr r30,r11,63,63
	ctx.r30.u64 = rotl64(ctx.r11.u64, 63) & 0xFFFFFFFFFFFFFFFF;
loc_82129650:
	// lwz r4,-4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + -4);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// rlwinm r10,r4,30,2,31
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// lwz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// add r11,r4,r6
	ctx.r11.u64 = ctx.r4.u64 + ctx.r6.u64;
	// addi r9,r11,-1
	ctx.r9.s64 = ctx.r11.s64 + -1;
	// rlwinm r8,r9,30,2,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
	// subf r7,r10,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r10.s64;
	// clrldi r11,r7,32
	ctx.r11.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// srad r9,r30,r11
	temp.u64 = ctx.r11.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r30.s64 < 0) & (((ctx.r30.s64 >> temp.u64) << temp.u64) != ctx.r30.s64);
	ctx.r9.s64 = ctx.r30.s64 >> temp.u64;
	// srd r7,r9,r10
	ctx.r7.u64 = ctx.r10.u8 & 0x40 ? 0 : (ctx.r9.u64 >> (ctx.r10.u8 & 0x7F));
	// bl 0x82238120
	ctx.lr = 0x82129684;
	sub_82238120(ctx, base);
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x821296a4
	if (ctx.cr6.eq) goto loc_821296A4;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821296a4
	if (ctx.cr6.eq) goto loc_821296A4;
	// li r3,15
	ctx.r3.s64 = 15;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82111400
	ctx.lr = 0x821296A4;
	sub_82111400(ctx, base);
loc_821296A4:
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// addi r31,r31,12
	ctx.r31.s64 = ctx.r31.s64 + 12;
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// bne 0x82129650
	if (!ctx.cr0.eq) goto loc_82129650;
loc_821296B4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821296BC"))) PPC_WEAK_FUNC(sub_821296BC);
PPC_FUNC_IMPL(__imp__sub_821296BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821296C0"))) PPC_WEAK_FUNC(sub_821296C0);
PPC_FUNC_IMPL(__imp__sub_821296C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x821296C8;
	__restfpr_29(ctx, base);
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r6,32(r5)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r5.u32 + 32);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r29,0(r3)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82129868
	if (ctx.cr6.eq) goto loc_82129868;
	// lwz r10,156(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 156);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82129868
	if (ctx.cr6.eq) goto loc_82129868;
	// cmplwi cr6,r6,1
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 1, ctx.xer);
	// bne cr6,0x821297d8
	if (!ctx.cr6.eq) goto loc_821297D8;
	// lwz r11,52(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 52);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// li r5,64
	ctx.r5.s64 = 64;
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x82129710;
	sub_8233E4E0(ctx, base);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lfs f12,152(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f12.f64 = double(temp.f32);
	// addi r5,r31,92
	ctx.r5.s64 = ctx.r31.s64 + 92;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// lfs f11,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f10.f64 = double(temp.f32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f9,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f9.f64 = double(temp.f32);
	// addi r3,r1,272
	ctx.r3.s64 = ctx.r1.s64 + 272;
	// lfs f8,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f7.f64 = double(temp.f32);
	// lfs f0,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,36(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,124(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f0,92(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f13,140(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f6,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f3.f64 = double(temp.f32);
	// stfs f12,112(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f11,128(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f0,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f9,100(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f8,116(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f7,132(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stfs f6,88(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f5,104(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f4,120(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// stfs f3,136(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// bl 0x822578d8
	ctx.lr = 0x821297A0;
	sub_822578D8(ctx, base);
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// rlwinm r7,r8,0,30,30
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x821297c8
	if (ctx.cr6.eq) goto loc_821297C8;
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r10,80(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// lwz r9,84(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// stw r11,320(r1)
	PPC_STORE_U32(ctx.r1.u32 + 320, ctx.r11.u32);
	// stw r10,324(r1)
	PPC_STORE_U32(ctx.r1.u32 + 324, ctx.r10.u32);
	// stw r9,328(r1)
	PPC_STORE_U32(ctx.r1.u32 + 328, ctx.r9.u32);
loc_821297C8:
	// addi r3,r1,272
	ctx.r3.s64 = ctx.r1.s64 + 272;
	// bl 0x82113ab8
	ctx.lr = 0x821297D0;
	sub_82113AB8(ctx, base);
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
loc_821297D8:
	// addi r5,r30,52
	ctx.r5.s64 = ctx.r30.s64 + 52;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82129010
	ctx.lr = 0x821297E4;
	sub_82129010(ctx, base);
	// addi r4,r31,92
	ctx.r4.s64 = ctx.r31.s64 + 92;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// li r5,64
	ctx.r5.s64 = 64;
	// bl 0x8233e4e0
	ctx.lr = 0x821297F4;
	sub_8233E4E0(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// rlwinm r10,r11,0,30,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82129834
	if (ctx.cr6.eq) goto loc_82129834;
	// lfs f0,256(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,76(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,80(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	ctx.f10.f64 = double(temp.f32);
	// fadds f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// lfs f8,84(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// fadds f7,f10,f13
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// fadds f6,f8,f12
	ctx.f6.f64 = double(float(ctx.f8.f64 + ctx.f12.f64));
	// stfs f9,256(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stfs f7,260(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// stfs f6,264(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
loc_82129834:
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x82113ab8
	ctx.lr = 0x8212983C;
	sub_82113AB8(ctx, base);
	// lwz r10,44(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 44);
	// li r11,1
	ctx.r11.s64 = 1;
	// li r12,1
	ctx.r12.s64 = 1;
	// rlwimi r10,r11,16,0,23
	ctx.r10.u64 = (rotl32(ctx.r11.u32, 16) & 0xFFFFFF00) | (ctx.r10.u64 & 0xFFFFFFFF000000FF);
	// rldicr r12,r12,56,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// stw r10,10144(r29)
	PPC_STORE_U32(ctx.r29.u32 + 10144, ctx.r10.u32);
	// ld r9,32(r29)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r29.u32 + 32);
	// or r8,r9,r12
	ctx.r8.u64 = ctx.r9.u64 | ctx.r12.u64;
	// std r8,32(r29)
	PPC_STORE_U64(ctx.r29.u32 + 32, ctx.r8.u64);
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
loc_82129868:
	// addi r3,r31,92
	ctx.r3.s64 = ctx.r31.s64 + 92;
	// bl 0x82113ab8
	ctx.lr = 0x82129870;
	sub_82113AB8(ctx, base);
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82129878"))) PPC_WEAK_FUNC(sub_82129878);
PPC_FUNC_IMPL(__imp__sub_82129878) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x82129880;
	__restfpr_14(ctx, base);
	// stfd f29,-176(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -176, ctx.f29.u64);
	// stfd f30,-168(r1)
	PPC_STORE_U64(ctx.r1.u32 + -168, ctx.f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, ctx.f31.u64);
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// lwz r23,0(r3)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stw r4,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r4.u32);
	// mr r18,r5
	ctx.r18.u64 = ctx.r5.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r11.u32);
	// beq cr6,0x821298bc
	if (ctx.cr6.eq) goto loc_821298BC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r10.u32);
loc_821298BC:
	// mr r25,r11
	ctx.r25.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82129cd0
	if (ctx.cr6.eq) goto loc_82129CD0;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r8,r10,31376
	ctx.r8.s64 = ctx.r10.s64 + 31376;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// lis r11,-32171
	ctx.r11.s64 = -2108358656;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,1
	ctx.r6.s64 = 1;
	// lis r10,-32171
	ctx.r10.s64 = -2108358656;
	// lis r9,-32183
	ctx.r9.s64 = -2109145088;
	// lfs f31,48(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// lfs f29,36(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 36);
	ctx.f29.f64 = double(temp.f32);
	// rldicr r16,r7,56,63
	ctx.r16.u64 = rotl64(ctx.r7.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// li r14,7
	ctx.r14.s64 = 7;
	// li r15,8
	ctx.r15.s64 = 8;
	// rldicr r17,r6,60,63
	ctx.r17.u64 = rotl64(ctx.r6.u64, 60) & 0xFFFFFFFFFFFFFFFF;
	// lis r20,-32171
	ctx.r20.s64 = -2108358656;
	// addi r19,r11,10596
	ctx.r19.s64 = ctx.r11.s64 + 10596;
	// addi r22,r10,10580
	ctx.r22.s64 = ctx.r10.s64 + 10580;
	// addi r21,r9,28184
	ctx.r21.s64 = ctx.r9.s64 + 28184;
loc_82129914:
	// lwz r29,12(r25)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// lwz r31,0(r29)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// rlwinm r11,r31,0,27,27
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82129930
	if (ctx.cr6.eq) goto loc_82129930;
	// lfs f30,212(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 212);
	ctx.f30.f64 = double(temp.f32);
	// b 0x82129934
	goto loc_82129934;
loc_82129930:
	// lfs f30,208(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 208);
	ctx.f30.f64 = double(temp.f32);
loc_82129934:
	// lwz r11,320(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 320);
	// lwz r27,16(r25)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r25.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82129998
	if (ctx.cr6.eq) goto loc_82129998;
	// lfs f0,64(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f0.f64 = double(temp.f32);
	// li r7,1
	ctx.r7.s64 = 1;
	// lfs f13,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f13.f64 = double(temp.f32);
	// li r6,2
	ctx.r6.s64 = 2;
	// lfs f12,72(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 72);
	ctx.f12.f64 = double(temp.f32);
	// rldicr r7,r7,38,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 38) & 0xFFFFFFFFFFFFFFFF;
	// lfs f11,76(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 76);
	ctx.f11.f64 = double(temp.f32);
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lfs f10,80(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	ctx.f10.f64 = double(temp.f32);
	// li r4,101
	ctx.r4.s64 = 101;
	// lfs f9,84(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 84);
	ctx.f9.f64 = double(temp.f32);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// stfs f0,128(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f13,132(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stfs f31,140(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// stfs f12,136(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f31,156(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// stfs f11,144(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f10,148(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f9,152(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// bl 0x82238120
	ctx.lr = 0x82129998;
	sub_82238120(ctx, base);
loc_82129998:
	// lwz r4,288(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 288);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x821299ac
	if (ctx.cr6.eq) goto loc_821299AC;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8212a5c8
	ctx.lr = 0x821299AC;
	sub_8212A5C8(ctx, base);
loc_821299AC:
	// lwz r4,292(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 292);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x821299c0
	if (ctx.cr6.eq) goto loc_821299C0;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8212a4c8
	ctx.lr = 0x821299C0;
	sub_8212A4C8(ctx, base);
loc_821299C0:
	// addi r9,r29,184
	ctx.r9.s64 = ctx.r29.s64 + 184;
	// lwz r8,176(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 176);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r7,180(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 180);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// ld r5,160(r29)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r29.u32 + 160);
	// ld r6,168(r29)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r29.u32 + 168);
	// bl 0x82129490
	ctx.lr = 0x821299E0;
	sub_82129490(ctx, base);
	// rlwinm r11,r31,0,21,21
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x400;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// beq cr6,0x82129a20
	if (ctx.cr6.eq) goto loc_82129A20;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x82129a4c
	if (ctx.cr6.eq) goto loc_82129A4C;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r10,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r10.u32);
	// lwz r9,10128(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 10128);
	// ori r8,r9,256
	ctx.r8.u64 = ctx.r9.u64 | 256;
	// stw r8,10128(r11)
	PPC_STORE_U32(ctx.r11.u32 + 10128, ctx.r8.u32);
	// ld r7,32(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 32);
	// or r6,r7,r16
	ctx.r6.u64 = ctx.r7.u64 | ctx.r16.u64;
	// std r6,32(r11)
	PPC_STORE_U64(ctx.r11.u32 + 32, ctx.r6.u64);
	// b 0x82129a4c
	goto loc_82129A4C;
loc_82129A20:
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82129a4c
	if (ctx.cr6.eq) goto loc_82129A4C;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// stw r11,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r11.u32);
	// lwz r9,10128(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 10128);
	// rlwinm r8,r9,0,24,22
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// stw r8,10128(r10)
	PPC_STORE_U32(ctx.r10.u32 + 10128, ctx.r8.u32);
	// ld r7,32(r10)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r10.u32 + 32);
	// or r6,r7,r16
	ctx.r6.u64 = ctx.r7.u64 | ctx.r16.u64;
	// std r6,32(r10)
	PPC_STORE_U64(ctx.r10.u32 + 32, ctx.r6.u64);
loc_82129A4C:
	// lbz r9,10(r29)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r29.u32 + 10);
	// lbz r10,11(r29)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r29.u32 + 11);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82129a6c
	if (!ctx.cr6.eq) goto loc_82129A6C;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,0
	ctx.r11.s64 = 0;
	// beq cr6,0x82129a70
	if (ctx.cr6.eq) goto loc_82129A70;
loc_82129A6C:
	// li r11,1
	ctx.r11.s64 = 1;
loc_82129A70:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// mr r24,r11
	ctx.r24.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82129aec
	if (ctx.cr6.eq) goto loc_82129AEC;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// lwz r10,1204(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 1204);
	// addic r8,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r8.s64 = ctx.r11.s64 + -1;
	// subfe r6,r7,r7
	temp.u8 = (~ctx.r7.u32 + ctx.r7.u32 < ~ctx.r7.u32) | (~ctx.r7.u32 + ctx.r7.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r6.u64 = ~ctx.r7.u64 + ctx.r7.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// subfic r5,r9,0
	ctx.xer.ca = ctx.r9.u32 <= 0;
	ctx.r5.s64 = 0 - ctx.r9.s64;
	// and r3,r6,r14
	ctx.r3.u64 = ctx.r6.u64 & ctx.r14.u64;
	// subfe r11,r4,r4
	temp.u8 = (~ctx.r4.u32 + ctx.r4.u32 < ~ctx.r4.u32) | (~ctx.r4.u32 + ctx.r4.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r4.u64 + ctx.r4.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r9,r11,r15
	ctx.r9.u64 = ctx.r11.u64 & ctx.r15.u64;
	// or r11,r3,r9
	ctx.r11.u64 = ctx.r3.u64 | ctx.r9.u64;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82129aec
	if (ctx.cr6.eq) goto loc_82129AEC;
	// lwz r10,0(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// li r12,1
	ctx.r12.s64 = 1;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// rldicr r12,r12,37,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 37) & 0xFFFFFFFFFFFFFFFF;
	// lwz r8,12792(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12792);
	// lwz r7,10460(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 10460);
	// subfic r6,r8,0
	ctx.xer.ca = ctx.r8.u32 <= 0;
	ctx.r6.s64 = 0 - ctx.r8.s64;
	// stw r11,12268(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12268, ctx.r11.u32);
	// subfe r4,r5,r5
	temp.u8 = (~ctx.r5.u32 + ctx.r5.u32 < ~ctx.r5.u32) | (~ctx.r5.u32 + ctx.r5.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r4.u64 = ~ctx.r5.u64 + ctx.r5.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r3,r4,r11
	ctx.r3.u64 = ctx.r4.u64 & ctx.r11.u64;
	// rlwimi r3,r7,0,0,27
	ctx.r3.u64 = (rotl32(ctx.r7.u32, 0) & 0xFFFFFFF0) | (ctx.r3.u64 & 0xFFFFFFFF0000000F);
	// stw r3,10460(r10)
	PPC_STORE_U32(ctx.r10.u32 + 10460, ctx.r3.u32);
	// ld r10,16(r10)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r10.u32 + 16);
	// or r8,r10,r12
	ctx.r8.u64 = ctx.r10.u64 | ctx.r12.u64;
	// std r8,16(r9)
	PPC_STORE_U64(ctx.r9.u32 + 16, ctx.r8.u64);
	// stw r11,1204(r21)
	PPC_STORE_U32(ctx.r21.u32 + 1204, ctx.r11.u32);
loc_82129AEC:
	// lbz r28,8(r29)
	ctx.r28.u64 = PPC_LOAD_U8(ctx.r29.u32 + 8);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82129b24
	if (ctx.cr6.eq) goto loc_82129B24;
	// lfs f0,12(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6240(r23)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + 6240, temp.u32);
	// lfs f13,16(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,6244(r23)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r23.u32 + 6244, temp.u32);
	// lfs f12,20(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,6248(r23)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r23.u32 + 6248, temp.u32);
	// lfs f11,24(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,6252(r23)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r23.u32 + 6252, temp.u32);
	// ld r11,8(r23)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r23.u32 + 8);
	// or r10,r11,r17
	ctx.r10.u64 = ctx.r11.u64 | ctx.r17.u64;
	// std r10,8(r23)
	PPC_STORE_U64(ctx.r23.u32 + 8, ctx.r10.u64);
loc_82129B24:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f30.f64;
	// bl 0x8212a650
	ctx.lr = 0x82129B30;
	sub_8212A650(ctx, base);
	// lwz r31,24(r25)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r25.u32 + 24);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82129b74
	if (ctx.cr6.eq) goto loc_82129B74;
	// rlwinm r30,r31,2,0,29
	ctx.r30.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
loc_82129B40:
	// lwz r11,20(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 20);
	// addi r30,r30,-4
	ctx.r30.s64 = ctx.r30.s64 + -4;
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// lwz r8,284(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 284);
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lwzx r4,r11,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// addi r31,r31,-1
	ctx.r31.s64 = ctx.r31.s64 + -1;
	// bl 0x82129ce8
	ctx.lr = 0x82129B68;
	sub_82129CE8(ctx, base);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x82129b40
	if (!ctx.cr6.eq) goto loc_82129B40;
	// lwz r30,80(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82129B74:
	// lwz r11,10576(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 10576);
	// clrlwi r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82129ba4
	if (!ctx.cr6.eq) goto loc_82129BA4;
	// ori r11,r11,1
	ctx.r11.u64 = ctx.r11.u64 | 1;
	// stfs f31,0(r22)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r22.u32 + 0, temp.u32);
	// stfs f31,4(r22)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r22.u32 + 4, temp.u32);
	// fmr f0,f31
	ctx.f0.f64 = ctx.f31.f64;
	// stfs f31,8(r22)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r22.u32 + 8, temp.u32);
	// stw r11,10576(r20)
	PPC_STORE_U32(ctx.r20.u32 + 10576, ctx.r11.u32);
	// stfs f31,12(r22)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r22.u32 + 12, temp.u32);
	// b 0x82129ba8
	goto loc_82129BA8;
loc_82129BA4:
	// lfs f0,0(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
loc_82129BA8:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82129bd8
	if (ctx.cr6.eq) goto loc_82129BD8;
	// stfs f0,6240(r23)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + 6240, temp.u32);
	// lfs f0,4(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6244(r23)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + 6244, temp.u32);
	// lfs f0,8(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6248(r23)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + 6248, temp.u32);
	// lfs f0,12(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 12);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6252(r23)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r23.u32 + 6252, temp.u32);
	// ld r10,8(r23)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r23.u32 + 8);
	// or r9,r10,r17
	ctx.r9.u64 = ctx.r10.u64 | ctx.r17.u64;
	// std r9,8(r23)
	PPC_STORE_U64(ctx.r23.u32 + 8, ctx.r9.u64);
loc_82129BD8:
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82129bf0
	if (ctx.cr6.eq) goto loc_82129BF0;
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82129BEC;
	sub_82111340(ctx, base);
	// lwz r11,10576(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 10576);
loc_82129BF0:
	// rlwinm r10,r11,0,30,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82129c10
	if (!ctx.cr6.eq) goto loc_82129C10;
	// ori r11,r11,2
	ctx.r11.u64 = ctx.r11.u64 | 2;
	// stfs f31,0(r19)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r19.u32 + 0, temp.u32);
	// stfs f31,4(r19)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r19.u32 + 4, temp.u32);
	// stfs f31,8(r19)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r19.u32 + 8, temp.u32);
	// stw r11,10576(r20)
	PPC_STORE_U32(ctx.r20.u32 + 10576, ctx.r11.u32);
loc_82129C10:
	// lwz r11,288(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 288);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82129c28
	if (ctx.cr6.eq) goto loc_82129C28;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8212a5c8
	ctx.lr = 0x82129C28;
	sub_8212A5C8(ctx, base);
loc_82129C28:
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82129c50
	if (ctx.cr6.eq) goto loc_82129C50;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r11,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r11.u32);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// li r4,8
	ctx.r4.s64 = 8;
	// bl 0x822381f8
	ctx.lr = 0x82129C50;
	sub_822381F8(ctx, base);
loc_82129C50:
	// lwz r11,320(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 320);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82129cb0
	if (ctx.cr6.eq) goto loc_82129CB0;
	// lis r11,-32226
	ctx.r11.s64 = -2111963136;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r6,r11,-21912
	ctx.r6.s64 = ctx.r11.s64 + -21912;
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x820867a0
	ctx.lr = 0x82129C74;
	sub_820867A0(ctx, base);
	// stfs f29,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f31,100(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// li r7,1
	ctx.r7.s64 = 1;
	// stfs f31,104(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// li r6,2
	ctx.r6.s64 = 2;
	// stfs f31,108(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// rldicr r7,r7,38,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 38) & 0xFFFFFFFFFFFFFFFF;
	// stfs f31,112(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// stfs f29,116(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// li r4,101
	ctx.r4.s64 = 101;
	// stfs f31,120(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// stfs f31,124(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// bl 0x82238120
	ctx.lr = 0x82129CB0;
	sub_82238120(ctx, base);
loc_82129CB0:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82129cc4
	if (ctx.cr6.eq) goto loc_82129CC4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r10.u32);
loc_82129CC4:
	// mr r25,r11
	ctx.r25.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82129914
	if (!ctx.cr6.eq) goto loc_82129914;
loc_82129CD0:
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// lfd f29,-176(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -176);
	// lfd f30,-168(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82129CE4"))) PPC_WEAK_FUNC(sub_82129CE4);
PPC_FUNC_IMPL(__imp__sub_82129CE4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82129CE8"))) PPC_WEAK_FUNC(sub_82129CE8);
PPC_FUNC_IMPL(__imp__sub_82129CE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x82129CF0;
	__restfpr_14(ctx, base);
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, ctx.f31.u64);
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,276(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 276);
	// mr r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	// mr r18,r4
	ctx.r18.u64 = ctx.r4.u64;
	// stw r7,404(r1)
	PPC_STORE_U32(ctx.r1.u32 + 404, ctx.r7.u32);
	// mr r19,r5
	ctx.r19.u64 = ctx.r5.u64;
	// mr r23,r6
	ctx.r23.u64 = ctx.r6.u64;
	// mr r24,r7
	ctx.r24.u64 = ctx.r7.u64;
	// mr r28,r8
	ctx.r28.u64 = ctx.r8.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212a0c8
	if (ctx.cr6.eq) goto loc_8212A0C8;
	// lwz r27,12(r4)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// lwz r9,12(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// rlwinm r11,r9,0,27,27
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212a0c8
	if (!ctx.cr6.eq) goto loc_8212A0C8;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// lfs f31,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f31.f64 = double(temp.f32);
	// addi r31,r11,-27800
	ctx.r31.s64 = ctx.r11.s64 + -27800;
	// lwz r11,2120(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2120);
	// rlwinm r10,r11,20,31,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 20) & 0x1;
	// rlwinm r8,r11,30,31,31
	ctx.r8.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x1;
	// rlwinm r7,r11,24,31,31
	ctx.r7.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0x1;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// stb r8,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r8.u8);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stb r7,82(r1)
	PPC_STORE_U8(ctx.r1.u32 + 82, ctx.r7.u8);
	// beq cr6,0x82129d74
	if (ctx.cr6.eq) goto loc_82129D74;
	// rlwinm r11,r9,0,20,20
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x800;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212a0c8
	if (ctx.cr6.eq) goto loc_8212A0C8;
loc_82129D74:
	// lbz r11,28(r18)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r18.u32 + 28);
	// li r29,11
	ctx.r29.s64 = 11;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82129e08
	if (ctx.cr6.eq) goto loc_82129E08;
	// lwz r11,2116(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2116);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bge cr6,0x82129e08
	if (!ctx.cr6.lt) goto loc_82129E08;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r10,r11,27648
	ctx.r10.s64 = ctx.r11.s64 + 27648;
	// lwz r30,36(r10)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82129dac
	if (ctx.cr6.eq) goto loc_82129DAC;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8222f080
	ctx.lr = 0x82129DAC;
	sub_8222F080(ctx, base);
loc_82129DAC:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82237900
	ctx.lr = 0x82129DB8;
	sub_82237900(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x82129DC0;
	sub_8222F0F8(ctx, base);
	// lis r11,6688
	ctx.r11.s64 = 438304768;
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lis r9,-32250
	ctx.r9.s64 = -2113536000;
	// ori r8,r11,43861
	ctx.r8.u64 = ctx.r11.u64 | 43861;
	// addi r6,r9,31376
	ctx.r6.s64 = ctx.r9.s64 + 31376;
	// subf r5,r10,r8
	ctx.r5.s64 = ctx.r8.s64 - ctx.r10.s64;
	// li r8,0
	ctx.r8.s64 = 0;
	// addic r4,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r4.s64 = ctx.r5.s64 + -1;
	// li r7,0
	ctx.r7.s64 = 0;
	// subfe r10,r3,r3
	temp.u8 = (~ctx.r3.u32 + ctx.r3.u32 < ~ctx.r3.u32) | (~ctx.r3.u32 + ctx.r3.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r10.u64 = ~ctx.r3.u64 + ctx.r3.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// lfs f1,36(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// li r6,0
	ctx.r6.s64 = 0;
	// and r9,r10,r29
	ctx.r9.u64 = ctx.r10.u64 & ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// rlwinm r3,r9,26,0,5
	ctx.r3.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0xFC000000;
	// lwz r11,2140(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2140);
	// addi r5,r11,120
	ctx.r5.s64 = ctx.r11.s64 + 120;
	// bl 0x8210af50
	ctx.lr = 0x82129E08;
	sub_8210AF50(ctx, base);
loc_82129E08:
	// lwz r11,280(r18)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r18.u32 + 280);
	// li r15,0
	ctx.r15.s64 = 0;
	// lwz r9,16(r18)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r18.u32 + 16);
	// addi r8,r31,2120
	ctx.r8.s64 = ctx.r31.s64 + 2120;
	// rlwinm r7,r11,0,27,27
	ctx.r7.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// lwz r6,32(r18)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r18.u32 + 32);
	// lwz r4,20(r18)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r18.u32 + 20);
	// addi r10,r18,156
	ctx.r10.s64 = ctx.r18.s64 + 156;
	// cntlzw r3,r7
	ctx.r3.u64 = ctx.r7.u32 == 0 ? 32 : __builtin_clz(ctx.r7.u32);
	// lwz r7,24(r18)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r18.u32 + 24);
	// lbz r30,9(r23)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r23.u32 + 9);
	// addi r26,r18,36
	ctx.r26.s64 = ctx.r18.s64 + 36;
	// rlwinm r3,r3,27,31,31
	ctx.r3.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 27) & 0x1;
	// lwz r5,324(r23)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r23.u32 + 324);
	// stfs f31,152(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// stw r9,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r9.u32);
	// xori r11,r3,1
	ctx.r11.u64 = ctx.r3.u64 ^ 1;
	// stw r6,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r6.u32);
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// stw r4,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r4.u32);
	// stw r7,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r7.u32);
	// addi r31,r11,1
	ctx.r31.s64 = ctx.r11.s64 + 1;
	// stw r26,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r26.u32);
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// stb r30,156(r1)
	PPC_STORE_U8(ctx.r1.u32 + 156, ctx.r30.u8);
	// stw r29,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r29.u32);
	// stb r15,157(r1)
	PPC_STORE_U8(ctx.r1.u32 + 157, ctx.r15.u8);
	// stw r15,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r15.u32);
	// stw r8,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r8.u32);
	// stw r28,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r28.u32);
	// beq cr6,0x82129e9c
	if (ctx.cr6.eq) goto loc_82129E9C;
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r3,0(r20)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	// li r6,4
	ctx.r6.s64 = 4;
	// rldicr r7,r7,37,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 37) & 0xFFFFFFFFFFFFFFFF;
	// li r4,104
	ctx.r4.s64 = 104;
	// bl 0x82238120
	ctx.lr = 0x82129E9C;
	sub_82238120(ctx, base);
loc_82129E9C:
	// cmpwi cr6,r24,0
	ctx.cr6.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// ble cr6,0x82129eac
	if (!ctx.cr6.gt) goto loc_82129EAC;
	// cmpwi cr6,r24,3
	ctx.cr6.compare<int32_t>(ctx.r24.s32, 3, ctx.xer);
	// ble cr6,0x82129eb8
	if (!ctx.cr6.gt) goto loc_82129EB8;
loc_82129EAC:
	// cmpwi cr6,r24,9
	ctx.cr6.compare<int32_t>(ctx.r24.s32, 9, ctx.xer);
	// mr r11,r15
	ctx.r11.u64 = ctx.r15.u64;
	// bne cr6,0x82129ebc
	if (!ctx.cr6.eq) goto loc_82129EBC;
loc_82129EB8:
	// li r11,1
	ctx.r11.s64 = 1;
loc_82129EBC:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// stb r11,81(r1)
	PPC_STORE_U8(ctx.r1.u32 + 81, ctx.r11.u8);
	// beq cr6,0x8212a0c8
	if (ctx.cr6.eq) goto loc_8212A0C8;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r16,r1,96
	ctx.r16.s64 = ctx.r1.s64 + 96;
	// mr r14,r31
	ctx.r14.u64 = ctx.r31.u64;
	// addi r25,r11,28184
	ctx.r25.s64 = ctx.r11.s64 + 28184;
	// b 0x82129ee0
	goto loc_82129EE0;
loc_82129EDC:
	// lwz r24,404(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 404);
loc_82129EE0:
	// lwz r17,0(r16)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	// addi r11,r18,156
	ctx.r11.s64 = ctx.r18.s64 + 156;
	// subf r11,r17,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r17.s64;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82129f24
	if (ctx.cr6.eq) goto loc_82129F24;
	// lbz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82129f24
	if (!ctx.cr6.eq) goto loc_82129F24;
	// lwz r11,280(r18)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r18.u32 + 280);
	// clrlwi r9,r11,31
	ctx.r9.u64 = ctx.r11.u32 & 0x1;
	// subfic r8,r9,0
	ctx.xer.ca = ctx.r9.u32 <= 0;
	ctx.r8.s64 = 0 - ctx.r9.s64;
	// subfe r7,r8,r8
	temp.u8 = (~ctx.r8.u32 + ctx.r8.u32 < ~ctx.r8.u32) | (~ctx.r8.u32 + ctx.r8.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r7.u64 = ~ctx.r8.u64 + ctx.r8.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r7,0,29,29
	ctx.r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x4;
	// addi r24,r11,6
	ctx.r24.s64 = ctx.r11.s64 + 6;
	// b 0x82129f48
	goto loc_82129F48;
loc_82129F24:
	// lwz r11,12(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// not r9,r11
	ctx.r9.u64 = ~ctx.r11.u64;
	// rlwinm r8,r9,27,31,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82129f48
	if (!ctx.cr6.eq) goto loc_82129F48;
	// lbz r9,81(r1)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r1.u32 + 81);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82129f48
	if (ctx.cr6.eq) goto loc_82129F48;
	// mr r24,r15
	ctx.r24.u64 = ctx.r15.u64;
loc_82129F48:
	// stw r24,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r24.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// stb r10,157(r1)
	PPC_STORE_U8(ctx.r1.u32 + 157, ctx.r10.u8);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8210f908
	ctx.lr = 0x82129F5C;
	sub_8210F908(ctx, base);
	// mr r21,r3
	ctx.r21.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8210fb60
	ctx.lr = 0x82129F68;
	sub_8210FB60(ctx, base);
	// mr r26,r15
	ctx.r26.u64 = ctx.r15.u64;
	// mr r22,r15
	ctx.r22.u64 = ctx.r15.u64;
loc_82129F70:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212a0ac
	if (ctx.cr6.eq) goto loc_8212A0AC;
	// add r11,r17,r22
	ctx.r11.u64 = ctx.r17.u64 + ctx.r22.u64;
	// addi r28,r11,12
	ctx.r28.s64 = ctx.r11.s64 + 12;
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82129fa0
	if (!ctx.cr6.eq) goto loc_82129FA0;
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// beq cr6,0x82129fa4
	if (ctx.cr6.eq) goto loc_82129FA4;
loc_82129FA0:
	// mr r11,r15
	ctx.r11.u64 = ctx.r15.u64;
loc_82129FA4:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212a09c
	if (!ctx.cr6.eq) goto loc_8212A09C;
	// lbz r10,82(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 82);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212a058
	if (ctx.cr6.eq) goto loc_8212A058;
	// lwz r11,12(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// rlwinm r10,r11,18,31,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82129fd8
	if (!ctx.cr6.eq) goto loc_82129FD8;
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212a064
	if (ctx.cr6.eq) goto loc_8212A064;
loc_82129FD8:
	// li r5,5
	ctx.r5.s64 = 5;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82110610
	ctx.lr = 0x82129FE8;
	sub_82110610(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,212
	ctx.r3.s64 = 212;
	// lwz r31,516(r25)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r25.u32 + 516);
	// lwz r30,548(r25)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r25.u32 + 548);
	// lwz r29,1204(r25)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r25.u32 + 1204);
	// bl 0x82111340
	ctx.lr = 0x8212A000;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82111340
	ctx.lr = 0x8212A00C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x82111340
	ctx.lr = 0x8212A018;
	sub_82111340(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r23
	ctx.r7.u64 = ctx.r23.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r19
	ctx.r5.u64 = ctx.r19.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x8212a0d8
	ctx.lr = 0x8212A034;
	sub_8212A0D8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x82111340
	ctx.lr = 0x8212A040;
	sub_82111340(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82111340
	ctx.lr = 0x8212A04C;
	sub_82111340(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212A058;
	sub_82111340(ctx, base);
loc_8212A058:
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212a090
	if (!ctx.cr6.eq) goto loc_8212A090;
loc_8212A064:
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82110610
	ctx.lr = 0x8212A074;
	sub_82110610(ctx, base);
	// mr r8,r21
	ctx.r8.u64 = ctx.r21.u64;
	// mr r7,r23
	ctx.r7.u64 = ctx.r23.u64;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r19
	ctx.r5.u64 = ctx.r19.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x8212a0d8
	ctx.lr = 0x8212A090;
	sub_8212A0D8(ctx, base);
loc_8212A090:
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
loc_8212A09C:
	// addi r22,r22,24
	ctx.r22.s64 = ctx.r22.s64 + 24;
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// cmplwi cr6,r22,120
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 120, ctx.xer);
	// blt cr6,0x82129f70
	if (ctx.cr6.lt) goto loc_82129F70;
loc_8212A0AC:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82110080
	ctx.lr = 0x8212A0B4;
	sub_82110080(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x821104c8
	ctx.lr = 0x8212A0BC;
	sub_821104C8(ctx, base);
	// addic. r14,r14,-1
	ctx.xer.ca = ctx.r14.u32 > 0;
	ctx.r14.s64 = ctx.r14.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r14.s32, 0, ctx.xer);
	// addi r16,r16,4
	ctx.r16.s64 = ctx.r16.s64 + 4;
	// bne 0x82129edc
	if (!ctx.cr0.eq) goto loc_82129EDC;
loc_8212A0C8:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212A0D4"))) PPC_WEAK_FUNC(sub_8212A0D4);
PPC_FUNC_IMPL(__imp__sub_8212A0D4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212A0D8"))) PPC_WEAK_FUNC(sub_8212A0D8);
PPC_FUNC_IMPL(__imp__sub_8212A0D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x8212A0E0;
	__restfpr_14(ctx, base);
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, ctx.f31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,0(r4)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r16,r4
	ctx.r16.u64 = ctx.r4.u64;
	// stw r5,292(r1)
	PPC_STORE_U32(ctx.r1.u32 + 292, ctx.r5.u32);
	// mr r17,r6
	ctx.r17.u64 = ctx.r6.u64;
	// mr r26,r7
	ctx.r26.u64 = ctx.r7.u64;
	// mr r19,r8
	ctx.r19.u64 = ctx.r8.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// stw r30,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r30.u32);
	// beq cr6,0x8212a4bc
	if (ctx.cr6.eq) goto loc_8212A4BC;
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r14,80(r1)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// lwz r15,88(r1)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// li r24,0
	ctx.r24.s64 = 0;
	// rldicr r20,r8,59,63
	ctx.r20.u64 = rotl64(ctx.r8.u64, 59) & 0xFFFFFFFFFFFFFFFF;
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r11.u32);
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// lis r23,16384
	ctx.r23.s64 = 1073741824;
	// lfs f31,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// li r21,-1
	ctx.r21.s64 = -1;
	// addi r18,r11,-29592
	ctx.r18.s64 = ctx.r11.s64 + -29592;
loc_8212A14C:
	// lwz r29,12(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,292(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r7,8(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// lwz r6,4(r29)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// bl 0x8222cc48
	ctx.lr = 0x8212A16C;
	sub_8222CC48(ctx, base);
	// lbz r27,20(r30)
	ctx.r27.u64 = PPC_LOAD_U8(ctx.r30.u32 + 20);
	// lwz r28,16(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// lbz r30,21(r30)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r30.u32 + 21);
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x8212a1a4
	if (ctx.cr6.eq) goto loc_8212A1A4;
	// lwz r11,300(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 300);
	// rlwinm r10,r28,2,0,29
	ctx.r10.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r5,296(r26)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r26.u32 + 296);
	// li r7,12
	ctx.r7.s64 = 12;
	// lwz r3,0(r22)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwzx r6,r11,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// bl 0x8222cc48
	ctx.lr = 0x8212A1A4;
	sub_8222CC48(ctx, base);
loc_8212A1A4:
	// clrlwi r25,r30,24
	ctx.r25.u64 = ctx.r30.u32 & 0xFF;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x8212a220
	if (ctx.cr6.eq) goto loc_8212A220;
	// lwz r11,316(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 316);
	// rlwinm r10,r28,2,0,29
	ctx.r10.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,312(r26)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r26.u32 + 312);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r5,308(r26)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r26.u32 + 308);
	// lwz r3,0(r22)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// lwzx r7,r11,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// lwzx r6,r9,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// bl 0x8222cc48
	ctx.lr = 0x8212A1D8;
	sub_8222CC48(ctx, base);
	// lfs f0,216(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 216);
	ctx.f0.f64 = double(temp.f32);
	// li r7,3
	ctx.r7.s64 = 3;
	// stfs f0,2176(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2176, temp.u32);
	// li r6,3
	ctx.r6.s64 = 3;
	// lfs f13,220(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 220);
	ctx.f13.f64 = double(temp.f32);
	// rldicr r7,r7,47,16
	ctx.r7.u64 = rotl64(ctx.r7.u64, 47) & 0xFFFF800000000000;
	// stfs f13,2180(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2180, temp.u32);
	// addi r5,r26,220
	ctx.r5.s64 = ctx.r26.s64 + 220;
	// lfs f12,224(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 224);
	ctx.f12.f64 = double(temp.f32);
	// li r4,62
	ctx.r4.s64 = 62;
	// stfs f12,2184(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2184, temp.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lfs f11,228(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 228);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,2188(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2188, temp.u32);
	// ld r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r11,r8,r20
	ctx.r11.u64 = ctx.r8.u64 | ctx.r20.u64;
	// std r11,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r11.u64);
	// bl 0x82238048
	ctx.lr = 0x8212A220;
	sub_82238048(ctx, base);
loc_8212A220:
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x821296c0
	ctx.lr = 0x8212A230;
	sub_821296C0(ctx, base);
	// mr r30,r24
	ctx.r30.u64 = ctx.r24.u64;
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x8212a26c
	if (ctx.cr6.eq) goto loc_8212A26C;
loc_8212A23C:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x821103d0
	ctx.lr = 0x8212A248;
	sub_821103D0(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,6
	ctx.r4.s64 = 6;
	// lwz r7,24(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r6,20(r29)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// bl 0x8222e3e0
	ctx.lr = 0x8212A260;
	sub_8222E3E0(ctx, base);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// cmplw cr6,r30,r19
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r19.u32, ctx.xer);
	// blt cr6,0x8212a23c
	if (ctx.cr6.lt) goto loc_8212A23C;
loc_8212A26C:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x8212a374
	if (ctx.cr6.eq) goto loc_8212A374;
	// lwz r29,12816(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12816);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8212a36c
	if (ctx.cr6.eq) goto loc_8212A36C;
	// lwz r11,11036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212a294
	if (ctx.cr6.eq) goto loc_8212A294;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// b 0x8212a36c
	goto loc_8212A36C;
loc_8212A294:
	// lwz r11,11040(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11040);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// and r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 & ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8212a36c
	if (ctx.cr6.eq) goto loc_8212A36C;
	// lwz r11,13912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13912);
	// lwz r10,13916(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13916);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x8212a34c
	if (ctx.cr6.lt) goto loc_8212A34C;
	// li r5,128
	ctx.r5.s64 = 128;
	// lwz r30,13908(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13908);
	// li r4,502
	ctx.r4.s64 = 502;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82230228
	ctx.lr = 0x8212A2CC;
	sub_82230228(ctx, base);
	// lbz r11,11069(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 11069);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212a2e8
	if (ctx.cr6.eq) goto loc_8212A2E8;
	// lwz r8,17120(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 17120);
	// b 0x8212a33c
	goto loc_8212A33C;
loc_8212A2E8:
	// rlwinm r11,r8,12,20,31
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 12) & 0xFFF;
	// stw r8,13908(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13908, ctx.r8.u32);
	// clrlwi r10,r8,3
	ctx.r10.u64 = ctx.r8.u32 & 0x1FFFFFFF;
	// stw r24,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r24.u32);
	// addi r11,r11,512
	ctx.r11.s64 = ctx.r11.s64 + 512;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// subf r3,r23,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r23.s64;
	// bne cr6,0x8212a31c
	if (!ctx.cr6.eq) goto loc_8212A31C;
	// lwz r11,13904(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13904);
	// stw r3,112(r11)
	PPC_STORE_U32(ctx.r11.u32 + 112, ctx.r3.u32);
	// b 0x8212a334
	goto loc_8212A334;
loc_8212A31C:
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// lwz r11,13912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13912);
	// subf r11,r30,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r30.s64;
	// addi r10,r11,-8
	ctx.r10.s64 = ctx.r11.s64 + -8;
	// srawi r9,r10,3
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 3;
	// stw r9,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r9.u32);
loc_8212A334:
	// addi r4,r3,2008
	ctx.r4.s64 = ctx.r3.s64 + 2008;
	// bl 0x8223b9b8
	ctx.lr = 0x8212A33C;
	sub_8223B9B8(ctx, base);
loc_8212A33C:
	// addi r11,r8,8
	ctx.r11.s64 = ctx.r8.s64 + 8;
	// addi r10,r8,2008
	ctx.r10.s64 = ctx.r8.s64 + 2008;
	// stw r11,13912(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13912, ctx.r11.u32);
	// stw r10,13916(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13916, ctx.r10.u32);
loc_8212A34C:
	// rlwimi r14,r29,30,2,31
	ctx.r14.u64 = (rotl32(ctx.r29.u32, 30) & 0x3FFFFFFF) | (ctx.r14.u64 & 0xFFFFFFFFC0000000);
	// stw r21,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r21.u32);
	// addi r10,r11,8
	ctx.r10.s64 = ctx.r11.s64 + 8;
	// rlwinm r14,r14,0,2,0
	ctx.r14.u64 = rotl64(ctx.r14.u32 | (ctx.r14.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r14,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r14.u32);
	// ld r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r9,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r9.u64);
	// stw r10,13912(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13912, ctx.r10.u32);
loc_8212A36C:
	// stw r24,12816(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12816, ctx.r24.u32);
	// stb r24,12881(r31)
	PPC_STORE_U8(ctx.r31.u32 + 12881, ctx.r24.u8);
loc_8212A374:
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x8212a4a4
	if (ctx.cr6.eq) goto loc_8212A4A4;
	// lwz r29,12820(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12820);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8212a474
	if (ctx.cr6.eq) goto loc_8212A474;
	// lwz r11,11036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212a39c
	if (ctx.cr6.eq) goto loc_8212A39C;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// b 0x8212a474
	goto loc_8212A474;
loc_8212A39C:
	// lwz r11,11040(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11040);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// and r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 & ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8212a474
	if (ctx.cr6.eq) goto loc_8212A474;
	// lwz r11,13912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13912);
	// lwz r10,13916(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13916);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x8212a454
	if (ctx.cr6.lt) goto loc_8212A454;
	// li r5,128
	ctx.r5.s64 = 128;
	// lwz r30,13908(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13908);
	// li r4,502
	ctx.r4.s64 = 502;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82230228
	ctx.lr = 0x8212A3D4;
	sub_82230228(ctx, base);
	// lbz r11,11069(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 11069);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212a3f0
	if (ctx.cr6.eq) goto loc_8212A3F0;
	// lwz r8,17120(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 17120);
	// b 0x8212a444
	goto loc_8212A444;
loc_8212A3F0:
	// rlwinm r11,r8,12,20,31
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 12) & 0xFFF;
	// stw r8,13908(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13908, ctx.r8.u32);
	// clrlwi r10,r8,3
	ctx.r10.u64 = ctx.r8.u32 & 0x1FFFFFFF;
	// stw r24,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r24.u32);
	// addi r11,r11,512
	ctx.r11.s64 = ctx.r11.s64 + 512;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// subf r3,r23,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r23.s64;
	// bne cr6,0x8212a424
	if (!ctx.cr6.eq) goto loc_8212A424;
	// lwz r11,13904(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13904);
	// stw r3,112(r11)
	PPC_STORE_U32(ctx.r11.u32 + 112, ctx.r3.u32);
	// b 0x8212a43c
	goto loc_8212A43C;
loc_8212A424:
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// lwz r11,13912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13912);
	// subf r11,r30,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r30.s64;
	// addi r10,r11,-8
	ctx.r10.s64 = ctx.r11.s64 + -8;
	// srawi r9,r10,3
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 3;
	// stw r9,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r9.u32);
loc_8212A43C:
	// addi r4,r3,2008
	ctx.r4.s64 = ctx.r3.s64 + 2008;
	// bl 0x8223b9b8
	ctx.lr = 0x8212A444;
	sub_8223B9B8(ctx, base);
loc_8212A444:
	// addi r11,r8,8
	ctx.r11.s64 = ctx.r8.s64 + 8;
	// addi r10,r8,2008
	ctx.r10.s64 = ctx.r8.s64 + 2008;
	// stw r11,13912(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13912, ctx.r11.u32);
	// stw r10,13916(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13916, ctx.r10.u32);
loc_8212A454:
	// stw r21,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r21.u32);
	// rlwimi r15,r29,30,2,31
	ctx.r15.u64 = (rotl32(ctx.r29.u32, 30) & 0x3FFFFFFF) | (ctx.r15.u64 & 0xFFFFFFFFC0000000);
	// addi r10,r11,8
	ctx.r10.s64 = ctx.r11.s64 + 8;
	// rlwinm r15,r15,0,2,0
	ctx.r15.u64 = rotl64(ctx.r15.u32 | (ctx.r15.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r15,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r15.u32);
	// ld r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r9,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r9.u64);
	// stw r10,13912(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13912, ctx.r10.u32);
loc_8212A474:
	// stb r24,12882(r31)
	PPC_STORE_U8(ctx.r31.u32 + 12882, ctx.r24.u8);
	// stw r24,12820(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12820, ctx.r24.u32);
	// stfs f31,2176(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2176, temp.u32);
	// lfs f0,4(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,2180(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2180, temp.u32);
	// lfs f0,8(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,2184(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2184, temp.u32);
	// lfs f0,12(r18)
	temp.u32 = PPC_LOAD_U32(ctx.r18.u32 + 12);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,2188(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2188, temp.u32);
	// ld r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r10,r11,r20
	ctx.r10.u64 = ctx.r11.u64 | ctx.r20.u64;
	// std r10,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r10.u64);
loc_8212A4A4:
	// lwz r30,8(r16)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r16.u32 + 8);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x8212a4bc
	if (ctx.cr6.eq) goto loc_8212A4BC;
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// stw r11,8(r16)
	PPC_STORE_U32(ctx.r16.u32 + 8, ctx.r11.u32);
	// bne cr6,0x8212a14c
	if (!ctx.cr6.eq) goto loc_8212A14C;
loc_8212A4BC:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212A4C8"))) PPC_WEAK_FUNC(sub_8212A4C8);
PPC_FUNC_IMPL(__imp__sub_8212A4C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x8233fa34
	ctx.lr = 0x8212A4D8;
	sub_8233FA34(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lfs f13,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lfs f12,24(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// lfs f11,48(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,12(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// li r7,3
	ctx.r7.s64 = 3;
	// lfs f9,36(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	ctx.f9.f64 = double(temp.f32);
	// li r6,6
	ctx.r6.s64 = 6;
	// lfs f8,60(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 60);
	ctx.f8.f64 = double(temp.f32);
	// rldicr r7,r7,43,20
	ctx.r7.u64 = rotl64(ctx.r7.u64, 43) & 0xFFFFF80000000000;
	// lfs f7,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lfs f0,36(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// li r4,78
	ctx.r4.s64 = 78;
	// lfs f6,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f6.f64 = double(temp.f32);
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lfs f5,52(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,40(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,64(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 64);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f1.f64 = double(temp.f32);
	// lfs f31,32(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	ctx.f31.f64 = double(temp.f32);
	// lfs f30,56(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 56);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f29.f64 = double(temp.f32);
	// lfs f28,44(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 44);
	ctx.f28.f64 = double(temp.f32);
	// lfs f27,68(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 68);
	ctx.f27.f64 = double(temp.f32);
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f0,92(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f11,88(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f0,124(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stfs f10,96(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f0,140(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// stfs f9,100(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f0,156(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// stfs f8,104(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f0,172(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// stfs f7,112(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f6,116(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f5,120(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// stfs f4,128(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f3,132(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stfs f2,136(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f1,144(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f31,148(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f30,152(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// stfs f29,160(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// stfs f28,164(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stfs f27,168(r1)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// bl 0x82238120
	ctx.lr = 0x8212A5B0;
	sub_82238120(ctx, base);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x8233fa80
	ctx.lr = 0x8212A5BC;
	__savefpr_27(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8212A5C8"))) PPC_WEAK_FUNC(sub_8212A5C8);
PPC_FUNC_IMPL(__imp__sub_8212A5C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f13,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f0,f0
	ctx.f11.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fmuls f10,f13,f13
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// lfs f12,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f9,f12,f12
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// addi r11,r11,31376
	ctx.r11.s64 = ctx.r11.s64 + 31376;
	// lfs f8,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fadds f7,f11,f10
	ctx.f7.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// fadds f6,f7,f9
	ctx.f6.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fsqrts f5,f6
	ctx.f5.f64 = double(simd::sqrt_f32(float(ctx.f6.f64)));
	// fcmpu cr6,f5,f8
	ctx.cr6.compare(ctx.f5.f64, ctx.f8.f64);
	// beq cr6,0x8212a620
	if (ctx.cr6.eq) goto loc_8212A620;
	// fadds f9,f10,f9
	ctx.f9.f64 = double(float(ctx.f10.f64 + ctx.f9.f64));
	// lfs f10,36(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	ctx.f10.f64 = double(temp.f32);
	// fadds f7,f9,f11
	ctx.f7.f64 = double(float(ctx.f9.f64 + ctx.f11.f64));
	// fsqrts f6,f7
	ctx.f6.f64 = double(simd::sqrt_f32(float(ctx.f7.f64)));
	// fdivs f5,f10,f6
	ctx.f5.f64 = double(float(ctx.f10.f64 / ctx.f6.f64));
	// fmuls f0,f0,f5
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f5.f64));
	// fmuls f13,f13,f5
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fmuls f12,f12,f5
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f5.f64));
loc_8212A620:
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r12,1
	ctx.r12.s64 = 1;
	// rldicr r12,r12,47,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 47) & 0xFFFFFFFFFFFFFFFF;
	// stfs f0,7072(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 7072, temp.u32);
	// stfs f13,7076(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 7076, temp.u32);
	// stfs f12,7080(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 7080, temp.u32);
	// stfs f8,7084(r11)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + 7084, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// or r9,r10,r12
	ctx.r9.u64 = ctx.r10.u64 | ctx.r12.u64;
	// std r9,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r9.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8212A64C"))) PPC_WEAK_FUNC(sub_8212A64C);
PPC_FUNC_IMPL(__imp__sub_8212A64C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212A650"))) PPC_WEAK_FUNC(sub_8212A650);
PPC_FUNC_IMPL(__imp__sub_8212A650) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f0,8(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f1
	ctx.cr6.compare(ctx.f0.f64, ctx.f1.f64);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r12,1
	ctx.r12.s64 = 1;
	// stfs f1,8(r3)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// addi r9,r11,31376
	ctx.r9.s64 = ctx.r11.s64 + 31376;
	// rldicr r12,r12,49,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 49) & 0xFFFFFFFFFFFFFFFF;
	// stfs f1,6956(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 6956, temp.u32);
	// lfs f0,36(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6944(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 6944, temp.u32);
	// stfs f0,6948(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 6948, temp.u32);
	// stfs f0,6952(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 6952, temp.u32);
	// ld r8,8(r10)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r10.u32 + 8);
	// or r7,r8,r12
	ctx.r7.u64 = ctx.r8.u64 | ctx.r12.u64;
	// std r7,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.r7.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8212A698"))) PPC_WEAK_FUNC(sub_8212A698);
PPC_FUNC_IMPL(__imp__sub_8212A698) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8212A6A0;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r27,4(r30)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// bl 0x82113ab8
	ctx.lr = 0x8212A6B8;
	sub_82113AB8(ctx, base);
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r29,r31,12
	ctx.r29.s64 = ctx.r31.s64 + 12;
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// beq cr6,0x8212a6dc
	if (ctx.cr6.eq) goto loc_8212A6DC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r10.u32);
loc_8212A6DC:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212a7e4
	if (ctx.cr6.eq) goto loc_8212A7E4;
loc_8212A6E8:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 9, ctx.xer);
	// bne cr6,0x8212a724
	if (!ctx.cr6.eq) goto loc_8212A724;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8212b5f8
	ctx.lr = 0x8212A700;
	sub_8212B5F8(ctx, base);
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212a714
	if (ctx.cr6.eq) goto loc_8212A714;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r10.u32);
loc_8212A714:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212a6e8
	if (!ctx.cr6.eq) goto loc_8212A6E8;
	// b 0x8212a7e4
	goto loc_8212A7E4;
loc_8212A724:
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// addi r28,r11,-27800
	ctx.r28.s64 = ctx.r11.s64 + -27800;
loc_8212A72C:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 10, ctx.xer);
	// bne cr6,0x8212a7e4
	if (!ctx.cr6.eq) goto loc_8212A7E4;
	// lwz r11,2120(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2120);
	// rlwinm r10,r11,0,29,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x8212a754
	if (ctx.cr6.eq) goto loc_8212A754;
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// addi r4,r31,24
	ctx.r4.s64 = ctx.r31.s64 + 24;
	// b 0x8212a794
	goto loc_8212A794;
loc_8212A754:
	// lwz r11,72(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// addi r4,r31,72
	ctx.r4.s64 = ctx.r31.s64 + 72;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212a774
	if (!ctx.cr6.eq) goto loc_8212A774;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// beq cr6,0x8212a778
	if (ctx.cr6.eq) goto loc_8212A778;
loc_8212A774:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8212A778:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212a78c
	if (!ctx.cr6.eq) goto loc_8212A78C;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8212b6e0
	ctx.lr = 0x8212A78C;
	sub_8212B6E0(ctx, base);
loc_8212A78C:
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r4,r31,48
	ctx.r4.s64 = ctx.r31.s64 + 48;
loc_8212A794:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212a7ac
	if (!ctx.cr6.eq) goto loc_8212A7AC;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// beq cr6,0x8212a7b0
	if (ctx.cr6.eq) goto loc_8212A7B0;
loc_8212A7AC:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8212A7B0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212a7c4
	if (!ctx.cr6.eq) goto loc_8212A7C4;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8212b6e0
	ctx.lr = 0x8212A7C4;
	sub_8212B6E0(ctx, base);
loc_8212A7C4:
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212a7d8
	if (ctx.cr6.eq) goto loc_8212A7D8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r10.u32);
loc_8212A7D8:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212a72c
	if (!ctx.cr6.eq) goto loc_8212A72C;
loc_8212A7E4:
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8212A800;
	sub_8222CC48(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8222cd68
	ctx.lr = 0x8212A80C;
	sub_8222CD68(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113ab8
	ctx.lr = 0x8212A814;
	sub_82113AB8(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212A824"))) PPC_WEAK_FUNC(sub_8212A824);
PPC_FUNC_IMPL(__imp__sub_8212A824) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212A828"))) PPC_WEAK_FUNC(sub_8212A828);
PPC_FUNC_IMPL(__imp__sub_8212A828) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x8212A830;
	__restfpr_14(ctx, base);
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, ctx.f31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r18,r10
	ctx.r18.u64 = ctx.r10.u64;
	// stw r7,308(r1)
	PPC_STORE_U32(ctx.r1.u32 + 308, ctx.r7.u32);
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// lwz r26,4(r3)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lwz r8,0(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// addi r7,r10,-27800
	ctx.r7.s64 = ctx.r10.s64 + -27800;
	// stw r5,292(r1)
	PPC_STORE_U32(ctx.r1.u32 + 292, ctx.r5.u32);
	// addi r22,r11,31376
	ctx.r22.s64 = ctx.r11.s64 + 31376;
	// lwz r14,0(r18)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	// mr r15,r3
	ctx.r15.u64 = ctx.r3.u64;
	// mr r17,r6
	ctx.r17.u64 = ctx.r6.u64;
	// subfic r6,r14,1
	ctx.xer.ca = ctx.r14.u32 <= 1;
	ctx.r6.s64 = 1 - ctx.r14.s64;
	// lwz r10,136(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 136);
	// lwz r11,2120(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 2120);
	// mr r21,r4
	ctx.r21.u64 = ctx.r4.u64;
	// subfe r4,r5,r5
	temp.u8 = (~ctx.r5.u32 + ctx.r5.u32 < ~ctx.r5.u32) | (~ctx.r5.u32 + ctx.r5.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r4.u64 = ~ctx.r5.u64 + ctx.r5.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// lfs f31,48(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// rlwinm r3,r11,0,23,27
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1F0;
	// li r19,1
	ctx.r19.s64 = 1;
	// rlwinm r3,r3,0,25,23
	ctx.r3.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
	// li r16,0
	ctx.r16.s64 = 0;
	// clrlwi r20,r4,31
	ctx.r20.u64 = ctx.r4.u32 & 0x1;
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x8212ac24
	if (ctx.cr6.eq) goto loc_8212AC24;
	// lwz r11,12(r17)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r17.u32 + 12);
	// rlwinm r8,r11,0,14,14
	ctx.r8.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20000;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8212ac24
	if (ctx.cr6.eq) goto loc_8212AC24;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r31,416(r17)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r17.u32 + 416);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,1
	ctx.r7.s64 = 1;
	// rldicr r24,r8,44,63
	ctx.r24.u64 = rotl64(ctx.r8.u64, 44) & 0xFFFFFFFFFFFFFFFF;
	// li r23,0
	ctx.r23.s64 = 0;
	// rldicr r28,r7,63,63
	ctx.r28.u64 = rotl64(ctx.r7.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// li r25,2
	ctx.r25.s64 = 2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// addi r30,r11,28184
	ctx.r30.s64 = ctx.r11.s64 + 28184;
	// beq cr6,0x8212aaac
	if (ctx.cr6.eq) goto loc_8212AAAC;
	// rlwinm r11,r9,2,0,29
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r16,r11,r10
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// beq cr6,0x8212aaac
	if (ctx.cr6.eq) goto loc_8212AAAC;
	// lwz r11,0(r16)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r16.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212aaac
	if (ctx.cr6.eq) goto loc_8212AAAC;
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212a908
	if (ctx.cr6.eq) goto loc_8212A908;
	// bl 0x820b91d0
	ctx.lr = 0x8212A904;
	sub_820B91D0(ctx, base);
	// b 0x8212a924
	goto loc_8212A924;
loc_8212A908:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212a91c
	if (ctx.cr6.eq) goto loc_8212A91C;
	// lwz r27,88(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x8212a928
	goto loc_8212A928;
loc_8212A91C:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x8212A924;
	sub_820B90A0(ctx, base);
loc_8212A924:
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
loc_8212A928:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x8212aaac
	if (ctx.cr6.eq) goto loc_8212AAAC;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,4(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// mr r23,r19
	ctx.r23.u64 = ctx.r19.u64;
	// bl 0x82111400
	ctx.lr = 0x8212A940;
	sub_82111400(ctx, base);
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// lfs f0,56(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 56);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,60(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 60);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,64(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 64);
	ctx.f12.f64 = double(temp.f32);
	// add r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 + ctx.r11.u64;
	// stfs f31,7260(r26)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7260, temp.u32);
	// stfs f0,7248(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7248, temp.u32);
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// stfs f13,7252(r26)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7252, temp.u32);
	// stfs f12,7256(r26)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7256, temp.u32);
	// ld r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r26.u32 + 8);
	// or r9,r10,r24
	ctx.r9.u64 = ctx.r10.u64 | ctx.r24.u64;
	// std r9,8(r26)
	PPC_STORE_U64(ctx.r26.u32 + 8, ctx.r9.u64);
	// add r29,r11,r30
	ctx.r29.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r7,1972(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1972);
	// cmplwi cr6,r7,2
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 2, ctx.xer);
	// beq cr6,0x8212a9c8
	if (ctx.cr6.eq) goto loc_8212A9C8;
	// addi r10,r31,48
	ctx.r10.s64 = ctx.r31.s64 + 48;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r7,r31,32
	ctx.r7.s64 = ctx.r31.s64 + 32;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// clrldi r4,r7,32
	ctx.r4.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// add r5,r10,r9
	ctx.r5.u64 = ctx.r10.u64 + ctx.r9.u64;
	// srd r3,r28,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r4.u8 & 0x7F));
	// rlwinm r10,r5,3,0,28
	ctx.r10.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// rlwimi r9,r19,11,19,21
	ctx.r9.u64 = (rotl32(ctx.r19.u32, 11) & 0x1C00) | (ctx.r9.u64 & 0xFFFFFFFFFFFFE3FF);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r5,r3,r7
	ctx.r5.u64 = ctx.r3.u64 | ctx.r7.u64;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r25,1972(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1972, ctx.r25.u32);
loc_8212A9C8:
	// lwz r11,1988(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212aa14
	if (ctx.cr6.eq) goto loc_8212AA14;
	// addi r10,r31,48
	ctx.r10.s64 = ctx.r31.s64 + 48;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r7,r31,32
	ctx.r7.s64 = ctx.r31.s64 + 32;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// clrldi r4,r7,32
	ctx.r4.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// add r5,r10,r9
	ctx.r5.u64 = ctx.r10.u64 + ctx.r9.u64;
	// srd r3,r28,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r4.u8 & 0x7F));
	// rlwinm r10,r5,3,0,28
	ctx.r10.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// rlwimi r9,r19,14,16,18
	ctx.r9.u64 = (rotl32(ctx.r19.u32, 14) & 0xE000) | (ctx.r9.u64 & 0xFFFFFFFFFFFF1FFF);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r5,r3,r7
	ctx.r5.u64 = ctx.r3.u64 | ctx.r7.u64;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r25,1988(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1988, ctx.r25.u32);
loc_8212AA14:
	// subfic r11,r8,1
	ctx.xer.ca = ctx.r8.u32 <= 1;
	ctx.r11.s64 = 1 - ctx.r8.s64;
	// lwz r9,2068(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2068);
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8212aa6c
	if (ctx.cr6.eq) goto loc_8212AA6C;
	// rlwinm r9,r31,1,0,30
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r8,r31,32
	ctx.r8.s64 = ctx.r31.s64 + 32;
	// add r7,r31,r9
	ctx.r7.u64 = ctx.r31.u64 + ctx.r9.u64;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// clrldi r5,r8,32
	ctx.r5.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// srd r4,r28,r5
	ctx.r4.u64 = ctx.r5.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r5.u8 & 0x7F));
	// lwz r3,1164(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r3,r10,23,7,8
	ctx.r3.u64 = (rotl32(ctx.r10.u32, 23) & 0x1800000) | (ctx.r3.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r3,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r3.u32);
	// ld r11,24(r6)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r6.u32 + 24);
	// or r9,r4,r11
	ctx.r9.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r9,24(r6)
	PPC_STORE_U64(ctx.r6.u32 + 24, ctx.r9.u64);
	// stw r10,2068(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2068, ctx.r10.u32);
loc_8212AA6C:
	// lwz r11,2052(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212aa8c
	if (ctx.cr6.eq) goto loc_8212AA8C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8222c0a0
	ctx.lr = 0x8212AA88;
	sub_8222C0A0(ctx, base);
	// stw r19,2052(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2052, ctx.r19.u32);
loc_8212AA8C:
	// lwz r11,2036(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212aaac
	if (ctx.cr6.eq) goto loc_8212AAAC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8222c248
	ctx.lr = 0x8212AAA8;
	sub_8222C248(ctx, base);
	// stw r19,2036(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2036, ctx.r19.u32);
loc_8212AAAC:
	// clrlwi r11,r23,24
	ctx.r11.u64 = ctx.r23.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212ac24
	if (!ctx.cr6.eq) goto loc_8212AC24;
	// lfs f0,36(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// stfs f0,7248(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7248, temp.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stfs f0,7252(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7252, temp.u32);
	// stfs f0,7256(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7256, temp.u32);
	// stfs f31,7260(r26)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7260, temp.u32);
	// ld r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r26.u32 + 8);
	// or r9,r10,r24
	ctx.r9.u64 = ctx.r10.u64 | ctx.r24.u64;
	// lwz r4,25796(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25796);
	// std r9,8(r26)
	PPC_STORE_U64(ctx.r26.u32 + 8, ctx.r9.u64);
	// bl 0x82111400
	ctx.lr = 0x8212AAE8;
	sub_82111400(ctx, base);
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r31,r11
	ctx.r8.u64 = ctx.r31.u64 + ctx.r11.u64;
	// rlwinm r11,r8,6,0,25
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// add r29,r11,r30
	ctx.r29.u64 = ctx.r11.u64 + ctx.r30.u64;
	// lwz r7,1972(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1972);
	// cmplwi cr6,r7,2
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 2, ctx.xer);
	// beq cr6,0x8212ab44
	if (ctx.cr6.eq) goto loc_8212AB44;
	// addi r10,r31,48
	ctx.r10.s64 = ctx.r31.s64 + 48;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r8,r31,32
	ctx.r8.s64 = ctx.r31.s64 + 32;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// clrldi r5,r8,32
	ctx.r5.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// add r6,r10,r9
	ctx.r6.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// srd r4,r28,r5
	ctx.r4.u64 = ctx.r5.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r5.u8 & 0x7F));
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// rlwimi r3,r19,11,19,21
	ctx.r3.u64 = (rotl32(ctx.r19.u32, 11) & 0x1C00) | (ctx.r3.u64 & 0xFFFFFFFFFFFFE3FF);
	// stwx r3,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r3.u32);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r10,r4,r11
	ctx.r10.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r10,24(r7)
	PPC_STORE_U64(ctx.r7.u32 + 24, ctx.r10.u64);
	// stw r25,1972(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1972, ctx.r25.u32);
loc_8212AB44:
	// lwz r11,1988(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212ab90
	if (ctx.cr6.eq) goto loc_8212AB90;
	// addi r10,r31,48
	ctx.r10.s64 = ctx.r31.s64 + 48;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r8,r31,32
	ctx.r8.s64 = ctx.r31.s64 + 32;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// clrldi r5,r8,32
	ctx.r5.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// add r6,r10,r9
	ctx.r6.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// srd r4,r28,r5
	ctx.r4.u64 = ctx.r5.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r5.u8 & 0x7F));
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// rlwimi r3,r19,14,16,18
	ctx.r3.u64 = (rotl32(ctx.r19.u32, 14) & 0xE000) | (ctx.r3.u64 & 0xFFFFFFFFFFFF1FFF);
	// stwx r3,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r3.u32);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r10,r4,r11
	ctx.r10.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r10,24(r7)
	PPC_STORE_U64(ctx.r7.u32 + 24, ctx.r10.u64);
	// stw r25,1988(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1988, ctx.r25.u32);
loc_8212AB90:
	// lwz r11,2068(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2068);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212abdc
	if (ctx.cr6.eq) goto loc_8212ABDC;
	// rlwinm r10,r31,1,0,30
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r9,r31,32
	ctx.r9.s64 = ctx.r31.s64 + 32;
	// add r8,r31,r10
	ctx.r8.u64 = ctx.r31.u64 + ctx.r10.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// clrldi r6,r9,32
	ctx.r6.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// srd r5,r28,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r6.u8 & 0x7F));
	// lwz r4,1164(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r4,r19,24,7,8
	ctx.r4.u64 = (rotl32(ctx.r19.u32, 24) & 0x1800000) | (ctx.r4.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r4,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r4.u32);
	// ld r3,24(r7)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r7.u32 + 24);
	// or r11,r5,r3
	ctx.r11.u64 = ctx.r5.u64 | ctx.r3.u64;
	// std r11,24(r7)
	PPC_STORE_U64(ctx.r7.u32 + 24, ctx.r11.u64);
	// stw r25,2068(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2068, ctx.r25.u32);
loc_8212ABDC:
	// lwz r11,2052(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212ac00
	if (ctx.cr6.eq) goto loc_8212AC00;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8222c0a0
	ctx.lr = 0x8212ABF8;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2052, ctx.r11.u32);
loc_8212AC00:
	// lwz r11,2036(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212ac24
	if (ctx.cr6.eq) goto loc_8212AC24;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8222c248
	ctx.lr = 0x8212AC1C;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2036(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2036, ctx.r11.u32);
loc_8212AC24:
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x8212ae50
	if (ctx.cr6.eq) goto loc_8212AE50;
	// li r11,1
	ctx.r11.s64 = 1;
	// clrlwi r27,r20,24
	ctx.r27.u64 = ctx.r20.u32 & 0xFF;
	// rldicr r25,r11,47,63
	ctx.r25.u64 = rotl64(ctx.r11.u64, 47) & 0xFFFFFFFFFFFFFFFF;
loc_8212AC38:
	// lwz r11,292(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// lwz r31,0(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r28,16(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r29,0(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// beq cr6,0x8212acfc
	if (ctx.cr6.eq) goto loc_8212ACFC;
	// rlwinm r30,r29,2,0,29
	ctx.r30.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8210b178
	ctx.lr = 0x8212AC64;
	sub_8210B178(ctx, base);
	// lwz r11,40(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8212ac88
	if (ctx.cr6.eq) goto loc_8212AC88;
	// addi r10,r3,-4
	ctx.r10.s64 = ctx.r3.s64 + -4;
	// mtctr r29
	ctx.ctr.u64 = ctx.r29.u64;
	// addi r11,r11,-2
	ctx.r11.s64 = ctx.r11.s64 + -2;
loc_8212AC7C:
	// lhzu r9,2(r11)
	ea = 2 + ctx.r11.u32;
	ctx.r9.u64 = PPC_LOAD_U16(ea);
	ctx.r11.u32 = ea;
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x8212ac7c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8212AC7C;
loc_8212AC88:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8210b488
	ctx.lr = 0x8212AC90;
	sub_8210B488(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,4
	ctx.r7.s64 = 4;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8212ACAC;
	sub_8222CC48(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,96
	ctx.r7.s64 = 96;
	// lwz r6,4(r18)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r18.u32 + 4);
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r5,8(r18)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r18.u32 + 8);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8212ACC8;
	sub_8222CC48(ctx, base);
	// clrldi r11,r29,32
	ctx.r11.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// stfs f31,2968(r26)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r26.u32 + 2968, temp.u32);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfd f0,88(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f0
	ctx.f13.f64 = double(ctx.f0.s64);
	// stfs f31,2972(r26)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r26.u32 + 2972, temp.u32);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// stfs f12,2960(r26)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r26.u32 + 2960, temp.u32);
	// stfs f31,2964(r26)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r26.u32 + 2964, temp.u32);
	// ld r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r26.u32 + 0);
	// or r9,r10,r25
	ctx.r9.u64 = ctx.r10.u64 | ctx.r25.u64;
	// std r9,0(r26)
	PPC_STORE_U64(ctx.r26.u32 + 0, ctx.r9.u64);
	// b 0x8212ad08
	goto loc_8212AD08;
loc_8212ACFC:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// bl 0x8222cd68
	ctx.lr = 0x8212AD08;
	sub_8222CD68(ctx, base);
loc_8212AD08:
	// li r8,1
	ctx.r8.s64 = 1;
	// lbz r7,6(r31)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r31.u32 + 6);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lwz r5,28(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// bl 0x8222cc48
	ctx.lr = 0x8212AD24;
	sub_8222CC48(ctx, base);
	// lbz r11,7(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 7);
	// rlwinm r10,r11,0,29,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212ad40
	if (ctx.cr6.eq) goto loc_8212AD40;
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// mr r11,r19
	ctx.r11.u64 = ctx.r19.u64;
	// bne cr6,0x8212ad44
	if (!ctx.cr6.eq) goto loc_8212AD44;
loc_8212AD40:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8212AD44:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212ad84
	if (ctx.cr6.eq) goto loc_8212AD84;
	// lhz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 24);
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r10,0(r15)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// rlwinm r6,r9,2,0,29
	ctx.r6.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r5,r11,468
	ctx.r5.s64 = ctx.r11.s64 + 468;
	// lwzx r6,r6,r16
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r16.u32);
	// bl 0x8222cc48
	ctx.lr = 0x8212AD84;
	sub_8222CC48(ctx, base);
loc_8212AD84:
	// lwz r24,308(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	// li r31,0
	ctx.r31.s64 = 0;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x8212add8
	if (ctx.cr6.eq) goto loc_8212ADD8;
loc_8212AD94:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x821103d0
	ctx.lr = 0x8212ADA0;
	sub_821103D0(ctx, base);
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,6
	ctx.r4.s64 = 6;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// beq cr6,0x8212adc0
	if (ctx.cr6.eq) goto loc_8212ADC0;
	// mullw r6,r29,r14
	ctx.r6.s64 = int64_t(ctx.r29.s32) * int64_t(ctx.r14.s32);
	// bl 0x8222dfc8
	ctx.lr = 0x8212ADBC;
	sub_8222DFC8(ctx, base);
	// b 0x8212adcc
	goto loc_8212ADCC;
loc_8212ADC0:
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// bl 0x8222e3e0
	ctx.lr = 0x8212ADCC;
	sub_8222E3E0(ctx, base);
loc_8212ADCC:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r24
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r24.u32, ctx.xer);
	// blt cr6,0x8212ad94
	if (ctx.cr6.lt) goto loc_8212AD94;
loc_8212ADD8:
	// lwz r11,292(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// stw r10,292(r1)
	PPC_STORE_U32(ctx.r1.u32 + 292, ctx.r10.u32);
	// beq cr6,0x8212ae08
	if (ctx.cr6.eq) goto loc_8212AE08;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8212AE08;
	sub_8222CC48(ctx, base);
loc_8212AE08:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x8212ae48
	if (ctx.cr6.eq) goto loc_8212AE48;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8212AE2C;
	sub_8222CC48(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8212AE48;
	sub_8222CC48(ctx, base);
loc_8212AE48:
	// addic. r21,r21,-1
	ctx.xer.ca = ctx.r21.u32 > 0;
	ctx.r21.s64 = ctx.r21.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r21.s32, 0, ctx.xer);
	// bne 0x8212ac38
	if (!ctx.cr0.eq) goto loc_8212AC38;
loc_8212AE50:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212AE5C"))) PPC_WEAK_FUNC(sub_8212AE5C);
PPC_FUNC_IMPL(__imp__sub_8212AE5C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212AE60"))) PPC_WEAK_FUNC(sub_8212AE60);
PPC_FUNC_IMPL(__imp__sub_8212AE60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x8212AE68;
	__restfpr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// std r5,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, ctx.r5.u64);
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// lwz r27,4(r3)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r25,r8
	ctx.r25.u64 = ctx.r8.u64;
	// std r6,184(r1)
	PPC_STORE_U64(ctx.r1.u32 + 184, ctx.r6.u64);
	// mr r26,r9
	ctx.r26.u64 = ctx.r9.u64;
	// cmpwi cr6,r4,8
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 8, ctx.xer);
	// beq cr6,0x8212b08c
	if (ctx.cr6.eq) goto loc_8212B08C;
	// cmpwi cr6,r4,5
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 5, ctx.xer);
	// beq cr6,0x8212b08c
	if (ctx.cr6.eq) goto loc_8212B08C;
	// cmpwi cr6,r4,6
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 6, ctx.xer);
	// beq cr6,0x8212b08c
	if (ctx.cr6.eq) goto loc_8212B08C;
	// cmpwi cr6,r4,10
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 10, ctx.xer);
	// beq cr6,0x8212b08c
	if (ctx.cr6.eq) goto loc_8212B08C;
	// cmpwi cr6,r4,0
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// beq cr6,0x8212b08c
	if (ctx.cr6.eq) goto loc_8212B08C;
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f0,176(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r27,8
	ctx.r11.s64 = ctx.r27.s64 + 8;
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// rldicr r12,r12,59,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 59) & 0xFFFFFFFFFFFFFFFF;
	// lfs f11,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f11.f64 = double(temp.f32);
	// cmpwi cr6,r4,9
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 9, ctx.xer);
	// stfs f0,6288(r27)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + 6288, temp.u32);
	// stfs f13,6292(r27)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r27.u32 + 6292, temp.u32);
	// stfs f12,6296(r27)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + 6296, temp.u32);
	// stfs f11,6300(r27)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r27.u32 + 6300, temp.u32);
	// ld r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r27.u32 + 8);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,8(r27)
	PPC_STORE_U64(ctx.r27.u32 + 8, ctx.r10.u64);
	// beq cr6,0x8212b08c
	if (ctx.cr6.eq) goto loc_8212B08C;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r30,1
	ctx.r30.s64 = 1;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,6772(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 6772);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212af2c
	if (ctx.cr6.eq) goto loc_8212AF2C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1512(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1512);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1512(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1512, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,1
	ctx.r6.u64 = ctx.r7.u64 | 65536;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,6772(r31)
	PPC_STORE_U32(ctx.r31.u32 + 6772, ctx.r10.u32);
loc_8212AF2C:
	// lwz r11,6788(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 6788);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212af60
	if (ctx.cr6.eq) goto loc_8212AF60;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1512(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1512);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1512(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1512, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,1
	ctx.r6.u64 = ctx.r7.u64 | 65536;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,6788(r31)
	PPC_STORE_U32(ctx.r31.u32 + 6788, ctx.r10.u32);
loc_8212AF60:
	// lwz r11,6836(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 6836);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212af84
	if (ctx.cr6.eq) goto loc_8212AF84;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,15
	ctx.r4.s64 = 15;
	// bl 0x8222c248
	ctx.lr = 0x8212AF7C;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,6836(r31)
	PPC_STORE_U32(ctx.r31.u32 + 6836, ctx.r30.u32);
loc_8212AF84:
	// lwz r11,6852(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 6852);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212afa8
	if (ctx.cr6.eq) goto loc_8212AFA8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,15
	ctx.r4.s64 = 15;
	// bl 0x8222c0a0
	ctx.lr = 0x8212AFA0;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,6852(r31)
	PPC_STORE_U32(ctx.r31.u32 + 6852, ctx.r30.u32);
loc_8212AFA8:
	// lwz r11,6868(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 6868);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212afdc
	if (ctx.cr6.eq) goto loc_8212AFDC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1524(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1524);
	// rlwimi r8,r30,24,7,8
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 24) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1524(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1524, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,1
	ctx.r6.u64 = ctx.r7.u64 | 65536;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,6868(r31)
	PPC_STORE_U32(ctx.r31.u32 + 6868, ctx.r10.u32);
loc_8212AFDC:
	// lwz r11,6820(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 6820);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x8212b010
	if (ctx.cr6.eq) goto loc_8212B010;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1532(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1532);
	// rlwimi r8,r30,0,30,31
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 0) & 0x3) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r8,1532(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1532, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,1
	ctx.r6.u64 = ctx.r7.u64 | 65536;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,6820(r31)
	PPC_STORE_U32(ctx.r31.u32 + 6820, ctx.r10.u32);
loc_8212B010:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x8212b08c
	if (ctx.cr6.eq) goto loc_8212B08C;
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r29,r26
	ctx.r29.u64 = ctx.r26.u64;
	// addi r31,r25,4
	ctx.r31.s64 = ctx.r25.s64 + 4;
	// rldicr r30,r11,63,63
	ctx.r30.u64 = rotl64(ctx.r11.u64, 63) & 0xFFFFFFFFFFFFFFFF;
loc_8212B028:
	// lwz r4,-4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + -4);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// rlwinm r10,r4,30,2,31
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// lwz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// add r11,r4,r6
	ctx.r11.u64 = ctx.r4.u64 + ctx.r6.u64;
	// addi r9,r11,-1
	ctx.r9.s64 = ctx.r11.s64 + -1;
	// rlwinm r8,r9,30,2,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
	// subf r7,r10,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r10.s64;
	// clrldi r11,r7,32
	ctx.r11.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// srad r9,r30,r11
	temp.u64 = ctx.r11.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r30.s64 < 0) & (((ctx.r30.s64 >> temp.u64) << temp.u64) != ctx.r30.s64);
	ctx.r9.s64 = ctx.r30.s64 >> temp.u64;
	// srd r7,r9,r10
	ctx.r7.u64 = ctx.r10.u8 & 0x40 ? 0 : (ctx.r9.u64 >> (ctx.r10.u8 & 0x7F));
	// bl 0x82238120
	ctx.lr = 0x8212B05C;
	sub_82238120(ctx, base);
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x8212b07c
	if (ctx.cr6.eq) goto loc_8212B07C;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212b07c
	if (ctx.cr6.eq) goto loc_8212B07C;
	// li r3,15
	ctx.r3.s64 = 15;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82111400
	ctx.lr = 0x8212B07C;
	sub_82111400(ctx, base);
loc_8212B07C:
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// addi r31,r31,12
	ctx.r31.s64 = ctx.r31.s64 + 12;
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// bne 0x8212b028
	if (!ctx.cr0.eq) goto loc_8212B028;
loc_8212B08C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212B094"))) PPC_WEAK_FUNC(sub_8212B094);
PPC_FUNC_IMPL(__imp__sub_8212B094) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212B098"))) PPC_WEAK_FUNC(sub_8212B098);
PPC_FUNC_IMPL(__imp__sub_8212B098) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x8212B0A0;
	__restfpr_14(ctx, base);
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, ctx.f31.u64);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r16,r7
	ctx.r16.u64 = ctx.r7.u64;
	// lwz r27,4(r3)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r9,r10,-27800
	ctx.r9.s64 = ctx.r10.s64 + -27800;
	// mr r17,r3
	ctx.r17.u64 = ctx.r3.u64;
	// mr r18,r4
	ctx.r18.u64 = ctx.r4.u64;
	// mr r15,r5
	ctx.r15.u64 = ctx.r5.u64;
	// mr r20,r6
	ctx.r20.u64 = ctx.r6.u64;
	// lwz r10,2120(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2120);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r11.u32);
	// rlwinm r8,r10,0,23,27
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1F0;
	// rlwinm r8,r8,0,25,23
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
	// addic r7,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r7.s64 = ctx.r8.s64 + -1;
	// subfe r10,r7,r8
	temp.u8 = (~ctx.r7.u32 + ctx.r8.u32 < ~ctx.r7.u32) | (~ctx.r7.u32 + ctx.r8.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r10.u64 = ~ctx.r7.u64 + ctx.r8.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// beq cr6,0x8212b3ec
	if (ctx.cr6.eq) goto loc_8212B3EC;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// clrlwi r14,r10,24
	ctx.r14.u64 = ctx.r10.u32 & 0xFF;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r8,r10,31376
	ctx.r8.s64 = ctx.r10.s64 + 31376;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// stw r9,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r9.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// lis r6,0
	ctx.r6.s64 = 0;
	// rldicr r19,r9,44,63
	ctx.r19.u64 = rotl64(ctx.r9.u64, 44) & 0xFFFFFFFFFFFFFFFF;
	// lfs f31,48(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// li r22,1
	ctx.r22.s64 = 1;
	// rldicr r25,r7,63,63
	ctx.r25.u64 = rotl64(ctx.r7.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// li r21,2
	ctx.r21.s64 = 2;
	// ori r23,r6,65535
	ctx.r23.u64 = ctx.r6.u64 | 65535;
	// addi r26,r10,28184
	ctx.r26.s64 = ctx.r10.s64 + 28184;
loc_8212B12C:
	// addi r9,r11,108
	ctx.r9.s64 = ctx.r11.s64 + 108;
	// lwz r24,12(r11)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// addi r8,r11,32
	ctx.r8.s64 = ctx.r11.s64 + 32;
	// lwz r7,104(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 104);
	// mr r4,r15
	ctx.r4.u64 = ctx.r15.u64;
	// ld r5,16(r11)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// bl 0x8212ae60
	ctx.lr = 0x8212B150;
	sub_8212AE60(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lwz r4,60(r24)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r24.u32 + 60);
	// bl 0x8222cd68
	ctx.lr = 0x8212B15C;
	sub_8222CD68(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lbz r7,32(r24)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r24.u32 + 32);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lwz r6,40(r24)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r24.u32 + 40);
	// lwz r5,56(r24)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r24.u32 + 56);
	// bl 0x8222cc48
	ctx.lr = 0x8212B178;
	sub_8222CC48(ctx, base);
	// cmplwi cr6,r14,0
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 0, ctx.xer);
	// beq cr6,0x8212b360
	if (ctx.cr6.eq) goto loc_8212B360;
	// lwz r11,12(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 12);
	// rlwinm r10,r11,0,14,14
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20000;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212b360
	if (ctx.cr6.eq) goto loc_8212B360;
	// lwz r11,72(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 72);
	// lwz r31,416(r20)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r20.u32 + 416);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x8212b360
	if (ctx.cr6.eq) goto loc_8212B360;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212b360
	if (ctx.cr6.eq) goto loc_8212B360;
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212b1bc
	if (ctx.cr6.eq) goto loc_8212B1BC;
	// bl 0x820b91d0
	ctx.lr = 0x8212B1B8;
	sub_820B91D0(ctx, base);
	// b 0x8212b1d8
	goto loc_8212B1D8;
loc_8212B1BC:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212b1d0
	if (ctx.cr6.eq) goto loc_8212B1D0;
	// lwz r29,88(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x8212b1dc
	goto loc_8212B1DC;
loc_8212B1D0:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x8212B1D8;
	sub_820B90A0(ctx, base);
loc_8212B1D8:
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
loc_8212B1DC:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8212b360
	if (ctx.cr6.eq) goto loc_8212B360;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,4(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// bl 0x82111400
	ctx.lr = 0x8212B1F0;
	sub_82111400(ctx, base);
	// lwz r8,20(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// lfs f0,56(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 56);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,60(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 60);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,64(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 64);
	ctx.f12.f64 = double(temp.f32);
	// add r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 + ctx.r11.u64;
	// stfs f31,7260(r27)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r27.u32 + 7260, temp.u32);
	// stfs f0,7248(r27)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + 7248, temp.u32);
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// stfs f13,7252(r27)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r27.u32 + 7252, temp.u32);
	// stfs f12,7256(r27)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + 7256, temp.u32);
	// ld r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r27.u32 + 8);
	// or r9,r10,r19
	ctx.r9.u64 = ctx.r10.u64 | ctx.r19.u64;
	// std r9,8(r27)
	PPC_STORE_U64(ctx.r27.u32 + 8, ctx.r9.u64);
	// add r30,r11,r26
	ctx.r30.u64 = ctx.r11.u64 + ctx.r26.u64;
	// lwz r7,1972(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1972);
	// cmplwi cr6,r7,2
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 2, ctx.xer);
	// beq cr6,0x8212b278
	if (ctx.cr6.eq) goto loc_8212B278;
	// addi r10,r31,48
	ctx.r10.s64 = ctx.r31.s64 + 48;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r7,r31,32
	ctx.r7.s64 = ctx.r31.s64 + 32;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// clrldi r4,r7,32
	ctx.r4.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// add r5,r10,r9
	ctx.r5.u64 = ctx.r10.u64 + ctx.r9.u64;
	// srd r3,r25,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x40 ? 0 : (ctx.r25.u64 >> (ctx.r4.u8 & 0x7F));
	// rlwinm r10,r5,3,0,28
	ctx.r10.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// rlwimi r9,r22,11,19,21
	ctx.r9.u64 = (rotl32(ctx.r22.u32, 11) & 0x1C00) | (ctx.r9.u64 & 0xFFFFFFFFFFFFE3FF);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r5,r3,r7
	ctx.r5.u64 = ctx.r3.u64 | ctx.r7.u64;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r21,1972(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1972, ctx.r21.u32);
loc_8212B278:
	// lwz r11,1988(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212b2c4
	if (ctx.cr6.eq) goto loc_8212B2C4;
	// addi r10,r31,48
	ctx.r10.s64 = ctx.r31.s64 + 48;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r7,r31,32
	ctx.r7.s64 = ctx.r31.s64 + 32;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// clrldi r4,r7,32
	ctx.r4.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// add r5,r10,r9
	ctx.r5.u64 = ctx.r10.u64 + ctx.r9.u64;
	// srd r3,r25,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x40 ? 0 : (ctx.r25.u64 >> (ctx.r4.u8 & 0x7F));
	// rlwinm r10,r5,3,0,28
	ctx.r10.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// rlwimi r9,r22,14,16,18
	ctx.r9.u64 = (rotl32(ctx.r22.u32, 14) & 0xE000) | (ctx.r9.u64 & 0xFFFFFFFFFFFF1FFF);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r5,r3,r7
	ctx.r5.u64 = ctx.r3.u64 | ctx.r7.u64;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r21,1988(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1988, ctx.r21.u32);
loc_8212B2C4:
	// subfic r11,r8,1
	ctx.xer.ca = ctx.r8.u32 <= 1;
	ctx.r11.s64 = 1 - ctx.r8.s64;
	// lwz r9,2068(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2068);
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8212b320
	if (ctx.cr6.eq) goto loc_8212B320;
	// rlwinm r9,r31,1,0,30
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r8,r31,32
	ctx.r8.s64 = ctx.r31.s64 + 32;
	// add r7,r31,r9
	ctx.r7.u64 = ctx.r31.u64 + ctx.r9.u64;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// clrldi r5,r8,32
	ctx.r5.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// srd r4,r25,r5
	ctx.r4.u64 = ctx.r5.u8 & 0x40 ? 0 : (ctx.r25.u64 >> (ctx.r5.u8 & 0x7F));
	// lwz r3,1164(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// addi r9,r11,1164
	ctx.r9.s64 = ctx.r11.s64 + 1164;
	// rlwimi r3,r10,23,7,8
	ctx.r3.u64 = (rotl32(ctx.r10.u32, 23) & 0x1800000) | (ctx.r3.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r3,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r3.u32);
	// ld r11,24(r6)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r6.u32 + 24);
	// or r9,r4,r11
	ctx.r9.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r9,24(r6)
	PPC_STORE_U64(ctx.r6.u32 + 24, ctx.r9.u64);
	// stw r10,2068(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2068, ctx.r10.u32);
loc_8212B320:
	// lwz r11,2052(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212b340
	if (ctx.cr6.eq) goto loc_8212B340;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8222c0a0
	ctx.lr = 0x8212B33C;
	sub_8222C0A0(ctx, base);
	// stw r22,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r22.u32);
loc_8212B340:
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212b360
	if (ctx.cr6.eq) goto loc_8212B360;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8222c248
	ctx.lr = 0x8212B35C;
	sub_8222C248(ctx, base);
	// stw r22,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r22.u32);
loc_8212B360:
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// beq cr6,0x8212b3d4
	if (ctx.cr6.eq) goto loc_8212B3D4;
loc_8212B36C:
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x821103d0
	ctx.lr = 0x8212B378;
	sub_821103D0(ctx, base);
	// lwz r31,28(r24)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r24.u32 + 28);
	// lwz r29,44(r24)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r24.u32 + 44);
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// ble cr6,0x8212b3c8
	if (!ctx.cr6.gt) goto loc_8212B3C8;
loc_8212B388:
	// cmpw cr6,r31,r23
	ctx.cr6.compare<int32_t>(ctx.r31.s32, ctx.r23.s32, ctx.xer);
	// ble cr6,0x8212b39c
	if (!ctx.cr6.gt) goto loc_8212B39C;
	// mr r30,r23
	ctx.r30.u64 = ctx.r23.u64;
	// subf r31,r23,r31
	ctx.r31.s64 = ctx.r31.s64 - ctx.r23.s64;
	// b 0x8212b3a4
	goto loc_8212B3A4;
loc_8212B39C:
	// mr r30,r31
	ctx.r30.u64 = ctx.r31.u64;
	// li r31,0
	ctx.r31.s64 = 0;
loc_8212B3A4:
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,6
	ctx.r4.s64 = 6;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8222e3e0
	ctx.lr = 0x8212B3BC;
	sub_8222E3E0(ctx, base);
	// add r29,r30,r29
	ctx.r29.u64 = ctx.r30.u64 + ctx.r29.u64;
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bgt cr6,0x8212b388
	if (ctx.cr6.gt) goto loc_8212B388;
loc_8212B3C8:
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// cmplw cr6,r28,r16
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r16.u32, ctx.xer);
	// blt cr6,0x8212b36c
	if (ctx.cr6.lt) goto loc_8212B36C;
loc_8212B3D4:
	// lwz r11,8(r18)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r18.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212b3ec
	if (ctx.cr6.eq) goto loc_8212B3EC;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r18)
	PPC_STORE_U32(ctx.r18.u32 + 8, ctx.r10.u32);
	// bne cr6,0x8212b12c
	if (!ctx.cr6.eq) goto loc_8212B12C;
loc_8212B3EC:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212B3F8"))) PPC_WEAK_FUNC(sub_8212B3F8);
PPC_FUNC_IMPL(__imp__sub_8212B3F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e440
	ctx.lr = 0x8212B400;
	__restfpr_18(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// stw r7,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r7.u32);
	// lis r5,-32250
	ctx.r5.s64 = -2113536000;
	// stb r8,93(r1)
	PPC_STORE_U8(ctx.r1.u32 + 93, ctx.r8.u8);
	// addi r9,r10,-27800
	ctx.r9.s64 = ctx.r10.s64 + -27800;
	// stw r6,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r6.u32);
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// addi r4,r5,31376
	ctx.r4.s64 = ctx.r5.s64 + 31376;
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// li r21,0
	ctx.r21.s64 = 0;
	// lwz r10,2120(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2120);
	// addi r3,r9,2120
	ctx.r3.s64 = ctx.r9.s64 + 2120;
	// li r8,11
	ctx.r8.s64 = 11;
	// stb r21,92(r1)
	PPC_STORE_U8(ctx.r1.u32 + 92, ctx.r21.u8);
	// li r7,-1
	ctx.r7.s64 = -1;
	// lfs f0,36(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
	// rlwinm r9,r10,24,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0x1;
	// stw r11,8(r23)
	PPC_STORE_U32(ctx.r23.u32 + 8, ctx.r11.u32);
	// rlwinm r18,r10,20,31,31
	ctx.r18.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0x1;
	// stw r21,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r21.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r21,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r21.u32);
	// stw r21,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r21.u32);
	// stw r3,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r3.u32);
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// beq cr6,0x8212b484
	if (ctx.cr6.eq) goto loc_8212B484;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r23)
	PPC_STORE_U32(ctx.r23.u32 + 8, ctx.r10.u32);
loc_8212B484:
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212b5ec
	if (ctx.cr6.eq) goto loc_8212B5EC;
	// li r10,1
	ctx.r10.s64 = 1;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// clrlwi r19,r9,24
	ctx.r19.u64 = ctx.r9.u32 & 0xFF;
	// rldicr r20,r10,37,63
	ctx.r20.u64 = rotl64(ctx.r10.u64, 37) & 0xFFFFFFFFFFFFFFFF;
	// addi r24,r11,28184
	ctx.r24.s64 = ctx.r11.s64 + 28184;
loc_8212B4A4:
	// lwz r25,24(r30)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r25.u32);
	// bl 0x8210f908
	ctx.lr = 0x8212B4B8;
	sub_8210F908(ctx, base);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8210fb60
	ctx.lr = 0x8212B4C4;
	sub_8210FB60(ctx, base);
	// addi r26,r30,12
	ctx.r26.s64 = ctx.r30.s64 + 12;
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x8212b594
	if (ctx.cr6.eq) goto loc_8212B594;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// rlwinm r10,r11,18,31,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8212b4ec
	if (!ctx.cr6.eq) goto loc_8212B4EC;
	// clrlwi r11,r18,24
	ctx.r11.u64 = ctx.r18.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212b594
	if (ctx.cr6.eq) goto loc_8212B594;
loc_8212B4EC:
	// li r5,5
	ctx.r5.s64 = 5;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82110610
	ctx.lr = 0x8212B4FC;
	sub_82110610(ctx, base);
	// lwz r11,1204(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1204);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
	// lwz r30,516(r24)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r24.u32 + 516);
	// lwz r29,548(r24)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r24.u32 + 548);
	// beq cr6,0x8212b540
	if (ctx.cr6.eq) goto loc_8212B540;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// mr r10,r21
	ctx.r10.u64 = ctx.r21.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,10460(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 10460);
	// stw r21,12268(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12268, ctx.r21.u32);
	// rlwinm r7,r8,0,0,27
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFF0;
	// stw r7,10460(r11)
	PPC_STORE_U32(ctx.r11.u32 + 10460, ctx.r7.u32);
	// ld r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// or r5,r6,r20
	ctx.r5.u64 = ctx.r6.u64 | ctx.r20.u64;
	// std r5,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r5.u64);
	// stw r21,1204(r24)
	PPC_STORE_U32(ctx.r24.u32 + 1204, ctx.r21.u32);
loc_8212B540:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82111340
	ctx.lr = 0x8212B54C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x82111340
	ctx.lr = 0x8212B558;
	sub_82111340(ctx, base);
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,5
	ctx.r5.s64 = 5;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x8212b098
	ctx.lr = 0x8212B570;
	sub_8212B098(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x82111340
	ctx.lr = 0x8212B57C;
	sub_82111340(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82111340
	ctx.lr = 0x8212B588;
	sub_82111340(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212B594;
	sub_82111340(ctx, base);
loc_8212B594:
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82110610
	ctx.lr = 0x8212B5A4;
	sub_82110610(ctx, base);
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x8212b098
	ctx.lr = 0x8212B5BC;
	sub_8212B098(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82110080
	ctx.lr = 0x8212B5C4;
	sub_82110080(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821104c8
	ctx.lr = 0x8212B5CC;
	sub_821104C8(ctx, base);
	// lwz r11,8(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212b5e0
	if (ctx.cr6.eq) goto loc_8212B5E0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r23)
	PPC_STORE_U32(ctx.r23.u32 + 8, ctx.r10.u32);
loc_8212B5E0:
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212b4a4
	if (!ctx.cr6.eq) goto loc_8212B4A4;
loc_8212B5EC:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x8233e490
	__restgprlr_18(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212B5F4"))) PPC_WEAK_FUNC(sub_8212B5F4);
PPC_FUNC_IMPL(__imp__sub_8212B5F4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212B5F8"))) PPC_WEAK_FUNC(sub_8212B5F8);
PPC_FUNC_IMPL(__imp__sub_8212B5F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8212B600;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r29,16(r4)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r11,12(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// rlwinm r10,r11,0,27,27
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8212b6d8
	if (!ctx.cr6.eq) goto loc_8212B6D8;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// lbz r30,28(r4)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r4.u32 + 28);
	// addi r10,r11,-27800
	ctx.r10.s64 = ctx.r11.s64 + -27800;
	// lwz r11,2120(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2120);
	// rlwinm r9,r11,0,29,29
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmpwi cr6,r9,0
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 0, ctx.xer);
	// beq cr6,0x8212b648
	if (ctx.cr6.eq) goto loc_8212B648;
	// lwz r11,44(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 44);
	// addi r4,r4,44
	ctx.r4.s64 = ctx.r4.s64 + 44;
	// b 0x8212b698
	goto loc_8212B698;
loc_8212B648:
	// lwz r11,92(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addi r4,r31,92
	ctx.r4.s64 = ctx.r31.s64 + 92;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212b668
	if (!ctx.cr6.eq) goto loc_8212B668;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// beq cr6,0x8212b66c
	if (ctx.cr6.eq) goto loc_8212B66C;
loc_8212B668:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8212B66C:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212b690
	if (!ctx.cr6.eq) goto loc_8212B690;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8212b3f8
	ctx.lr = 0x8212B690;
	sub_8212B3F8(ctx, base);
loc_8212B690:
	// lwz r11,68(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	// addi r4,r31,68
	ctx.r4.s64 = ctx.r31.s64 + 68;
loc_8212B698:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212b6b0
	if (!ctx.cr6.eq) goto loc_8212B6B0;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// beq cr6,0x8212b6b4
	if (ctx.cr6.eq) goto loc_8212B6B4;
loc_8212B6B0:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8212B6B4:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212b6d8
	if (!ctx.cr6.eq) goto loc_8212B6D8;
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// lwz r7,24(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r6,20(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8212b3f8
	ctx.lr = 0x8212B6D8;
	sub_8212B3F8(ctx, base);
loc_8212B6D8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212B6E0"))) PPC_WEAK_FUNC(sub_8212B6E0);
PPC_FUNC_IMPL(__imp__sub_8212B6E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x8212B6E8;
	__restfpr_14(ctx, base);
	// stwu r1,-464(r1)
	ea = -464 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lis r8,-32250
	ctx.r8.s64 = -2113536000;
	// lwz r26,4(r3)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r9,r10,-27800
	ctx.r9.s64 = ctx.r10.s64 + -27800;
	// stw r4,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r4.u32);
	// addi r7,r8,31376
	ctx.r7.s64 = ctx.r8.s64 + 31376;
	// mr r25,r4
	ctx.r25.u64 = ctx.r4.u64;
	// mr r19,r3
	ctx.r19.u64 = ctx.r3.u64;
	// li r18,0
	ctx.r18.s64 = 0;
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r26.u32);
	// lwz r10,2120(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2120);
	// li r6,11
	ctx.r6.s64 = 11;
	// addi r5,r9,2120
	ctx.r5.s64 = ctx.r9.s64 + 2120;
	// lfs f0,36(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r3,r10,24,31,31
	ctx.r3.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0x1;
	// stfs f0,136(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// li r4,-1
	ctx.r4.s64 = -1;
	// stw r6,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r6.u32);
	// rlwinm r10,r10,20,31,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0x1;
	// stb r18,140(r1)
	PPC_STORE_U8(ctx.r1.u32 + 140, ctx.r18.u8);
	// stw r11,8(r25)
	PPC_STORE_U32(ctx.r25.u32 + 8, ctx.r11.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stb r18,141(r1)
	PPC_STORE_U8(ctx.r1.u32 + 141, ctx.r18.u8);
	// stw r18,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r18.u32);
	// stb r3,81(r1)
	PPC_STORE_U8(ctx.r1.u32 + 81, ctx.r3.u8);
	// stw r18,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r18.u32);
	// stb r10,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r10.u8);
	// stw r18,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r18.u32);
	// stw r18,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r18.u32);
	// stw r18,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r18.u32);
	// stw r5,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r5.u32);
	// stw r4,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r4.u32);
	// beq cr6,0x8212b77c
	if (ctx.cr6.eq) goto loc_8212B77C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r25)
	PPC_STORE_U32(ctx.r25.u32 + 8, ctx.r10.u32);
loc_8212B77C:
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212bb68
	if (ctx.cr6.eq) goto loc_8212BB68;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// addi r16,r11,27648
	ctx.r16.s64 = ctx.r11.s64 + 27648;
	// addi r20,r10,28184
	ctx.r20.s64 = ctx.r10.s64 + 28184;
loc_8212B798:
	// lwz r24,12(r27)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// lwz r17,20(r27)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// addi r9,r24,96
	ctx.r9.s64 = ctx.r24.s64 + 96;
	// addi r8,r24,20
	ctx.r8.s64 = ctx.r24.s64 + 20;
	// mr r4,r17
	ctx.r4.u64 = ctx.r17.u64;
	// lwz r7,92(r24)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r24.u32 + 92);
	// ld r5,4(r24)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r24.u32 + 4);
	// ld r6,12(r24)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r24.u32 + 12);
	// bl 0x8212ae60
	ctx.lr = 0x8212B7C0;
	sub_8212AE60(ctx, base);
	// lwz r14,16(r27)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// cmplwi cr6,r14,1
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 1, ctx.xer);
	// stw r14,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r14.u32);
	// ble cr6,0x8212b8a8
	if (!ctx.cr6.gt) goto loc_8212B8A8;
	// stw r18,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r18.u32);
	// rlwinm r11,r14,1,0,30
	ctx.r11.u64 = rotl64(ctx.r14.u32 | (ctx.r14.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r18,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r18.u32);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// add r11,r14,r11
	ctx.r11.u64 = ctx.r14.u64 + ctx.r11.u64;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// rlwinm r28,r11,5,0,26
	ctx.r28.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8210b178
	ctx.lr = 0x8212B7F4;
	sub_8210B178(ctx, base);
	// cmplwi cr6,r14,0
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 0, ctx.xer);
	// beq cr6,0x8212b854
	if (ctx.cr6.eq) goto loc_8212B854;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r31,r24,120
	ctx.r31.s64 = ctx.r24.s64 + 120;
	// mr r29,r14
	ctx.r29.u64 = ctx.r14.u64;
loc_8212B808:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// bl 0x82257a50
	ctx.lr = 0x8212B814;
	sub_82257A50(ctx, base);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// li r5,48
	ctx.r5.s64 = 48;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x8212B824;
	sub_8233E4E0(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// addi r5,r20,100
	ctx.r5.s64 = ctx.r20.s64 + 100;
	// bl 0x82257b38
	ctx.lr = 0x8212B834;
	sub_82257B38(ctx, base);
	// addi r3,r30,48
	ctx.r3.s64 = ctx.r30.s64 + 48;
	// addi r4,r1,240
	ctx.r4.s64 = ctx.r1.s64 + 240;
	// li r5,48
	ctx.r5.s64 = 48;
	// bl 0x8233e4e0
	ctx.lr = 0x8212B844;
	sub_8233E4E0(ctx, base);
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r31,r31,236
	ctx.r31.s64 = ctx.r31.s64 + 236;
	// addi r30,r30,96
	ctx.r30.s64 = ctx.r30.s64 + 96;
	// bne 0x8212b808
	if (!ctx.cr0.eq) goto loc_8212B808;
loc_8212B854:
	// lwz r11,272(r16)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r16.u32 + 272);
	// addi r8,r16,200
	ctx.r8.s64 = ctx.r16.s64 + 200;
	// lwz r9,268(r16)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r16.u32 + 268);
	// li r5,0
	ctx.r5.s64 = 0;
	// add r11,r28,r11
	ctx.r11.u64 = ctx.r28.u64 + ctx.r11.u64;
	// stb r18,264(r16)
	PPC_STORE_U8(ctx.r16.u32 + 264, ctx.r18.u8);
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,31
	ctx.r11.s64 = ctx.r11.s64 + 31;
	// mr r10,r18
	ctx.r10.u64 = ctx.r18.u64;
	// rlwinm r11,r11,0,0,26
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// stw r11,272(r16)
	PPC_STORE_U32(ctx.r16.u32 + 272, ctx.r11.u32);
	// lwzx r3,r7,r8
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lwz r6,24(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r4,r6,0,0,29
	ctx.r4.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFC;
	// bl 0x8222ee68
	ctx.lr = 0x8212B890;
	sub_8222EE68(ctx, base);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// li r22,4
	ctx.r22.s64 = 4;
	// stw r5,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r5.u32);
	// stw r4,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r4.u32);
	// b 0x8212b8ac
	goto loc_8212B8AC;
loc_8212B8A8:
	// mr r22,r18
	ctx.r22.u64 = ctx.r18.u64;
loc_8212B8AC:
	// addi r3,r24,120
	ctx.r3.s64 = ctx.r24.s64 + 120;
	// bl 0x82113ab8
	ctx.lr = 0x8212B8B4;
	sub_82113AB8(ctx, base);
	// lfs f0,184(r24)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 184);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,2896(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 2896, temp.u32);
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f13,188(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 188);
	ctx.f13.f64 = double(temp.f32);
	// cmpwi cr6,r17,0
	ctx.cr6.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// stfs f13,2900(r26)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r26.u32 + 2900, temp.u32);
	// rldicr r12,r12,48,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 48) & 0xFFFFFFFFFFFFFFFF;
	// lfs f12,192(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 192);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,2904(r26)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r26.u32 + 2904, temp.u32);
	// lfs f11,196(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 196);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,2908(r26)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r26.u32 + 2908, temp.u32);
	// ld r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r26.u32 + 0);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,0(r26)
	PPC_STORE_U64(ctx.r26.u32 + 0, ctx.r10.u64);
	// lbz r9,28(r27)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r27.u32 + 28);
	// stb r9,141(r1)
	PPC_STORE_U8(ctx.r1.u32 + 141, ctx.r9.u8);
	// ble cr6,0x8212b900
	if (!ctx.cr6.gt) goto loc_8212B900;
	// cmpwi cr6,r17,3
	ctx.cr6.compare<int32_t>(ctx.r17.s32, 3, ctx.xer);
	// ble cr6,0x8212b90c
	if (!ctx.cr6.gt) goto loc_8212B90C;
loc_8212B900:
	// cmpwi cr6,r17,9
	ctx.cr6.compare<int32_t>(ctx.r17.s32, 9, ctx.xer);
	// mr r11,r18
	ctx.r11.u64 = ctx.r18.u64;
	// bne cr6,0x8212b910
	if (!ctx.cr6.eq) goto loc_8212B910;
loc_8212B90C:
	// li r11,1
	ctx.r11.s64 = 1;
loc_8212B910:
	// lwz r21,24(r27)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r27.u32 + 24);
	// clrlwi r15,r11,24
	ctx.r15.u64 = ctx.r11.u32 & 0xFF;
	// lwz r11,0(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,8(r21)
	PPC_STORE_U32(ctx.r21.u32 + 8, ctx.r11.u32);
	// beq cr6,0x8212bb08
	if (ctx.cr6.eq) goto loc_8212BB08;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r21)
	PPC_STORE_U32(ctx.r21.u32 + 8, ctx.r10.u32);
loc_8212B930:
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r31,0(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// rlwinm r9,r10,0,27,27
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8212b960
	if (ctx.cr6.eq) goto loc_8212B960;
	// lwz r11,8(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212bb08
	if (ctx.cr6.eq) goto loc_8212BB08;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r21)
	PPC_STORE_U32(ctx.r21.u32 + 8, ctx.r10.u32);
	// b 0x8212bb00
	goto loc_8212BB00;
loc_8212B960:
	// not r10,r10
	ctx.r10.u64 = ~ctx.r10.u64;
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x8212b980
	if (!ctx.cr6.eq) goto loc_8212B980;
	// clrlwi r10,r15,24
	ctx.r10.u64 = ctx.r15.u32 & 0xFF;
	// stw r18,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r18.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8212b984
	if (!ctx.cr6.eq) goto loc_8212B984;
loc_8212B980:
	// stw r17,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r17.u32);
loc_8212B984:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r27,8(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r26,12(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r25,16(r11)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// stw r10,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r10.u32);
	// bl 0x8210f908
	ctx.lr = 0x8212B9A4;
	sub_8210F908(ctx, base);
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8210fb60
	ctx.lr = 0x8212B9B0;
	sub_8210FB60(ctx, base);
	// lbz r8,81(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 81);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8212ba94
	if (ctx.cr6.eq) goto loc_8212BA94;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// rlwinm r10,r11,18,31,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 18) & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8212b9d8
	if (!ctx.cr6.eq) goto loc_8212B9D8;
	// lbz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212ba94
	if (ctx.cr6.eq) goto loc_8212BA94;
loc_8212B9D8:
	// li r5,5
	ctx.r5.s64 = 5;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82110610
	ctx.lr = 0x8212B9E8;
	sub_82110610(ctx, base);
	// lwz r11,1204(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 1204);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
	// lwz r30,516(r20)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r20.u32 + 516);
	// lwz r29,548(r20)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r20.u32 + 548);
	// beq cr6,0x8212ba34
	if (ctx.cr6.eq) goto loc_8212BA34;
	// lwz r11,0(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	// li r12,1
	ctx.r12.s64 = 1;
	// mr r10,r18
	ctx.r10.u64 = ctx.r18.u64;
	// rldicr r12,r12,37,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 37) & 0xFFFFFFFFFFFFFFFF;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// stw r18,12268(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12268, ctx.r18.u32);
	// lwz r8,10460(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 10460);
	// rlwinm r7,r8,0,0,27
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFF0;
	// stw r7,10460(r11)
	PPC_STORE_U32(ctx.r11.u32 + 10460, ctx.r7.u32);
	// ld r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// or r5,r6,r12
	ctx.r5.u64 = ctx.r6.u64 | ctx.r12.u64;
	// std r5,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r5.u64);
	// stw r18,1204(r20)
	PPC_STORE_U32(ctx.r20.u32 + 1204, ctx.r18.u32);
loc_8212BA34:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82111340
	ctx.lr = 0x8212BA40;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x82111340
	ctx.lr = 0x8212BA4C;
	sub_82111340(ctx, base);
	// addi r10,r1,104
	ctx.r10.s64 = ctx.r1.s64 + 104;
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x8212a828
	ctx.lr = 0x8212BA70;
	sub_8212A828(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x82111340
	ctx.lr = 0x8212BA7C;
	sub_82111340(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x82111340
	ctx.lr = 0x8212BA88;
	sub_82111340(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212BA94;
	sub_82111340(ctx, base);
loc_8212BA94:
	// lbz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8212bad4
	if (!ctx.cr6.eq) goto loc_8212BAD4;
	// mr r5,r17
	ctx.r5.u64 = ctx.r17.u64;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82110610
	ctx.lr = 0x8212BAB0;
	sub_82110610(ctx, base);
	// addi r10,r1,104
	ctx.r10.s64 = ctx.r1.s64 + 104;
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// mr r8,r24
	ctx.r8.u64 = ctx.r24.u64;
	// mr r7,r23
	ctx.r7.u64 = ctx.r23.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x8212a828
	ctx.lr = 0x8212BAD4;
	sub_8212A828(ctx, base);
loc_8212BAD4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82110080
	ctx.lr = 0x8212BADC;
	sub_82110080(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821104c8
	ctx.lr = 0x8212BAE4;
	sub_821104C8(ctx, base);
	// lwz r11,8(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212baf8
	if (ctx.cr6.eq) goto loc_8212BAF8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r21)
	PPC_STORE_U32(ctx.r21.u32 + 8, ctx.r10.u32);
loc_8212BAF8:
	// lwz r26,92(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r25,96(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_8212BB00:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212b930
	if (!ctx.cr6.eq) goto loc_8212B930;
loc_8212BB08:
	// cmplwi cr6,r14,1
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 1, ctx.xer);
	// ble cr6,0x8212bb48
	if (!ctx.cr6.gt) goto loc_8212BB48;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8212BB2C;
	sub_8222CC48(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8212BB48;
	sub_8222CC48(ctx, base);
loc_8212BB48:
	// lwz r11,8(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212bb5c
	if (ctx.cr6.eq) goto loc_8212BB5C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r25)
	PPC_STORE_U32(ctx.r25.u32 + 8, ctx.r10.u32);
loc_8212BB5C:
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212b798
	if (!ctx.cr6.eq) goto loc_8212B798;
loc_8212BB68:
	// addi r1,r1,464
	ctx.r1.s64 = ctx.r1.s64 + 464;
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212BB70"))) PPC_WEAK_FUNC(sub_8212BB70);
PPC_FUNC_IMPL(__imp__sub_8212BB70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x8212BB78;
	__restfpr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x8233fa38
	ctx.lr = 0x8212BB80;
	sub_8233FA38(ctx, base);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r27,16(r4)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mr r16,r3
	ctx.r16.u64 = ctx.r3.u64;
	// mr r21,r4
	ctx.r21.u64 = ctx.r4.u64;
	// lwz r10,12(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r27.u32);
	// rlwinm r11,r10,0,27,27
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212c264
	if (!ctx.cr6.eq) goto loc_8212C264;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// lwz r20,24(r4)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// lis r9,-32250
	ctx.r9.s64 = -2113536000;
	// lwz r30,4(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r19,r11,-27800
	ctx.r19.s64 = ctx.r11.s64 + -27800;
	// lwz r14,12(r4)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r17,20(r4)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// addi r8,r9,31376
	ctx.r8.s64 = ctx.r9.s64 + 31376;
	// lwz r18,28(r4)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// addi r26,r11,28184
	ctx.r26.s64 = ctx.r11.s64 + 28184;
	// lwz r7,0(r20)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r20.u32 + 0);
	// li r24,1
	ctx.r24.s64 = 1;
	// lwz r11,2120(r19)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r19.u32 + 2120);
	// li r15,0
	ctx.r15.s64 = 0;
	// rlwinm r6,r11,0,23,27
	ctx.r6.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1F0;
	// lfs f30,36(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// lfs f31,48(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// lwz r11,136(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 136);
	// rlwinm r6,r6,0,25,23
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
	// cmpwi cr6,r6,0
	ctx.cr6.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// beq cr6,0x8212bf7c
	if (ctx.cr6.eq) goto loc_8212BF7C;
	// rlwinm r10,r10,0,14,14
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20000;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212bf7c
	if (ctx.cr6.eq) goto loc_8212BF7C;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r31,416(r27)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r27.u32 + 416);
	// li r9,1
	ctx.r9.s64 = 1;
	// li r22,0
	ctx.r22.s64 = 0;
	// rldicr r23,r10,44,63
	ctx.r23.u64 = rotl64(ctx.r10.u64, 44) & 0xFFFFFFFFFFFFFFFF;
	// rldicr r28,r9,63,63
	ctx.r28.u64 = rotl64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// li r25,2
	ctx.r25.s64 = 2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212be08
	if (ctx.cr6.eq) goto loc_8212BE08;
	// lwz r10,32(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r15,r9,r11
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// cmplwi cr6,r15,0
	ctx.cr6.compare<uint32_t>(ctx.r15.u32, 0, ctx.xer);
	// beq cr6,0x8212be08
	if (ctx.cr6.eq) goto loc_8212BE08;
	// lwz r11,0(r15)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212be08
	if (ctx.cr6.eq) goto loc_8212BE08;
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212bc60
	if (ctx.cr6.eq) goto loc_8212BC60;
	// bl 0x820b91d0
	ctx.lr = 0x8212BC5C;
	sub_820B91D0(ctx, base);
	// b 0x8212bc7c
	goto loc_8212BC7C;
loc_8212BC60:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212bc74
	if (ctx.cr6.eq) goto loc_8212BC74;
	// lwz r27,88(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x8212bc80
	goto loc_8212BC80;
loc_8212BC74:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x8212BC7C;
	sub_820B90A0(ctx, base);
loc_8212BC7C:
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
loc_8212BC80:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x8212be04
	if (ctx.cr6.eq) goto loc_8212BE04;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,4(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// mr r22,r24
	ctx.r22.u64 = ctx.r24.u64;
	// bl 0x82111400
	ctx.lr = 0x8212BC98;
	sub_82111400(ctx, base);
	// lwz r8,20(r27)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// lfs f0,56(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 56);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,60(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 60);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,64(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 64);
	ctx.f12.f64 = double(temp.f32);
	// add r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 + ctx.r11.u64;
	// stfs f31,7260(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7260, temp.u32);
	// stfs f0,7248(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7248, temp.u32);
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// stfs f13,7252(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7252, temp.u32);
	// stfs f12,7256(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7256, temp.u32);
	// ld r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r9,r10,r23
	ctx.r9.u64 = ctx.r10.u64 | ctx.r23.u64;
	// std r9,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r9.u64);
	// add r29,r11,r26
	ctx.r29.u64 = ctx.r11.u64 + ctx.r26.u64;
	// lwz r7,1972(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1972);
	// cmplwi cr6,r7,2
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 2, ctx.xer);
	// beq cr6,0x8212bd20
	if (ctx.cr6.eq) goto loc_8212BD20;
	// addi r10,r31,48
	ctx.r10.s64 = ctx.r31.s64 + 48;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r7,r31,32
	ctx.r7.s64 = ctx.r31.s64 + 32;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// clrldi r4,r7,32
	ctx.r4.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// add r5,r10,r9
	ctx.r5.u64 = ctx.r10.u64 + ctx.r9.u64;
	// srd r3,r28,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r4.u8 & 0x7F));
	// rlwinm r10,r5,3,0,28
	ctx.r10.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// rlwimi r9,r24,11,19,21
	ctx.r9.u64 = (rotl32(ctx.r24.u32, 11) & 0x1C00) | (ctx.r9.u64 & 0xFFFFFFFFFFFFE3FF);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r5,r3,r7
	ctx.r5.u64 = ctx.r3.u64 | ctx.r7.u64;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r25,1972(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1972, ctx.r25.u32);
loc_8212BD20:
	// lwz r11,1988(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212bd6c
	if (ctx.cr6.eq) goto loc_8212BD6C;
	// addi r10,r31,48
	ctx.r10.s64 = ctx.r31.s64 + 48;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r7,r31,32
	ctx.r7.s64 = ctx.r31.s64 + 32;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// clrldi r4,r7,32
	ctx.r4.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// add r5,r10,r9
	ctx.r5.u64 = ctx.r10.u64 + ctx.r9.u64;
	// srd r3,r28,r4
	ctx.r3.u64 = ctx.r4.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r4.u8 & 0x7F));
	// rlwinm r10,r5,3,0,28
	ctx.r10.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// rlwimi r9,r24,14,16,18
	ctx.r9.u64 = (rotl32(ctx.r24.u32, 14) & 0xE000) | (ctx.r9.u64 & 0xFFFFFFFFFFFF1FFF);
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r9.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r5,r3,r7
	ctx.r5.u64 = ctx.r3.u64 | ctx.r7.u64;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r25,1988(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1988, ctx.r25.u32);
loc_8212BD6C:
	// subfic r11,r8,1
	ctx.xer.ca = ctx.r8.u32 <= 1;
	ctx.r11.s64 = 1 - ctx.r8.s64;
	// lwz r9,2068(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2068);
	// subfe r11,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8212bdc4
	if (ctx.cr6.eq) goto loc_8212BDC4;
	// rlwinm r9,r31,1,0,30
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r8,r31,32
	ctx.r8.s64 = ctx.r31.s64 + 32;
	// add r7,r31,r9
	ctx.r7.u64 = ctx.r31.u64 + ctx.r9.u64;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// clrldi r5,r8,32
	ctx.r5.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// srd r4,r28,r5
	ctx.r4.u64 = ctx.r5.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r5.u8 & 0x7F));
	// lwz r3,1164(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r3,r10,23,7,8
	ctx.r3.u64 = (rotl32(ctx.r10.u32, 23) & 0x1800000) | (ctx.r3.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r3,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r3.u32);
	// ld r11,24(r6)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r6.u32 + 24);
	// or r9,r4,r11
	ctx.r9.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r9,24(r6)
	PPC_STORE_U64(ctx.r6.u32 + 24, ctx.r9.u64);
	// stw r10,2068(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2068, ctx.r10.u32);
loc_8212BDC4:
	// lwz r11,2052(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212bde4
	if (ctx.cr6.eq) goto loc_8212BDE4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8222c0a0
	ctx.lr = 0x8212BDE0;
	sub_8222C0A0(ctx, base);
	// stw r24,2052(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2052, ctx.r24.u32);
loc_8212BDE4:
	// lwz r11,2036(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212be04
	if (ctx.cr6.eq) goto loc_8212BE04;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8222c248
	ctx.lr = 0x8212BE00;
	sub_8222C248(ctx, base);
	// stw r24,2036(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2036, ctx.r24.u32);
loc_8212BE04:
	// lwz r27,80(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_8212BE08:
	// clrlwi r11,r22,24
	ctx.r11.u64 = ctx.r22.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212bf7c
	if (!ctx.cr6.eq) goto loc_8212BF7C;
	// stfs f30,7248(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7248, temp.u32);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// stfs f30,7252(r30)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7252, temp.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stfs f30,7256(r30)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7256, temp.u32);
	// stfs f31,7260(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7260, temp.u32);
	// ld r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r9,r10,r23
	ctx.r9.u64 = ctx.r10.u64 | ctx.r23.u64;
	// std r9,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r9.u64);
	// lwz r4,25796(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25796);
	// bl 0x82111400
	ctx.lr = 0x8212BE40;
	sub_82111400(ctx, base);
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r31,r11
	ctx.r8.u64 = ctx.r31.u64 + ctx.r11.u64;
	// rlwinm r11,r8,6,0,25
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0xFFFFFFC0;
	// add r29,r11,r26
	ctx.r29.u64 = ctx.r11.u64 + ctx.r26.u64;
	// lwz r7,1972(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1972);
	// cmplwi cr6,r7,2
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 2, ctx.xer);
	// beq cr6,0x8212be9c
	if (ctx.cr6.eq) goto loc_8212BE9C;
	// addi r10,r31,48
	ctx.r10.s64 = ctx.r31.s64 + 48;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r8,r31,32
	ctx.r8.s64 = ctx.r31.s64 + 32;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// clrldi r5,r8,32
	ctx.r5.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// add r6,r10,r9
	ctx.r6.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// srd r4,r28,r5
	ctx.r4.u64 = ctx.r5.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r5.u8 & 0x7F));
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// rlwimi r3,r24,11,19,21
	ctx.r3.u64 = (rotl32(ctx.r24.u32, 11) & 0x1C00) | (ctx.r3.u64 & 0xFFFFFFFFFFFFE3FF);
	// stwx r3,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r3.u32);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r10,r4,r11
	ctx.r10.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r10,24(r7)
	PPC_STORE_U64(ctx.r7.u32 + 24, ctx.r10.u64);
	// stw r25,1972(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1972, ctx.r25.u32);
loc_8212BE9C:
	// lwz r11,1988(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212bee8
	if (ctx.cr6.eq) goto loc_8212BEE8;
	// addi r10,r31,48
	ctx.r10.s64 = ctx.r31.s64 + 48;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r8,r31,32
	ctx.r8.s64 = ctx.r31.s64 + 32;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// clrldi r5,r8,32
	ctx.r5.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// add r6,r10,r9
	ctx.r6.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// srd r4,r28,r5
	ctx.r4.u64 = ctx.r5.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r5.u8 & 0x7F));
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// rlwimi r3,r24,14,16,18
	ctx.r3.u64 = (rotl32(ctx.r24.u32, 14) & 0xE000) | (ctx.r3.u64 & 0xFFFFFFFFFFFF1FFF);
	// stwx r3,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r3.u32);
	// ld r11,24(r11)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r10,r4,r11
	ctx.r10.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r10,24(r7)
	PPC_STORE_U64(ctx.r7.u32 + 24, ctx.r10.u64);
	// stw r25,1988(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1988, ctx.r25.u32);
loc_8212BEE8:
	// lwz r11,2068(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2068);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212bf34
	if (ctx.cr6.eq) goto loc_8212BF34;
	// rlwinm r10,r31,1,0,30
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r9,r31,32
	ctx.r9.s64 = ctx.r31.s64 + 32;
	// add r8,r31,r10
	ctx.r8.u64 = ctx.r31.u64 + ctx.r10.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// clrldi r6,r9,32
	ctx.r6.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// srd r5,r28,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r6.u8 & 0x7F));
	// lwz r4,1164(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r4,r24,24,7,8
	ctx.r4.u64 = (rotl32(ctx.r24.u32, 24) & 0x1800000) | (ctx.r4.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r4,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r4.u32);
	// ld r3,24(r7)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r7.u32 + 24);
	// or r11,r5,r3
	ctx.r11.u64 = ctx.r5.u64 | ctx.r3.u64;
	// std r11,24(r7)
	PPC_STORE_U64(ctx.r7.u32 + 24, ctx.r11.u64);
	// stw r25,2068(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2068, ctx.r25.u32);
loc_8212BF34:
	// lwz r11,2052(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212bf58
	if (ctx.cr6.eq) goto loc_8212BF58;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8222c0a0
	ctx.lr = 0x8212BF50;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2052, ctx.r11.u32);
loc_8212BF58:
	// lwz r11,2036(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212bf7c
	if (ctx.cr6.eq) goto loc_8212BF7C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8222c248
	ctx.lr = 0x8212BF74;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2036(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2036, ctx.r11.u32);
loc_8212BF7C:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82126bd8
	ctx.lr = 0x8212BF84;
	sub_82126BD8(ctx, base);
	// lis r9,-32171
	ctx.r9.s64 = -2108358656;
	// lbz r8,40(r21)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r21.u32 + 40);
	// li r7,-1
	ctx.r7.s64 = -1;
	// lwz r6,36(r21)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r21.u32 + 36);
	// addi r5,r19,2120
	ctx.r5.s64 = ctx.r19.s64 + 2120;
	// lis r11,-32171
	ctx.r11.s64 = -2108358656;
	// stfs f30,104(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stw r17,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r17.u32);
	// lwz r10,10572(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10572);
	// addi r11,r11,10556
	ctx.r11.s64 = ctx.r11.s64 + 10556;
	// stw r7,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r7.u32);
	// clrlwi r4,r10,31
	ctx.r4.u64 = ctx.r10.u32 & 0x1;
	// stb r8,109(r1)
	PPC_STORE_U8(ctx.r1.u32 + 109, ctx.r8.u8);
	// stw r5,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r5.u32);
	// stw r6,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r6.u32);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x8212bfe8
	if (!ctx.cr6.eq) goto loc_8212BFE8;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stfs f31,0(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// stfs f31,4(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 4, temp.u32);
	// fmr f0,f31
	ctx.f0.f64 = ctx.f31.f64;
	// stfs f31,8(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 8, temp.u32);
	// stw r10,10572(r9)
	PPC_STORE_U32(ctx.r9.u32 + 10572, ctx.r10.u32);
	// stfs f31,12(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 12, temp.u32);
	// b 0x8212bfec
	goto loc_8212BFEC;
loc_8212BFE8:
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
loc_8212BFEC:
	// stfs f0,6240(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6240, temp.u32);
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f0,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// addi r3,r20,120
	ctx.r3.s64 = ctx.r20.s64 + 120;
	// stfs f0,6244(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6244, temp.u32);
	// rldicr r12,r12,60,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 60) & 0xFFFFFFFFFFFFFFFF;
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6248(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6248, temp.u32);
	// lfs f0,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6252(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6252, temp.u32);
	// ld r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r10.u64);
	// bl 0x82113ab8
	ctx.lr = 0x8212C024;
	sub_82113AB8(ctx, base);
	// lfs f0,4(r20)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6288(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6288, temp.u32);
	// li r12,1
	ctx.r12.s64 = 1;
	// addi r9,r20,96
	ctx.r9.s64 = ctx.r20.s64 + 96;
	// rldicr r12,r12,59,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 59) & 0xFFFFFFFFFFFFFFFF;
	// addi r8,r20,20
	ctx.r8.s64 = ctx.r20.s64 + 20;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
	// lfs f13,8(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,6292(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6292, temp.u32);
	// lfs f12,12(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,6296(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6296, temp.u32);
	// lfs f11,16(r20)
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,6300(r30)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6300, temp.u32);
	// ld r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r6,r7,r12
	ctx.r6.u64 = ctx.r7.u64 | ctx.r12.u64;
	// std r6,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r6.u64);
	// lwz r7,92(r20)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r20.u32 + 92);
	// ld r5,4(r20)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r20.u32 + 4);
	// ld r6,12(r20)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r20.u32 + 12);
	// lwz r4,36(r21)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r21.u32 + 36);
	// bl 0x8212ae60
	ctx.lr = 0x8212C078;
	sub_8212AE60(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,32(r18)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r18.u32 + 32);
	// bl 0x8222cd68
	ctx.lr = 0x8212C084;
	sub_8222CD68(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// lbz r7,6(r18)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r18.u32 + 6);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r6,12(r18)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r18.u32 + 12);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r5,28(r18)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r18.u32 + 28);
	// bl 0x8222cc48
	ctx.lr = 0x8212C0A0;
	sub_8222CC48(ctx, base);
	// lbz r5,7(r18)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r18.u32 + 7);
	// rlwinm r4,r5,0,29,29
	ctx.r4.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x8212c0bc
	if (ctx.cr6.eq) goto loc_8212C0BC;
	// cmplwi cr6,r15,0
	ctx.cr6.compare<uint32_t>(ctx.r15.u32, 0, ctx.xer);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// bne cr6,0x8212c0c0
	if (!ctx.cr6.eq) goto loc_8212C0C0;
loc_8212C0BC:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8212C0C0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212c0f4
	if (ctx.cr6.eq) goto loc_8212C0F4;
	// lhz r11,24(r18)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r18.u32 + 24);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r5,r14,468
	ctx.r5.s64 = ctx.r14.s64 + 468;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwzx r6,r10,r15
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r15.u32);
	// bl 0x8222cc48
	ctx.lr = 0x8212C0F4;
	sub_8222CC48(ctx, base);
loc_8212C0F4:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8210f908
	ctx.lr = 0x8212C100;
	sub_8210F908(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,36(r21)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r21.u32 + 36);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82110610
	ctx.lr = 0x8212C114;
	sub_82110610(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8210fb60
	ctx.lr = 0x8212C11C;
	sub_8210FB60(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// lfs f0,200(r20)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 200);
	ctx.f0.f64 = double(temp.f32);
	// fmr f28,f30
	ctx.f28.f64 = ctx.f30.f64;
	// rldicr r28,r11,49,63
	ctx.r28.u64 = rotl64(ctx.r11.u64, 49) & 0xFFFFFFFFFFFFFFFF;
	// fcmpu cr6,f0,f30
	ctx.cr6.compare(ctx.f0.f64, ctx.f30.f64);
	// beq cr6,0x8212c16c
	if (ctx.cr6.eq) goto loc_8212C16C;
	// stfs f30,6944(r30)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6944, temp.u32);
	// fmr f28,f0
	ctx.f28.f64 = ctx.f0.f64;
	// stfs f0,6956(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6956, temp.u32);
	// stfs f30,6948(r30)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6948, temp.u32);
	// stfs f30,6952(r30)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6952, temp.u32);
	// ld r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r10,r11,r28
	ctx.r10.u64 = ctx.r11.u64 | ctx.r28.u64;
	// std r10,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r10.u64);
	// lwz r11,288(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 288);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x8212c16c
	if (!ctx.cr6.eq) goto loc_8212C16C;
	// li r3,12545
	ctx.r3.s64 = 12545;
	// lwz r4,368(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 368);
	// bl 0x82113bc0
	ctx.lr = 0x8212C16C;
	sub_82113BC0(ctx, base);
loc_8212C16C:
	// li r11,1
	ctx.r11.s64 = 1;
	// lfs f0,204(r20)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r20.u32 + 204);
	ctx.f0.f64 = double(temp.f32);
	// fmr f29,f31
	ctx.f29.f64 = ctx.f31.f64;
	// rldicr r27,r11,38,63
	ctx.r27.u64 = rotl64(ctx.r11.u64, 38) & 0xFFFFFFFFFFFFFFFF;
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// beq cr6,0x8212c1a4
	if (ctx.cr6.eq) goto loc_8212C1A4;
	// stfs f0,7664(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7664, temp.u32);
	// fmr f29,f0
	ctx.f29.f64 = ctx.f0.f64;
	// stfs f31,7668(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7668, temp.u32);
	// stfs f31,7672(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7672, temp.u32);
	// stfs f31,7676(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7676, temp.u32);
	// ld r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r10,r11,r27
	ctx.r10.u64 = ctx.r11.u64 | ctx.r27.u64;
	// std r10,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r10.u64);
loc_8212C1A4:
	// li r31,0
	ctx.r31.s64 = 0;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8212c1e0
	if (ctx.cr6.eq) goto loc_8212C1E0;
loc_8212C1B0:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x821103d0
	ctx.lr = 0x8212C1BC;
	sub_821103D0(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,6
	ctx.r4.s64 = 6;
	// lwz r7,0(r18)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r18.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r6,16(r18)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r18.u32 + 16);
	// bl 0x8222e3e0
	ctx.lr = 0x8212C1D4;
	sub_8222E3E0(ctx, base);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r29
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r29.u32, ctx.xer);
	// blt cr6,0x8212c1b0
	if (ctx.cr6.lt) goto loc_8212C1B0;
loc_8212C1E0:
	// lwz r31,80(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82110080
	ctx.lr = 0x8212C1EC;
	sub_82110080(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821104c8
	ctx.lr = 0x8212C1F4;
	sub_821104C8(ctx, base);
	// fcmpu cr6,f28,f30
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f28.f64, ctx.f30.f64);
	// beq cr6,0x8212c218
	if (ctx.cr6.eq) goto loc_8212C218;
	// stfs f30,6944(r30)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6944, temp.u32);
	// stfs f30,6952(r30)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6952, temp.u32);
	// stfs f30,6956(r30)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6956, temp.u32);
	// stfs f30,6948(r30)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6948, temp.u32);
	// ld r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r10,r11,r28
	ctx.r10.u64 = ctx.r11.u64 | ctx.r28.u64;
	// std r10,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r10.u64);
loc_8212C218:
	// fcmpu cr6,f29,f31
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f29.f64, ctx.f31.f64);
	// beq cr6,0x8212c23c
	if (ctx.cr6.eq) goto loc_8212C23C;
	// stfs f31,7664(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7664, temp.u32);
	// stfs f31,7668(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7668, temp.u32);
	// stfs f31,7672(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7672, temp.u32);
	// stfs f31,7676(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7676, temp.u32);
	// ld r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r10,r11,r27
	ctx.r10.u64 = ctx.r11.u64 | ctx.r27.u64;
	// std r10,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r10.u64);
loc_8212C23C:
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8212C258;
	sub_8222CC48(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8222cd68
	ctx.lr = 0x8212C264;
	sub_8222CD68(ctx, base);
loc_8212C264:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x8233fa84
	ctx.lr = 0x8212C270;
	__savefpr_28(ctx, base);
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212C274"))) PPC_WEAK_FUNC(sub_8212C274);
PPC_FUNC_IMPL(__imp__sub_8212C274) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212C278"))) PPC_WEAK_FUNC(sub_8212C278);
PPC_FUNC_IMPL(__imp__sub_8212C278) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x8212C280;
	__restfpr_25(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r28,20(r4)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r11,12(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	// rlwinm r10,r11,0,27,27
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8212c50c
	if (!ctx.cr6.eq) goto loc_8212C50C;
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r30,4(r27)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// lwz r26,24(r4)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// lwz r29,16(r4)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// bl 0x82113ab8
	ctx.lr = 0x8212C2B4;
	sub_82113AB8(ctx, base);
	// lfs f0,32(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	ctx.f0.f64 = double(temp.f32);
	// li r12,1
	ctx.r12.s64 = 1;
	// stfs f0,6288(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6288, temp.u32);
	// addi r9,r31,124
	ctx.r9.s64 = ctx.r31.s64 + 124;
	// lfs f13,36(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// rldicr r12,r12,59,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 59) & 0xFFFFFFFFFFFFFFFF;
	// stfs f13,6292(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6292, temp.u32);
	// addi r8,r31,48
	ctx.r8.s64 = ctx.r31.s64 + 48;
	// lfs f12,40(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stfs f12,6296(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6296, temp.u32);
	// lfs f11,44(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,6300(r30)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + 6300, temp.u32);
	// ld r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r10.u64);
	// lwz r7,120(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	// ld r5,32(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// ld r6,40(r31)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r31.u32 + 40);
	// lwz r4,148(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 148);
	// bl 0x8212ae60
	ctx.lr = 0x8212C308;
	sub_8212AE60(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,60(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 60);
	// bl 0x8222cd68
	ctx.lr = 0x8212C314;
	sub_8222CD68(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// lbz r7,32(r29)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r29.u32 + 32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r6,40(r29)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r29.u32 + 40);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r5,56(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 56);
	// bl 0x8222cc48
	ctx.lr = 0x8212C330;
	sub_8222CC48(ctx, base);
	// lis r8,-32182
	ctx.r8.s64 = -2109079552;
	// lis r9,-32250
	ctx.r9.s64 = -2113536000;
	// lwz r5,148(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 148);
	// addi r11,r8,-27800
	ctx.r11.s64 = ctx.r8.s64 + -27800;
	// lbz r10,152(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 152);
	// addi r7,r9,31376
	ctx.r7.s64 = ctx.r9.s64 + 31376;
	// stw r26,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r26.u32);
	// addi r6,r11,2120
	ctx.r6.s64 = ctx.r11.s64 + 2120;
	// li r26,0
	ctx.r26.s64 = 0;
	// li r25,-1
	ctx.r25.s64 = -1;
	// stw r6,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r6.u32);
	// stb r26,108(r1)
	PPC_STORE_U8(ctx.r1.u32 + 108, ctx.r26.u8);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lfs f0,36(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stw r26,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r26.u32);
	// stfs f0,104(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stw r26,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r26.u32);
	// stw r26,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r26.u32);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r25,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r25.u32);
	// stw r5,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r5.u32);
	// stb r10,109(r1)
	PPC_STORE_U8(ctx.r1.u32 + 109, ctx.r10.u8);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r11.u32);
	// bl 0x8210f908
	ctx.lr = 0x8212C394;
	sub_8210F908(ctx, base);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,148(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 148);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82110610
	ctx.lr = 0x8212C3A8;
	sub_82110610(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8210fb60
	ctx.lr = 0x8212C3B0;
	sub_8210FB60(ctx, base);
	// mr r31,r26
	ctx.r31.u64 = ctx.r26.u64;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x8212c3ec
	if (ctx.cr6.eq) goto loc_8212C3EC;
loc_8212C3BC:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x821103d0
	ctx.lr = 0x8212C3C8;
	sub_821103D0(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,6
	ctx.r4.s64 = 6;
	// lwz r7,28(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r6,44(r29)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r29.u32 + 44);
	// bl 0x8222e3e0
	ctx.lr = 0x8212C3E0;
	sub_8222E3E0(ctx, base);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplw cr6,r31,r27
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x8212c3bc
	if (ctx.cr6.lt) goto loc_8212C3BC;
loc_8212C3EC:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82110080
	ctx.lr = 0x8212C3F4;
	sub_82110080(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x821104c8
	ctx.lr = 0x8212C3FC;
	sub_821104C8(ctx, base);
	// lwz r29,12812(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12812);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8212c4f8
	if (ctx.cr6.eq) goto loc_8212C4F8;
	// lwz r11,11036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 11036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212c41c
	if (ctx.cr6.eq) goto loc_8212C41C;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// b 0x8212c4f8
	goto loc_8212C4F8;
loc_8212C41C:
	// lwz r11,11040(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 11040);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// and r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 & ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8212c4f8
	if (ctx.cr6.eq) goto loc_8212C4F8;
	// lwz r11,13912(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 13912);
	// lwz r10,13916(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 13916);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x8212c4d4
	if (ctx.cr6.lt) goto loc_8212C4D4;
	// li r5,128
	ctx.r5.s64 = 128;
	// lwz r31,13908(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 13908);
	// li r4,502
	ctx.r4.s64 = 502;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82230228
	ctx.lr = 0x8212C454;
	sub_82230228(ctx, base);
	// lbz r11,11069(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 11069);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212c470
	if (ctx.cr6.eq) goto loc_8212C470;
	// lwz r8,17120(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 17120);
	// b 0x8212c4c4
	goto loc_8212C4C4;
loc_8212C470:
	// rlwinm r11,r8,12,20,31
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 12) & 0xFFF;
	// stw r8,13908(r30)
	PPC_STORE_U32(ctx.r30.u32 + 13908, ctx.r8.u32);
	// clrlwi r10,r8,3
	ctx.r10.u64 = ctx.r8.u32 & 0x1FFFFFFF;
	// stw r26,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r26.u32);
	// addi r11,r11,512
	ctx.r11.s64 = ctx.r11.s64 + 512;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addis r3,r10,-16384
	ctx.r3.s64 = ctx.r10.s64 + -1073741824;
	// bne cr6,0x8212c4a4
	if (!ctx.cr6.eq) goto loc_8212C4A4;
	// lwz r11,13904(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 13904);
	// stw r3,112(r11)
	PPC_STORE_U32(ctx.r11.u32 + 112, ctx.r3.u32);
	// b 0x8212c4bc
	goto loc_8212C4BC;
loc_8212C4A4:
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// lwz r11,13912(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 13912);
	// subf r11,r31,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r31.s64;
	// addi r10,r11,-8
	ctx.r10.s64 = ctx.r11.s64 + -8;
	// srawi r9,r10,3
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 3;
	// stw r9,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r9.u32);
loc_8212C4BC:
	// addi r4,r3,2008
	ctx.r4.s64 = ctx.r3.s64 + 2008;
	// bl 0x8223b9b8
	ctx.lr = 0x8212C4C4;
	sub_8223B9B8(ctx, base);
loc_8212C4C4:
	// addi r11,r8,8
	ctx.r11.s64 = ctx.r8.s64 + 8;
	// addi r10,r8,2008
	ctx.r10.s64 = ctx.r8.s64 + 2008;
	// stw r11,13912(r30)
	PPC_STORE_U32(ctx.r30.u32 + 13912, ctx.r11.u32);
	// stw r10,13916(r30)
	PPC_STORE_U32(ctx.r30.u32 + 13916, ctx.r10.u32);
loc_8212C4D4:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r9,r11,8
	ctx.r9.s64 = ctx.r11.s64 + 8;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r25.u32);
	// rlwimi r10,r29,30,2,31
	ctx.r10.u64 = (rotl32(ctx.r29.u32, 30) & 0x3FFFFFFF) | (ctx.r10.u64 & 0xFFFFFFFFC0000000);
	// rlwinm r8,r10,0,2,0
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
	// ld r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r7,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r7.u64);
	// stw r9,13912(r30)
	PPC_STORE_U32(ctx.r30.u32 + 13912, ctx.r9.u32);
loc_8212C4F8:
	// stw r26,12812(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12812, ctx.r26.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stb r26,12880(r30)
	PPC_STORE_U8(ctx.r30.u32 + 12880, ctx.r26.u8);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8222cd68
	ctx.lr = 0x8212C50C;
	sub_8222CD68(ctx, base);
loc_8212C50C:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212C514"))) PPC_WEAK_FUNC(sub_8212C514);
PPC_FUNC_IMPL(__imp__sub_8212C514) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212C518"))) PPC_WEAK_FUNC(sub_8212C518);
PPC_FUNC_IMPL(__imp__sub_8212C518) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// lis r8,-32178
	ctx.r8.s64 = -2108817408;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r11,0
	ctx.r11.s64 = 0;
	// li r7,15
	ctx.r7.s64 = 15;
	// lfs f13,48(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// li r6,12
	ctx.r6.s64 = 12;
	// stfs f13,1452(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 1452, temp.u32);
	// stw r11,26076(r8)
	PPC_STORE_U32(ctx.r8.u32 + 26076, ctx.r11.u32);
	// stfs f13,1456(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 1456, temp.u32);
	// addi r3,r3,12
	ctx.r3.s64 = ctx.r3.s64 + 12;
	// lfs f0,36(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,1460(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1460, temp.u32);
	// stfs f0,1464(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1464, temp.u32);
	// stfs f0,1468(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1468, temp.u32);
	// stfs f0,1472(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1472, temp.u32);
	// stb r10,1476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1476, ctx.r10.u8);
	// lfs f12,964(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 964);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,1480(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1480, temp.u32);
	// stw r11,1676(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1676, ctx.r11.u32);
	// lfs f12,32(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// stw r11,1680(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1680, ctx.r11.u32);
	// stw r11,480(r31)
	PPC_STORE_U32(ctx.r31.u32 + 480, ctx.r11.u32);
	// stfs f12,1496(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1496, temp.u32);
	// stw r11,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r11.u32);
	// stfs f0,1500(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1500, temp.u32);
	// stw r11,464(r31)
	PPC_STORE_U32(ctx.r31.u32 + 464, ctx.r11.u32);
	// stfs f13,1504(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1504, temp.u32);
	// stw r11,472(r31)
	PPC_STORE_U32(ctx.r31.u32 + 472, ctx.r11.u32);
	// stfs f13,1508(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1508, temp.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// stfs f0,1512(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1512, temp.u32);
	// stb r11,1476(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1476, ctx.r11.u8);
	// stfs f0,1516(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1516, temp.u32);
	// stfs f0,1520(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1520, temp.u32);
	// stw r7,476(r31)
	PPC_STORE_U32(ctx.r31.u32 + 476, ctx.r7.u32);
	// stfs f13,1524(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1524, temp.u32);
	// stw r10,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r10.u32);
	// stfs f12,1528(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1528, temp.u32);
	// stw r6,460(r31)
	PPC_STORE_U32(ctx.r31.u32 + 460, ctx.r6.u32);
	// stfs f12,1532(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1532, temp.u32);
	// stw r10,468(r31)
	PPC_STORE_U32(ctx.r31.u32 + 468, ctx.r10.u32);
	// stfs f13,1536(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1536, temp.u32);
	// addi r11,r31,1452
	ctx.r11.s64 = ctx.r31.s64 + 1452;
	// stfs f0,1540(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 1540, temp.u32);
	// stfs f13,0(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// stfs f13,4(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 4, temp.u32);
	// bl 0x8212d380
	ctx.lr = 0x8212C5F0;
	sub_8212D380(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8212C608"))) PPC_WEAK_FUNC(sub_8212C608);
PPC_FUNC_IMPL(__imp__sub_8212C608) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,44
	ctx.r11.s64 = 2883584;
	// li r10,5
	ctx.r10.s64 = 5;
	// ori r11,r11,9125
	ctx.r11.u64 = ctx.r11.u64 | 9125;
	// li r9,0
	ctx.r9.s64 = 0;
	// stb r10,101(r1)
	PPC_STORE_U8(ctx.r1.u32 + 101, ctx.r10.u8);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// li r4,3
	ctx.r4.s64 = 3;
	// stb r9,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, ctx.r9.u8);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// bl 0x821160a8
	ctx.lr = 0x8212C648;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8212C64C;
	sub_82116360(ctx, base);
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r31,r11,-30672
	ctx.r31.s64 = ctx.r11.s64 + -30672;
	// beq cr6,0x8212c67c
	if (ctx.cr6.eq) goto loc_8212C67C;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r6,r11,-31152
	ctx.r6.s64 = ctx.r11.s64 + -31152;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C670;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25936(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25936, ctx.r3.u32);
	// b 0x8212c688
	goto loc_8212C688;
loc_8212C67C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25936(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25936, ctx.r11.u32);
loc_8212C688:
	// bl 0x82116360
	ctx.lr = 0x8212C68C;
	sub_82116360(ctx, base);
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r30,r11,-30048
	ctx.r30.s64 = ctx.r11.s64 + -30048;
	// beq cr6,0x8212c6bc
	if (ctx.cr6.eq) goto loc_8212C6BC;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-30352
	ctx.r6.s64 = ctx.r11.s64 + -30352;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C6B0;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25940(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25940, ctx.r3.u32);
	// b 0x8212c6c8
	goto loc_8212C6C8;
loc_8212C6BC:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25940(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25940, ctx.r11.u32);
loc_8212C6C8:
	// bl 0x82116360
	ctx.lr = 0x8212C6CC;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c6f4
	if (ctx.cr6.eq) goto loc_8212C6F4;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-29728
	ctx.r6.s64 = ctx.r11.s64 + -29728;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C6E8;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25948(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25948, ctx.r3.u32);
	// b 0x8212c700
	goto loc_8212C700;
loc_8212C6F4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25948(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25948, ctx.r11.u32);
loc_8212C700:
	// bl 0x82116360
	ctx.lr = 0x8212C704;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c72c
	if (ctx.cr6.eq) goto loc_8212C72C;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-29296
	ctx.r6.s64 = ctx.r11.s64 + -29296;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C720;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25952(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25952, ctx.r3.u32);
	// b 0x8212c738
	goto loc_8212C738;
loc_8212C72C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25952(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25952, ctx.r11.u32);
loc_8212C738:
	// bl 0x82116360
	ctx.lr = 0x8212C73C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c764
	if (ctx.cr6.eq) goto loc_8212C764;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-28864
	ctx.r6.s64 = ctx.r11.s64 + -28864;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C758;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25956(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25956, ctx.r3.u32);
	// b 0x8212c770
	goto loc_8212C770;
loc_8212C764:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25956(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25956, ctx.r11.u32);
loc_8212C770:
	// bl 0x82116360
	ctx.lr = 0x8212C774;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c79c
	if (ctx.cr6.eq) goto loc_8212C79C;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-28384
	ctx.r6.s64 = ctx.r11.s64 + -28384;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C790;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25960(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25960, ctx.r3.u32);
	// b 0x8212c7a8
	goto loc_8212C7A8;
loc_8212C79C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25960(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25960, ctx.r11.u32);
loc_8212C7A8:
	// bl 0x82116360
	ctx.lr = 0x8212C7AC;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c7d4
	if (ctx.cr6.eq) goto loc_8212C7D4;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r6,r11,-27904
	ctx.r6.s64 = ctx.r11.s64 + -27904;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C7C8;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25964(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25964, ctx.r3.u32);
	// b 0x8212c7e0
	goto loc_8212C7E0;
loc_8212C7D4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25964(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25964, ctx.r11.u32);
loc_8212C7E0:
	// bl 0x82116360
	ctx.lr = 0x8212C7E4;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c80c
	if (ctx.cr6.eq) goto loc_8212C80C;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r6,r11,-27312
	ctx.r6.s64 = ctx.r11.s64 + -27312;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C800;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25968(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25968, ctx.r3.u32);
	// b 0x8212c818
	goto loc_8212C818;
loc_8212C80C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25968(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25968, ctx.r11.u32);
loc_8212C818:
	// bl 0x82116360
	ctx.lr = 0x8212C81C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c844
	if (ctx.cr6.eq) goto loc_8212C844;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-26720
	ctx.r6.s64 = ctx.r11.s64 + -26720;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C838;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25972(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25972, ctx.r3.u32);
	// b 0x8212c850
	goto loc_8212C850;
loc_8212C844:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25972(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25972, ctx.r11.u32);
loc_8212C850:
	// bl 0x82116360
	ctx.lr = 0x8212C854;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c87c
	if (ctx.cr6.eq) goto loc_8212C87C;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-26320
	ctx.r6.s64 = ctx.r11.s64 + -26320;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C870;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25944(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25944, ctx.r3.u32);
	// b 0x8212c888
	goto loc_8212C888;
loc_8212C87C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25944(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25944, ctx.r11.u32);
loc_8212C888:
	// bl 0x82116360
	ctx.lr = 0x8212C88C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c8b4
	if (ctx.cr6.eq) goto loc_8212C8B4;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-25952
	ctx.r6.s64 = ctx.r11.s64 + -25952;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C8A8;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25988(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25988, ctx.r3.u32);
	// b 0x8212c8c0
	goto loc_8212C8C0;
loc_8212C8B4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25988(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25988, ctx.r11.u32);
loc_8212C8C0:
	// bl 0x82116360
	ctx.lr = 0x8212C8C4;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c8ec
	if (ctx.cr6.eq) goto loc_8212C8EC;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-25304
	ctx.r6.s64 = ctx.r11.s64 + -25304;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C8E0;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25992(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25992, ctx.r3.u32);
	// b 0x8212c8f8
	goto loc_8212C8F8;
loc_8212C8EC:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25992(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25992, ctx.r11.u32);
loc_8212C8F8:
	// bl 0x82116360
	ctx.lr = 0x8212C8FC;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c924
	if (ctx.cr6.eq) goto loc_8212C924;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-24360
	ctx.r6.s64 = ctx.r11.s64 + -24360;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C918;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25996(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25996, ctx.r3.u32);
	// b 0x8212c930
	goto loc_8212C930;
loc_8212C924:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25996(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25996, ctx.r11.u32);
loc_8212C930:
	// bl 0x82116360
	ctx.lr = 0x8212C934;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c95c
	if (ctx.cr6.eq) goto loc_8212C95C;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-23504
	ctx.r6.s64 = ctx.r11.s64 + -23504;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C950;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26000(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26000, ctx.r3.u32);
	// b 0x8212c968
	goto loc_8212C968;
loc_8212C95C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26000(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26000, ctx.r11.u32);
loc_8212C968:
	// bl 0x82116360
	ctx.lr = 0x8212C96C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c994
	if (ctx.cr6.eq) goto loc_8212C994;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-23104
	ctx.r6.s64 = ctx.r11.s64 + -23104;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C988;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26004(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26004, ctx.r3.u32);
	// b 0x8212c9a0
	goto loc_8212C9A0;
loc_8212C994:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26004(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26004, ctx.r11.u32);
loc_8212C9A0:
	// bl 0x82116360
	ctx.lr = 0x8212C9A4;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212c9cc
	if (ctx.cr6.eq) goto loc_8212C9CC;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-22704
	ctx.r6.s64 = ctx.r11.s64 + -22704;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C9C0;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26008(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26008, ctx.r3.u32);
	// b 0x8212c9d8
	goto loc_8212C9D8;
loc_8212C9CC:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26008(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26008, ctx.r11.u32);
loc_8212C9D8:
	// bl 0x82116360
	ctx.lr = 0x8212C9DC;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212ca04
	if (ctx.cr6.eq) goto loc_8212CA04;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-22352
	ctx.r6.s64 = ctx.r11.s64 + -22352;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212C9F8;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26012(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26012, ctx.r3.u32);
	// b 0x8212ca10
	goto loc_8212CA10;
loc_8212CA04:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26012(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26012, ctx.r11.u32);
loc_8212CA10:
	// bl 0x82116360
	ctx.lr = 0x8212CA14;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212ca3c
	if (ctx.cr6.eq) goto loc_8212CA3C;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-22000
	ctx.r6.s64 = ctx.r11.s64 + -22000;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CA30;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26016(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26016, ctx.r3.u32);
	// b 0x8212ca48
	goto loc_8212CA48;
loc_8212CA3C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26016(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26016, ctx.r11.u32);
loc_8212CA48:
	// bl 0x82116360
	ctx.lr = 0x8212CA4C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212ca74
	if (ctx.cr6.eq) goto loc_8212CA74;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-21528
	ctx.r6.s64 = ctx.r11.s64 + -21528;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CA68;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26020(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26020, ctx.r3.u32);
	// b 0x8212ca80
	goto loc_8212CA80;
loc_8212CA74:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26020(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26020, ctx.r11.u32);
loc_8212CA80:
	// bl 0x82116360
	ctx.lr = 0x8212CA84;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212caac
	if (ctx.cr6.eq) goto loc_8212CAAC;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-20864
	ctx.r6.s64 = ctx.r11.s64 + -20864;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CAA0;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26024(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26024, ctx.r3.u32);
	// b 0x8212cab8
	goto loc_8212CAB8;
loc_8212CAAC:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26024(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26024, ctx.r11.u32);
loc_8212CAB8:
	// bl 0x82116360
	ctx.lr = 0x8212CABC;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cae4
	if (ctx.cr6.eq) goto loc_8212CAE4;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-20144
	ctx.r6.s64 = ctx.r11.s64 + -20144;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CAD8;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26028(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26028, ctx.r3.u32);
	// b 0x8212caf0
	goto loc_8212CAF0;
loc_8212CAE4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26028(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26028, ctx.r11.u32);
loc_8212CAF0:
	// bl 0x82116360
	ctx.lr = 0x8212CAF4;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cb20
	if (ctx.cr6.eq) goto loc_8212CB20;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,-19584
	ctx.r6.s64 = ctx.r11.s64 + -19584;
	// addi r5,r10,-19056
	ctx.r5.s64 = ctx.r10.s64 + -19056;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CB14;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25976(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25976, ctx.r3.u32);
	// b 0x8212cb2c
	goto loc_8212CB2C;
loc_8212CB20:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25976(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25976, ctx.r11.u32);
loc_8212CB2C:
	// bl 0x82116360
	ctx.lr = 0x8212CB30;
	sub_82116360(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r31,r11,8368
	ctx.r31.s64 = ctx.r11.s64 + 8368;
	// beq cr6,0x8212cb60
	if (ctx.cr6.eq) goto loc_8212CB60;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r6,r11,8064
	ctx.r6.s64 = ctx.r11.s64 + 8064;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CB54;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25980(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25980, ctx.r3.u32);
	// b 0x8212cb6c
	goto loc_8212CB6C;
loc_8212CB60:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25980(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25980, ctx.r11.u32);
loc_8212CB6C:
	// bl 0x82116360
	ctx.lr = 0x8212CB70;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cb9c
	if (ctx.cr6.eq) goto loc_8212CB9C;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,-18744
	ctx.r6.s64 = ctx.r11.s64 + -18744;
	// addi r5,r10,-18408
	ctx.r5.s64 = ctx.r10.s64 + -18408;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CB90;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25984(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25984, ctx.r3.u32);
	// b 0x8212cba8
	goto loc_8212CBA8;
loc_8212CB9C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25984(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25984, ctx.r11.u32);
loc_8212CBA8:
	// bl 0x82116360
	ctx.lr = 0x8212CBAC;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cbd8
	if (ctx.cr6.eq) goto loc_8212CBD8;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,-18096
	ctx.r6.s64 = ctx.r11.s64 + -18096;
	// addi r5,r10,-15096
	ctx.r5.s64 = ctx.r10.s64 + -15096;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CBCC;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,26032(r9)
	PPC_STORE_U32(ctx.r9.u32 + 26032, ctx.r3.u32);
	// b 0x8212cbe4
	goto loc_8212CBE4;
loc_8212CBD8:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26032(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26032, ctx.r11.u32);
loc_8212CBE4:
	// bl 0x82116360
	ctx.lr = 0x8212CBE8;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cc10
	if (ctx.cr6.eq) goto loc_8212CC10;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-14784
	ctx.r6.s64 = ctx.r11.s64 + -14784;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CC04;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26036(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26036, ctx.r3.u32);
	// b 0x8212cc1c
	goto loc_8212CC1C;
loc_8212CC10:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26036(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26036, ctx.r11.u32);
loc_8212CC1C:
	// bl 0x82116360
	ctx.lr = 0x8212CC20;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cc48
	if (ctx.cr6.eq) goto loc_8212CC48;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-14224
	ctx.r6.s64 = ctx.r11.s64 + -14224;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CC3C;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26040(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26040, ctx.r3.u32);
	// b 0x8212cc54
	goto loc_8212CC54;
loc_8212CC48:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26040(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26040, ctx.r11.u32);
loc_8212CC54:
	// bl 0x82116360
	ctx.lr = 0x8212CC58;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cc80
	if (ctx.cr6.eq) goto loc_8212CC80;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-13752
	ctx.r6.s64 = ctx.r11.s64 + -13752;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CC74;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26044(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26044, ctx.r3.u32);
	// b 0x8212cc8c
	goto loc_8212CC8C;
loc_8212CC80:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26044(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26044, ctx.r11.u32);
loc_8212CC8C:
	// bl 0x82116360
	ctx.lr = 0x8212CC90;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212ccb8
	if (ctx.cr6.eq) goto loc_8212CCB8;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,-13280
	ctx.r6.s64 = ctx.r11.s64 + -13280;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CCAC;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26048(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26048, ctx.r3.u32);
	// b 0x8212ccc4
	goto loc_8212CCC4;
loc_8212CCB8:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26048(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26048, ctx.r11.u32);
loc_8212CCC4:
	// bl 0x82116360
	ctx.lr = 0x8212CCC8;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212ccf4
	if (ctx.cr6.eq) goto loc_8212CCF4;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,-12808
	ctx.r6.s64 = ctx.r11.s64 + -12808;
	// addi r5,r10,-11824
	ctx.r5.s64 = ctx.r10.s64 + -11824;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CCE8;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,26056(r9)
	PPC_STORE_U32(ctx.r9.u32 + 26056, ctx.r3.u32);
	// b 0x8212cd00
	goto loc_8212CD00;
loc_8212CCF4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26056(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26056, ctx.r11.u32);
loc_8212CD00:
	// bl 0x82116360
	ctx.lr = 0x8212CD04;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cd30
	if (ctx.cr6.eq) goto loc_8212CD30;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,-11448
	ctx.r6.s64 = ctx.r11.s64 + -11448;
	// addi r5,r10,-10328
	ctx.r5.s64 = ctx.r10.s64 + -10328;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CD24;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,26060(r9)
	PPC_STORE_U32(ctx.r9.u32 + 26060, ctx.r3.u32);
	// b 0x8212cd3c
	goto loc_8212CD3C;
loc_8212CD30:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26060(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26060, ctx.r11.u32);
loc_8212CD3C:
	// bl 0x82116360
	ctx.lr = 0x8212CD40;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cd6c
	if (ctx.cr6.eq) goto loc_8212CD6C;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,-10008
	ctx.r6.s64 = ctx.r11.s64 + -10008;
	// addi r5,r10,-9472
	ctx.r5.s64 = ctx.r10.s64 + -9472;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CD60;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,26064(r9)
	PPC_STORE_U32(ctx.r9.u32 + 26064, ctx.r3.u32);
	// b 0x8212cd78
	goto loc_8212CD78;
loc_8212CD6C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26064(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26064, ctx.r11.u32);
loc_8212CD78:
	// bl 0x82116360
	ctx.lr = 0x8212CD7C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cda4
	if (ctx.cr6.eq) goto loc_8212CDA4;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r6,r11,-9152
	ctx.r6.s64 = ctx.r11.s64 + -9152;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CD98;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,26068(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26068, ctx.r3.u32);
	// b 0x8212cdb0
	goto loc_8212CDB0;
loc_8212CDA4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26068(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26068, ctx.r11.u32);
loc_8212CDB0:
	// bl 0x82116360
	ctx.lr = 0x8212CDB4;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cde0
	if (ctx.cr6.eq) goto loc_8212CDE0;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,-7472
	ctx.r6.s64 = ctx.r11.s64 + -7472;
	// addi r5,r10,-6464
	ctx.r5.s64 = ctx.r10.s64 + -6464;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CDD4;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,26072(r9)
	PPC_STORE_U32(ctx.r9.u32 + 26072, ctx.r3.u32);
	// b 0x8212cdec
	goto loc_8212CDEC;
loc_8212CDE0:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26072(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26072, ctx.r11.u32);
loc_8212CDEC:
	// bl 0x82116360
	ctx.lr = 0x8212CDF0;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212ce1c
	if (ctx.cr6.eq) goto loc_8212CE1C;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,-6080
	ctx.r6.s64 = ctx.r11.s64 + -6080;
	// addi r5,r10,-5760
	ctx.r5.s64 = ctx.r10.s64 + -5760;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CE10;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,26052(r9)
	PPC_STORE_U32(ctx.r9.u32 + 26052, ctx.r3.u32);
	// b 0x8212ce28
	goto loc_8212CE28;
loc_8212CE1C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26052(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26052, ctx.r11.u32);
loc_8212CE28:
	// bl 0x82116360
	ctx.lr = 0x8212CE2C;
	sub_82116360(ctx, base);
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r31,r11,-4824
	ctx.r31.s64 = ctx.r11.s64 + -4824;
	// beq cr6,0x8212ce5c
	if (ctx.cr6.eq) goto loc_8212CE5C;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r6,r11,-5440
	ctx.r6.s64 = ctx.r11.s64 + -5440;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CE50;
	sub_8211C770(ctx, base);
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// stw r3,-25588(r10)
	PPC_STORE_U32(ctx.r10.u32 + -25588, ctx.r3.u32);
	// b 0x8212ce68
	goto loc_8212CE68;
loc_8212CE5C:
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,-25588(r10)
	PPC_STORE_U32(ctx.r10.u32 + -25588, ctx.r11.u32);
loc_8212CE68:
	// bl 0x82116360
	ctx.lr = 0x8212CE6C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212ce94
	if (ctx.cr6.eq) goto loc_8212CE94;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r6,r11,-4504
	ctx.r6.s64 = ctx.r11.s64 + -4504;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CE88;
	sub_8211C770(ctx, base);
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// stw r3,-25592(r10)
	PPC_STORE_U32(ctx.r10.u32 + -25592, ctx.r3.u32);
	// b 0x8212cea0
	goto loc_8212CEA0;
loc_8212CE94:
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,-25592(r10)
	PPC_STORE_U32(ctx.r10.u32 + -25592, ctx.r11.u32);
loc_8212CEA0:
	// bl 0x82116360
	ctx.lr = 0x8212CEA4;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cecc
	if (ctx.cr6.eq) goto loc_8212CECC;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r6,r11,-4008
	ctx.r6.s64 = ctx.r11.s64 + -4008;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CEC0;
	sub_8211C770(ctx, base);
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// stw r3,-25596(r10)
	PPC_STORE_U32(ctx.r10.u32 + -25596, ctx.r3.u32);
	// b 0x8212ced8
	goto loc_8212CED8;
loc_8212CECC:
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,-25596(r10)
	PPC_STORE_U32(ctx.r10.u32 + -25596, ctx.r11.u32);
loc_8212CED8:
	// bl 0x82116360
	ctx.lr = 0x8212CEDC;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cf04
	if (ctx.cr6.eq) goto loc_8212CF04;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r6,r11,-3328
	ctx.r6.s64 = ctx.r11.s64 + -3328;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212CEF8;
	sub_8211C770(ctx, base);
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// stw r3,-25600(r10)
	PPC_STORE_U32(ctx.r10.u32 + -25600, ctx.r3.u32);
	// b 0x8212cf10
	goto loc_8212CF10;
loc_8212CF04:
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,-25600(r10)
	PPC_STORE_U32(ctx.r10.u32 + -25600, ctx.r11.u32);
loc_8212CF10:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8212CF28"))) PPC_WEAK_FUNC(sub_8212CF28);
PPC_FUNC_IMPL(__imp__sub_8212CF28) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// lwz r3,25936(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25936);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cf50
	if (ctx.cr6.eq) goto loc_8212CF50;
	// bl 0x8211af20
	ctx.lr = 0x8212CF50;
	sub_8211AF20(ctx, base);
loc_8212CF50:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25936(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25936, ctx.r11.u32);
	// lwz r3,25940(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25940);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cf6c
	if (ctx.cr6.eq) goto loc_8212CF6C;
	// bl 0x8211af20
	ctx.lr = 0x8212CF6C;
	sub_8211AF20(ctx, base);
loc_8212CF6C:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25940(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25940, ctx.r11.u32);
	// lwz r3,25944(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25944);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cf88
	if (ctx.cr6.eq) goto loc_8212CF88;
	// bl 0x8211af20
	ctx.lr = 0x8212CF88;
	sub_8211AF20(ctx, base);
loc_8212CF88:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25944(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25944, ctx.r11.u32);
	// lwz r3,25948(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25948);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cfa4
	if (ctx.cr6.eq) goto loc_8212CFA4;
	// bl 0x8211af20
	ctx.lr = 0x8212CFA4;
	sub_8211AF20(ctx, base);
loc_8212CFA4:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25948(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25948, ctx.r11.u32);
	// lwz r3,25952(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25952);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cfc0
	if (ctx.cr6.eq) goto loc_8212CFC0;
	// bl 0x8211af20
	ctx.lr = 0x8212CFC0;
	sub_8211AF20(ctx, base);
loc_8212CFC0:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25952(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25952, ctx.r11.u32);
	// lwz r3,25956(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25956);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cfdc
	if (ctx.cr6.eq) goto loc_8212CFDC;
	// bl 0x8211af20
	ctx.lr = 0x8212CFDC;
	sub_8211AF20(ctx, base);
loc_8212CFDC:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25956(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25956, ctx.r11.u32);
	// lwz r3,25960(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25960);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212cff8
	if (ctx.cr6.eq) goto loc_8212CFF8;
	// bl 0x8211af20
	ctx.lr = 0x8212CFF8;
	sub_8211AF20(ctx, base);
loc_8212CFF8:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25960(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25960, ctx.r11.u32);
	// lwz r3,25964(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25964);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d014
	if (ctx.cr6.eq) goto loc_8212D014;
	// bl 0x8211af20
	ctx.lr = 0x8212D014;
	sub_8211AF20(ctx, base);
loc_8212D014:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25964(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25964, ctx.r11.u32);
	// lwz r3,25968(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25968);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d030
	if (ctx.cr6.eq) goto loc_8212D030;
	// bl 0x8211af20
	ctx.lr = 0x8212D030;
	sub_8211AF20(ctx, base);
loc_8212D030:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25968(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25968, ctx.r11.u32);
	// lwz r3,25972(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25972);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d04c
	if (ctx.cr6.eq) goto loc_8212D04C;
	// bl 0x8211af20
	ctx.lr = 0x8212D04C;
	sub_8211AF20(ctx, base);
loc_8212D04C:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25972, ctx.r11.u32);
	// lwz r3,25976(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25976);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d068
	if (ctx.cr6.eq) goto loc_8212D068;
	// bl 0x8211af20
	ctx.lr = 0x8212D068;
	sub_8211AF20(ctx, base);
loc_8212D068:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25976(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25976, ctx.r11.u32);
	// lwz r3,25980(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25980);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d084
	if (ctx.cr6.eq) goto loc_8212D084;
	// bl 0x8211af20
	ctx.lr = 0x8212D084;
	sub_8211AF20(ctx, base);
loc_8212D084:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25980(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25980, ctx.r11.u32);
	// lwz r3,25984(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25984);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d0a0
	if (ctx.cr6.eq) goto loc_8212D0A0;
	// bl 0x8211af20
	ctx.lr = 0x8212D0A0;
	sub_8211AF20(ctx, base);
loc_8212D0A0:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25984(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25984, ctx.r11.u32);
	// lwz r3,25988(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25988);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d0bc
	if (ctx.cr6.eq) goto loc_8212D0BC;
	// bl 0x8211af20
	ctx.lr = 0x8212D0BC;
	sub_8211AF20(ctx, base);
loc_8212D0BC:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25988, ctx.r11.u32);
	// lwz r3,25992(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25992);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d0d8
	if (ctx.cr6.eq) goto loc_8212D0D8;
	// bl 0x8211af20
	ctx.lr = 0x8212D0D8;
	sub_8211AF20(ctx, base);
loc_8212D0D8:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25992(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25992, ctx.r11.u32);
	// lwz r3,25996(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25996);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d0f4
	if (ctx.cr6.eq) goto loc_8212D0F4;
	// bl 0x8211af20
	ctx.lr = 0x8212D0F4;
	sub_8211AF20(ctx, base);
loc_8212D0F4:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25996(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25996, ctx.r11.u32);
	// lwz r3,26000(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 26000);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d110
	if (ctx.cr6.eq) goto loc_8212D110;
	// bl 0x8211af20
	ctx.lr = 0x8212D110;
	sub_8211AF20(ctx, base);
loc_8212D110:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26000(r30)
	PPC_STORE_U32(ctx.r30.u32 + 26000, ctx.r11.u32);
	// lwz r3,26004(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26004);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d12c
	if (ctx.cr6.eq) goto loc_8212D12C;
	// bl 0x8211af20
	ctx.lr = 0x8212D12C;
	sub_8211AF20(ctx, base);
loc_8212D12C:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26004(r31)
	PPC_STORE_U32(ctx.r31.u32 + 26004, ctx.r11.u32);
	// lwz r3,26008(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 26008);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d148
	if (ctx.cr6.eq) goto loc_8212D148;
	// bl 0x8211af20
	ctx.lr = 0x8212D148;
	sub_8211AF20(ctx, base);
loc_8212D148:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26008(r30)
	PPC_STORE_U32(ctx.r30.u32 + 26008, ctx.r11.u32);
	// lwz r3,26012(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26012);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d164
	if (ctx.cr6.eq) goto loc_8212D164;
	// bl 0x8211af20
	ctx.lr = 0x8212D164;
	sub_8211AF20(ctx, base);
loc_8212D164:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26012(r31)
	PPC_STORE_U32(ctx.r31.u32 + 26012, ctx.r11.u32);
	// lwz r3,26016(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 26016);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d180
	if (ctx.cr6.eq) goto loc_8212D180;
	// bl 0x8211af20
	ctx.lr = 0x8212D180;
	sub_8211AF20(ctx, base);
loc_8212D180:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26016(r30)
	PPC_STORE_U32(ctx.r30.u32 + 26016, ctx.r11.u32);
	// lwz r3,26020(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26020);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d19c
	if (ctx.cr6.eq) goto loc_8212D19C;
	// bl 0x8211af20
	ctx.lr = 0x8212D19C;
	sub_8211AF20(ctx, base);
loc_8212D19C:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 26020, ctx.r11.u32);
	// lwz r3,26024(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 26024);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d1b8
	if (ctx.cr6.eq) goto loc_8212D1B8;
	// bl 0x8211af20
	ctx.lr = 0x8212D1B8;
	sub_8211AF20(ctx, base);
loc_8212D1B8:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26024(r30)
	PPC_STORE_U32(ctx.r30.u32 + 26024, ctx.r11.u32);
	// lwz r3,26028(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26028);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d1d4
	if (ctx.cr6.eq) goto loc_8212D1D4;
	// bl 0x8211af20
	ctx.lr = 0x8212D1D4;
	sub_8211AF20(ctx, base);
loc_8212D1D4:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26028(r31)
	PPC_STORE_U32(ctx.r31.u32 + 26028, ctx.r11.u32);
	// lwz r3,26036(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 26036);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d1f0
	if (ctx.cr6.eq) goto loc_8212D1F0;
	// bl 0x8211af20
	ctx.lr = 0x8212D1F0;
	sub_8211AF20(ctx, base);
loc_8212D1F0:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 26036, ctx.r11.u32);
	// lwz r3,26040(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26040);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d20c
	if (ctx.cr6.eq) goto loc_8212D20C;
	// bl 0x8211af20
	ctx.lr = 0x8212D20C;
	sub_8211AF20(ctx, base);
loc_8212D20C:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26040(r31)
	PPC_STORE_U32(ctx.r31.u32 + 26040, ctx.r11.u32);
	// lwz r3,26044(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 26044);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d228
	if (ctx.cr6.eq) goto loc_8212D228;
	// bl 0x8211af20
	ctx.lr = 0x8212D228;
	sub_8211AF20(ctx, base);
loc_8212D228:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26044(r30)
	PPC_STORE_U32(ctx.r30.u32 + 26044, ctx.r11.u32);
	// lwz r3,26048(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26048);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d244
	if (ctx.cr6.eq) goto loc_8212D244;
	// bl 0x8211af20
	ctx.lr = 0x8212D244;
	sub_8211AF20(ctx, base);
loc_8212D244:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26048(r31)
	PPC_STORE_U32(ctx.r31.u32 + 26048, ctx.r11.u32);
	// lwz r3,26052(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 26052);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d260
	if (ctx.cr6.eq) goto loc_8212D260;
	// bl 0x8211af20
	ctx.lr = 0x8212D260;
	sub_8211AF20(ctx, base);
loc_8212D260:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 26052, ctx.r11.u32);
	// lwz r3,26056(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26056);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d27c
	if (ctx.cr6.eq) goto loc_8212D27C;
	// bl 0x8211af20
	ctx.lr = 0x8212D27C;
	sub_8211AF20(ctx, base);
loc_8212D27C:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 26056, ctx.r11.u32);
	// lwz r3,26060(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 26060);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d298
	if (ctx.cr6.eq) goto loc_8212D298;
	// bl 0x8211af20
	ctx.lr = 0x8212D298;
	sub_8211AF20(ctx, base);
loc_8212D298:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26060(r30)
	PPC_STORE_U32(ctx.r30.u32 + 26060, ctx.r11.u32);
	// lwz r3,26064(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26064);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d2b4
	if (ctx.cr6.eq) goto loc_8212D2B4;
	// bl 0x8211af20
	ctx.lr = 0x8212D2B4;
	sub_8211AF20(ctx, base);
loc_8212D2B4:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26064(r31)
	PPC_STORE_U32(ctx.r31.u32 + 26064, ctx.r11.u32);
	// lwz r3,26068(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 26068);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d2d0
	if (ctx.cr6.eq) goto loc_8212D2D0;
	// bl 0x8211af20
	ctx.lr = 0x8212D2D0;
	sub_8211AF20(ctx, base);
loc_8212D2D0:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26068(r30)
	PPC_STORE_U32(ctx.r30.u32 + 26068, ctx.r11.u32);
	// lwz r3,26072(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26072);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d2ec
	if (ctx.cr6.eq) goto loc_8212D2EC;
	// bl 0x8211af20
	ctx.lr = 0x8212D2EC;
	sub_8211AF20(ctx, base);
loc_8212D2EC:
	// lis r30,-32182
	ctx.r30.s64 = -2109079552;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,26072(r31)
	PPC_STORE_U32(ctx.r31.u32 + 26072, ctx.r11.u32);
	// lwz r3,-25596(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + -25596);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d308
	if (ctx.cr6.eq) goto loc_8212D308;
	// bl 0x8211af20
	ctx.lr = 0x8212D308;
	sub_8211AF20(ctx, base);
loc_8212D308:
	// lis r31,-32182
	ctx.r31.s64 = -2109079552;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,-25596(r30)
	PPC_STORE_U32(ctx.r30.u32 + -25596, ctx.r11.u32);
	// lwz r3,-25588(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -25588);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d324
	if (ctx.cr6.eq) goto loc_8212D324;
	// bl 0x8211af20
	ctx.lr = 0x8212D324;
	sub_8211AF20(ctx, base);
loc_8212D324:
	// lis r30,-32182
	ctx.r30.s64 = -2109079552;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,-25588(r31)
	PPC_STORE_U32(ctx.r31.u32 + -25588, ctx.r11.u32);
	// lwz r3,-25592(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + -25592);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d340
	if (ctx.cr6.eq) goto loc_8212D340;
	// bl 0x8211af20
	ctx.lr = 0x8212D340;
	sub_8211AF20(ctx, base);
loc_8212D340:
	// lis r31,-32182
	ctx.r31.s64 = -2109079552;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,-25592(r30)
	PPC_STORE_U32(ctx.r30.u32 + -25592, ctx.r11.u32);
	// lwz r3,-25600(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -25600);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212d35c
	if (ctx.cr6.eq) goto loc_8212D35C;
	// bl 0x8211af20
	ctx.lr = 0x8212D35C;
	sub_8211AF20(ctx, base);
loc_8212D35C:
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,-25600(r31)
	PPC_STORE_U32(ctx.r31.u32 + -25600, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8212D37C"))) PPC_WEAK_FUNC(sub_8212D37C);
PPC_FUNC_IMPL(__imp__sub_8212D37C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212D380"))) PPC_WEAK_FUNC(sub_8212D380);
PPC_FUNC_IMPL(__imp__sub_8212D380) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x8212D388;
	__restfpr_25(ctx, base);
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x8233fa28
	ctx.lr = 0x8212D390;
	sub_8233FA28(ctx, base);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r9,5
	ctx.r9.s64 = 5;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// li r8,11
	ctx.r8.s64 = 11;
	// stw r9,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r9.u32);
	// li r7,16
	ctx.r7.s64 = 16;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// stw r8,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r8.u32);
	// li r26,0
	ctx.r26.s64 = 0;
	// stw r7,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r7.u32);
	// lfs f28,48(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	ctx.f28.f64 = double(temp.f32);
	// li r11,0
	ctx.r11.s64 = 0;
	// lfs f26,120(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 120);
	ctx.f26.f64 = double(temp.f32);
	// addi r27,r1,104
	ctx.r27.s64 = ctx.r1.s64 + 104;
	// lfs f27,60(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	ctx.f27.f64 = double(temp.f32);
	// fmr f0,f28
	ctx.f0.f64 = ctx.f28.f64;
loc_8212D3D4:
	// lwz r31,0(r27)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r28,r11,1
	ctx.r28.s64 = ctx.r11.s64 + 1;
	// li r30,0
	ctx.r30.s64 = 0;
	// clrldi r10,r28,32
	ctx.r10.u64 = ctx.r28.u64 & 0xFFFFFFFF;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f12,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r31,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r31.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f11,f12
	ctx.f11.f64 = double(ctx.f12.s64);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// fcfid f10,f13
	ctx.f10.f64 = double(ctx.f13.s64);
	// frsp f9,f11
	ctx.f9.f64 = double(float(ctx.f11.f64));
	// frsp f8,f10
	ctx.f8.f64 = double(float(ctx.f10.f64));
	// fmuls f31,f9,f27
	ctx.f31.f64 = double(float(ctx.f9.f64 * ctx.f27.f64));
	// fdivs f29,f26,f8
	ctx.f29.f64 = double(float(ctx.f26.f64 / ctx.f8.f64));
	// beq cr6,0x8212d484
	if (ctx.cr6.eq) goto loc_8212D484;
	// rlwinm r11,r26,4,0,27
	ctx.r11.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 4) & 0xFFFFFFF0;
	// fmuls f30,f0,f27
	ctx.f30.f64 = double(float(ctx.f0.f64 * ctx.f27.f64));
	// add r26,r31,r26
	ctx.r26.u64 = ctx.r31.u64 + ctx.r26.u64;
	// add r29,r11,r25
	ctx.r29.u64 = ctx.r11.u64 + ctx.r25.u64;
loc_8212D428:
	// clrldi r11,r30,32
	ctx.r11.u64 = ctx.r30.u64 & 0xFFFFFFFF;
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r11.u64);
	// lfd f0,96(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f0
	ctx.f13.f64 = double(ctx.f0.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// fmadds f25,f12,f29,f30
	ctx.f25.f64 = double(std::fma(float(ctx.f12.f64), float(ctx.f29.f64), float(ctx.f30.f64)));
	// fmr f1,f25
	ctx.f1.f64 = ctx.f25.f64;
	// bl 0x8233c950
	ctx.lr = 0x8212D448;
	sub_8233C950(ctx, base);
	// frsp f24,f1
	ctx.fpscr.disableFlushMode();
	ctx.f24.f64 = double(float(ctx.f1.f64));
	// fmr f1,f25
	ctx.f1.f64 = ctx.f25.f64;
	// bl 0x8233c870
	ctx.lr = 0x8212D454;
	sub_8233C870(ctx, base);
	// frsp f11,f1
	ctx.fpscr.disableFlushMode();
	ctx.f11.f64 = double(float(ctx.f1.f64));
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// fmuls f10,f24,f31
	ctx.f10.f64 = double(float(ctx.f24.f64 * ctx.f31.f64));
	// addi r29,r29,16
	ctx.r29.s64 = ctx.r29.s64 + 16;
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
	// stfs f10,0(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// stfs f28,8(r10)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// stfs f28,12(r10)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
	// fmuls f9,f11,f31
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// stfs f9,4(r10)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// blt cr6,0x8212d428
	if (ctx.cr6.lt) goto loc_8212D428;
loc_8212D484:
	// fmr f0,f29
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f29.f64;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// addi r27,r27,4
	ctx.r27.s64 = ctx.r27.s64 + 4;
	// cmplwi cr6,r28,2
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 2, ctx.xer);
	// blt cr6,0x8212d3d4
	if (ctx.cr6.lt) goto loc_8212D3D4;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// addi r12,r1,-64
	ctx.r12.s64 = ctx.r1.s64 + -64;
	// bl 0x8233fa74
	ctx.lr = 0x8212D4A8;
	__savefpr_24(ctx, base);
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212D4AC"))) PPC_WEAK_FUNC(sub_8212D4AC);
PPC_FUNC_IMPL(__imp__sub_8212D4AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212D4B0"))) PPC_WEAK_FUNC(sub_8212D4B0);
PPC_FUNC_IMPL(__imp__sub_8212D4B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x8212D4B8;
	__restfpr_24(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lfs f0,400(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 400);
	ctx.f0.f64 = double(temp.f32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stfs f0,1672(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 1672, temp.u32);
	// lwz r11,288(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 288);
	// rlwinm r10,r11,30,31,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x1;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// clrlwi r31,r11,31
	ctx.r31.u64 = ctx.r11.u32 & 0x1;
	// rlwinm r27,r11,31,31,31
	ctx.r27.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x1;
	// rlwinm r26,r11,17,31,31
	ctx.r26.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 17) & 0x1;
	// rlwinm r24,r11,29,31,31
	ctx.r24.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1;
	// rlwinm r25,r11,27,31,31
	ctx.r25.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212d518
	if (ctx.cr6.eq) goto loc_8212D518;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f13,80(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// lfs f0,48(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// beq cr6,0x8212d518
	if (ctx.cr6.eq) goto loc_8212D518;
	// lwz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// ori r10,r11,512
	ctx.r10.u64 = ctx.r11.u64 | 512;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
loc_8212D518:
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212D524;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8212D530;
	sub_821112B0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x8212D53C;
	sub_82113BC0(ctx, base);
	// clrlwi r11,r31,24
	ctx.r11.u64 = ctx.r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212d554
	if (ctx.cr6.eq) goto loc_8212D554;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8212ee90
	ctx.lr = 0x8212D554;
	sub_8212EE90(ctx, base);
loc_8212D554:
	// clrlwi r11,r27,24
	ctx.r11.u64 = ctx.r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212d574
	if (ctx.cr6.eq) goto loc_8212D574;
	// addi r4,r28,44
	ctx.r4.s64 = ctx.r28.s64 + 44;
	// lfs f2,396(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 396);
	ctx.f2.f64 = double(temp.f32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lfs f1,392(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 392);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821303c8
	ctx.lr = 0x8212D574;
	sub_821303C8(ctx, base);
loc_8212D574:
	// clrlwi r11,r26,24
	ctx.r11.u64 = ctx.r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212d594
	if (ctx.cr6.eq) goto loc_8212D594;
	// addi r4,r28,60
	ctx.r4.s64 = ctx.r28.s64 + 60;
	// lfs f2,396(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 396);
	ctx.f2.f64 = double(temp.f32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lfs f1,392(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 392);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82131910
	ctx.lr = 0x8212D594;
	sub_82131910(ctx, base);
loc_8212D594:
	// clrlwi r11,r25,24
	ctx.r11.u64 = ctx.r25.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212d624
	if (ctx.cr6.eq) goto loc_8212D624;
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// lwz r11,1680(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// lwz r26,292(r28)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r28.u32 + 292);
	// addi r31,r11,1056
	ctx.r31.s64 = ctx.r11.s64 + 1056;
	// addi r27,r11,2700
	ctx.r27.s64 = ctx.r11.s64 + 2700;
	// lbz r9,25549(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 25549);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x8212d5c4
	if (!ctx.cr6.eq) goto loc_8212D5C4;
	// addi r27,r11,2604
	ctx.r27.s64 = ctx.r11.s64 + 2604;
loc_8212D5C4:
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r11,640
	ctx.r3.s64 = ctx.r11.s64 + 640;
	// bl 0x8212eb18
	ctx.lr = 0x8212D5D4;
	sub_8212EB18(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8212eb18
	ctx.lr = 0x8212D5E4;
	sub_8212EB18(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8212eb18
	ctx.lr = 0x8212D5F4;
	sub_8212EB18(ctx, base);
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// addi r7,r28,144
	ctx.r7.s64 = ctx.r28.s64 + 144;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8212fd98
	ctx.lr = 0x8212D610;
	sub_8212FD98(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8212e530
	ctx.lr = 0x8212D624;
	sub_8212E530(ctx, base);
loc_8212D624:
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82132178
	ctx.lr = 0x8212D630;
	sub_82132178(ctx, base);
	// addi r4,r30,404
	ctx.r4.s64 = ctx.r30.s64 + 404;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// li r5,64
	ctx.r5.s64 = 64;
	// bl 0x8233e4e0
	ctx.lr = 0x8212D640;
	sub_8233E4E0(ctx, base);
	// addi r11,r30,320
	ctx.r11.s64 = ctx.r30.s64 + 320;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r11,48
	ctx.r4.s64 = ctx.r11.s64 + 48;
	// li r5,16
	ctx.r5.s64 = 16;
	// bl 0x8233e4e0
	ctx.lr = 0x8212D654;
	sub_8233E4E0(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// ld r5,320(r30)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r30.u32 + 320);
	// ld r6,328(r30)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r30.u32 + 328);
	// ld r7,336(r30)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r30.u32 + 336);
	// ld r8,344(r30)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r30.u32 + 344);
	// ld r9,352(r30)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r30.u32 + 352);
	// ld r10,360(r30)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r30.u32 + 360);
	// bl 0x8212d8d8
	ctx.lr = 0x8212D678;
	sub_8212D8D8(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8212d6c8
	ctx.lr = 0x8212D684;
	sub_8212D6C8(ctx, base);
	// clrlwi r11,r24,24
	ctx.r11.u64 = ctx.r24.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212d69c
	if (ctx.cr6.eq) goto loc_8212D69C;
	// addi r4,r28,88
	ctx.r4.s64 = ctx.r28.s64 + 88;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82131c90
	ctx.lr = 0x8212D69C;
	sub_82131C90(ctx, base);
loc_8212D69C:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8212D6A8;
	sub_821112B0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// li r4,7
	ctx.r4.s64 = 7;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212D6BC;
	sub_82111340(ctx, base);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212D6C4"))) PPC_WEAK_FUNC(sub_8212D6C4);
PPC_FUNC_IMPL(__imp__sub_8212D6C4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212D6C8"))) PPC_WEAK_FUNC(sub_8212D6C8);
PPC_FUNC_IMPL(__imp__sub_8212D6C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x8212D6D0;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r30,1676(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// rlwinm r10,r11,0,22,22
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x200;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212d8d0
	if (ctx.cr6.eq) goto loc_8212D8D0;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r27,r11,27648
	ctx.r27.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 36);
	// mr r26,r11
	ctx.r26.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212d714
	if (ctx.cr6.eq) goto loc_8212D714;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x8222f080
	ctx.lr = 0x8212D710;
	sub_8222F080(ctx, base);
	// lwz r11,36(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 36);
loc_8212D714:
	// lwz r10,1680(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// addi r5,r10,2844
	ctx.r5.s64 = ctx.r10.s64 + 2844;
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212d734
	if (ctx.cr6.eq) goto loc_8212D734;
	// stw r5,36(r27)
	PPC_STORE_U32(ctx.r27.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212D734;
	sub_8222CDF8(ctx, base);
loc_8212D734:
	// lwz r10,288(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 288);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// rlwinm r9,r10,0,17,17
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4000;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8212d75c
	if (ctx.cr6.eq) goto loc_8212D75C;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25980(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25980);
	// bl 0x8211c5f0
	ctx.lr = 0x8212D758;
	sub_8211C5F0(ctx, base);
	// b 0x8212d808
	goto loc_8212D808;
loc_8212D75C:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25976(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25976);
	// bl 0x8211c5f0
	ctx.lr = 0x8212D768;
	sub_8211C5F0(ctx, base);
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f0,80(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,7744(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7744, temp.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// rldicr r12,r12,36,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// stfs f0,7748(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7748, temp.u32);
	// stfs f0,7752(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7752, temp.u32);
	// stfs f0,7756(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7756, temp.u32);
	// ld r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r9,r10,r12
	ctx.r9.u64 = ctx.r10.u64 | ctx.r12.u64;
	// std r9,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r9.u64);
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// addi r4,r11,1004
	ctx.r4.s64 = ctx.r11.s64 + 1004;
	// bl 0x82111400
	ctx.lr = 0x8212D7A0;
	sub_82111400(ctx, base);
	// lwz r11,2292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2292);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212d7d4
	if (ctx.cr6.eq) goto loc_8212D7D4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwinm r7,r8,0,22,18
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFE3FF;
	// stw r7,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,16384
	ctx.r5.u64 = ctx.r6.u64 | 1073741824;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2292, ctx.r10.u32);
loc_8212D7D4:
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212d808
	if (ctx.cr6.eq) goto loc_8212D808;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwinm r7,r8,0,19,15
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFF1FFF;
	// stw r7,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,16384
	ctx.r5.u64 = ctx.r6.u64 | 1073741824;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r10.u32);
loc_8212D808:
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r4,r11,120
	ctx.r4.s64 = ctx.r11.s64 + 120;
	// bl 0x82111400
	ctx.lr = 0x8212D818;
	sub_82111400(ctx, base);
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212d84c
	if (ctx.cr6.eq) goto loc_8212D84C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwinm r7,r8,0,22,18
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFE3FF;
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_8212D84C:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212d880
	if (ctx.cr6.eq) goto loc_8212D880;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwinm r7,r8,0,19,15
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFF1FFF;
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8212D880:
	// bl 0x8210b0d8
	ctx.lr = 0x8212D884;
	sub_8210B0D8(ctx, base);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r5,r11,1004
	ctx.r5.s64 = ctx.r11.s64 + 1004;
	// lfs f1,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210af50
	ctx.lr = 0x8212D8B0;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 36);
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212d8d0
	if (ctx.cr6.eq) goto loc_8212D8D0;
	// stw r26,36(r27)
	PPC_STORE_U32(ctx.r27.u32 + 36, ctx.r26.u32);
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212D8D0;
	sub_8222CDF8(ctx, base);
loc_8212D8D0:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212D8D8"))) PPC_WEAK_FUNC(sub_8212D8D8);
PPC_FUNC_IMPL(__imp__sub_8212D8D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e454
	ctx.lr = 0x8212D8E0;
	__restfpr_23(ctx, base);
	// stfd f29,-104(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -104, ctx.f29.u64);
	// stfd f30,-96(r1)
	PPC_STORE_U64(ctx.r1.u32 + -96, ctx.f30.u64);
	// stfd f31,-88(r1)
	PPC_STORE_U64(ctx.r1.u32 + -88, ctx.f31.u64);
	// stwu r1,-944(r1)
	ea = -944 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// std r5,976(r1)
	PPC_STORE_U64(ctx.r1.u32 + 976, ctx.r5.u64);
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// std r6,984(r1)
	PPC_STORE_U64(ctx.r1.u32 + 984, ctx.r6.u64);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// std r7,992(r1)
	PPC_STORE_U64(ctx.r1.u32 + 992, ctx.r7.u64);
	// lwz r11,288(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 288);
	// std r8,1000(r1)
	PPC_STORE_U64(ctx.r1.u32 + 1000, ctx.r8.u64);
	// std r9,1008(r1)
	PPC_STORE_U64(ctx.r1.u32 + 1008, ctx.r9.u64);
	// std r10,1016(r1)
	PPC_STORE_U64(ctx.r1.u32 + 1016, ctx.r10.u64);
	// rlwinm r10,r11,0,18,18
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2000;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8212d940
	if (!ctx.cr6.eq) goto loc_8212D940;
	// lis r10,-32198
	ctx.r10.s64 = -2110128128;
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,-7284(r10)
	PPC_STORE_U8(ctx.r10.u32 + -7284, ctx.r11.u8);
	// addi r1,r1,944
	ctx.r1.s64 = ctx.r1.s64 + 944;
	// lfd f29,-104(r1)
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f30,-96(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// lfd f31,-88(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
loc_8212D940:
	// li r9,2
	ctx.r9.s64 = 2;
	// addi r11,r1,464
	ctx.r11.s64 = ctx.r1.s64 + 464;
	// addi r8,r1,984
	ctx.r8.s64 = ctx.r1.s64 + 984;
	// addi r10,r11,-24
	ctx.r10.s64 = ctx.r11.s64 + -24;
	// addi r11,r8,-12
	ctx.r11.s64 = ctx.r8.s64 + -12;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8212D958:
	// lfs f13,4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfsu f0,32(r11)
	ea = 32 + ctx.r11.u32;
	temp.u32 = PPC_LOAD_U32(ea);
	ctx.r11.u32 = ea;
	ctx.f0.f64 = double(temp.f32);
	// stfd f13,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.f13.u64);
	// stfd f12,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, ctx.f12.u64);
	// stfd f11,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.f11.u64);
	// stfd f10,32(r10)
	PPC_STORE_U64(ctx.r10.u32 + 32, ctx.f10.u64);
	// stfd f9,40(r10)
	PPC_STORE_U64(ctx.r10.u32 + 40, ctx.f9.u64);
	// stfd f8,48(r10)
	PPC_STORE_U64(ctx.r10.u32 + 48, ctx.f8.u64);
	// stfd f7,56(r10)
	PPC_STORE_U64(ctx.r10.u32 + 56, ctx.f7.u64);
	// stfdu f0,64(r10)
	ea = 64 + ctx.r10.u32;
	PPC_STORE_U64(ea, ctx.r0.u64);
	ctx.r10.u32 = ea;
	// bdnz 0x8212d958
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8212D958;
	// li r9,2
	ctx.r9.s64 = 2;
	// addi r11,r1,336
	ctx.r11.s64 = ctx.r1.s64 + 336;
	// addi r8,r1,1048
	ctx.r8.s64 = ctx.r1.s64 + 1048;
	// addi r10,r11,-24
	ctx.r10.s64 = ctx.r11.s64 + -24;
	// addi r11,r8,-12
	ctx.r11.s64 = ctx.r8.s64 + -12;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8212D9B4:
	// lfs f13,4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,24(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,28(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfsu f0,32(r11)
	ea = 32 + ctx.r11.u32;
	temp.u32 = PPC_LOAD_U32(ea);
	ctx.r11.u32 = ea;
	ctx.f0.f64 = double(temp.f32);
	// stfd f13,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.f13.u64);
	// stfd f12,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, ctx.f12.u64);
	// stfd f11,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.f11.u64);
	// stfd f10,32(r10)
	PPC_STORE_U64(ctx.r10.u32 + 32, ctx.f10.u64);
	// stfd f9,40(r10)
	PPC_STORE_U64(ctx.r10.u32 + 40, ctx.f9.u64);
	// stfd f8,48(r10)
	PPC_STORE_U64(ctx.r10.u32 + 48, ctx.f8.u64);
	// stfd f7,56(r10)
	PPC_STORE_U64(ctx.r10.u32 + 56, ctx.f7.u64);
	// stfdu f0,64(r10)
	ea = 64 + ctx.r10.u32;
	PPC_STORE_U64(ea, ctx.r0.u64);
	ctx.r10.u32 = ea;
	// bdnz 0x8212d9b4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8212D9B4;
	// addi r4,r1,576
	ctx.r4.s64 = ctx.r1.s64 + 576;
	// addi r3,r1,448
	ctx.r3.s64 = ctx.r1.s64 + 448;
	// bl 0x82133fd0
	ctx.lr = 0x8212DA04;
	sub_82133FD0(ctx, base);
	// lis r31,-32198
	ctx.r31.s64 = -2110128128;
	// lbz r11,-7284(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + -7284);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212da40
	if (ctx.cr6.eq) goto loc_8212DA40;
	// addi r5,r1,320
	ctx.r5.s64 = ctx.r1.s64 + 320;
	// addi r4,r23,1544
	ctx.r4.s64 = ctx.r23.s64 + 1544;
	// addi r3,r1,576
	ctx.r3.s64 = ctx.r1.s64 + 576;
	// bl 0x82133c88
	ctx.lr = 0x8212DA24;
	sub_82133C88(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stb r11,-7284(r31)
	PPC_STORE_U8(ctx.r31.u32 + -7284, ctx.r11.u8);
	// addi r1,r1,944
	ctx.r1.s64 = ctx.r1.s64 + 944;
	// lfd f29,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f30,-96(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// lfd f31,-88(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
loc_8212DA40:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f0,84(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 84);
	ctx.f0.f64 = double(temp.f32);
	// lwz r30,1676(r23)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r23.u32 + 1676);
	// addi r27,r11,31376
	ctx.r27.s64 = ctx.r11.s64 + 31376;
	// lfs f12,48(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,36(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	ctx.cr6.compare(ctx.f0.f64, ctx.f12.f64);
	// bge cr6,0x8212da94
	if (!ctx.cr6.lt) goto loc_8212DA94;
	// fmr f29,f12
	ctx.f29.f64 = ctx.f12.f64;
loc_8212DA64:
	// lfs f31,96(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 96);
	ctx.f31.f64 = double(temp.f32);
loc_8212DA68:
	// li r25,1
	ctx.r25.s64 = 1;
	// fmr f30,f13
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f13.f64;
	// fcmpu cr6,f31,f13
	ctx.cr6.compare(ctx.f31.f64, ctx.f13.f64);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// ble cr6,0x8212db14
	if (!ctx.cr6.gt) goto loc_8212DB14;
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
loc_8212DA80:
	// fnmsubs f0,f0,f29,f13
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = -double(std::fma(float(ctx.f0.f64), float(ctx.f29.f64), -float(ctx.f13.f64)));
	// fcmpu cr6,f0,f12
	ctx.cr6.compare(ctx.f0.f64, ctx.f12.f64);
	// bge cr6,0x8212dae4
	if (!ctx.cr6.lt) goto loc_8212DAE4;
	// fmr f0,f12
	ctx.f0.f64 = ctx.f12.f64;
	// b 0x8212daf0
	goto loc_8212DAF0;
loc_8212DA94:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// ble cr6,0x8212daa4
	if (!ctx.cr6.gt) goto loc_8212DAA4;
	// fmr f29,f13
	ctx.f29.f64 = ctx.f13.f64;
	// b 0x8212dab0
	goto loc_8212DAB0;
loc_8212DAA4:
	// fmr f29,f0
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f0.f64;
	// fcmpu cr6,f0,f12
	ctx.cr6.compare(ctx.f0.f64, ctx.f12.f64);
	// ble cr6,0x8212da64
	if (!ctx.cr6.gt) goto loc_8212DA64;
loc_8212DAB0:
	// fdivs f1,f13,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f13.f64 / ctx.f29.f64));
	// bl 0x8233ca30
	ctx.lr = 0x8212DAB8;
	sub_8233CA30(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64));
	// lfs f13,96(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,48(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x8212dad8
	if (!ctx.cr6.lt) goto loc_8212DAD8;
	// lfs f13,36(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// fmr f31,f0
	ctx.f31.f64 = ctx.f0.f64;
	// b 0x8212da68
	goto loc_8212DA68;
loc_8212DAD8:
	// fmr f31,f13
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f13.f64;
	// lfs f13,36(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// b 0x8212da68
	goto loc_8212DA68;
loc_8212DAE4:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// ble cr6,0x8212daf0
	if (!ctx.cr6.gt) goto loc_8212DAF0;
	// fmr f0,f13
	ctx.f0.f64 = ctx.f13.f64;
loc_8212DAF0:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// fadds f30,f0,f30
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = double(float(ctx.f0.f64 + ctx.f30.f64));
	// clrldi r10,r11,32
	ctx.r10.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f11,f0
	ctx.f11.f64 = double(ctx.f0.s64);
	// frsp f0,f11
	ctx.f0.f64 = double(float(ctx.f11.f64));
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// blt cr6,0x8212da80
	if (ctx.cr6.lt) goto loc_8212DA80;
loc_8212DB14:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,1680(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 1680);
	// addi r26,r11,27648
	ctx.r26.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,1932
	ctx.r5.s64 = ctx.r10.s64 + 1932;
	// lwz r11,36(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 36);
	// mr r24,r11
	ctx.r24.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212db40
	if (ctx.cr6.eq) goto loc_8212DB40;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x8222f080
	ctx.lr = 0x8212DB3C;
	sub_8222F080(ctx, base);
	// lwz r11,36(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 36);
loc_8212DB40:
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212db58
	if (ctx.cr6.eq) goto loc_8212DB58;
	// stw r5,36(r26)
	PPC_STORE_U32(ctx.r26.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212DB58;
	sub_8222CDF8(ctx, base);
loc_8212DB58:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r11,26072(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26072);
	// lwz r10,25980(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 25980);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r9,12216(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12216, ctx.r9.u32);
	// ld r8,16(r30)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r30.u32 + 16);
	// oris r7,r8,8
	ctx.r7.u64 = ctx.r8.u64 | 524288;
	// std r7,16(r30)
	PPC_STORE_U64(ctx.r30.u32 + 16, ctx.r7.u64);
	// lwz r4,8(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x8212DB88;
	sub_82238728(ctx, base);
	// lwz r11,26072(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26072);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x8212DB98;
	sub_82238380(ctx, base);
	// lwz r11,1680(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 1680);
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// addi r28,r11,120
	ctx.r28.s64 = ctx.r11.s64 + 120;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r5,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r5.u32);
	// stw r4,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r4.u32);
	// stw r3,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r3.u32);
	// stw r10,12(r6)
	PPC_STORE_U32(ctx.r6.u32 + 12, ctx.r10.u32);
	// lfs f12,104(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// fctidz f7,f0
	ctx.f7.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// fadds f9,f12,f0
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// lwz r11,152(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	// fadds f8,f11,f13
	ctx.f8.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fctidz f10,f13
	ctx.f10.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// stfd f10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f10.u64);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfd f7,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f7.u64);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// clrlwi r29,r11,26
	ctx.r29.u64 = ctx.r11.u32 & 0x3F;
	// stw r9,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r9.u32);
	// fctidz f6,f9
	ctx.f6.s64 = (ctx.f9.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f9.f64);
	// stfd f6,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f6.u64);
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// fctidz f5,f8
	ctx.f5.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f5,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f5.u64);
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r29,50
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 50, ctx.xer);
	// stw r8,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r8.u32);
	// stw r7,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r7.u32);
	// stw r6,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r6.u32);
	// bne cr6,0x8212dc38
	if (!ctx.cr6.eq) goto loc_8212DC38;
	// li r10,3
	ctx.r10.s64 = 3;
	// rlwimi r11,r10,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r10.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r28)
	PPC_STORE_U32(ctx.r28.u32 + 32, ctx.r11.u32);
loc_8212DC38:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,188(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 188);
	// li r8,0
	ctx.r8.s64 = 0;
	// lfs f1,36(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82227e30
	ctx.lr = 0x8212DC5C;
	sub_82227E30(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,32(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 32);
	// rlwimi r11,r29,0,26,31
	ctx.r11.u64 = (rotl32(ctx.r29.u32, 0) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r28)
	PPC_STORE_U32(ctx.r28.u32 + 32, ctx.r11.u32);
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x8212dc98
	if (ctx.cr6.eq) goto loc_8212DC98;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x8212DC94;
	sub_82237A38(ctx, base);
	// stw r28,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r28.u32);
loc_8212DC98:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212dccc
	if (ctx.cr6.eq) goto loc_8212DCCC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r25,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r25.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_8212DCCC:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212dd00
	if (ctx.cr6.eq) goto loc_8212DD00;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r25,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r25.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8212DD00:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// beq cr6,0x8212dd24
	if (ctx.cr6.eq) goto loc_8212DD24;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8212DD1C;
	sub_8222C0A0(ctx, base);
	// li r11,4
	ctx.r11.s64 = 4;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
loc_8212DD24:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// beq cr6,0x8212dd48
	if (ctx.cr6.eq) goto loc_8212DD48;
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8212DD40;
	sub_8222C248(ctx, base);
	// li r11,4
	ctx.r11.s64 = 4;
	// stw r11,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r11.u32);
loc_8212DD48:
	// lwz r11,1680(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 1680);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r4,r11,16
	ctx.r4.s64 = ctx.r11.s64 + 16;
	// bl 0x82111400
	ctx.lr = 0x8212DD58;
	sub_82111400(ctx, base);
	// lwz r11,2292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2292);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212dd8c
	if (ctx.cr6.eq) goto loc_8212DD8C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r25,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r25.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2292, ctx.r10.u32);
loc_8212DD8C:
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212ddc0
	if (ctx.cr6.eq) goto loc_8212DDC0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r25,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r25.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r10.u32);
loc_8212DDC0:
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212dde4
	if (ctx.cr6.eq) goto loc_8212DDE4;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x8212DDDC;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r11.u32);
loc_8212DDE4:
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212de08
	if (ctx.cr6.eq) goto loc_8212DE08;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x8212DE00;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r11.u32);
loc_8212DE08:
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// addi r3,r1,320
	ctx.r3.s64 = ctx.r1.s64 + 320;
	// bl 0x82133fd0
	ctx.lr = 0x8212DE14;
	sub_82133FD0(ctx, base);
	// addi r5,r1,448
	ctx.r5.s64 = ctx.r1.s64 + 448;
	// addi r4,r1,704
	ctx.r4.s64 = ctx.r1.s64 + 704;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x82133c88
	ctx.lr = 0x8212DE24;
	sub_82133C88(ctx, base);
	// addi r31,r23,1544
	ctx.r31.s64 = ctx.r23.s64 + 1544;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r3,r1,704
	ctx.r3.s64 = ctx.r1.s64 + 704;
	// bl 0x82133c88
	ctx.lr = 0x8212DE38;
	sub_82133C88(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x82133c10
	ctx.lr = 0x8212DE44;
	sub_82133C10(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82257a50
	ctx.lr = 0x8212DE50;
	sub_82257A50(ctx, base);
	// addi r5,r1,320
	ctx.r5.s64 = ctx.r1.s64 + 320;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,576
	ctx.r3.s64 = ctx.r1.s64 + 576;
	// bl 0x82133c88
	ctx.lr = 0x8212DE60;
	sub_82133C88(ctx, base);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x822365d8
	ctx.lr = 0x8212DE70;
	sub_822365D8(ctx, base);
	// lwz r8,120(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r10,124(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lfs f0,104(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 104);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f31,f0
	ctx.f13.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// lfs f0,48(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,7752(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7752, temp.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stfs f0,7756(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7756, temp.u32);
	// li r7,3
	ctx.r7.s64 = 3;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// rldicr r11,r11,36,63
	ctx.r11.u64 = rotl64(ctx.r11.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// std r10,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r10.u64);
	// lfs f0,36(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// fdivs f11,f0,f30
	ctx.f11.f64 = double(float(ctx.f0.f64 / ctx.f30.f64));
	// rldicr r7,r7,35,28
	ctx.r7.u64 = rotl64(ctx.r7.u64, 35) & 0xFFFFFFF800000000;
	// fdivs f12,f0,f31
	ctx.f12.f64 = double(float(ctx.f0.f64 / ctx.f31.f64));
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// li r4,110
	ctx.r4.s64 = 110;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lfd f10,80(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// lfd f9,96(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f8,f10
	ctx.f8.f64 = double(ctx.f10.s64);
	// fcfid f7,f9
	ctx.f7.f64 = double(ctx.f9.s64);
	// frsp f6,f8
	ctx.f6.f64 = double(float(ctx.f8.f64));
	// frsp f5,f7
	ctx.f5.f64 = double(float(ctx.f7.f64));
	// fdivs f4,f13,f6
	ctx.f4.f64 = double(float(ctx.f13.f64 / ctx.f6.f64));
	// stfs f4,7748(r30)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7748, temp.u32);
	// fdivs f3,f5,f6
	ctx.f3.f64 = double(float(ctx.f5.f64 / ctx.f6.f64));
	// stfs f3,7744(r30)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7744, temp.u32);
	// ld r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r8,r9,r11
	ctx.r8.u64 = ctx.r9.u64 | ctx.r11.u64;
	// std r8,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r8.u64);
	// stfs f11,7772(r30)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7772, temp.u32);
	// stfs f31,7760(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7760, temp.u32);
	// stfs f12,7764(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7764, temp.u32);
	// stfs f29,7768(r30)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7768, temp.u32);
	// ld r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 | ctx.r11.u64;
	// std r9,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r9.u64);
	// bl 0x82238120
	ctx.lr = 0x8212DF14;
	sub_82238120(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212DF18;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lfs f1,36(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210af50
	ctx.lr = 0x8212DF38;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 36);
	// cmplw cr6,r24,r11
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212df58
	if (ctx.cr6.eq) goto loc_8212DF58;
	// stw r24,36(r26)
	PPC_STORE_U32(ctx.r26.u32 + 36, ctx.r24.u32);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212DF58;
	sub_8222CDF8(ctx, base);
loc_8212DF58:
	// addi r1,r1,944
	ctx.r1.s64 = ctx.r1.s64 + 944;
	// lfd f29,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f30,-96(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// lfd f31,-88(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212DF6C"))) PPC_WEAK_FUNC(sub_8212DF6C);
PPC_FUNC_IMPL(__imp__sub_8212DF6C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212DF70"))) PPC_WEAK_FUNC(sub_8212DF70);
PPC_FUNC_IMPL(__imp__sub_8212DF70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x8212DF78;
	__restfpr_24(ctx, base);
	// stfd f31,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, ctx.f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r4
	ctx.r24.u64 = ctx.r4.u64;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x822365d8
	ctx.lr = 0x8212DF98;
	sub_822365D8(ctx, base);
	// lis r10,6690
	ctx.r10.s64 = 438435840;
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// ori r9,r10,346
	ctx.r9.u64 = ctx.r10.u64 | 346;
	// addi r30,r11,27648
	ctx.r30.s64 = ctx.r11.s64 + 27648;
	// subf r6,r7,r9
	ctx.r6.s64 = ctx.r9.s64 - ctx.r7.s64;
	// li r8,11
	ctx.r8.s64 = 11;
	// cntlzw r5,r6
	ctx.r5.u64 = ctx.r6.u32 == 0 ? 32 : __builtin_clz(ctx.r6.u32);
	// rlwinm r11,r5,27,31,31
	ctx.r11.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 27) & 0x1;
	// subfic r4,r11,0
	ctx.xer.ca = ctx.r11.u32 <= 0;
	ctx.r4.s64 = 0 - ctx.r11.s64;
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
	// subfe r11,r3,r3
	temp.u8 = (~ctx.r3.u32 + ctx.r3.u32 < ~ctx.r3.u32) | (~ctx.r3.u32 + ctx.r3.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r3.u64 + ctx.r3.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r26,r11,r8
	ctx.r26.u64 = ctx.r11.u64 & ctx.r8.u64;
	// lwz r31,36(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8212dfe0
	if (ctx.cr6.eq) goto loc_8212DFE0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222f080
	ctx.lr = 0x8212DFE0;
	sub_8222F080(ctx, base);
loc_8212DFE0:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82237900
	ctx.lr = 0x8212DFEC;
	sub_82237900(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x8212DFF4;
	sub_8222F0F8(ctx, base);
	// lis r11,6184
	ctx.r11.s64 = 405274624;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r25,1
	ctx.r25.s64 = 1;
	// ori r11,r11,32694
	ctx.r11.u64 = ctx.r11.u64 | 32694;
	// cmpw cr6,r9,r11
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r11.s32, ctx.xer);
	// beq cr6,0x8212e020
	if (ctx.cr6.eq) goto loc_8212E020;
	// lis r10,6184
	ctx.r10.s64 = 405274624;
	// ori r8,r10,438
	ctx.r8.u64 = ctx.r10.u64 | 438;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// cmpw cr6,r9,r8
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, ctx.xer);
	// bne cr6,0x8212e024
	if (!ctx.cr6.eq) goto loc_8212E024;
loc_8212E020:
	// li r10,0
	ctx.r10.s64 = 0;
loc_8212E024:
	// subf r11,r9,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r9.s64;
	// clrlwi r8,r10,24
	ctx.r8.u64 = ctx.r10.u32 & 0xFF;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r11,r10,27,31,31
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,1680(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// addi r5,r11,2988
	ctx.r5.s64 = ctx.r11.s64 + 2988;
	// bne cr6,0x8212e04c
	if (!ctx.cr6.eq) goto loc_8212E04C;
	// addi r5,r11,2940
	ctx.r5.s64 = ctx.r11.s64 + 2940;
loc_8212E04C:
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// addi r29,r11,796
	ctx.r29.s64 = ctx.r11.s64 + 796;
	// bne cr6,0x8212e05c
	if (!ctx.cr6.eq) goto loc_8212E05C;
	// addi r29,r11,744
	ctx.r29.s64 = ctx.r11.s64 + 744;
loc_8212E05C:
	// clrlwi r10,r8,24
	ctx.r10.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212e06c
	if (ctx.cr6.eq) goto loc_8212E06C;
	// addi r5,r11,2892
	ctx.r5.s64 = ctx.r11.s64 + 2892;
loc_8212E06C:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// addi r28,r11,2652
	ctx.r28.s64 = ctx.r11.s64 + 2652;
	// bne cr6,0x8212e080
	if (!ctx.cr6.eq) goto loc_8212E080;
	// addi r28,r11,2700
	ctx.r28.s64 = ctx.r11.s64 + 2700;
	// beq cr6,0x8212e084
	if (ctx.cr6.eq) goto loc_8212E084;
loc_8212E080:
	// addi r29,r11,692
	ctx.r29.s64 = ctx.r11.s64 + 692;
loc_8212E084:
	// lwz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212e0a0
	if (ctx.cr6.eq) goto loc_8212E0A0;
	// stw r5,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212E0A0;
	sub_8222CDF8(ctx, base);
loc_8212E0A0:
	// lwz r11,52(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212e0d8
	if (ctx.cr6.eq) goto loc_8212E0D8;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x8222f080
	ctx.lr = 0x8212E0B8;
	sub_8222F080(ctx, base);
	// lwz r11,52(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212e0d8
	if (ctx.cr6.eq) goto loc_8212E0D8;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,52(r30)
	PPC_STORE_U32(ctx.r30.u32 + 52, ctx.r11.u32);
	// bl 0x8222d188
	ctx.lr = 0x8212E0D8;
	sub_8222D188(ctx, base);
loc_8212E0D8:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// rlwinm r27,r26,26,0,5
	ctx.r27.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 26) & 0xFC000000;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lfs f31,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x8210af50
	ctx.lr = 0x8212E108;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212e128
	if (ctx.cr6.eq) goto loc_8212E128;
	// stw r28,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r28.u32);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212E128;
	sub_8222CDF8(ctx, base);
loc_8212E128:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8212e140
	if (ctx.cr6.eq) goto loc_8212E140;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8210b080
	ctx.lr = 0x8212E138;
	sub_8210B080(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x8212E140;
	sub_8222F0F8(ctx, base);
loc_8212E140:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x8212e170
	if (ctx.cr6.eq) goto loc_8212E170;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x8212E16C;
	sub_82237A38(ctx, base);
	// stw r29,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r29.u32);
loc_8212E170:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212e194
	if (ctx.cr6.eq) goto loc_8212E194;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8212E18C;
	sub_8222C0A0(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r25,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r25.u32);
loc_8212E194:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212e1b8
	if (ctx.cr6.eq) goto loc_8212E1B8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8212E1B0;
	sub_8222C248(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r25,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r25.u32);
loc_8212E1B8:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212e1ec
	if (ctx.cr6.eq) goto loc_8212E1EC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r25,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r25.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_8212E1EC:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212e220
	if (ctx.cr6.eq) goto loc_8212E220;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r25,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r25.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8212E220:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25980(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25980);
	// bl 0x8211c5f0
	ctx.lr = 0x8212E22C;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212E230;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8210af50
	ctx.lr = 0x8212E250;
	sub_8210AF50(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212E25C"))) PPC_WEAK_FUNC(sub_8212E25C);
PPC_FUNC_IMPL(__imp__sub_8212E25C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212E260"))) PPC_WEAK_FUNC(sub_8212E260);
PPC_FUNC_IMPL(__imp__sub_8212E260) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x8212E268;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// lwz r3,25940(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25940);
	// bl 0x8211c5f0
	ctx.lr = 0x8212E288;
	sub_8211C5F0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r30,1
	ctx.r30.s64 = 1;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212e2b8
	if (ctx.cr6.eq) goto loc_8212E2B8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8212E2B0;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_8212E2B8:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212e2ec
	if (ctx.cr6.eq) goto loc_8212E2EC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_8212E2EC:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212e320
	if (ctx.cr6.eq) goto loc_8212E320;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8212E320:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212e348
	if (ctx.cr6.eq) goto loc_8212E348;
	// stw r29,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r29.u32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212E348;
	sub_8222CDF8(ctx, base);
loc_8212E348:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8212E354;
	sub_821112B0(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8212E360;
	sub_82111400(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212E364;
	sub_8210B0D8(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// rlwinm r3,r26,26,0,5
	ctx.r3.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 26) & 0xFC000000;
	// lfs f1,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210af50
	ctx.lr = 0x8212E38C;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212e3b0
	if (ctx.cr6.eq) goto loc_8212E3B0;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x8212E3B0;
	sub_8222CDF8(ctx, base);
loc_8212E3B0:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212E3B8"))) PPC_WEAK_FUNC(sub_8212E3B8);
PPC_FUNC_IMPL(__imp__sub_8212E3B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8212E3C0;
	__restfpr_27(ctx, base);
	// stfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8212e3f8
	if (ctx.cr6.eq) goto loc_8212E3F8;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212E3F8;
	sub_8222CDF8(ctx, base);
loc_8212E3F8:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8212E404;
	sub_821112B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r30,1
	ctx.r30.s64 = 1;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212e434
	if (ctx.cr6.eq) goto loc_8212E434;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8212E42C;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_8212E434:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212e468
	if (ctx.cr6.eq) goto loc_8212E468;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_8212E468:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212e49c
	if (ctx.cr6.eq) goto loc_8212E49C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8212E49C:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25952(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25952);
	// bl 0x8211c5f0
	ctx.lr = 0x8212E4A8;
	sub_8211C5F0(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8212E4B4;
	sub_82111400(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212E4B8;
	sub_8210B0D8(ctx, base);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// rlwinm r31,r27,26,0,5
	ctx.r31.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 26) & 0xFC000000;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// lfs f31,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x8210af50
	ctx.lr = 0x8212E4E8;
	sub_8210AF50(ctx, base);
	// lis r8,-32178
	ctx.r8.s64 = -2108817408;
	// lwz r3,25948(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 25948);
	// bl 0x8211c5f0
	ctx.lr = 0x8212E4F4;
	sub_8211C5F0(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8212E500;
	sub_82111400(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212E504;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8210af50
	ctx.lr = 0x8212E524;
	sub_8210AF50(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212E530"))) PPC_WEAK_FUNC(sub_8212E530);
PPC_FUNC_IMPL(__imp__sub_8212E530) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8212E538;
	__restfpr_27(ctx, base);
	// stfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8212e570
	if (ctx.cr6.eq) goto loc_8212E570;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212E570;
	sub_8222CDF8(ctx, base);
loc_8212E570:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8212E57C;
	sub_821112B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r30,1
	ctx.r30.s64 = 1;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212e5ac
	if (ctx.cr6.eq) goto loc_8212E5AC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8212E5A4;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_8212E5AC:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212e5d0
	if (ctx.cr6.eq) goto loc_8212E5D0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8212E5C8;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_8212E5D0:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212e604
	if (ctx.cr6.eq) goto loc_8212E604;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_8212E604:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212e638
	if (ctx.cr6.eq) goto loc_8212E638;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8212E638:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25960(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25960);
	// bl 0x8211c5f0
	ctx.lr = 0x8212E644;
	sub_8211C5F0(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8212E650;
	sub_82111400(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212E654;
	sub_8210B0D8(ctx, base);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// rlwinm r31,r27,26,0,5
	ctx.r31.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 26) & 0xFC000000;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// lfs f31,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x8210af50
	ctx.lr = 0x8212E684;
	sub_8210AF50(ctx, base);
	// lis r8,-32178
	ctx.r8.s64 = -2108817408;
	// lwz r3,25956(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 25956);
	// bl 0x8211c5f0
	ctx.lr = 0x8212E690;
	sub_8211C5F0(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8212E69C;
	sub_82111400(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212E6A0;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8210af50
	ctx.lr = 0x8212E6C0;
	sub_8210AF50(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212E6CC"))) PPC_WEAK_FUNC(sub_8212E6CC);
PPC_FUNC_IMPL(__imp__sub_8212E6CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212E6D0"))) PPC_WEAK_FUNC(sub_8212E6D0);
PPC_FUNC_IMPL(__imp__sub_8212E6D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8212E6D8;
	__restfpr_27(ctx, base);
	// stfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8212e710
	if (ctx.cr6.eq) goto loc_8212E710;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212E710;
	sub_8222CDF8(ctx, base);
loc_8212E710:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8212E71C;
	sub_821112B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r30,1
	ctx.r30.s64 = 1;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212e74c
	if (ctx.cr6.eq) goto loc_8212E74C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8212E744;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_8212E74C:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212e770
	if (ctx.cr6.eq) goto loc_8212E770;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8212E768;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_8212E770:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212e7a4
	if (ctx.cr6.eq) goto loc_8212E7A4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_8212E7A4:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212e7d8
	if (ctx.cr6.eq) goto loc_8212E7D8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8212E7D8:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25968(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25968);
	// bl 0x8211c5f0
	ctx.lr = 0x8212E7E4;
	sub_8211C5F0(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8212E7F0;
	sub_82111400(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212E7F4;
	sub_8210B0D8(ctx, base);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// rlwinm r31,r27,26,0,5
	ctx.r31.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 26) & 0xFC000000;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// lfs f31,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x8210af50
	ctx.lr = 0x8212E824;
	sub_8210AF50(ctx, base);
	// lis r8,-32178
	ctx.r8.s64 = -2108817408;
	// lwz r3,25964(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 25964);
	// bl 0x8211c5f0
	ctx.lr = 0x8212E830;
	sub_8211C5F0(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8212E83C;
	sub_82111400(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212E840;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8210af50
	ctx.lr = 0x8212E860;
	sub_8210AF50(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212E86C"))) PPC_WEAK_FUNC(sub_8212E86C);
PPC_FUNC_IMPL(__imp__sub_8212E86C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212E870"))) PPC_WEAK_FUNC(sub_8212E870);
PPC_FUNC_IMPL(__imp__sub_8212E870) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8212E878;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,288(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 288);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// li r27,1
	ctx.r27.s64 = 1;
	// clrlwi r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212e8a4
	if (ctx.cr6.eq) goto loc_8212E8A4;
	// lbz r10,21(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 21);
	// mr r31,r27
	ctx.r31.u64 = ctx.r27.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8212e8a8
	if (!ctx.cr6.eq) goto loc_8212E8A8;
loc_8212E8A4:
	// li r31,0
	ctx.r31.s64 = 0;
loc_8212E8A8:
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// rlwinm r29,r11,27,31,31
	ctx.r29.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// rlwinm r30,r11,31,31,31
	ctx.r30.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x1;
	// bl 0x82111340
	ctx.lr = 0x8212E8BC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8212E8C8;
	sub_821112B0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x8212E8D4;
	sub_82113BC0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// clrlwi r10,r31,24
	ctx.r10.u64 = ctx.r31.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lbz r10,25549(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 25549);
	// beq cr6,0x8212e8f8
	if (ctx.cr6.eq) goto loc_8212E8F8;
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// bne cr6,0x8212e8fc
	if (!ctx.cr6.eq) goto loc_8212E8FC;
loc_8212E8F8:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8212E8FC:
	// clrlwi r9,r30,24
	ctx.r9.u64 = ctx.r30.u32 & 0xFF;
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x8212e918
	if (!ctx.cr6.eq) goto loc_8212E918;
	// clrlwi r9,r29,24
	ctx.r9.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8212e928
	if (ctx.cr6.eq) goto loc_8212E928;
loc_8212E918:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8212e92c
	if (!ctx.cr6.eq) goto loc_8212E92C;
loc_8212E928:
	// li r9,0
	ctx.r9.s64 = 0;
loc_8212E92C:
	// clrlwi r8,r11,24
	ctx.r8.u64 = ctx.r11.u32 & 0xFF;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// clrlwi r31,r9,24
	ctx.r31.u64 = ctx.r9.u32 & 0xFF;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// addi r29,r11,31376
	ctx.r29.s64 = ctx.r11.s64 + 31376;
	// addi r30,r10,27648
	ctx.r30.s64 = ctx.r10.s64 + 27648;
	// beq cr6,0x8212eaa4
	if (ctx.cr6.eq) goto loc_8212EAA4;
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// addi r4,r11,588
	ctx.r4.s64 = ctx.r11.s64 + 588;
	// bl 0x8212df70
	ctx.lr = 0x8212E95C;
	sub_8212DF70(ctx, base);
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// clrlwi r11,r31,24
	ctx.r11.u64 = ctx.r31.u32 & 0xFF;
	// ori r9,r10,2
	ctx.r9.u64 = ctx.r10.u64 | 2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r9,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r9.u32);
	// beq cr6,0x8212eacc
	if (ctx.cr6.eq) goto loc_8212EACC;
	// lwz r10,1680(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// lwz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// addi r5,r10,2700
	ctx.r5.s64 = ctx.r10.s64 + 2700;
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212e998
	if (ctx.cr6.eq) goto loc_8212E998;
	// stw r5,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212E998;
	sub_8222CDF8(ctx, base);
loc_8212E998:
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r4,r11,692
	ctx.r4.s64 = ctx.r11.s64 + 692;
	// bl 0x82111400
	ctx.lr = 0x8212E9A8;
	sub_82111400(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212e9d4
	if (ctx.cr6.eq) goto loc_8212E9D4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8212E9CC;
	sub_8222C0A0(ctx, base);
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r27.u32);
loc_8212E9D4:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212e9f8
	if (ctx.cr6.eq) goto loc_8212E9F8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8212E9F0;
	sub_8222C248(ctx, base);
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r27.u32);
loc_8212E9F8:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212ea2c
	if (ctx.cr6.eq) goto loc_8212EA2C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r27,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r27.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_8212EA2C:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212ea60
	if (ctx.cr6.eq) goto loc_8212EA60;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r27,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r27.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8212EA60:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25980(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25980);
	// bl 0x8211c5f0
	ctx.lr = 0x8212EA6C;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212EA70;
	sub_8210B0D8(ctx, base);
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// li r8,0
	ctx.r8.s64 = 0;
	// lfs f1,36(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r5,r11,640
	ctx.r5.s64 = ctx.r11.s64 + 640;
	// bl 0x8210af50
	ctx.lr = 0x8212EA94;
	sub_8210AF50(ctx, base);
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// ori r9,r10,8
	ctx.r9.u64 = ctx.r10.u64 | 8;
	// stw r9,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r9.u32);
	// b 0x8212eacc
	goto loc_8212EACC;
loc_8212EAA4:
	// clrlwi r11,r31,24
	ctx.r11.u64 = ctx.r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212eacc
	if (ctx.cr6.eq) goto loc_8212EACC;
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// addi r4,r11,640
	ctx.r4.s64 = ctx.r11.s64 + 640;
	// bl 0x8212df70
	ctx.lr = 0x8212EAC0;
	sub_8212DF70(ctx, base);
	// lwz r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// ori r10,r11,8
	ctx.r10.u64 = ctx.r11.u64 | 8;
	// stw r10,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r10.u32);
loc_8212EACC:
	// lwz r10,1680(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// lwz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// addi r5,r10,2460
	ctx.r5.s64 = ctx.r10.s64 + 2460;
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212eaf0
	if (ctx.cr6.eq) goto loc_8212EAF0;
	// stw r5,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212EAF0;
	sub_8222CDF8(ctx, base);
loc_8212EAF0:
	// li r6,0
	ctx.r6.s64 = 0;
	// lfs f1,48(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x8210afd8
	ctx.lr = 0x8212EB04;
	sub_8210AFD8(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212EB10;
	sub_82111340(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212EB18"))) PPC_WEAK_FUNC(sub_8212EB18);
PPC_FUNC_IMPL(__imp__sub_8212EB18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8212EB20;
	__restfpr_28(ctx, base);
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8212eb54
	if (ctx.cr6.eq) goto loc_8212EB54;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212EB54;
	sub_8222CDF8(ctx, base);
loc_8212EB54:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8212EB60;
	sub_821112B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r30,1
	ctx.r30.s64 = 1;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212eb90
	if (ctx.cr6.eq) goto loc_8212EB90;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8212EB88;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_8212EB90:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212ebb4
	if (ctx.cr6.eq) goto loc_8212EBB4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8212EBAC;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_8212EBB4:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212ebe8
	if (ctx.cr6.eq) goto loc_8212EBE8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_8212EBE8:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212ec1c
	if (ctx.cr6.eq) goto loc_8212EC1C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8212EC1C:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,26040(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26040);
	// bl 0x8211c5f0
	ctx.lr = 0x8212EC28;
	sub_8211C5F0(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8212EC34;
	sub_82111400(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212EC38;
	sub_8210B0D8(ctx, base);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lfs f31,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// li r3,0
	ctx.r3.s64 = 0;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x8210af50
	ctx.lr = 0x8212EC64;
	sub_8210AF50(ctx, base);
	// lis r8,-32178
	ctx.r8.s64 = -2108817408;
	// lwz r3,26044(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 26044);
	// bl 0x8211c5f0
	ctx.lr = 0x8212EC70;
	sub_8211C5F0(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8212EC7C;
	sub_82111400(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212EC80;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210af50
	ctx.lr = 0x8212ECA0;
	sub_8210AF50(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212ECAC"))) PPC_WEAK_FUNC(sub_8212ECAC);
PPC_FUNC_IMPL(__imp__sub_8212ECAC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212ECB0"))) PPC_WEAK_FUNC(sub_8212ECB0);
PPC_FUNC_IMPL(__imp__sub_8212ECB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8212ECB8;
	__restfpr_28(ctx, base);
	// stfd f30,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r29,1676(r3)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// fmr f31,f1
	ctx.f31.f64 = ctx.f1.f64;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// fmr f30,f2
	ctx.f30.f64 = ctx.f2.f64;
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r8,r10
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8212ed00
	if (ctx.cr6.eq) goto loc_8212ED00;
	// stw r8,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r8.u32);
	// mr r5,r8
	ctx.r5.u64 = ctx.r8.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212ED00;
	sub_8222CDF8(ctx, base);
loc_8212ED00:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8212ED0C;
	sub_821112B0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25972(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25972);
	// bl 0x8211c5f0
	ctx.lr = 0x8212ED18;
	sub_8211C5F0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82132d28
	ctx.lr = 0x8212ED28;
	sub_82132D28(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r9,1
	ctx.r9.s64 = 1;
	// addi r11,r11,28184
	ctx.r11.s64 = ctx.r11.s64 + 28184;
	// lwz r10,1972(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1972);
	// cmplwi cr6,r10,2
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 2, ctx.xer);
	// beq cr6,0x8212ed68
	if (ctx.cr6.eq) goto loc_8212ED68;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// li r8,2
	ctx.r8.s64 = 2;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// lwz r6,1152(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1152);
	// rlwimi r6,r9,11,19,21
	ctx.r6.u64 = (rotl32(ctx.r9.u32, 11) & 0x1C00) | (ctx.r6.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r6,1152(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1152, ctx.r6.u32);
	// ld r5,24(r10)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// oris r4,r5,32768
	ctx.r4.u64 = ctx.r5.u64 | 2147483648;
	// std r4,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r4.u64);
	// stw r8,1972(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1972, ctx.r8.u32);
loc_8212ED68:
	// lwz r10,1988(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1988);
	// cmplwi cr6,r10,2
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 2, ctx.xer);
	// beq cr6,0x8212ed9c
	if (ctx.cr6.eq) goto loc_8212ED9C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// li r8,2
	ctx.r8.s64 = 2;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// lwz r6,1152(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1152);
	// rlwimi r6,r9,14,16,18
	ctx.r6.u64 = (rotl32(ctx.r9.u32, 14) & 0xE000) | (ctx.r6.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r6,1152(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1152, ctx.r6.u32);
	// ld r5,24(r10)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// oris r4,r5,32768
	ctx.r4.u64 = ctx.r5.u64 | 2147483648;
	// std r4,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r4.u64);
	// stw r8,1988(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1988, ctx.r8.u32);
loc_8212ED9C:
	// lwz r10,2292(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2292);
	// cmplwi cr6,r10,2
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 2, ctx.xer);
	// beq cr6,0x8212edd0
	if (ctx.cr6.eq) goto loc_8212EDD0;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// li r8,2
	ctx.r8.s64 = 2;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// lwz r6,1176(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1176);
	// rlwimi r6,r9,11,19,21
	ctx.r6.u64 = (rotl32(ctx.r9.u32, 11) & 0x1C00) | (ctx.r6.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r6,1176(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1176, ctx.r6.u32);
	// ld r5,24(r10)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// oris r4,r5,16384
	ctx.r4.u64 = ctx.r5.u64 | 1073741824;
	// std r4,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r4.u64);
	// stw r8,2292(r11)
	PPC_STORE_U32(ctx.r11.u32 + 2292, ctx.r8.u32);
loc_8212EDD0:
	// lwz r10,2308(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2308);
	// cmplwi cr6,r10,2
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 2, ctx.xer);
	// beq cr6,0x8212ee04
	if (ctx.cr6.eq) goto loc_8212EE04;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// li r8,2
	ctx.r8.s64 = 2;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// lwz r6,1176(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1176);
	// rlwimi r6,r9,14,16,18
	ctx.r6.u64 = (rotl32(ctx.r9.u32, 14) & 0xE000) | (ctx.r6.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r6,1176(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1176, ctx.r6.u32);
	// ld r5,24(r10)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// oris r4,r5,16384
	ctx.r4.u64 = ctx.r5.u64 | 1073741824;
	// std r4,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r4.u64);
	// stw r8,2308(r11)
	PPC_STORE_U32(ctx.r11.u32 + 2308, ctx.r8.u32);
loc_8212EE04:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r12,1
	ctx.r12.s64 = 1;
	// addi r28,r11,31376
	ctx.r28.s64 = ctx.r11.s64 + 31376;
	// rldicr r12,r12,36,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f0,60(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 60);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,48(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f30,f0
	ctx.f12.f64 = double(float(ctx.f30.f64 * ctx.f0.f64));
	// fmuls f11,f31,f0
	ctx.f11.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// stfs f12,7748(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 7748, temp.u32);
	// stfs f13,7752(r29)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r29.u32 + 7752, temp.u32);
	// stfs f13,7756(r29)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r29.u32 + 7756, temp.u32);
	// stfs f11,7744(r29)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r29.u32 + 7744, temp.u32);
	// ld r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r29.u32 + 8);
	// or r9,r10,r12
	ctx.r9.u64 = ctx.r10.u64 | ctx.r12.u64;
	// std r9,8(r29)
	PPC_STORE_U64(ctx.r29.u32 + 8, ctx.r9.u64);
	// bl 0x82111400
	ctx.lr = 0x8212EE4C;
	sub_82111400(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111400
	ctx.lr = 0x8212EE58;
	sub_82111400(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212EE5C;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lfs f1,36(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lis r3,11264
	ctx.r3.s64 = 738197504;
	// bl 0x8210af50
	ctx.lr = 0x8212EE7C;
	sub_8210AF50(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f30,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212EE8C"))) PPC_WEAK_FUNC(sub_8212EE8C);
PPC_FUNC_IMPL(__imp__sub_8212EE8C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212EE90"))) PPC_WEAK_FUNC(sub_8212EE90);
PPC_FUNC_IMPL(__imp__sub_8212EE90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x8212EE98;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r10,21(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 21);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r11,1680(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1680);
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// addi r29,r11,848
	ctx.r29.s64 = ctx.r11.s64 + 848;
	// beq cr6,0x8212efa4
	if (ctx.cr6.eq) goto loc_8212EFA4;
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// lbz r9,25549(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 25549);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8212eedc
	if (ctx.cr6.eq) goto loc_8212EEDC;
	// addi r4,r11,588
	ctx.r4.s64 = ctx.r11.s64 + 588;
	// addi r31,r11,2652
	ctx.r31.s64 = ctx.r11.s64 + 2652;
	// addi r27,r11,2748
	ctx.r27.s64 = ctx.r11.s64 + 2748;
	// addi r30,r11,1784
	ctx.r30.s64 = ctx.r11.s64 + 1784;
	// b 0x8212ef24
	goto loc_8212EF24;
loc_8212EEDC:
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// addi r31,r11,692
	ctx.r31.s64 = ctx.r11.s64 + 692;
	// clrlwi r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x8212ef14
	if (!ctx.cr6.eq) goto loc_8212EF14;
	// li r6,11
	ctx.r6.s64 = 11;
	// addi r5,r11,2508
	ctx.r5.s64 = ctx.r11.s64 + 2508;
	// addi r3,r11,120
	ctx.r3.s64 = ctx.r11.s64 + 120;
	// bl 0x8212e260
	ctx.lr = 0x8212EF04;
	sub_8212E260(ctx, base);
	// lwz r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// ori r10,r11,1
	ctx.r10.u64 = ctx.r11.u64 | 1;
	// stw r10,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r10.u32);
loc_8212EF14:
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// addi r31,r11,2508
	ctx.r31.s64 = ctx.r11.s64 + 2508;
	// addi r27,r11,2652
	ctx.r27.s64 = ctx.r11.s64 + 2652;
	// addi r30,r11,1680
	ctx.r30.s64 = ctx.r11.s64 + 1680;
loc_8212EF24:
	// mr r7,r31
	ctx.r7.u64 = ctx.r31.u64;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8212fc90
	ctx.lr = 0x8212EF38;
	sub_8212FC90(ctx, base);
	// li r6,11
	ctx.r6.s64 = 11;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8212e530
	ctx.lr = 0x8212EF4C;
	sub_8212E530(ctx, base);
	// li r6,11
	ctx.r6.s64 = 11;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8212e530
	ctx.lr = 0x8212EF60;
	sub_8212E530(ctx, base);
	// li r6,11
	ctx.r6.s64 = 11;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8212e260
	ctx.lr = 0x8212EF74;
	sub_8212E260(ctx, base);
	// li r6,11
	ctx.r6.s64 = 11;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8212e6d0
	ctx.lr = 0x8212EF88;
	sub_8212E6D0(ctx, base);
	// mr r8,r31
	ctx.r8.u64 = ctx.r31.u64;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// lfs f2,16(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	ctx.f2.f64 = double(temp.f32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lfs f1,12(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8212ecb0
	ctx.lr = 0x8212EFA4;
	sub_8212ECB0(ctx, base);
loc_8212EFA4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212EFAC"))) PPC_WEAK_FUNC(sub_8212EFAC);
PPC_FUNC_IMPL(__imp__sub_8212EFAC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212EFB0"))) PPC_WEAK_FUNC(sub_8212EFB0);
PPC_FUNC_IMPL(__imp__sub_8212EFB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,1680(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1680);
	// lwz r30,1676(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,2460
	ctx.r5.s64 = ctx.r10.s64 + 2460;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8212eff8
	if (ctx.cr6.eq) goto loc_8212EFF8;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212EFF8;
	sub_8222CDF8(ctx, base);
loc_8212EFF8:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8212F004;
	sub_821112B0(ctx, base);
	// lwz r8,1680(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r7,0(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r6,4(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// lwz r5,8(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lfs f0,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,144(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stw r7,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r7.u32);
	// lfs f13,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// stw r6,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r6.u32);
	// stfs f13,148(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stw r5,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r5.u32);
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// stw r10,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r10.u32);
	// lfs f0,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f8.f64 = double(temp.f32);
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fctidz f9,f13
	ctx.f9.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// stfd f9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.f9.u64);
	// lwz r7,100(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// fctidz f11,f12
	ctx.f11.s64 = (ctx.f12.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f12.f64);
	// stfd f11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f11.u64);
	// fctidz f10,f0
	ctx.f10.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f7,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.f7.u64);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r6,100(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stw r7,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r7.u32);
	// stw r9,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r9.u32);
	// stw r8,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r8.u32);
	// stw r6,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r6.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x8212F0A0;
	sub_8222CBC8(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x8212F0AC;
	sub_82111340(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212f0e0
	if (ctx.cr6.eq) goto loc_8212F0E0;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x8212F0D8;
	sub_82237A38(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r11.u32);
loc_8212F0E0:
	// li r4,8
	ctx.r4.s64 = 8;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212F0EC;
	sub_82111340(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8212F104"))) PPC_WEAK_FUNC(sub_8212F104);
PPC_FUNC_IMPL(__imp__sub_8212F104) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212F108"))) PPC_WEAK_FUNC(sub_8212F108);
PPC_FUNC_IMPL(__imp__sub_8212F108) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, ctx.f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,1680(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1680);
	// lwz r30,1676(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,2460
	ctx.r5.s64 = ctx.r10.s64 + 2460;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8212f154
	if (ctx.cr6.eq) goto loc_8212F154;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212F154;
	sub_8222CDF8(ctx, base);
loc_8212F154:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8212F160;
	sub_821112B0(ctx, base);
	// lwz r8,1680(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// addi r11,r1,112
	ctx.r11.s64 = ctx.r1.s64 + 112;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r7,0(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r6,4(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// lwz r5,8(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lfs f0,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,144(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stw r7,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r7.u32);
	// lfs f31,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// stw r6,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r6.u32);
	// stfs f31,148(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stw r5,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r5.u32);
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// stw r10,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r10.u32);
	// lfs f0,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f8.f64 = double(temp.f32);
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fctidz f9,f13
	ctx.f9.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// stfd f9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.f9.u64);
	// lwz r7,100(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// fctidz f11,f12
	ctx.f11.s64 = (ctx.f12.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f12.f64);
	// stfd f11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f11.u64);
	// fctidz f10,f0
	ctx.f10.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f7,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.f7.u64);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r6,100(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stw r7,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r7.u32);
	// stw r9,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r9.u32);
	// stw r8,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r8.u32);
	// stw r6,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r6.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x8212F1FC;
	sub_8222CBC8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8212F208;
	sub_821112B0(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r3,175
	ctx.r3.s64 = 175;
	// bl 0x8210afd8
	ctx.lr = 0x8212F21C;
	sub_8210AFD8(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x8212F228;
	sub_82111340(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212F234;
	sub_82111340(ctx, base);
	// lis r4,14119
	ctx.r4.s64 = 925302784;
	// li r3,208
	ctx.r3.s64 = 208;
	// ori r4,r4,50604
	ctx.r4.u64 = ctx.r4.u64 | 50604;
	// bl 0x82111340
	ctx.lr = 0x8212F244;
	sub_82111340(ctx, base);
	// lis r4,16384
	ctx.r4.s64 = 1073741824;
	// li r3,204
	ctx.r3.s64 = 204;
	// bl 0x82111340
	ctx.lr = 0x8212F250;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8212F25C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8212F268;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,368
	ctx.r3.s64 = 368;
	// bl 0x82111340
	ctx.lr = 0x8212F274;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,372
	ctx.r3.s64 = 372;
	// bl 0x82111340
	ctx.lr = 0x8212F280;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x8212F28C;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,136
	ctx.r3.s64 = 136;
	// bl 0x82111340
	ctx.lr = 0x8212F298;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,140
	ctx.r3.s64 = 140;
	// bl 0x82111340
	ctx.lr = 0x8212F2A4;
	sub_82111340(ctx, base);
	// li r4,5
	ctx.r4.s64 = 5;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82111340
	ctx.lr = 0x8212F2B0;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x8212F2BC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82111340
	ctx.lr = 0x8212F2C8;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x82111340
	ctx.lr = 0x8212F2D4;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,132
	ctx.r3.s64 = 132;
	// bl 0x82111340
	ctx.lr = 0x8212F2E0;
	sub_82111340(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8212F2FC"))) PPC_WEAK_FUNC(sub_8212F2FC);
PPC_FUNC_IMPL(__imp__sub_8212F2FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212F300"))) PPC_WEAK_FUNC(sub_8212F300);
PPC_FUNC_IMPL(__imp__sub_8212F300) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e454
	ctx.lr = 0x8212F308;
	__restfpr_23(ctx, base);
	// stfd f31,-88(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -88, ctx.f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r27,1676(r3)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,208
	ctx.r3.s64 = 208;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x82111340
	ctx.lr = 0x8212F330;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,204
	ctx.r3.s64 = 204;
	// bl 0x82111340
	ctx.lr = 0x8212F33C;
	sub_82111340(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r29,r11,27648
	ctx.r29.s64 = ctx.r11.s64 + 27648;
	// lwz r11,52(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 52);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// mr r23,r11
	ctx.r23.u64 = ctx.r11.u64;
	// beq cr6,0x8212f37c
	if (ctx.cr6.eq) goto loc_8212F37C;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x8222f080
	ctx.lr = 0x8212F35C;
	sub_8222F080(ctx, base);
	// lwz r11,52(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 52);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212f37c
	if (ctx.cr6.eq) goto loc_8212F37C;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,52(r29)
	PPC_STORE_U32(ctx.r29.u32 + 52, ctx.r11.u32);
	// bl 0x8222d188
	ctx.lr = 0x8212F37C;
	sub_8222D188(ctx, base);
loc_8212F37C:
	// li r4,8
	ctx.r4.s64 = 8;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212F388;
	sub_82111340(ctx, base);
	// lwz r10,1680(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// lwz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	// addi r5,r10,2988
	ctx.r5.s64 = ctx.r10.s64 + 2988;
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212f3ac
	if (ctx.cr6.eq) goto loc_8212F3AC;
	// stw r5,36(r29)
	PPC_STORE_U32(ctx.r29.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212F3AC;
	sub_8222CDF8(ctx, base);
loc_8212F3AC:
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// addi r31,r11,1524
	ctx.r31.s64 = ctx.r11.s64 + 1524;
	// lwz r11,1556(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1556);
	// clrlwi r30,r11,26
	ctx.r30.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r30,50
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 50, ctx.xer);
	// bne cr6,0x8212f3d0
	if (!ctx.cr6.eq) goto loc_8212F3D0;
	// li r10,3
	ctx.r10.s64 = 3;
	// rlwimi r11,r10,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r10.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_8212F3D0:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lfs f31,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// li r4,0
	ctx.r4.s64 = 0;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82227e30
	ctx.lr = 0x8212F400;
	sub_82227E30(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// lwz r7,32(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// rlwimi r7,r30,0,26,31
	ctx.r7.u64 = (rotl32(ctx.r30.u32, 0) & 0x3F) | (ctx.r7.u64 & 0xFFFFFFFFFFFFFFC0);
	// lbz r8,25549(r9)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + 25549);
	// stw r7,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r7.u32);
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8212f42c
	if (ctx.cr6.eq) goto loc_8212F42C;
	// addi r25,r11,1628
	ctx.r25.s64 = ctx.r11.s64 + 1628;
	// addi r30,r11,2700
	ctx.r30.s64 = ctx.r11.s64 + 2700;
	// b 0x8212f434
	goto loc_8212F434;
loc_8212F42C:
	// addi r25,r11,1524
	ctx.r25.s64 = ctx.r11.s64 + 1524;
	// addi r30,r11,2604
	ctx.r30.s64 = ctx.r11.s64 + 2604;
loc_8212F434:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x8212F440;
	sub_82113BC0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r24,1
	ctx.r24.s64 = 1;
	// cmplwi cr6,r26,1
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 1, ctx.xer);
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// blt cr6,0x8212f47c
	if (ctx.cr6.lt) goto loc_8212F47C;
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// addi r3,r11,1524
	ctx.r3.s64 = ctx.r11.s64 + 1524;
	// beq cr6,0x8212f474
	if (ctx.cr6.eq) goto loc_8212F474;
	// bl 0x8212e6d0
	ctx.lr = 0x8212F470;
	sub_8212E6D0(ctx, base);
	// b 0x8212f58c
	goto loc_8212F58C;
loc_8212F474:
	// bl 0x8212e530
	ctx.lr = 0x8212F478;
	sub_8212E530(ctx, base);
	// b 0x8212f58c
	goto loc_8212F58C;
loc_8212F47C:
	// lwz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212f49c
	if (ctx.cr6.eq) goto loc_8212F49C;
	// stw r30,36(r29)
	PPC_STORE_U32(ctx.r29.u32 + 36, ctx.r30.u32);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212F49C;
	sub_8222CDF8(ctx, base);
loc_8212F49C:
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r4,r11,1524
	ctx.r4.s64 = ctx.r11.s64 + 1524;
	// bl 0x82111400
	ctx.lr = 0x8212F4AC;
	sub_82111400(ctx, base);
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212f4d0
	if (ctx.cr6.eq) goto loc_8212F4D0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8212F4C8;
	sub_8222C0A0(ctx, base);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// stw r24,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r24.u32);
loc_8212F4D0:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212f4f4
	if (ctx.cr6.eq) goto loc_8212F4F4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8212F4EC;
	sub_8222C248(ctx, base);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// stw r24,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r24.u32);
loc_8212F4F4:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212f528
	if (ctx.cr6.eq) goto loc_8212F528;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r24,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r24.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_8212F528:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212f55c
	if (ctx.cr6.eq) goto loc_8212F55C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r24,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r24.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8212F55C:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25936);
	// bl 0x8211c5f0
	ctx.lr = 0x8212F568;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212F56C;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210af50
	ctx.lr = 0x8212F58C;
	sub_8210AF50(ctx, base);
loc_8212F58C:
	// lwz r10,1680(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// lwz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	// addi r5,r10,2460
	ctx.r5.s64 = ctx.r10.s64 + 2460;
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212f5b0
	if (ctx.cr6.eq) goto loc_8212F5B0;
	// stw r5,36(r29)
	PPC_STORE_U32(ctx.r29.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212F5B0;
	sub_8222CDF8(ctx, base);
loc_8212F5B0:
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x8212f5c8
	if (ctx.cr6.eq) goto loc_8212F5C8;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x8210b080
	ctx.lr = 0x8212F5C0;
	sub_8210B080(ctx, base);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x8212F5C8;
	sub_8222F0F8(ctx, base);
loc_8212F5C8:
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r10,2496(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2496);
	// rlwinm r3,r10,14,18,31
	ctx.r3.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 14) & 0x3FFF;
	// bl 0x8210c6e0
	ctx.lr = 0x8212F5DC;
	sub_8210C6E0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,16
	ctx.r7.s64 = 16;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8212F5F8;
	sub_8222CC48(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8212F604;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x8212F610;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,136
	ctx.r3.s64 = 136;
	// bl 0x82111340
	ctx.lr = 0x8212F61C;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,140
	ctx.r3.s64 = 140;
	// bl 0x82111340
	ctx.lr = 0x8212F628;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82111340
	ctx.lr = 0x8212F634;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x8212F640;
	sub_82111340(ctx, base);
	// li r4,128
	ctx.r4.s64 = 128;
	// li r3,132
	ctx.r3.s64 = 132;
	// bl 0x82111340
	ctx.lr = 0x8212F64C;
	sub_82111340(ctx, base);
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lwz r11,25980(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25980);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r9,12216(r27)
	PPC_STORE_U32(ctx.r27.u32 + 12216, ctx.r9.u32);
	// ld r8,16(r27)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r27.u32 + 16);
	// oris r7,r8,8
	ctx.r7.u64 = ctx.r8.u64 | 524288;
	// std r7,16(r27)
	PPC_STORE_U64(ctx.r27.u32 + 16, ctx.r7.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x8212F674;
	sub_82238728(ctx, base);
	// lwz r11,25980(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25980);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x8212F684;
	sub_82238380(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8212F690;
	sub_82111400(ctx, base);
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212f6b4
	if (ctx.cr6.eq) goto loc_8212F6B4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8212F6AC;
	sub_8222C0A0(ctx, base);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// stw r24,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r24.u32);
loc_8212F6B4:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212f6d8
	if (ctx.cr6.eq) goto loc_8212F6D8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8212F6D0;
	sub_8222C248(ctx, base);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// stw r24,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r24.u32);
loc_8212F6D8:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,8
	ctx.r4.s64 = 8;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// add r31,r11,r10
	ctx.r31.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x8212F6F8;
	sub_8222DFC8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x8212F704;
	sub_82113BC0(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8212F710;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,368
	ctx.r3.s64 = 368;
	// bl 0x82111340
	ctx.lr = 0x8212F71C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,372
	ctx.r3.s64 = 372;
	// bl 0x82111340
	ctx.lr = 0x8212F728;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x8212F734;
	sub_82111340(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lwz r11,25784(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25784);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r27)
	PPC_STORE_U32(ctx.r27.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r27)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r27.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r27)
	PPC_STORE_U64(ctx.r27.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x8212F75C;
	sub_82238728(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82238380
	ctx.lr = 0x8212F768;
	sub_82238380(ctx, base);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x8212F77C;
	sub_8222DFC8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8212F788;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82111340
	ctx.lr = 0x8212F794;
	sub_82111340(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212F7A0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82232270
	ctx.lr = 0x8212F7AC;
	sub_82232270(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212F7B8"))) PPC_WEAK_FUNC(sub_8212F7B8);
PPC_FUNC_IMPL(__imp__sub_8212F7B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, ctx.f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// std r4,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.r4.u64);
	// lwz r31,1676(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// addi r30,r11,31376
	ctx.r30.s64 = ctx.r11.s64 + 31376;
	// std r5,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, ctx.r5.u64);
	// lfd f1,992(r30)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r30.u32 + 992);
	// bl 0x8233d628
	ctx.lr = 0x8212F7EC;
	sub_8233D628(ctx, base);
	// frsp f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64));
	// lfs f0,524(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 524);
	ctx.f0.f64 = double(temp.f32);
	// lfd f1,1000(r30)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r30.u32 + 1000);
	// fmuls f31,f13,f0
	ctx.f31.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// bl 0x8233d628
	ctx.lr = 0x8212F800;
	sub_8233D628(ctx, base);
	// frsp f12,f1
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f1.f64));
	// lfs f0,524(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 524);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,208(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 208);
	ctx.f13.f64 = double(temp.f32);
	// lfd f1,1008(r30)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r30.u32 + 1008);
	// fmuls f11,f12,f0
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmadds f31,f11,f13,f31
	ctx.f31.f64 = double(std::fma(float(ctx.f11.f64), float(ctx.f13.f64), float(ctx.f31.f64)));
	// bl 0x8233d628
	ctx.lr = 0x8212F820;
	sub_8233D628(ctx, base);
	// frsp f10,f1
	ctx.fpscr.disableFlushMode();
	ctx.f10.f64 = double(float(ctx.f1.f64));
	// lfs f0,524(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 524);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,208(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 208);
	ctx.f13.f64 = double(temp.f32);
	// lfd f1,1016(r30)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r30.u32 + 1016);
	// fmuls f9,f10,f0
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// stfs f9,84(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmadds f31,f9,f13,f31
	ctx.f31.f64 = double(std::fma(float(ctx.f9.f64), float(ctx.f13.f64), float(ctx.f31.f64)));
	// bl 0x8233d628
	ctx.lr = 0x8212F840;
	sub_8233D628(ctx, base);
	// frsp f8,f1
	ctx.fpscr.disableFlushMode();
	ctx.f8.f64 = double(float(ctx.f1.f64));
	// lfs f0,524(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 524);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,208(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 208);
	ctx.f13.f64 = double(temp.f32);
	// lfd f1,1024(r30)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r30.u32 + 1024);
	// fmuls f7,f8,f0
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f7,88(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmadds f31,f7,f13,f31
	ctx.f31.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f13.f64), float(ctx.f31.f64)));
	// bl 0x8233d628
	ctx.lr = 0x8212F860;
	sub_8233D628(ctx, base);
	// frsp f6,f1
	ctx.fpscr.disableFlushMode();
	ctx.f6.f64 = double(float(ctx.f1.f64));
	// lfs f0,524(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 524);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,96(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// lfd f1,1032(r30)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r30.u32 + 1032);
	// fmuls f5,f6,f0
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// stfs f5,92(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmadds f31,f5,f13,f31
	ctx.f31.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f13.f64), float(ctx.f31.f64)));
	// bl 0x8233d628
	ctx.lr = 0x8212F880;
	sub_8233D628(ctx, base);
	// frsp f4,f1
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = double(float(ctx.f1.f64));
	// lfs f0,524(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 524);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,208(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 208);
	ctx.f13.f64 = double(temp.f32);
	// lfd f1,1040(r30)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r30.u32 + 1040);
	// fmuls f3,f4,f0
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// stfs f3,96(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmadds f31,f3,f13,f31
	ctx.f31.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f13.f64), float(ctx.f31.f64)));
	// bl 0x8233d628
	ctx.lr = 0x8212F8A0;
	sub_8233D628(ctx, base);
	// frsp f2,f1
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = double(float(ctx.f1.f64));
	// lfs f0,524(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 524);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,208(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 208);
	ctx.f13.f64 = double(temp.f32);
	// lfd f1,1048(r30)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r30.u32 + 1048);
	// fmuls f0,f2,f0
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f0,100(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fmadds f31,f0,f13,f31
	ctx.f31.f64 = double(std::fma(float(ctx.f0.f64), float(ctx.f13.f64), float(ctx.f31.f64)));
	// bl 0x8233d628
	ctx.lr = 0x8212F8C0;
	sub_8233D628(ctx, base);
	// frsp f12,f1
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f1.f64));
	// lfs f0,524(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 524);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,96(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// lfd f1,1056(r30)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r30.u32 + 1056);
	// fmuls f11,f12,f0
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// stfs f11,104(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmadds f31,f11,f13,f31
	ctx.f31.f64 = double(std::fma(float(ctx.f11.f64), float(ctx.f13.f64), float(ctx.f31.f64)));
	// bl 0x8233d628
	ctx.lr = 0x8212F8E0;
	sub_8233D628(ctx, base);
	// frsp f10,f1
	ctx.fpscr.disableFlushMode();
	ctx.f10.f64 = double(float(ctx.f1.f64));
	// lfs f0,524(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 524);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,96(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// lfd f1,1064(r30)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r30.u32 + 1064);
	// fmuls f9,f10,f0
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// stfs f9,108(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmadds f31,f9,f13,f31
	ctx.f31.f64 = double(std::fma(float(ctx.f9.f64), float(ctx.f13.f64), float(ctx.f31.f64)));
	// bl 0x8233d628
	ctx.lr = 0x8212F900;
	sub_8233D628(ctx, base);
	// lfs f0,524(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 524);
	ctx.f0.f64 = double(temp.f32);
	// frsp f8,f1
	ctx.f8.f64 = double(float(ctx.f1.f64));
	// lfs f13,208(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 208);
	ctx.f13.f64 = double(temp.f32);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r6,3
	ctx.r6.s64 = 3;
	// fmuls f3,f8,f0
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f12,56(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	ctx.f12.f64 = double(temp.f32);
	// lfs f7,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// rldicr r7,r10,36,63
	ctx.r7.u64 = rotl64(ctx.r10.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// lfs f6,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f6.f64 = double(temp.f32);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lfs f5,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f5.f64 = double(temp.f32);
	// li r4,109
	ctx.r4.s64 = 109;
	// lfs f4,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f4.f64 = double(temp.f32);
	// stfs f3,112(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// fmadds f2,f3,f13,f31
	ctx.f2.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f13.f64), float(ctx.f31.f64)));
	// fdivs f1,f12,f2
	ctx.f1.f64 = double(float(ctx.f12.f64 / ctx.f2.f64));
	// fmuls f0,f1,f7
	ctx.f0.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// stfs f0,7744(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7744, temp.u32);
	// fmuls f13,f6,f1
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// stfs f13,7748(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7748, temp.u32);
	// fmuls f12,f5,f1
	ctx.f12.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// stfs f12,7752(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7752, temp.u32);
	// fmuls f11,f1,f4
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f4.f64));
	// stfs f11,7756(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7756, temp.u32);
	// ld r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r3,r8,r7
	ctx.r3.u64 = ctx.r8.u64 | ctx.r7.u64;
	// std r3,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r3.u64);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238120
	ctx.lr = 0x8212F978;
	sub_82238120(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// lfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8212F994"))) PPC_WEAK_FUNC(sub_8212F994);
PPC_FUNC_IMPL(__imp__sub_8212F994) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212F998"))) PPC_WEAK_FUNC(sub_8212F998);
PPC_FUNC_IMPL(__imp__sub_8212F998) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e450
	ctx.lr = 0x8212F9A0;
	__restfpr_22(ctx, base);
	// stfd f31,-96(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -96, ctx.f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8212F9BC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8212F9C8;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x8212F9D4;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8212F9E0;
	sub_821112B0(ctx, base);
	// lwz r11,1680(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// li r22,3
	ctx.r22.s64 = 3;
	// addi r31,r11,952
	ctx.r31.s64 = ctx.r11.s64 + 952;
	// addi r26,r11,1524
	ctx.r26.s64 = ctx.r11.s64 + 1524;
	// addi r24,r11,1628
	ctx.r24.s64 = ctx.r11.s64 + 1628;
	// lwz r11,984(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 984);
	// clrlwi r28,r11,26
	ctx.r28.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r28,50
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 50, ctx.xer);
	// bne cr6,0x8212fa0c
	if (!ctx.cr6.eq) goto loc_8212FA0C;
	// rlwimi r11,r22,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r22.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_8212FA0C:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// addi r25,r11,31376
	ctx.r25.s64 = ctx.r11.s64 + 31376;
	// addi r30,r10,27648
	ctx.r30.s64 = ctx.r10.s64 + 27648;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lfs f31,36(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// li r4,0
	ctx.r4.s64 = 0;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82227e30
	ctx.lr = 0x8212FA44;
	sub_82227E30(ctx, base);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// rlwimi r11,r28,0,26,31
	ctx.r11.u64 = (rotl32(ctx.r28.u32, 0) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// lwz r4,8(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// bl 0x8212f300
	ctx.lr = 0x8212FA5C;
	sub_8212F300(ctx, base);
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// mr r28,r31
	ctx.r28.u64 = ctx.r31.u64;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x8212fb24
	if (!ctx.cr6.gt) goto loc_8212FB24;
	// lwz r11,52(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// mr r23,r11
	ctx.r23.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212faa4
	if (ctx.cr6.eq) goto loc_8212FAA4;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x8222f080
	ctx.lr = 0x8212FA84;
	sub_8222F080(ctx, base);
	// lwz r11,52(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212faa4
	if (ctx.cr6.eq) goto loc_8212FAA4;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,52(r30)
	PPC_STORE_U32(ctx.r30.u32 + 52, ctx.r11.u32);
	// bl 0x8222d188
	ctx.lr = 0x8212FAA4;
	sub_8222D188(ctx, base);
loc_8212FAA4:
	// lwz r11,1680(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// addi r5,r11,2604
	ctx.r5.s64 = ctx.r11.s64 + 2604;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8212e260
	ctx.lr = 0x8212FABC;
	sub_8212E260(ctx, base);
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// mr r28,r26
	ctx.r28.u64 = ctx.r26.u64;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// ble cr6,0x8212fae8
	if (!ctx.cr6.gt) goto loc_8212FAE8;
	// lwz r11,1680(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// addi r5,r11,2700
	ctx.r5.s64 = ctx.r11.s64 + 2700;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8212e260
	ctx.lr = 0x8212FAE4;
	sub_8212E260(ctx, base);
	// mr r28,r24
	ctx.r28.u64 = ctx.r24.u64;
loc_8212FAE8:
	// lwz r10,1680(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// lwz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// addi r5,r10,2460
	ctx.r5.s64 = ctx.r10.s64 + 2460;
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212fb0c
	if (ctx.cr6.eq) goto loc_8212FB0C;
	// stw r5,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212FB0C;
	sub_8222CDF8(ctx, base);
loc_8212FB0C:
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x8212fb24
	if (ctx.cr6.eq) goto loc_8212FB24;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x8210b080
	ctx.lr = 0x8212FB1C;
	sub_8210B080(ctx, base);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x8212FB24;
	sub_8222F0F8(ctx, base);
loc_8212FB24:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x8212FB30;
	sub_82113BC0(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lfs f1,48(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// li r3,15
	ctx.r3.s64 = 15;
	// bl 0x8210afd8
	ctx.lr = 0x8212FB44;
	sub_8210AFD8(ctx, base);
	// lfs f0,4(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stfs f13,92(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// ld r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// ld r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// bl 0x8212f7b8
	ctx.lr = 0x8212FB6C;
	sub_8212F7B8(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8212FB78;
	sub_82111340(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,26068(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26068);
	// bl 0x8211c5f0
	ctx.lr = 0x8212FB84;
	sub_8211C5F0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r27,r11,28184
	ctx.r27.s64 = ctx.r11.s64 + 28184;
	// lwz r11,292(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 292);
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x8212fbb4
	if (ctx.cr6.eq) goto loc_8212FBB4;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x8212FBB0;
	sub_82237A38(ctx, base);
	// stw r28,292(r27)
	PPC_STORE_U32(ctx.r27.u32 + 292, ctx.r28.u32);
loc_8212FBB4:
	// bl 0x8210b0d8
	ctx.lr = 0x8212FBB8;
	sub_8210B0D8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8212FBC4;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8212FBD0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x8212FBDC;
	sub_82111340(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212FBE8;
	sub_82111340(ctx, base);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// clrlwi r28,r11,26
	ctx.r28.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r28,50
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 50, ctx.xer);
	// bne cr6,0x8212fc00
	if (!ctx.cr6.eq) goto loc_8212FC00;
	// rlwimi r11,r22,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r22.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_8212FC00:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82227e30
	ctx.lr = 0x8212FC24;
	sub_82227E30(ctx, base);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// rlwimi r11,r28,0,26,31
	ctx.r11.u64 = (rotl32(ctx.r28.u32, 0) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// lwz r10,1680(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// lwz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// addi r5,r10,1932
	ctx.r5.s64 = ctx.r10.s64 + 1932;
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212fc54
	if (ctx.cr6.eq) goto loc_8212FC54;
	// stw r5,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212FC54;
	sub_8222CDF8(ctx, base);
loc_8212FC54:
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212FC60;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,208
	ctx.r3.s64 = 208;
	// bl 0x82111340
	ctx.lr = 0x8212FC6C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,204
	ctx.r3.s64 = 204;
	// bl 0x82111340
	ctx.lr = 0x8212FC78;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8212FC84;
	sub_821112B0(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-96(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x8233e4a0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212FC90"))) PPC_WEAK_FUNC(sub_8212FC90);
PPC_FUNC_IMPL(__imp__sub_8212FC90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8212FC98;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r27,1676(r3)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r30,r7
	ctx.r30.u64 = ctx.r7.u64;
	// bl 0x82132d28
	ctx.lr = 0x8212FCC0;
	sub_82132D28(ctx, base);
	// lfs f0,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// li r12,1
	ctx.r12.s64 = 1;
	// stfs f0,7744(r27)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + 7744, temp.u32);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lfs f13,4(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// rldicr r12,r12,36,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// stfs f13,7748(r27)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r27.u32 + 7748, temp.u32);
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// lfs f12,8(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,7752(r27)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r27.u32 + 7752, temp.u32);
	// lfs f11,12(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,7756(r27)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r27.u32 + 7756, temp.u32);
	// ld r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r27.u32 + 8);
	// or r9,r10,r12
	ctx.r9.u64 = ctx.r10.u64 | ctx.r12.u64;
	// std r9,8(r27)
	PPC_STORE_U64(ctx.r27.u32 + 8, ctx.r9.u64);
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r30,r10
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8212fd1c
	if (ctx.cr6.eq) goto loc_8212FD1C;
	// stw r30,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r30.u32);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212FD1C;
	sub_8222CDF8(ctx, base);
loc_8212FD1C:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8212FD28;
	sub_821112B0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25944(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25944);
	// bl 0x8211c5f0
	ctx.lr = 0x8212FD34;
	sub_8211C5F0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r30,r11,28184
	ctx.r30.s64 = ctx.r11.s64 + 28184;
	// lwz r11,292(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 292);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x8212fd64
	if (ctx.cr6.eq) goto loc_8212FD64;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x8212FD60;
	sub_82237A38(ctx, base);
	// stw r31,292(r30)
	PPC_STORE_U32(ctx.r30.u32 + 292, ctx.r31.u32);
loc_8212FD64:
	// bl 0x8210b0d8
	ctx.lr = 0x8212FD68;
	sub_8210B0D8(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lis r3,11264
	ctx.r3.s64 = 738197504;
	// lfs f1,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210af50
	ctx.lr = 0x8212FD90;
	sub_8210AF50(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212FD98"))) PPC_WEAK_FUNC(sub_8212FD98);
PPC_FUNC_IMPL(__imp__sub_8212FD98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8212FDA0;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r10,1676(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// lfs f0,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// li r12,1
	ctx.r12.s64 = 1;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// rldicr r12,r12,36,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// stfs f0,7744(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 7744, temp.u32);
	// mr r31,r8
	ctx.r31.u64 = ctx.r8.u64;
	// lfs f13,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// stfs f13,7748(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 7748, temp.u32);
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// lfs f12,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,7752(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 7752, temp.u32);
	// lfs f11,12(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,7756(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 7756, temp.u32);
	// ld r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r10.u32 + 8);
	// or r8,r9,r12
	ctx.r8.u64 = ctx.r9.u64 | ctx.r12.u64;
	// std r8,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, ctx.r8.u64);
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r6,r10
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8212fe10
	if (ctx.cr6.eq) goto loc_8212FE10;
	// stw r6,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r6.u32);
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212FE10;
	sub_8222CDF8(ctx, base);
loc_8212FE10:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8212FE1C;
	sub_821112B0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,26036(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26036);
	// bl 0x8211c5f0
	ctx.lr = 0x8212FE28;
	sub_8211C5F0(ctx, base);
	// lwz r3,96(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212fe3c
	if (ctx.cr6.eq) goto loc_8212FE3C;
	// bl 0x820b91d0
	ctx.lr = 0x8212FE38;
	sub_820B91D0(ctx, base);
	// b 0x8212fe58
	goto loc_8212FE58;
loc_8212FE3C:
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212fe50
	if (ctx.cr6.eq) goto loc_8212FE50;
	// lwz r3,88(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// b 0x8212fe58
	goto loc_8212FE58;
loc_8212FE50:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x820b90a0
	ctx.lr = 0x8212FE58;
	sub_820B90A0(ctx, base);
loc_8212FE58:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r30,4(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x8212fe8c
	if (ctx.cr6.eq) goto loc_8212FE8C;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x8212FE88;
	sub_82237A38(ctx, base);
	// stw r29,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r29.u32);
loc_8212FE8C:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82132d28
	ctx.lr = 0x8212FE9C;
	sub_82132D28(ctx, base);
	// lwz r11,296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 296);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x8212fec0
	if (ctx.cr6.eq) goto loc_8212FEC0;
	// lis r6,16384
	ctx.r6.s64 = 1073741824;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82237a38
	ctx.lr = 0x8212FEBC;
	sub_82237A38(ctx, base);
	// stw r30,296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 296, ctx.r30.u32);
loc_8212FEC0:
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82132d28
	ctx.lr = 0x8212FED0;
	sub_82132D28(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8212FED4;
	sub_8210B0D8(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f1,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210af50
	ctx.lr = 0x8212FEFC;
	sub_8210AF50(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212FF04"))) PPC_WEAK_FUNC(sub_8212FF04);
PPC_FUNC_IMPL(__imp__sub_8212FF04) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8212FF08"))) PPC_WEAK_FUNC(sub_8212FF08);
PPC_FUNC_IMPL(__imp__sub_8212FF08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8212FF10;
	__restfpr_27(ctx, base);
	// stfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fsubs f13,f2,f1
	ctx.f13.f64 = static_cast<float>(ctx.f2.f64 - ctx.f1.f64);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// lwz r9,1676(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// addi r7,r11,31376
	ctx.r7.s64 = ctx.r11.s64 + 31376;
	// lfs f12,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// li r8,1
	ctx.r8.s64 = 1;
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// rldicr r11,r8,36,63
	ctx.r11.u64 = rotl64(ctx.r8.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// stfs f12,7744(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7744, temp.u32);
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// lfs f0,48(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// stfs f0,7756(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7756, temp.u32);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stfs f11,7748(r9)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7748, temp.u32);
	// addi r31,r10,28184
	ctx.r31.s64 = ctx.r10.s64 + 28184;
	// fdivs f9,f2,f13
	ctx.f9.f64 = double(float(ctx.f2.f64 / ctx.f13.f64));
	// stfs f10,7752(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7752, temp.u32);
	// ld r6,8(r9)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// or r5,r6,r11
	ctx.r5.u64 = ctx.r6.u64 | ctx.r11.u64;
	// fmuls f8,f9,f1
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f1.f64));
	// std r5,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, ctx.r5.u64);
	// lfs f31,36(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// stfs f9,7764(r9)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7764, temp.u32);
	// stfs f31,7768(r9)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7768, temp.u32);
	// stfs f0,7772(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7772, temp.u32);
	// fneg f7,f8
	ctx.f7.u64 = ctx.f8.u64 ^ 0x8000000000000000;
	// stfs f7,7760(r9)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7760, temp.u32);
	// ld r4,8(r9)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// or r3,r4,r11
	ctx.r3.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r3,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, ctx.r3.u64);
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x8212ffc8
	if (ctx.cr6.eq) goto loc_8212FFC8;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x8212FFC4;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_8212FFC8:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212fff0
	if (ctx.cr6.eq) goto loc_8212FFF0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8212FFE8;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_8212FFF0:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82130014
	if (ctx.cr6.eq) goto loc_82130014;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8213000C;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_82130014:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130048
	if (ctx.cr6.eq) goto loc_82130048;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82130048:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8213007c
	if (ctx.cr6.eq) goto loc_8213007C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8213007C:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111400
	ctx.lr = 0x82130088;
	sub_82111400(ctx, base);
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821300ac
	if (ctx.cr6.eq) goto loc_821300AC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x821300A4;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r11.u32);
loc_821300AC:
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821300d0
	if (ctx.cr6.eq) goto loc_821300D0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x821300C8;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r11.u32);
loc_821300D0:
	// lwz r11,2292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2292);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130104
	if (ctx.cr6.eq) goto loc_82130104;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2292, ctx.r10.u32);
loc_82130104:
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130138
	if (ctx.cr6.eq) goto loc_82130138;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r10.u32);
loc_82130138:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r28,r10
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82130160
	if (ctx.cr6.eq) goto loc_82130160;
	// stw r28,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r28.u32);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82130160;
	sub_8222CDF8(ctx, base);
loc_82130160:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8213016C;
	sub_821112B0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25988(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25988);
	// bl 0x8211c5f0
	ctx.lr = 0x82130178;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8213017C;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210af50
	ctx.lr = 0x8213019C;
	sub_8210AF50(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821301A8"))) PPC_WEAK_FUNC(sub_821301A8);
PPC_FUNC_IMPL(__imp__sub_821301A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x821301B0;
	__restfpr_26(ctx, base);
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r26,1676(r3)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// bl 0x822365d8
	ctx.lr = 0x821301DC;
	sub_822365D8(ctx, base);
	// lwz r6,120(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lwz r5,124(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// li r10,1
	ctx.r10.s64 = 1;
	// addi r9,r11,31376
	ctx.r9.s64 = ctx.r11.s64 + 31376;
	// lfs f11,12(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// rldicr r11,r10,36,63
	ctx.r11.u64 = rotl64(ctx.r10.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// std r6,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r6.u64);
	// lfd f8,80(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r5,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r5.u64);
	// lfd f7,80(r1)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f6,f7
	ctx.f6.f64 = double(ctx.f7.s64);
	// lfs f31,36(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// fcfid f5,f8
	ctx.f5.f64 = double(ctx.f8.s64);
	// lfs f13,112(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,108(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 108);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f11,f13
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f0,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f9,f11,f12
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// addi r31,r10,28184
	ctx.r31.s64 = ctx.r10.s64 + 28184;
	// frsp f4,f6
	ctx.f4.f64 = double(float(ctx.f6.f64));
	// frsp f3,f5
	ctx.f3.f64 = double(float(ctx.f5.f64));
	// fdivs f2,f31,f4
	ctx.f2.f64 = double(float(ctx.f31.f64 / ctx.f4.f64));
	// stfs f2,7756(r26)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7756, temp.u32);
	// fdivs f1,f31,f3
	ctx.f1.f64 = double(float(ctx.f31.f64 / ctx.f3.f64));
	// stfs f1,7744(r26)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7744, temp.u32);
	// stfs f1,7748(r26)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7748, temp.u32);
	// stfs f1,7752(r26)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7752, temp.u32);
	// ld r4,8(r26)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r26.u32 + 8);
	// or r3,r4,r11
	ctx.r3.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r3,8(r26)
	PPC_STORE_U64(ctx.r26.u32 + 8, ctx.r3.u64);
	// stfs f10,7760(r26)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7760, temp.u32);
	// stfs f9,7764(r26)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7764, temp.u32);
	// stfs f0,7768(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7768, temp.u32);
	// stfs f0,7772(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 7772, temp.u32);
	// ld r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r26.u32 + 8);
	// or r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 | ctx.r11.u64;
	// std r9,8(r26)
	PPC_STORE_U64(ctx.r26.u32 + 8, ctx.r9.u64);
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x821302a0
	if (ctx.cr6.eq) goto loc_821302A0;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x8213029C;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_821302A0:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821302c8
	if (ctx.cr6.eq) goto loc_821302C8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x821302C0;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_821302C8:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821302ec
	if (ctx.cr6.eq) goto loc_821302EC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x821302E4;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_821302EC:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130320
	if (ctx.cr6.eq) goto loc_82130320;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82130320:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130354
	if (ctx.cr6.eq) goto loc_82130354;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_82130354:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r29,r10
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8213037c
	if (ctx.cr6.eq) goto loc_8213037C;
	// stw r29,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r29.u32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8213037C;
	sub_8222CDF8(ctx, base);
loc_8213037C:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82130388;
	sub_821112B0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25992(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25992);
	// bl 0x8211c5f0
	ctx.lr = 0x82130394;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x82130398;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210af50
	ctx.lr = 0x821303B8;
	sub_8210AF50(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821303C4"))) PPC_WEAK_FUNC(sub_821303C4);
PPC_FUNC_IMPL(__imp__sub_821303C4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821303C8"))) PPC_WEAK_FUNC(sub_821303C8);
PPC_FUNC_IMPL(__imp__sub_821303C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x821303D0;
	__restfpr_29(ctx, base);
	// stfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, ctx.f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lfs f0,12(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	ctx.f0.f64 = double(temp.f32);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lbz r10,25549(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 25549);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r29,r11,31376
	ctx.r29.s64 = ctx.r11.s64 + 31376;
	// lwz r11,1680(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1680);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// addi r7,r11,2460
	ctx.r7.s64 = ctx.r11.s64 + 2460;
	// addi r6,r11,1264
	ctx.r6.s64 = ctx.r11.s64 + 1264;
	// lfs f31,60(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 60);
	ctx.f31.f64 = double(temp.f32);
	// addi r5,r11,16
	ctx.r5.s64 = ctx.r11.s64 + 16;
	// addi r4,r11,120
	ctx.r4.s64 = ctx.r11.s64 + 120;
	// beq cr6,0x821304f0
	if (ctx.cr6.eq) goto loc_821304F0;
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// blt cr6,0x821304c4
	if (ctx.cr6.lt) goto loc_821304C4;
	// bl 0x8212ff08
	ctx.lr = 0x82130424;
	sub_8212FF08(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,2604
	ctx.r5.s64 = ctx.r11.s64 + 2604;
	// addi r4,r11,1524
	ctx.r4.s64 = ctx.r11.s64 + 1524;
	// addi r3,r11,1264
	ctx.r3.s64 = ctx.r11.s64 + 1264;
	// bl 0x8212e260
	ctx.lr = 0x8213043C;
	sub_8212E260(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,2700
	ctx.r5.s64 = ctx.r11.s64 + 2700;
	// addi r4,r11,1628
	ctx.r4.s64 = ctx.r11.s64 + 1628;
	// addi r3,r11,1524
	ctx.r3.s64 = ctx.r11.s64 + 1524;
	// bl 0x8212e260
	ctx.lr = 0x82130454;
	sub_8212E260(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// addi r5,r11,1524
	ctx.r5.s64 = ctx.r11.s64 + 1524;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r11,2604
	ctx.r6.s64 = ctx.r11.s64 + 2604;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// bl 0x821301a8
	ctx.lr = 0x82130470;
	sub_821301A8(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// addi r5,r11,1628
	ctx.r5.s64 = ctx.r11.s64 + 1628;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r11,2700
	ctx.r6.s64 = ctx.r11.s64 + 2700;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// bl 0x821301a8
	ctx.lr = 0x8213048C;
	sub_821301A8(ctx, base);
	// lfs f13,12(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f13,f31
	ctx.f12.f64 = static_cast<float>(ctx.f13.f64 - ctx.f31.f64);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// lfs f0,56(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 56);
	ctx.f0.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r7,r11,2604
	ctx.r7.s64 = ctx.r11.s64 + 2604;
	// addi r6,r11,1160
	ctx.r6.s64 = ctx.r11.s64 + 1160;
	// addi r5,r11,1628
	ctx.r5.s64 = ctx.r11.s64 + 1628;
	// addi r4,r11,1524
	ctx.r4.s64 = ctx.r11.s64 + 1524;
	// fmuls f1,f12,f0
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// bl 0x82131f58
	ctx.lr = 0x821304B8;
	sub_82131F58(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
loc_821304C4:
	// bl 0x8212ff08
	ctx.lr = 0x821304C8;
	sub_8212FF08(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,2604
	ctx.r5.s64 = ctx.r11.s64 + 2604;
	// addi r4,r11,1524
	ctx.r4.s64 = ctx.r11.s64 + 1524;
	// addi r3,r11,1264
	ctx.r3.s64 = ctx.r11.s64 + 1264;
	// bl 0x8212e260
	ctx.lr = 0x821304E0;
	sub_8212E260(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// addi r6,r11,2604
	ctx.r6.s64 = ctx.r11.s64 + 2604;
	// addi r4,r11,1524
	ctx.r4.s64 = ctx.r11.s64 + 1524;
	// b 0x82130594
	goto loc_82130594;
loc_821304F0:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// blt cr6,0x82130584
	if (ctx.cr6.lt) goto loc_82130584;
	// bl 0x8212ff08
	ctx.lr = 0x821304FC;
	sub_8212FF08(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,2604
	ctx.r5.s64 = ctx.r11.s64 + 2604;
	// addi r4,r11,1524
	ctx.r4.s64 = ctx.r11.s64 + 1524;
	// addi r3,r11,1264
	ctx.r3.s64 = ctx.r11.s64 + 1264;
	// bl 0x8212e260
	ctx.lr = 0x82130514;
	sub_8212E260(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// addi r5,r11,1264
	ctx.r5.s64 = ctx.r11.s64 + 1264;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r11,2460
	ctx.r6.s64 = ctx.r11.s64 + 2460;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// bl 0x821301a8
	ctx.lr = 0x82130530;
	sub_821301A8(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// addi r5,r11,1524
	ctx.r5.s64 = ctx.r11.s64 + 1524;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r11,2604
	ctx.r6.s64 = ctx.r11.s64 + 2604;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// bl 0x821301a8
	ctx.lr = 0x8213054C;
	sub_821301A8(ctx, base);
	// lfs f13,12(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f13,f31
	ctx.f12.f64 = static_cast<float>(ctx.f13.f64 - ctx.f31.f64);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// lfs f0,56(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 56);
	ctx.f0.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r7,r11,2460
	ctx.r7.s64 = ctx.r11.s64 + 2460;
	// addi r6,r11,1160
	ctx.r6.s64 = ctx.r11.s64 + 1160;
	// addi r5,r11,1524
	ctx.r5.s64 = ctx.r11.s64 + 1524;
	// addi r4,r11,1264
	ctx.r4.s64 = ctx.r11.s64 + 1264;
	// fmuls f1,f12,f0
	ctx.f1.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// bl 0x82131f58
	ctx.lr = 0x82130578;
	sub_82131F58(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
loc_82130584:
	// bl 0x8212ff08
	ctx.lr = 0x82130588;
	sub_8212FF08(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// addi r6,r11,2460
	ctx.r6.s64 = ctx.r11.s64 + 2460;
	// addi r4,r11,1264
	ctx.r4.s64 = ctx.r11.s64 + 1264;
loc_82130594:
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// addi r5,r11,1160
	ctx.r5.s64 = ctx.r11.s64 + 1160;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821301a8
	ctx.lr = 0x821305A4;
	sub_821301A8(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821305B0"))) PPC_WEAK_FUNC(sub_821305B0);
PPC_FUNC_IMPL(__imp__sub_821305B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82298e30
	ctx.lr = 0x821305D0;
	sub_82298E30(ctx, base);
	// lis r10,6690
	ctx.r10.s64 = 438435840;
	// lwz r5,112(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// li r11,0
	ctx.r11.s64 = 0;
	// ori r9,r10,346
	ctx.r9.u64 = ctx.r10.u64 | 346;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// cmpw cr6,r5,r9
	ctx.cr6.compare<int32_t>(ctx.r5.s32, ctx.r9.s32, ctx.xer);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// bne cr6,0x82130604
	if (!ctx.cr6.eq) goto loc_82130604;
	// lis r5,6688
	ctx.r5.s64 = 438304768;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// ori r5,r5,43861
	ctx.r5.u64 = ctx.r5.u64 | 43861;
loc_82130604:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r4,104(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// mr r8,r31
	ctx.r8.u64 = ctx.r31.u64;
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,0
	ctx.r6.s64 = 0;
	// bl 0x82298188
	ctx.lr = 0x82130620;
	sub_82298188(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x822985e0
	ctx.lr = 0x82130630;
	sub_822985E0(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82130644"))) PPC_WEAK_FUNC(sub_82130644);
PPC_FUNC_IMPL(__imp__sub_82130644) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82130648"))) PPC_WEAK_FUNC(sub_82130648);
PPC_FUNC_IMPL(__imp__sub_82130648) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82130650;
	__restfpr_26(ctx, base);
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f31.u64);
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r28,1676(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1676);
	// bl 0x822365d8
	ctx.lr = 0x82130674;
	sub_822365D8(ctx, base);
	// lfs f0,13008(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13008);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,13012(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13012);
	ctx.f13.f64 = double(temp.f32);
	// fctidz f12,f0
	ctx.f12.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// lfs f11,13000(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13000);
	ctx.f11.f64 = double(temp.f32);
	// fctidz f10,f13
	ctx.f10.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// lfs f8,13004(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13004);
	ctx.f8.f64 = double(temp.f32);
	// fctidz f9,f11
	ctx.f9.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// stfd f12,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f12.u64);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f9.u64);
	// stfd f7,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f7.u64);
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r6,92(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// lwz r10,44(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 44);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lfs f6,13016(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13016);
	ctx.f6.f64 = double(temp.f32);
	// stw r9,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r9.u32);
	// rlwinm r11,r10,26,28,31
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0xF;
	// lfs f5,13020(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13020);
	ctx.f5.f64 = double(temp.f32);
	// stfs f6,112(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stw r8,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r8.u32);
	// stfs f5,116(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stw r7,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r7.u32);
	// stw r6,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r6.u32);
	// addi r27,r11,1
	ctx.r27.s64 = ctx.r11.s64 + 1;
	// bl 0x821305b0
	ctx.lr = 0x821306EC;
	sub_821305B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// addi r26,r11,27648
	ctx.r26.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8213071c
	if (ctx.cr6.eq) goto loc_8213071C;
	// addi r11,r1,160
	ctx.r11.s64 = ctx.r1.s64 + 160;
	// lwz r3,188(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 188);
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// stw r11,36(r26)
	PPC_STORE_U32(ctx.r26.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x8213071C;
	sub_8222CDF8(ctx, base);
loc_8213071C:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x8213074c
	if (ctx.cr6.eq) goto loc_8213074C;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x82130748;
	sub_82237A38(ctx, base);
	// stw r29,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r29.u32);
loc_8213074C:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82130774
	if (ctx.cr6.eq) goto loc_82130774;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8213076C;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_82130774:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82130798
	if (ctx.cr6.eq) goto loc_82130798;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82130790;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_82130798:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821307cc
	if (ctx.cr6.eq) goto loc_821307CC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1164(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwinm r7,r8,0,9,6
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFE7FFFFF;
	// stw r7,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r10.u32);
loc_821307CC:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130800
	if (ctx.cr6.eq) goto loc_82130800;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82130800:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130834
	if (ctx.cr6.eq) goto loc_82130834;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_82130834:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25940(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25940);
	// bl 0x8211c5f0
	ctx.lr = 0x82130840;
	sub_8211C5F0(ctx, base);
	// cmplwi cr6,r27,1
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 1, ctx.xer);
	// ble cr6,0x821308f4
	if (!ctx.cr6.gt) goto loc_821308F4;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// lfs f31,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
loc_82130854:
	// addi r5,r1,208
	ctx.r5.s64 = ctx.r1.s64 + 208;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82298e30
	ctx.lr = 0x82130864;
	sub_82298E30(ctx, base);
	// li r9,6
	ctx.r9.s64 = 6;
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// addi r10,r11,-4
	ctx.r10.s64 = ctx.r11.s64 + -4;
	// addi r11,r8,-4
	ctx.r11.s64 = ctx.r8.s64 + -4;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8213087C:
	// lwzu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	ctx.r9.u64 = PPC_LOAD_U32(ea);
	ctx.r11.u32 = ea;
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x8213087c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213087C;
	// lwz r11,212(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r10,216(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r11,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r11.u32);
	// stw r10,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r10.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x821308A4;
	sub_8222CBC8(ctx, base);
	// lwz r11,2180(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2180);
	// addi r5,r30,-1
	ctx.r5.s64 = ctx.r30.s64 + -1;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x821308c4
	if (ctx.cr6.eq) goto loc_821308C4;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x8222c730
	ctx.lr = 0x821308C0;
	sub_8222C730(ctx, base);
	// stw r5,2180(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2180, ctx.r5.u32);
loc_821308C4:
	// bl 0x8210b0d8
	ctx.lr = 0x821308C8;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = ctx.r30.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lis r3,11264
	ctx.r3.s64 = 738197504;
	// bl 0x8210af50
	ctx.lr = 0x821308E8;
	sub_8210AF50(ctx, base);
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// cmplw cr6,r30,r27
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r27.u32, ctx.xer);
	// blt cr6,0x82130854
	if (ctx.cr6.lt) goto loc_82130854;
loc_821308F4:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8222cbc8
	ctx.lr = 0x82130900;
	sub_8222CBC8(ctx, base);
	// lwz r11,2180(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2180);
	// cmplwi cr6,r11,13
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 13, ctx.xer);
	// beq cr6,0x82130924
	if (ctx.cr6.eq) goto loc_82130924;
	// li r5,13
	ctx.r5.s64 = 13;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c730
	ctx.lr = 0x8213091C;
	sub_8222C730(ctx, base);
	// li r11,13
	ctx.r11.s64 = 13;
	// stw r11,2180(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2180, ctx.r11.u32);
loc_82130924:
	// lwz r11,36(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82130948
	if (ctx.cr6.eq) goto loc_82130948;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 188);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,36(r26)
	PPC_STORE_U32(ctx.r26.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82130948;
	sub_8222CDF8(ctx, base);
loc_82130948:
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82130954"))) PPC_WEAK_FUNC(sub_82130954);
PPC_FUNC_IMPL(__imp__sub_82130954) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82130958"))) PPC_WEAK_FUNC(sub_82130958);
PPC_FUNC_IMPL(__imp__sub_82130958) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x82130960;
	__restfpr_29(ctx, base);
	// stfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, ctx.f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x821305b0
	ctx.lr = 0x8213097C;
	sub_821305B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x821309ac
	if (ctx.cr6.eq) goto loc_821309AC;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x821309A8;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_821309AC:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821309d4
	if (ctx.cr6.eq) goto loc_821309D4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x821309CC;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_821309D4:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821309f8
	if (ctx.cr6.eq) goto loc_821309F8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x821309F0;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_821309F8:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130a2c
	if (ctx.cr6.eq) goto loc_82130A2C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82130A2C:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130a60
	if (ctx.cr6.eq) goto loc_82130A60;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_82130A60:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82130a90
	if (ctx.cr6.eq) goto loc_82130A90;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82130A90;
	sub_8222CDF8(ctx, base);
loc_82130A90:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,26000(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26000);
	// bl 0x8211c5f0
	ctx.lr = 0x82130A9C;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x82130AA0;
	sub_8210B0D8(ctx, base);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lfs f31,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// li r3,0
	ctx.r3.s64 = 0;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x8210af50
	ctx.lr = 0x82130ACC;
	sub_8210AF50(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x82130AD8;
	sub_82111400(ctx, base);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// cmplw cr6,r8,r11
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82130b00
	if (ctx.cr6.eq) goto loc_82130B00;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82130B00;
	sub_8222CDF8(ctx, base);
loc_82130B00:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,26004(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26004);
	// bl 0x8211c5f0
	ctx.lr = 0x82130B0C;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x82130B10;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210af50
	ctx.lr = 0x82130B30;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82130b54
	if (ctx.cr6.eq) goto loc_82130B54;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82130B54;
	sub_8222CDF8(ctx, base);
loc_82130B54:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82130B60"))) PPC_WEAK_FUNC(sub_82130B60);
PPC_FUNC_IMPL(__imp__sub_82130B60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82130B68;
	__restfpr_27(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x82130bac
	if (ctx.cr6.eq) goto loc_82130BAC;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x82130BA8;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_82130BAC:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82130bd4
	if (ctx.cr6.eq) goto loc_82130BD4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82130BCC;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_82130BD4:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82130bf8
	if (ctx.cr6.eq) goto loc_82130BF8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82130BF0;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_82130BF8:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130c2c
	if (ctx.cr6.eq) goto loc_82130C2C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82130C2C:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130c60
	if (ctx.cr6.eq) goto loc_82130C60;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_82130C60:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111400
	ctx.lr = 0x82130C6C;
	sub_82111400(ctx, base);
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82130c90
	if (ctx.cr6.eq) goto loc_82130C90;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x82130C88;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r30.u32);
loc_82130C90:
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82130cb4
	if (ctx.cr6.eq) goto loc_82130CB4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82130CAC;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r30.u32);
loc_82130CB4:
	// lwz r11,2292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2292);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130ce8
	if (ctx.cr6.eq) goto loc_82130CE8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2292, ctx.r10.u32);
loc_82130CE8:
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130d1c
	if (ctx.cr6.eq) goto loc_82130D1C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r10.u32);
loc_82130D1C:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x821305b0
	ctx.lr = 0x82130D28;
	sub_821305B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82130d58
	if (ctx.cr6.eq) goto loc_82130D58;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82130D58;
	sub_8222CDF8(ctx, base);
loc_82130D58:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,26008(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26008);
	// bl 0x8211c5f0
	ctx.lr = 0x82130D64;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x82130D68;
	sub_8210B0D8(ctx, base);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lis r3,11264
	ctx.r3.s64 = 738197504;
	// lfs f1,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210af50
	ctx.lr = 0x82130D90;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82130db4
	if (ctx.cr6.eq) goto loc_82130DB4;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82130DB4;
	sub_8222CDF8(ctx, base);
loc_82130DB4:
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82130648
	ctx.lr = 0x82130DC0;
	sub_82130648(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82130DC8"))) PPC_WEAK_FUNC(sub_82130DC8);
PPC_FUNC_IMPL(__imp__sub_82130DC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x82130DD0;
	__restfpr_25(ctx, base);
	// stfd f30,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, ctx.f30.u64);
	// stfd f31,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, ctx.f31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// clrlwi r28,r8,24
	ctx.r28.u64 = ctx.r8.u32 & 0xFF;
	// lwz r30,1676(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// fmr f31,f1
	ctx.f31.f64 = ctx.f1.f64;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// mr r25,r6
	ctx.r25.u64 = ctx.r6.u64;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// addi r31,r11,31376
	ctx.r31.s64 = ctx.r11.s64 + 31376;
	// beq cr6,0x82130e10
	if (ctx.cr6.eq) goto loc_82130E10;
	// lfs f0,56(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f31,f1,f0
	ctx.f31.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
loc_82130E10:
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x822365d8
	ctx.lr = 0x82130E20;
	sub_822365D8(ctx, base);
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lfs f13,1468(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 1468);
	ctx.f13.f64 = double(temp.f32);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// fmuls f9,f31,f13
	ctx.f9.f64 = double(float(ctx.f31.f64 * ctx.f13.f64));
	// lfs f30,36(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// lfs f0,1464(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 1464);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f10,f31,f0
	ctx.f10.f64 = double(float(ctx.f31.f64 * ctx.f0.f64));
	// lfs f0,424(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 424);
	ctx.f0.f64 = double(temp.f32);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f12,f13
	ctx.f12.f64 = double(ctx.f13.s64);
	// frsp f11,f12
	ctx.f11.f64 = double(float(ctx.f12.f64));
	// fdivs f13,f30,f11
	ctx.f13.f64 = double(float(ctx.f30.f64 / ctx.f11.f64));
	// fmuls f8,f13,f0
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f0,48(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// beq cr6,0x82130e6c
	if (ctx.cr6.eq) goto loc_82130E6C;
	// fmr f12,f30
	ctx.f12.f64 = ctx.f30.f64;
	// fmr f11,f0
	ctx.f11.f64 = ctx.f0.f64;
	// b 0x82130e74
	goto loc_82130E74;
loc_82130E6C:
	// fmr f11,f30
	ctx.fpscr.disableFlushMode();
	ctx.f11.f64 = ctx.f30.f64;
	// fmr f12,f0
	ctx.f12.f64 = ctx.f0.f64;
loc_82130E74:
	// li r11,1
	ctx.r11.s64 = 1;
	// stfs f10,7744(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7744, temp.u32);
	// stfs f9,7748(r30)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7748, temp.u32);
	// li r7,31
	ctx.r7.s64 = 31;
	// rldicr r11,r11,36,63
	ctx.r11.u64 = rotl64(ctx.r11.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// stfs f8,7752(r30)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7752, temp.u32);
	// stfs f13,7756(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7756, temp.u32);
	// ld r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 | ctx.r11.u64;
	// std r9,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r9.u64);
	// stfs f0,7760(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7760, temp.u32);
	// rldicr r7,r7,32,31
	ctx.r7.u64 = rotl64(ctx.r7.u64, 32) & 0xFFFFFFFF00000000;
	// stfs f12,7764(r30)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7764, temp.u32);
	// li r6,16
	ctx.r6.s64 = 16;
	// stfs f11,7768(r30)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7768, temp.u32);
	// addi r5,r27,12
	ctx.r5.s64 = ctx.r27.s64 + 12;
	// stfs f0,7772(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7772, temp.u32);
	// ld r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r4,r8,r11
	ctx.r4.u64 = ctx.r8.u64 | ctx.r11.u64;
	// std r4,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r4.u64);
	// li r4,110
	ctx.r4.s64 = 110;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82238120
	ctx.lr = 0x82130ED0;
	sub_82238120(ctx, base);
	// lis r3,1
	ctx.r3.s64 = 65536;
	// li r12,1
	ctx.r12.s64 = 1;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// ori r10,r3,16
	ctx.r10.u64 = ctx.r3.u64 | 16;
	// rldicr r12,r12,56,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// stw r10,10208(r30)
	PPC_STORE_U32(ctx.r30.u32 + 10208, ctx.r10.u32);
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// ld r9,32(r30)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r30.u32 + 32);
	// or r8,r9,r12
	ctx.r8.u64 = ctx.r9.u64 | ctx.r12.u64;
	// std r8,32(r30)
	PPC_STORE_U64(ctx.r30.u32 + 32, ctx.r8.u64);
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82130f20
	if (ctx.cr6.eq) goto loc_82130F20;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x82130F1C;
	sub_82237A38(ctx, base);
	// stw r29,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r29.u32);
loc_82130F20:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82130f48
	if (ctx.cr6.eq) goto loc_82130F48;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82130F40;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_82130F48:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82130f6c
	if (ctx.cr6.eq) goto loc_82130F6C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82130F64;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_82130F6C:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82130fa0
	if (ctx.cr6.eq) goto loc_82130FA0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1164(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r8,r30,23,7,8
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 23) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r30,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r30.u32);
loc_82130FA0:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82130fd4
	if (ctx.cr6.eq) goto loc_82130FD4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82130FD4:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82131008
	if (ctx.cr6.eq) goto loc_82131008;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_82131008:
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111400
	ctx.lr = 0x82131014;
	sub_82111400(ctx, base);
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82131038
	if (ctx.cr6.eq) goto loc_82131038;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x82131030;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r30.u32);
loc_82131038:
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8213105c
	if (ctx.cr6.eq) goto loc_8213105C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82131054;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r30.u32);
loc_8213105C:
	// lwz r11,2388(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2388);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82131090
	if (ctx.cr6.eq) goto loc_82131090;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r9,2
	ctx.r9.s64 = 2;
	// addi r10,r11,24
	ctx.r10.s64 = ctx.r11.s64 + 24;
	// lwz r10,1188(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1188);
	// rlwimi r10,r30,24,7,8
	ctx.r10.u64 = (rotl32(ctx.r30.u32, 24) & 0x1800000) | (ctx.r10.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r10,1188(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1188, ctx.r10.u32);
	// ld r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r7,r8,16384
	ctx.r7.u64 = ctx.r8.u64 | 1073741824;
	// std r7,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r7.u64);
	// stw r9,2388(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2388, ctx.r9.u32);
loc_82131090:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111390
	ctx.lr = 0x821310A0;
	sub_82111390(ctx, base);
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821310d4
	if (ctx.cr6.eq) goto loc_821310D4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r10.u32);
loc_821310D4:
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x821305b0
	ctx.lr = 0x821310E0;
	sub_821305B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82131110
	if (ctx.cr6.eq) goto loc_82131110;
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82131110;
	sub_8222CDF8(ctx, base);
loc_82131110:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8213111C;
	sub_821112B0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25996(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25996);
	// bl 0x8211c5f0
	ctx.lr = 0x82131128;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8213112C;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f30.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lis r3,11264
	ctx.r3.s64 = 738197504;
	// bl 0x8210af50
	ctx.lr = 0x8213114C;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82131170
	if (ctx.cr6.eq) goto loc_82131170;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82131170;
	sub_8222CDF8(ctx, base);
loc_82131170:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lfd f30,-80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// lfd f31,-72(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82131180"))) PPC_WEAK_FUNC(sub_82131180);
PPC_FUNC_IMPL(__imp__sub_82131180) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82131188;
	__restfpr_27(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x821311cc
	if (ctx.cr6.eq) goto loc_821311CC;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x821311C8;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_821311CC:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821311f4
	if (ctx.cr6.eq) goto loc_821311F4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x821311EC;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_821311F4:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82131218
	if (ctx.cr6.eq) goto loc_82131218;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82131210;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_82131218:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8213124c
	if (ctx.cr6.eq) goto loc_8213124C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1164(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r8,r30,24,7,8
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 24) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r10.u32);
loc_8213124C:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82131280
	if (ctx.cr6.eq) goto loc_82131280;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82131280:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821312b4
	if (ctx.cr6.eq) goto loc_821312B4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_821312B4:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111400
	ctx.lr = 0x821312C0;
	sub_82111400(ctx, base);
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821312e4
	if (ctx.cr6.eq) goto loc_821312E4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x821312DC;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r30.u32);
loc_821312E4:
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82131308
	if (ctx.cr6.eq) goto loc_82131308;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82131300;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r30.u32);
loc_82131308:
	// lwz r11,2292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2292);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8213133c
	if (ctx.cr6.eq) goto loc_8213133C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2292, ctx.r10.u32);
loc_8213133C:
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82131370
	if (ctx.cr6.eq) goto loc_82131370;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r10.u32);
loc_82131370:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x821305b0
	ctx.lr = 0x8213137C;
	sub_821305B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x821313ac
	if (ctx.cr6.eq) goto loc_821313AC;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x821313AC;
	sub_8222CDF8(ctx, base);
loc_821313AC:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,26012(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26012);
	// bl 0x8211c5f0
	ctx.lr = 0x821313B8;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x821313BC;
	sub_8210B0D8(ctx, base);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lis r3,11264
	ctx.r3.s64 = 738197504;
	// lfs f1,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210af50
	ctx.lr = 0x821313E4;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82131408
	if (ctx.cr6.eq) goto loc_82131408;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82131408;
	sub_8222CDF8(ctx, base);
loc_82131408:
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82130648
	ctx.lr = 0x82131414;
	sub_82130648(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213141C"))) PPC_WEAK_FUNC(sub_8213141C);
PPC_FUNC_IMPL(__imp__sub_8213141C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82131420"))) PPC_WEAK_FUNC(sub_82131420);
PPC_FUNC_IMPL(__imp__sub_82131420) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82131428;
	__restfpr_28(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r3.u32, ctx.xer);
	// beq cr6,0x82131468
	if (ctx.cr6.eq) goto loc_82131468;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x82131464;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_82131468:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82131490
	if (ctx.cr6.eq) goto loc_82131490;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82131488;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_82131490:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821314b4
	if (ctx.cr6.eq) goto loc_821314B4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x821314AC;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_821314B4:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821314e8
	if (ctx.cr6.eq) goto loc_821314E8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_821314E8:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8213151c
	if (ctx.cr6.eq) goto loc_8213151C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8213151C:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111400
	ctx.lr = 0x82131528;
	sub_82111400(ctx, base);
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8213154c
	if (ctx.cr6.eq) goto loc_8213154C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x82131544;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r30.u32);
loc_8213154C:
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82131570
	if (ctx.cr6.eq) goto loc_82131570;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82131568;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r30.u32);
loc_82131570:
	// lwz r11,2292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2292);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821315a4
	if (ctx.cr6.eq) goto loc_821315A4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2292, ctx.r10.u32);
loc_821315A4:
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821315d8
	if (ctx.cr6.eq) goto loc_821315D8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r10.u32);
loc_821315D8:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x821305b0
	ctx.lr = 0x821315E4;
	sub_821305B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82131614
	if (ctx.cr6.eq) goto loc_82131614;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82131614;
	sub_8222CDF8(ctx, base);
loc_82131614:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,26016(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26016);
	// bl 0x8211c5f0
	ctx.lr = 0x82131620;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x82131624;
	sub_8210B0D8(ctx, base);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lis r3,11264
	ctx.r3.s64 = 738197504;
	// lfs f1,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210af50
	ctx.lr = 0x8213164C;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82131670
	if (ctx.cr6.eq) goto loc_82131670;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82131670;
	sub_8222CDF8(ctx, base);
loc_82131670:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82131678"))) PPC_WEAK_FUNC(sub_82131678);
PPC_FUNC_IMPL(__imp__sub_82131678) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82131680;
	__restfpr_28(ctx, base);
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// fsubs f13,f2,f1
	ctx.f13.f64 = static_cast<float>(ctx.f2.f64 - ctx.f1.f64);
	// lwz r9,1676(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r7,r11,31376
	ctx.r7.s64 = ctx.r11.s64 + 31376;
	// rldicr r11,r8,36,63
	ctx.r11.u64 = rotl64(ctx.r8.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// lfs f0,60(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 60);
	ctx.f0.f64 = double(temp.f32);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// fmuls f12,f4,f0
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// lfs f31,36(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// lfs f0,48(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// addi r31,r10,28184
	ctx.r31.s64 = ctx.r10.s64 + 28184;
	// fdivs f11,f2,f13
	ctx.f11.f64 = double(float(ctx.f2.f64 / ctx.f13.f64));
	// fsubs f10,f3,f12
	ctx.f10.f64 = static_cast<float>(ctx.f3.f64 - ctx.f12.f64);
	// stfs f10,7748(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7748, temp.u32);
	// fadds f9,f12,f3
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f3.f64));
	// stfs f9,7752(r9)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7752, temp.u32);
	// fmuls f8,f11,f1
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f1.f64));
	// fsubs f7,f10,f5
	ctx.f7.f64 = static_cast<float>(ctx.f10.f64 - ctx.f5.f64);
	// stfs f7,7744(r9)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7744, temp.u32);
	// fadds f6,f9,f5
	ctx.f6.f64 = double(float(ctx.f9.f64 + ctx.f5.f64));
	// stfs f6,7756(r9)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7756, temp.u32);
	// ld r6,8(r9)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// or r5,r6,r11
	ctx.r5.u64 = ctx.r6.u64 | ctx.r11.u64;
	// std r5,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, ctx.r5.u64);
	// fneg f5,f8
	ctx.f5.u64 = ctx.f8.u64 ^ 0x8000000000000000;
	// stfs f5,7760(r9)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7760, temp.u32);
	// stfs f11,7764(r9)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7764, temp.u32);
	// stfs f31,7768(r9)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7768, temp.u32);
	// stfs f0,7772(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7772, temp.u32);
	// ld r4,8(r9)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// or r3,r4,r11
	ctx.r3.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r3,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, ctx.r3.u64);
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82131740
	if (ctx.cr6.eq) goto loc_82131740;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x8213173C;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_82131740:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82131764
	if (ctx.cr6.eq) goto loc_82131764;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8213175C;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
loc_82131764:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82131788
	if (ctx.cr6.eq) goto loc_82131788;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82131780;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r11.u32);
loc_82131788:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// li r9,1
	ctx.r9.s64 = 1;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821317c0
	if (ctx.cr6.eq) goto loc_821317C0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,11,19,21
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 11) & 0x1C00) | (ctx.r7.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_821317C0:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821317f4
	if (ctx.cr6.eq) goto loc_821317F4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,14,16,18
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 14) & 0xE000) | (ctx.r7.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_821317F4:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x821305b0
	ctx.lr = 0x82131800;
	sub_821305B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82131830
	if (ctx.cr6.eq) goto loc_82131830;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82131830;
	sub_8222CDF8(ctx, base);
loc_82131830:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,26020(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26020);
	// bl 0x8211c5f0
	ctx.lr = 0x8213183C;
	sub_8211C5F0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x82131840;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210af50
	ctx.lr = 0x82131860;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82131884
	if (ctx.cr6.eq) goto loc_82131884;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82131884;
	sub_8222CDF8(ctx, base);
loc_82131884:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x821305b0
	ctx.lr = 0x82131890;
	sub_821305B0(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8212e260
	ctx.lr = 0x821318A4;
	sub_8212E260(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x821318B0;
	sub_82111340(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82130958
	ctx.lr = 0x821318BC;
	sub_82130958(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8212e3b8
	ctx.lr = 0x821318D0;
	sub_8212E3B8(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x821318DC;
	sub_82111340(ctx, base);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82131900
	if (ctx.cr6.eq) goto loc_82131900;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82131900;
	sub_8222CDF8(ctx, base);
loc_82131900:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213190C"))) PPC_WEAK_FUNC(sub_8213190C);
PPC_FUNC_IMPL(__imp__sub_8213190C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82131910"))) PPC_WEAK_FUNC(sub_82131910);
PPC_FUNC_IMPL(__imp__sub_82131910) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,1680(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1680);
	// lfs f5,8(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f4.f64 = double(temp.f32);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lfs f3,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// addi r6,r11,1368
	ctx.r6.s64 = ctx.r11.s64 + 1368;
	// addi r5,r11,1576
	ctx.r5.s64 = ctx.r11.s64 + 1576;
	// addi r4,r11,16
	ctx.r4.s64 = ctx.r11.s64 + 16;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x82131678
	ctx.lr = 0x8213194C;
	sub_82131678(ctx, base);
	// lbz r11,17(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 17);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82131a30
	if (ctx.cr6.eq) goto loc_82131A30;
	// lbz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 16);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821319ec
	if (ctx.cr6.eq) goto loc_821319EC;
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r11,1472
	ctx.r6.s64 = ctx.r11.s64 + 1472;
	// addi r5,r11,1368
	ctx.r5.s64 = ctx.r11.s64 + 1368;
	// addi r4,r11,120
	ctx.r4.s64 = ctx.r11.s64 + 120;
	// bl 0x82130b60
	ctx.lr = 0x8213197C;
	sub_82130B60(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// li r8,0
	ctx.r8.s64 = 0;
	// lfs f1,12(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r11,1212
	ctx.r6.s64 = ctx.r11.s64 + 1212;
	// addi r5,r11,1368
	ctx.r5.s64 = ctx.r11.s64 + 1368;
	// addi r4,r11,1472
	ctx.r4.s64 = ctx.r11.s64 + 1472;
	// bl 0x82130dc8
	ctx.lr = 0x8213199C;
	sub_82130DC8(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r11,1732
	ctx.r6.s64 = ctx.r11.s64 + 1732;
	// addi r5,r11,1576
	ctx.r5.s64 = ctx.r11.s64 + 1576;
	// addi r4,r11,1472
	ctx.r4.s64 = ctx.r11.s64 + 1472;
	// bl 0x82131180
	ctx.lr = 0x821319B4;
	sub_82131180(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// li r8,1
	ctx.r8.s64 = 1;
	// lfs f1,12(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r11,1680
	ctx.r6.s64 = ctx.r11.s64 + 1680;
	// addi r5,r11,1576
	ctx.r5.s64 = ctx.r11.s64 + 1576;
	// addi r4,r11,1732
	ctx.r4.s64 = ctx.r11.s64 + 1732;
	// bl 0x82130dc8
	ctx.lr = 0x821319D4;
	sub_82130DC8(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// addi r5,r11,1212
	ctx.r5.s64 = ctx.r11.s64 + 1212;
	// addi r4,r11,1680
	ctx.r4.s64 = ctx.r11.s64 + 1680;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// bl 0x82131420
	ctx.lr = 0x821319E8;
	sub_82131420(ctx, base);
	// b 0x82131ab0
	goto loc_82131AB0;
loc_821319EC:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82131a30
	if (ctx.cr6.eq) goto loc_82131A30;
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r11,1472
	ctx.r6.s64 = ctx.r11.s64 + 1472;
	// addi r5,r11,1368
	ctx.r5.s64 = ctx.r11.s64 + 1368;
	// addi r4,r11,120
	ctx.r4.s64 = ctx.r11.s64 + 120;
	// bl 0x82130b60
	ctx.lr = 0x82131A0C;
	sub_82130B60(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// li r8,0
	ctx.r8.s64 = 0;
	// lfs f1,12(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r11,1212
	ctx.r6.s64 = ctx.r11.s64 + 1212;
	// addi r5,r11,1368
	ctx.r5.s64 = ctx.r11.s64 + 1368;
	// addi r4,r11,1472
	ctx.r4.s64 = ctx.r11.s64 + 1472;
	// bl 0x82130dc8
	ctx.lr = 0x82131A2C;
	sub_82130DC8(ctx, base);
	// b 0x82131ab0
	goto loc_82131AB0;
loc_82131A30:
	// lbz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82131ab0
	if (ctx.cr6.eq) goto loc_82131AB0;
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// li r6,11
	ctx.r6.s64 = 11;
	// addi r5,r11,2508
	ctx.r5.s64 = ctx.r11.s64 + 2508;
	// addi r4,r11,1420
	ctx.r4.s64 = ctx.r11.s64 + 1420;
	// addi r3,r11,120
	ctx.r3.s64 = ctx.r11.s64 + 120;
	// bl 0x8212e260
	ctx.lr = 0x82131A54;
	sub_8212E260(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r11,1732
	ctx.r6.s64 = ctx.r11.s64 + 1732;
	// addi r5,r11,1576
	ctx.r5.s64 = ctx.r11.s64 + 1576;
	// addi r4,r11,1420
	ctx.r4.s64 = ctx.r11.s64 + 1420;
	// bl 0x82131180
	ctx.lr = 0x82131A6C;
	sub_82131180(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// li r8,1
	ctx.r8.s64 = 1;
	// lfs f1,12(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r6,r11,1680
	ctx.r6.s64 = ctx.r11.s64 + 1680;
	// addi r5,r11,1576
	ctx.r5.s64 = ctx.r11.s64 + 1576;
	// addi r4,r11,1732
	ctx.r4.s64 = ctx.r11.s64 + 1732;
	// bl 0x82130dc8
	ctx.lr = 0x82131A8C;
	sub_82130DC8(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r11,1212
	ctx.r3.s64 = ctx.r11.s64 + 1212;
	// bl 0x821305b0
	ctx.lr = 0x82131A9C;
	sub_821305B0(ctx, base);
	// lwz r11,1680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1680);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// addi r4,r11,1212
	ctx.r4.s64 = ctx.r11.s64 + 1212;
	// addi r3,r11,1680
	ctx.r3.s64 = ctx.r11.s64 + 1680;
	// bl 0x82132090
	ctx.lr = 0x82131AB0;
	sub_82132090(ctx, base);
loc_82131AB0:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82131AC8"))) PPC_WEAK_FUNC(sub_82131AC8);
PPC_FUNC_IMPL(__imp__sub_82131AC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82131AD0;
	__restfpr_27(ctx, base);
	// stfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lwz r9,1676(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// lfs f0,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// addi r6,r11,31376
	ctx.r6.s64 = ctx.r11.s64 + 31376;
	// lfs f13,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// li r8,1
	ctx.r8.s64 = 1;
	// lfs f12,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,12(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// lfs f10,16(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// rldicr r11,r8,36,63
	ctx.r11.u64 = rotl64(ctx.r8.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// lfs f9,20(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// lfs f31,36(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// fdivs f8,f31,f0
	ctx.f8.f64 = double(float(ctx.f31.f64 / ctx.f0.f64));
	// stfs f13,7744(r9)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7744, temp.u32);
	// stfs f8,7748(r9)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7748, temp.u32);
	// addi r31,r10,28184
	ctx.r31.s64 = ctx.r10.s64 + 28184;
	// stfs f12,7752(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7752, temp.u32);
	// li r30,1
	ctx.r30.s64 = 1;
	// stfs f11,7756(r9)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7756, temp.u32);
	// ld r5,8(r9)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// or r4,r5,r11
	ctx.r4.u64 = ctx.r5.u64 | ctx.r11.u64;
	// lfs f0,48(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// std r4,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, ctx.r4.u64);
	// stfs f10,7760(r9)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7760, temp.u32);
	// stfs f9,7764(r9)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7764, temp.u32);
	// stfs f0,7768(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7768, temp.u32);
	// stfs f0,7772(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 7772, temp.u32);
	// ld r3,8(r9)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r9.u32 + 8);
	// or r11,r3,r11
	ctx.r11.u64 = ctx.r3.u64 | ctx.r11.u64;
	// std r11,8(r9)
	PPC_STORE_U64(ctx.r9.u32 + 8, ctx.r11.u64);
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82131b84
	if (ctx.cr6.eq) goto loc_82131B84;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82131B7C;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_82131B84:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82131ba8
	if (ctx.cr6.eq) goto loc_82131BA8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82131BA0;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_82131BA8:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82131bdc
	if (ctx.cr6.eq) goto loc_82131BDC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82131BDC:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82131c10
	if (ctx.cr6.eq) goto loc_82131C10;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_82131C10:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r29,r10
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82131c38
	if (ctx.cr6.eq) goto loc_82131C38;
	// stw r29,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r29.u32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82131C38;
	sub_8222CDF8(ctx, base);
loc_82131C38:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82131C44;
	sub_821112B0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,26024(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26024);
	// bl 0x8211c5f0
	ctx.lr = 0x82131C50;
	sub_8211C5F0(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x82131C5C;
	sub_82111400(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x82131C60;
	sub_8210B0D8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210af50
	ctx.lr = 0x82131C80;
	sub_8210AF50(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82131C8C"))) PPC_WEAK_FUNC(sub_82131C8C);
PPC_FUNC_IMPL(__imp__sub_82131C8C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82131C90"))) PPC_WEAK_FUNC(sub_82131C90);
PPC_FUNC_IMPL(__imp__sub_82131C90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e44c
	ctx.lr = 0x82131C98;
	__restfpr_21(ctx, base);
	// stfd f29,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, ctx.f29.u64);
	// stfd f30,-112(r1)
	PPC_STORE_U64(ctx.r1.u32 + -112, ctx.f30.u64);
	// stfd f31,-104(r1)
	PPC_STORE_U64(ctx.r1.u32 + -104, ctx.f31.u64);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// lwz r11,1680(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1680);
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r30,r11,68
	ctx.r30.s64 = ctx.r11.s64 + 68;
	// lwz r31,1676(r29)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1676);
	// bl 0x82113bc0
	ctx.lr = 0x82131CC8;
	sub_82113BC0(ctx, base);
	// lwz r11,1680(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwz r10,32(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// addi r26,r11,900
	ctx.r26.s64 = ctx.r11.s64 + 900;
	// clrlwi r27,r10,26
	ctx.r27.u64 = ctx.r10.u32 & 0x3F;
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r27,50
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 50, ctx.xer);
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r6,8(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// stw r7,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r7.u32);
	// stw r6,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r6.u32);
	// stw r5,12(r9)
	PPC_STORE_U32(ctx.r9.u32 + 12, ctx.r5.u32);
	// lfs f30,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f30.f64 = double(temp.f32);
	// lfs f13,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// lfs f29,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f29.f64 = double(temp.f32);
	// lfs f0,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// fctidz f9,f0
	ctx.f9.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// fadds f11,f30,f0
	ctx.f11.f64 = double(float(ctx.f30.f64 + ctx.f0.f64));
	// fadds f10,f29,f13
	ctx.f10.f64 = double(float(ctx.f29.f64 + ctx.f13.f64));
	// fctidz f12,f13
	ctx.f12.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// stfd f12,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f12.u64);
	// lwz r21,84(r1)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfd f9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f9.u64);
	// lwz r22,84(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r21,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r21.u32);
	// fctidz f8,f11
	ctx.f8.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// stfd f8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f8.u64);
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// fctidz f7,f10
	ctx.f7.s64 = (ctx.f10.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f10.f64);
	// stfd f7,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f7.u64);
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r22,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r22.u32);
	// stw r4,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r4.u32);
	// stw r3,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r3.u32);
	// bne cr6,0x82131d68
	if (!ctx.cr6.eq) goto loc_82131D68;
	// li r11,3
	ctx.r11.s64 = 3;
	// rlwimi r10,r11,1,26,31
	ctx.r10.u64 = (rotl32(ctx.r11.u32, 1) & 0x3F) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r10,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r10.u32);
loc_82131D68:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// addi r24,r11,31376
	ctx.r24.s64 = ctx.r11.s64 + 31376;
	// addi r23,r10,27648
	ctx.r23.s64 = ctx.r10.s64 + 27648;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lfs f31,36(r24)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r3,188(r23)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r23.u32 + 188);
	// li r4,0
	ctx.r4.s64 = 0;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82227e30
	ctx.lr = 0x82131DA0;
	sub_82227E30(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r9,32(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// rlwimi r9,r27,0,26,31
	ctx.r9.u64 = (rotl32(ctx.r27.u32, 0) & 0x3F) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFC0);
	// lbz r10,25549(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 25549);
	// stw r9,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r9.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lwz r11,1680(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// beq cr6,0x82131dd8
	if (ctx.cr6.eq) goto loc_82131DD8;
	// addi r27,r11,640
	ctx.r27.s64 = ctx.r11.s64 + 640;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// addi r25,r11,2700
	ctx.r25.s64 = ctx.r11.s64 + 2700;
	// bl 0x8212df70
	ctx.lr = 0x82131DD4;
	sub_8212DF70(ctx, base);
	// b 0x82131df4
	goto loc_82131DF4;
loc_82131DD8:
	// addi r27,r11,744
	ctx.r27.s64 = ctx.r11.s64 + 744;
	// addi r25,r11,2604
	ctx.r25.s64 = ctx.r11.s64 + 2604;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// bl 0x8212e260
	ctx.lr = 0x82131DF4;
	sub_8212E260(ctx, base);
loc_82131DF4:
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82131ac8
	ctx.lr = 0x82131E0C;
	sub_82131AC8(ctx, base);
	// lfs f13,4(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,60(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 60);
	ctx.f0.f64 = double(temp.f32);
	// li r12,1
	ctx.r12.s64 = 1;
	// fmuls f11,f13,f0
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// lfs f12,0(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,16(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// rldicr r12,r12,36,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// lfs f9,20(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stfs f12,7744(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7744, temp.u32);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// stfs f10,7752(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7752, temp.u32);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// stfs f9,7756(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7756, temp.u32);
	// fdivs f8,f31,f11
	ctx.f8.f64 = double(float(ctx.f31.f64 / ctx.f11.f64));
	// stfs f8,7748(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7748, temp.u32);
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// bl 0x82132d28
	ctx.lr = 0x82131E5C;
	sub_82132D28(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82132d28
	ctx.lr = 0x82131E6C;
	sub_82132D28(ctx, base);
	// lwz r10,1680(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// lwz r11,36(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 36);
	// addi r5,r10,1836
	ctx.r5.s64 = ctx.r10.s64 + 1836;
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82131e90
	if (ctx.cr6.eq) goto loc_82131E90;
	// stw r5,36(r23)
	PPC_STORE_U32(ctx.r23.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r23)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r23.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82131E90;
	sub_8222CDF8(ctx, base);
loc_82131E90:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82131E9C;
	sub_821112B0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,26028(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26028);
	// bl 0x8211c5f0
	ctx.lr = 0x82131EA8;
	sub_8211C5F0(ctx, base);
	// fctidz f0,f30
	ctx.fpscr.disableFlushMode();
	ctx.f0.s64 = (ctx.f30.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f30.f64);
	// stfd f0,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f0.u64);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// fctidz f13,f29
	ctx.f13.s64 = (ctx.f29.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f29.f64);
	// stfd f13,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f13.u64);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lfs f0,48(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// stw r10,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r10.u32);
	// stfs f31,112(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stw r9,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r9.u32);
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stw r22,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r22.u32);
	// stw r21,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r21.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cbc8
	ctx.lr = 0x82131EE8;
	sub_8222CBC8(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r26.u32, ctx.xer);
	// beq cr6,0x82131f18
	if (ctx.cr6.eq) goto loc_82131F18;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x82131F14;
	sub_82237A38(ctx, base);
	// stw r26,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r26.u32);
loc_82131F18:
	// lwz r11,296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 296);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x82131f3c
	if (ctx.cr6.eq) goto loc_82131F3C;
	// lis r6,16384
	ctx.r6.s64 = 1073741824;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82237a38
	ctx.lr = 0x82131F38;
	sub_82237A38(ctx, base);
	// stw r30,296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 296, ctx.r30.u32);
loc_82131F3C:
	// bl 0x8210b0d8
	ctx.lr = 0x82131F40;
	sub_8210B0D8(ctx, base);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// lfd f29,-120(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// lfd f30,-112(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// lfd f31,-104(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82131F54"))) PPC_WEAK_FUNC(sub_82131F54);
PPC_FUNC_IMPL(__imp__sub_82131F54) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82131F58"))) PPC_WEAK_FUNC(sub_82131F58);
PPC_FUNC_IMPL(__imp__sub_82131F58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82131F60;
	__restfpr_27(ctx, base);
	// stfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r31,1676(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// fmr f31,f1
	ctx.f31.f64 = ctx.f1.f64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r30,r7
	ctx.r30.u64 = ctx.r7.u64;
	// bl 0x82132d28
	ctx.lr = 0x82131F90;
	sub_82132D28(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82132d28
	ctx.lr = 0x82131FA0;
	sub_82132D28(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r30,r10
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82131fc8
	if (ctx.cr6.eq) goto loc_82131FC8;
	// stw r30,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r30.u32);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82131FC8;
	sub_8222CDF8(ctx, base);
loc_82131FC8:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82131FD4;
	sub_821112B0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25976(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25976);
	// bl 0x8211c5f0
	ctx.lr = 0x82131FE0;
	sub_8211C5F0(ctx, base);
	// li r12,1
	ctx.r12.s64 = 1;
	// stfs f31,7744(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7744, temp.u32);
	// stfs f31,7748(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7748, temp.u32);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// rldicr r12,r12,36,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// stfs f31,7752(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7752, temp.u32);
	// stfs f31,7756(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7756, temp.u32);
	// ld r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r9,r10,r12
	ctx.r9.u64 = ctx.r10.u64 | ctx.r12.u64;
	// std r9,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r9.u64);
	// addi r30,r11,28184
	ctx.r30.s64 = ctx.r11.s64 + 28184;
	// lwz r11,292(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 292);
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82132034
	if (ctx.cr6.eq) goto loc_82132034;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x82132030;
	sub_82237A38(ctx, base);
	// stw r29,292(r30)
	PPC_STORE_U32(ctx.r30.u32 + 292, ctx.r29.u32);
loc_82132034:
	// lwz r11,296(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 296);
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82132058
	if (ctx.cr6.eq) goto loc_82132058;
	// lis r6,16384
	ctx.r6.s64 = 1073741824;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82237a38
	ctx.lr = 0x82132054;
	sub_82237A38(ctx, base);
	// stw r28,296(r30)
	PPC_STORE_U32(ctx.r30.u32 + 296, ctx.r28.u32);
loc_82132058:
	// bl 0x8210b0d8
	ctx.lr = 0x8213205C;
	sub_8210B0D8(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f1,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210af50
	ctx.lr = 0x82132084;
	sub_8210AF50(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82132090"))) PPC_WEAK_FUNC(sub_82132090);
PPC_FUNC_IMPL(__imp__sub_82132090) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82132098;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// bl 0x82132d28
	ctx.lr = 0x821320B0;
	sub_82132D28(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r30,r11,27648
	ctx.r30.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x821320d8
	if (ctx.cr6.eq) goto loc_821320D8;
	// stw r29,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r29.u32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x821320D8;
	sub_8222CDF8(ctx, base);
loc_821320D8:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x821320E4;
	sub_821112B0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25980(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25980);
	// bl 0x8211c5f0
	ctx.lr = 0x821320F0;
	sub_8211C5F0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r29,r11,28184
	ctx.r29.s64 = ctx.r11.s64 + 28184;
	// lwz r11,292(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 292);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x82132120
	if (ctx.cr6.eq) goto loc_82132120;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x8213211C;
	sub_82237A38(ctx, base);
	// stw r31,292(r29)
	PPC_STORE_U32(ctx.r29.u32 + 292, ctx.r31.u32);
loc_82132120:
	// bl 0x8210b0d8
	ctx.lr = 0x82132124;
	sub_8210B0D8(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lis r3,11264
	ctx.r3.s64 = 738197504;
	// lfs f1,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210af50
	ctx.lr = 0x8213214C;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82132170
	if (ctx.cr6.eq) goto loc_82132170;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cdf8
	ctx.lr = 0x82132170;
	sub_8222CDF8(ctx, base);
loc_82132170:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82132178"))) PPC_WEAK_FUNC(sub_82132178);
PPC_FUNC_IMPL(__imp__sub_82132178) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e438
	ctx.lr = 0x82132180;
	__restfpr_16(ctx, base);
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x8233fa14
	ctx.lr = 0x82132188;
	sub_8233FA14(ctx, base);
	// stwu r1,-416(r1)
	ea = -416 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lwz r10,288(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 288);
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// lwz r31,1676(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// addi r26,r11,31376
	ctx.r26.s64 = ctx.r11.s64 + 31376;
	// lwz r11,1680(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1680);
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// rlwinm r8,r10,0,29,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// li r18,0
	ctx.r18.s64 = 0;
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lfs f23,48(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 48);
	ctx.f23.f64 = double(temp.f32);
	// lwz r6,4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// li r20,1
	ctx.r20.s64 = 1;
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// lwz r4,12(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// addi r23,r11,120
	ctx.r23.s64 = ctx.r11.s64 + 120;
	// addi r22,r11,16
	ctx.r22.s64 = ctx.r11.s64 + 16;
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// stw r6,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r6.u32);
	// stw r5,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r5.u32);
	// stw r4,12(r9)
	PPC_STORE_U32(ctx.r9.u32 + 12, ctx.r4.u32);
	// beq cr6,0x82132208
	if (ctx.cr6.eq) goto loc_82132208;
	// rlwinm r11,r10,0,17,17
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82132208
	if (!ctx.cr6.eq) goto loc_82132208;
	// lfs f0,80(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// stw r20,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r20.u32);
	// fcmpu cr6,f0,f23
	ctx.cr6.compare(ctx.f0.f64, ctx.f23.f64);
	// bne cr6,0x8213220c
	if (!ctx.cr6.eq) goto loc_8213220C;
loc_82132208:
	// stw r18,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r18.u32);
loc_8213220C:
	// clrlwi r11,r10,31
	ctx.r11.u64 = ctx.r10.u32 & 0x1;
	// rlwinm r9,r10,31,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
	// rlwinm r8,r10,27,31,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// rlwinm r7,r10,26,31,31
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x1;
	// stw r9,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r9.u32);
	// rlwinm r16,r10,17,31,31
	ctx.r16.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 17) & 0x1;
	// stw r8,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r8.u32);
	// stw r7,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r7.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r16,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r16.u32);
	// beq cr6,0x82132248
	if (ctx.cr6.eq) goto loc_82132248;
	// lbz r9,21(r29)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r29.u32 + 21);
	// stw r20,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r20.u32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x8213224c
	if (!ctx.cr6.eq) goto loc_8213224C;
loc_82132248:
	// stw r18,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r18.u32);
loc_8213224C:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82132264
	if (ctx.cr6.eq) goto loc_82132264;
	// lbz r11,20(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 20);
	// stw r20,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r20.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82132268
	if (!ctx.cr6.eq) goto loc_82132268;
loc_82132264:
	// stw r18,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r18.u32);
loc_82132268:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// rlwinm r9,r10,23,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 23) & 0x1;
	// addi r30,r11,28184
	ctx.r30.s64 = ctx.r11.s64 + 28184;
	// rlwinm r21,r10,24,31,31
	ctx.r21.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0x1;
	// stw r9,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r9.u32);
	// rlwinm r19,r10,22,31,31
	ctx.r19.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 22) & 0x1;
	// rlwinm r17,r10,20,31,31
	ctx.r17.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0x1;
	// stw r21,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r21.u32);
	// stw r19,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r19.u32);
	// lwz r11,292(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 292);
	// stw r17,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r17.u32);
	// cmplw cr6,r11,r23
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r23.u32, ctx.xer);
	// beq cr6,0x821322b8
	if (ctx.cr6.eq) goto loc_821322B8;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x821322B4;
	sub_82237A38(ctx, base);
	// stw r23,292(r30)
	PPC_STORE_U32(ctx.r30.u32 + 292, ctx.r23.u32);
loc_821322B8:
	// lwz r11,2052(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821322dc
	if (ctx.cr6.eq) goto loc_821322DC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x821322D4;
	sub_8222C0A0(ctx, base);
	// mr r11,r20
	ctx.r11.u64 = ctx.r20.u64;
	// stw r20,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r20.u32);
loc_821322DC:
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82132300
	if (ctx.cr6.eq) goto loc_82132300;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x821322F8;
	sub_8222C248(ctx, base);
	// mr r11,r20
	ctx.r11.u64 = ctx.r20.u64;
	// stw r20,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r20.u32);
loc_82132300:
	// lwz r11,1972(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82132334
	if (ctx.cr6.eq) goto loc_82132334;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r20,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r20.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1972, ctx.r10.u32);
loc_82132334:
	// lwz r11,1988(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82132368
	if (ctx.cr6.eq) goto loc_82132368;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r20,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r20.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1988, ctx.r10.u32);
loc_82132368:
	// lwz r11,1680(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1680);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// addi r28,r11,848
	ctx.r28.s64 = ctx.r11.s64 + 848;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82132d28
	ctx.lr = 0x82132380;
	sub_82132D28(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111400
	ctx.lr = 0x8213238C;
	sub_82111400(ctx, base);
	// lwz r11,2292(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2292);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821323c0
	if (ctx.cr6.eq) goto loc_821323C0;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r20,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r20.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2292, ctx.r10.u32);
loc_821323C0:
	// lwz r11,2308(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821323f4
	if (ctx.cr6.eq) goto loc_821323F4;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r20,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r20.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2308, ctx.r10.u32);
loc_821323F4:
	// lwz r11,2372(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2372);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82132418
	if (ctx.cr6.eq) goto loc_82132418;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x82132410;
	sub_8222C0A0(ctx, base);
	// mr r11,r20
	ctx.r11.u64 = ctx.r20.u64;
	// stw r20,2372(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2372, ctx.r20.u32);
loc_82132418:
	// lwz r11,2356(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2356);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8213243c
	if (ctx.cr6.eq) goto loc_8213243C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82132434;
	sub_8222C248(ctx, base);
	// mr r11,r20
	ctx.r11.u64 = ctx.r20.u64;
	// stw r20,2356(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2356, ctx.r20.u32);
loc_8213243C:
	// li r11,1
	ctx.r11.s64 = 1;
	// lfs f0,4(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// li r5,2
	ctx.r5.s64 = 2;
	// lfs f12,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f12.f64 = double(temp.f32);
	// rldicr r27,r11,35,63
	ctx.r27.u64 = rotl64(ctx.r11.u64, 35) & 0xFFFFFFFFFFFFFFFF;
	// lfs f11,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f11.f64 = double(temp.f32);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// stfs f12,7848(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7848, temp.u32);
	// stfs f11,7852(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7852, temp.u32);
	// stfs f0,7844(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7844, temp.u32);
	// stfs f13,7840(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7840, temp.u32);
	// ld r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r9,r10,r27
	ctx.r9.u64 = ctx.r10.u64 | ctx.r27.u64;
	// std r9,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r9.u64);
	// lwz r11,1680(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1680);
	// addi r28,r11,1108
	ctx.r28.s64 = ctx.r11.s64 + 1108;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82132d28
	ctx.lr = 0x82132488;
	sub_82132D28(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x82111400
	ctx.lr = 0x82132494;
	sub_82111400(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x82111390
	ctx.lr = 0x821324A4;
	sub_82111390(ctx, base);
	// lwz r11,2628(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2628);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821324d8
	if (ctx.cr6.eq) goto loc_821324D8;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1200(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1200);
	// rlwimi r8,r20,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r20.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1200(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1200, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,8192
	ctx.r6.u64 = ctx.r7.u64 | 536870912;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2628(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2628, ctx.r10.u32);
loc_821324D8:
	// lwz r11,2692(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2692);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821324fc
	if (ctx.cr6.eq) goto loc_821324FC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8222c0a0
	ctx.lr = 0x821324F4;
	sub_8222C0A0(ctx, base);
	// mr r11,r18
	ctx.r11.u64 = ctx.r18.u64;
	// stw r18,2692(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2692, ctx.r18.u32);
loc_821324FC:
	// lwz r11,2676(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2676);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82132520
	if (ctx.cr6.eq) goto loc_82132520;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8222c248
	ctx.lr = 0x82132518;
	sub_8222C248(ctx, base);
	// mr r11,r18
	ctx.r11.u64 = ctx.r18.u64;
	// stw r18,2676(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2676, ctx.r18.u32);
loc_82132520:
	// lfs f22,36(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 36);
	ctx.f22.f64 = double(temp.f32);
	// li r11,1
	ctx.r11.s64 = 1;
	// lfs f20,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f20.f64 = double(temp.f32);
	// li r5,3
	ctx.r5.s64 = 3;
	// lfs f19,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f19.f64 = double(temp.f32);
	// fdivs f13,f22,f20
	ctx.f13.f64 = double(float(ctx.f22.f64 / ctx.f20.f64));
	// fdivs f12,f22,f19
	ctx.f12.f64 = double(float(ctx.f22.f64 / ctx.f19.f64));
	// lfs f11,164(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 164);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,168(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 168);
	ctx.f10.f64 = double(temp.f32);
	// rldicr r25,r11,33,63
	ctx.r25.u64 = rotl64(ctx.r11.u64, 33) & 0xFFFFFFFFFFFFFFFF;
	// lfs f9,172(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 172);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,176(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 176);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,1448(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 1448);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f7,f11,f13
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// stfs f7,7856(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7856, temp.u32);
	// fmuls f6,f10,f12
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// stfs f6,7860(r31)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7860, temp.u32);
	// fmuls f5,f9,f13
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// stfs f5,7864(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7864, temp.u32);
	// fmuls f4,f8,f12
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// stfs f4,7868(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7868, temp.u32);
	// ld r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r9,r10,r27
	ctx.r9.u64 = ctx.r10.u64 | ctx.r27.u64;
	// std r9,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r9.u64);
	// stfs f0,7984(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7984, temp.u32);
	// stfs f23,7988(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7988, temp.u32);
	// stfs f23,7992(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7992, temp.u32);
	// stfs f23,7996(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7996, temp.u32);
	// ld r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r7,r8,r25
	ctx.r7.u64 = ctx.r8.u64 | ctx.r25.u64;
	// std r7,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r7.u64);
	// lwz r11,1680(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1680);
	// addi r28,r11,1004
	ctx.r28.s64 = ctx.r11.s64 + 1004;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82132d28
	ctx.lr = 0x821325B0;
	sub_82132D28(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,3
	ctx.r3.s64 = 3;
	// bl 0x82111400
	ctx.lr = 0x821325BC;
	sub_82111400(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,3
	ctx.r3.s64 = 3;
	// bl 0x82111390
	ctx.lr = 0x821325CC;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,3
	ctx.r3.s64 = 3;
	// bl 0x82111390
	ctx.lr = 0x821325DC;
	sub_82111390(ctx, base);
	// lfs f3,80(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 80);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,7744(r31)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7744, temp.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// lfs f2,84(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// li r5,4
	ctx.r5.s64 = 4;
	// stfs f2,7748(r31)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7748, temp.u32);
	// rldicr r28,r6,36,63
	ctx.r28.u64 = rotl64(ctx.r6.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// lfs f1,88(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// stfs f1,7752(r31)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7752, temp.u32);
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// lfs f0,92(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,7756(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7756, temp.u32);
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r10,r11,r28
	ctx.r10.u64 = ctx.r11.u64 | ctx.r28.u64;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// bl 0x82132d28
	ctx.lr = 0x82132620;
	sub_82132D28(ctx, base);
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// li r3,4
	ctx.r3.s64 = 4;
	// bl 0x82111400
	ctx.lr = 0x8213262C;
	sub_82111400(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,4
	ctx.r3.s64 = 4;
	// bl 0x82111390
	ctx.lr = 0x8213263C;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,4
	ctx.r3.s64 = 4;
	// bl 0x82111390
	ctx.lr = 0x8213264C;
	sub_82111390(ctx, base);
	// lwz r11,1680(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1680);
	// li r5,5
	ctx.r5.s64 = 5;
	// addi r27,r11,1160
	ctx.r27.s64 = ctx.r11.s64 + 1160;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82132d28
	ctx.lr = 0x82132664;
	sub_82132D28(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// li r3,5
	ctx.r3.s64 = 5;
	// bl 0x82111400
	ctx.lr = 0x82132670;
	sub_82111400(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,5
	ctx.r3.s64 = 5;
	// bl 0x82111390
	ctx.lr = 0x82132680;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,5
	ctx.r3.s64 = 5;
	// bl 0x82111390
	ctx.lr = 0x82132690;
	sub_82111390(ctx, base);
	// lfs f0,56(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 56);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,56(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f0,f22
	ctx.cr6.compare(ctx.f0.f64, ctx.f22.f64);
	// blt cr6,0x821326a8
	if (ctx.cr6.lt) goto loc_821326A8;
	// fmr f0,f22
	ctx.f0.f64 = ctx.f22.f64;
loc_821326A8:
	// lfs f13,48(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// li r5,6
	ctx.r5.s64 = 6;
	// lfs f12,44(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 44);
	ctx.f12.f64 = double(temp.f32);
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// lfs f11,52(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 52);
	ctx.f11.f64 = double(temp.f32);
	// stfs f13,7760(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7760, temp.u32);
	// stfs f12,7764(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7764, temp.u32);
	// stfs f0,7772(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7772, temp.u32);
	// stfs f11,7768(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7768, temp.u32);
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r10,r11,r28
	ctx.r10.u64 = ctx.r11.u64 | ctx.r28.u64;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// lwz r11,1680(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1680);
	// addi r28,r11,1056
	ctx.r28.s64 = ctx.r11.s64 + 1056;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82132d28
	ctx.lr = 0x821326E8;
	sub_82132D28(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// li r3,6
	ctx.r3.s64 = 6;
	// bl 0x82111400
	ctx.lr = 0x821326F4;
	sub_82111400(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,6
	ctx.r3.s64 = 6;
	// bl 0x82111390
	ctx.lr = 0x82132704;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,6
	ctx.r3.s64 = 6;
	// bl 0x82111390
	ctx.lr = 0x82132714;
	sub_82111390(ctx, base);
	// li r9,1
	ctx.r9.s64 = 1;
	// cmpwi cr6,r21,0
	ctx.cr6.compare<int32_t>(ctx.r21.s32, 0, ctx.xer);
	// stw r18,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r18.u32);
	// rldicr r28,r9,34,63
	ctx.r28.u64 = rotl64(ctx.r9.u64, 34) & 0xFFFFFFFFFFFFFFFF;
	// beq cr6,0x82132928
	if (ctx.cr6.eq) goto loc_82132928;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,296(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 296);
	// bl 0x82172e00
	ctx.lr = 0x82132734;
	sub_82172E00(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82132748
	if (!ctx.cr6.eq) goto loc_82132748;
	// stw r18,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r18.u32);
	// b 0x82132928
	goto loc_82132928;
loc_82132748:
	// lwz r11,296(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 296);
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82132760
	if (ctx.cr6.eq) goto loc_82132760;
	// bl 0x820b91d0
	ctx.lr = 0x8213275C;
	sub_820B91D0(ctx, base);
	// b 0x8213277c
	goto loc_8213277C;
loc_82132760:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82132774
	if (ctx.cr6.eq) goto loc_82132774;
	// lwz r3,88(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x8213277c
	goto loc_8213277C;
loc_82132774:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x8213277C;
	sub_820B90A0(ctx, base);
loc_8213277C:
	// lwz r27,4(r3)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r5,7
	ctx.r5.s64 = 7;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82132d28
	ctx.lr = 0x82132790;
	sub_82132D28(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// li r3,7
	ctx.r3.s64 = 7;
	// bl 0x82111400
	ctx.lr = 0x8213279C;
	sub_82111400(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,7
	ctx.r3.s64 = 7;
	// bl 0x82111390
	ctx.lr = 0x821327AC;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,7
	ctx.r3.s64 = 7;
	// bl 0x82111390
	ctx.lr = 0x821327BC;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,8
	ctx.r4.s64 = 8;
	// li r3,7
	ctx.r3.s64 = 7;
	// bl 0x82111390
	ctx.lr = 0x821327CC;
	sub_82111390(ctx, base);
	// lwz r11,4292(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4292);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821327f0
	if (ctx.cr6.eq) goto loc_821327F0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,7
	ctx.r4.s64 = 7;
	// bl 0x8222c0a0
	ctx.lr = 0x821327E8;
	sub_8222C0A0(ctx, base);
	// mr r11,r20
	ctx.r11.u64 = ctx.r20.u64;
	// stw r20,4292(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4292, ctx.r20.u32);
loc_821327F0:
	// lwz r11,4276(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4276);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82132814
	if (ctx.cr6.eq) goto loc_82132814;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,7
	ctx.r4.s64 = 7;
	// bl 0x8222c248
	ctx.lr = 0x8213280C;
	sub_8222C248(ctx, base);
	// mr r11,r20
	ctx.r11.u64 = ctx.r20.u64;
	// stw r20,4276(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4276, ctx.r20.u32);
loc_82132814:
	// lfs f31,200(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 200);
	ctx.f31.f64 = double(temp.f32);
	// fcmpu cr6,f31,f23
	ctx.cr6.compare(ctx.f31.f64, ctx.f23.f64);
	// ble cr6,0x82132904
	if (!ctx.cr6.gt) goto loc_82132904;
	// lwz r3,300(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 300);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82132904
	if (ctx.cr6.eq) goto loc_82132904;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82172e00
	ctx.lr = 0x82132834;
	sub_82172E00(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82132904
	if (ctx.cr6.eq) goto loc_82132904;
	// lwz r11,300(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 300);
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82132858
	if (ctx.cr6.eq) goto loc_82132858;
	// bl 0x820b91d0
	ctx.lr = 0x82132854;
	sub_820B91D0(ctx, base);
	// b 0x82132874
	goto loc_82132874;
loc_82132858:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213286c
	if (ctx.cr6.eq) goto loc_8213286C;
	// lwz r3,88(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x82132874
	goto loc_82132874;
loc_8213286C:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x82132874;
	sub_820B90A0(ctx, base);
loc_82132874:
	// lwz r27,4(r3)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r5,8
	ctx.r5.s64 = 8;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82132d28
	ctx.lr = 0x82132888;
	sub_82132D28(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x82111400
	ctx.lr = 0x82132894;
	sub_82111400(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x82111390
	ctx.lr = 0x821328A4;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x82111390
	ctx.lr = 0x821328B4;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,8
	ctx.r4.s64 = 8;
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x82111390
	ctx.lr = 0x821328C4;
	sub_82111390(ctx, base);
	// lwz r11,4612(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4612);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821328e8
	if (ctx.cr6.eq) goto loc_821328E8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,8
	ctx.r4.s64 = 8;
	// bl 0x8222c0a0
	ctx.lr = 0x821328E0;
	sub_8222C0A0(ctx, base);
	// mr r11,r20
	ctx.r11.u64 = ctx.r20.u64;
	// stw r20,4612(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4612, ctx.r20.u32);
loc_821328E8:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x82111390
	ctx.lr = 0x821328F8;
	sub_82111390(ctx, base);
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r20.u32);
	// stw r18,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r18.u32);
	// b 0x82132908
	goto loc_82132908;
loc_82132904:
	// fmr f31,f23
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f23.f64;
loc_82132908:
	// lfs f0,192(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 192);
	ctx.f0.f64 = double(temp.f32);
	// stfs f23,7912(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7912, temp.u32);
	// stfs f31,7908(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7908, temp.u32);
	// stfs f0,7904(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7904, temp.u32);
	// stfs f23,7916(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7916, temp.u32);
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r10,r11,r28
	ctx.r10.u64 = ctx.r11.u64 | ctx.r28.u64;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
loc_82132928:
	// lfs f0,184(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 184);
	ctx.f0.f64 = double(temp.f32);
	// cmpwi cr6,r19,0
	ctx.cr6.compare<int32_t>(ctx.r19.s32, 0, ctx.xer);
	// lfs f13,180(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f12,f22,f0
	ctx.f12.f64 = double(float(ctx.f22.f64 / ctx.f0.f64));
	// stfs f23,7928(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7928, temp.u32);
	// stfs f23,7932(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7932, temp.u32);
	// stfs f13,7924(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7924, temp.u32);
	// stfs f12,7920(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7920, temp.u32);
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r10,r11,r28
	ctx.r10.u64 = ctx.r11.u64 | ctx.r28.u64;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// beq cr6,0x82132b0c
	if (ctx.cr6.eq) goto loc_82132B0C;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,304(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 304);
	// bl 0x82172e00
	ctx.lr = 0x82132964;
	sub_82172E00(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82132978
	if (!ctx.cr6.eq) goto loc_82132978;
	// stw r18,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r18.u32);
	// b 0x82132b0c
	goto loc_82132B0C;
loc_82132978:
	// lwz r11,236(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 236);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x8213298c
	if (!ctx.cr6.eq) goto loc_8213298C;
	// fmr f21,f22
	ctx.fpscr.disableFlushMode();
	ctx.f21.f64 = ctx.f22.f64;
	// b 0x82132990
	goto loc_82132990;
loc_8213298C:
	// fmr f21,f23
	ctx.fpscr.disableFlushMode();
	ctx.f21.f64 = ctx.f23.f64;
loc_82132990:
	// lwz r11,304(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 304);
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821329a8
	if (ctx.cr6.eq) goto loc_821329A8;
	// bl 0x820b91d0
	ctx.lr = 0x821329A4;
	sub_820B91D0(ctx, base);
	// b 0x821329c4
	goto loc_821329C4;
loc_821329A8:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821329bc
	if (ctx.cr6.eq) goto loc_821329BC;
	// lwz r28,88(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x821329c8
	goto loc_821329C8;
loc_821329BC:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x821329C4;
	sub_820B90A0(ctx, base);
loc_821329C4:
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
loc_821329C8:
	// lbz r11,232(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 232);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821329f4
	if (!ctx.cr6.eq) goto loc_821329F4;
	// fmr f2,f22
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = ctx.f22.f64;
	// fmr f1,f23
	ctx.f1.f64 = ctx.f23.f64;
	// bl 0x8208d3b0
	ctx.lr = 0x821329E0;
	sub_8208D3B0(ctx, base);
	// stfs f1,0(r24)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r24.u32 + 0, temp.u32);
	// fmr f2,f22
	ctx.f2.f64 = ctx.f22.f64;
	// fmr f1,f23
	ctx.f1.f64 = ctx.f23.f64;
	// bl 0x8208d3b0
	ctx.lr = 0x821329F0;
	sub_8208D3B0(ctx, base);
	// stfs f1,4(r24)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r24.u32 + 4, temp.u32);
loc_821329F4:
	// lwz r9,16(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// lfs f0,224(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 224);
	ctx.f0.f64 = double(temp.f32);
	// lwz r8,12(r28)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	// lfs f13,228(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 228);
	ctx.f13.f64 = double(temp.f32);
	// li r3,9
	ctx.r3.s64 = 9;
	// lfs f31,0(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	ctx.f31.f64 = double(temp.f32);
	// lfs f30,4(r24)
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 4);
	ctx.f30.f64 = double(temp.f32);
	// lwz r4,4(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// lfs f29,212(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 212);
	ctx.f29.f64 = double(temp.f32);
	// std r9,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r9.u64);
	// lfs f28,216(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 216);
	ctx.f28.f64 = double(temp.f32);
	// std r8,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r8.u64);
	// lfs f27,220(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 220);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,208(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 208);
	ctx.f26.f64 = double(temp.f32);
	// lfd f12,136(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// lfd f11,144(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f10,f12
	ctx.f10.f64 = double(ctx.f12.s64);
	// fcfid f9,f11
	ctx.f9.f64 = double(ctx.f11.s64);
	// frsp f8,f10
	ctx.f8.f64 = double(float(ctx.f10.f64));
	// frsp f7,f9
	ctx.f7.f64 = double(float(ctx.f9.f64));
	// fdivs f6,f13,f8
	ctx.f6.f64 = double(float(ctx.f13.f64 / ctx.f8.f64));
	// fdivs f5,f0,f7
	ctx.f5.f64 = double(float(ctx.f0.f64 / ctx.f7.f64));
	// fmuls f24,f6,f19
	ctx.f24.f64 = double(float(ctx.f6.f64 * ctx.f19.f64));
	// fmuls f25,f5,f20
	ctx.f25.f64 = double(float(ctx.f5.f64 * ctx.f20.f64));
	// bl 0x82111400
	ctx.lr = 0x82132A58;
	sub_82111400(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,9
	ctx.r3.s64 = 9;
	// bl 0x82111390
	ctx.lr = 0x82132A68;
	sub_82111390(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,9
	ctx.r3.s64 = 9;
	// bl 0x82111390
	ctx.lr = 0x82132A78;
	sub_82111390(ctx, base);
	// lwz r11,4932(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4932);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82132a9c
	if (ctx.cr6.eq) goto loc_82132A9C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,9
	ctx.r4.s64 = 9;
	// bl 0x8222c0a0
	ctx.lr = 0x82132A94;
	sub_8222C0A0(ctx, base);
	// mr r11,r18
	ctx.r11.u64 = ctx.r18.u64;
	// stw r18,4932(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4932, ctx.r18.u32);
loc_82132A9C:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,9
	ctx.r3.s64 = 9;
	// bl 0x82111390
	ctx.lr = 0x82132AAC;
	sub_82111390(ctx, base);
	// stfs f31,7936(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7936, temp.u32);
	// stfs f30,7940(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7940, temp.u32);
	// stfs f24,7948(r31)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7948, temp.u32);
	// stfs f25,7944(r31)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7944, temp.u32);
	// lfs f0,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r10,r11,r25
	ctx.r10.u64 = ctx.r11.u64 | ctx.r25.u64;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// stfs f29,7952(r31)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7952, temp.u32);
	// stfs f28,7956(r31)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7956, temp.u32);
	// stfs f27,7960(r31)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7960, temp.u32);
	// stfs f26,7964(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7964, temp.u32);
	// ld r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r8,r9,r25
	ctx.r8.u64 = ctx.r9.u64 | ctx.r25.u64;
	// std r8,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r8.u64);
	// stfs f0,7980(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7980, temp.u32);
	// stfs f21,7968(r31)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7968, temp.u32);
	// stfs f13,7972(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7972, temp.u32);
	// stfs f12,7976(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7976, temp.u32);
	// ld r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r6,r7,r25
	ctx.r6.u64 = ctx.r7.u64 | ctx.r25.u64;
	// std r6,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r6.u64);
loc_82132B0C:
	// cmpwi cr6,r17,0
	ctx.cr6.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// beq cr6,0x82132b58
	if (ctx.cr6.eq) goto loc_82132B58;
	// lwz r11,1680(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1680);
	// li r5,10
	ctx.r5.s64 = 10;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// addi r30,r11,952
	ctx.r30.s64 = ctx.r11.s64 + 952;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82132d28
	ctx.lr = 0x82132B2C;
	sub_82132D28(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// li r3,10
	ctx.r3.s64 = 10;
	// bl 0x82111400
	ctx.lr = 0x82132B38;
	sub_82111400(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,10
	ctx.r3.s64 = 10;
	// bl 0x82111390
	ctx.lr = 0x82132B48;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,10
	ctx.r3.s64 = 10;
	// bl 0x82111390
	ctx.lr = 0x82132B58;
	sub_82111390(ctx, base);
loc_82132B58:
	// cmpwi cr6,r16,0
	ctx.cr6.compare<int32_t>(ctx.r16.s32, 0, ctx.xer);
	// beq cr6,0x82132ba4
	if (ctx.cr6.eq) goto loc_82132BA4;
	// lwz r11,1680(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1680);
	// li r5,11
	ctx.r5.s64 = 11;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// addi r30,r11,1212
	ctx.r30.s64 = ctx.r11.s64 + 1212;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82132d28
	ctx.lr = 0x82132B78;
	sub_82132D28(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// li r3,11
	ctx.r3.s64 = 11;
	// bl 0x82111400
	ctx.lr = 0x82132B84;
	sub_82111400(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,11
	ctx.r3.s64 = 11;
	// bl 0x82111390
	ctx.lr = 0x82132B94;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,11
	ctx.r3.s64 = 11;
	// bl 0x82111390
	ctx.lr = 0x82132BA4;
	sub_82111390(ctx, base);
loc_82132BA4:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,1680(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1680);
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,1836
	ctx.r5.s64 = ctx.r10.s64 + 1836;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82132bd0
	if (ctx.cr6.eq) goto loc_82132BD0;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82132BD0;
	sub_8222CDF8(ctx, base);
loc_82132BD0:
	// lwz r11,1680(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 1680);
	// addi r3,r11,1884
	ctx.r3.s64 = ctx.r11.s64 + 1884;
	// bl 0x8210b080
	ctx.lr = 0x82132BDC;
	sub_8210B080(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,26032(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26032);
	// bl 0x8211c5f0
	ctx.lr = 0x82132BE8;
	sub_8211C5F0(ctx, base);
	// fctidz f0,f19
	ctx.fpscr.disableFlushMode();
	ctx.f0.s64 = (ctx.f19.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f19.f64);
	// stfd f0,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.f0.u64);
	// lwz r10,148(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// fctidz f13,f20
	ctx.f13.s64 = (ctx.f20.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f20.f64);
	// stfd f13,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.f13.u64);
	// lwz r9,148(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// stfs f22,160(r1)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// stw r18,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r18.u32);
	// stfs f23,164(r1)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stw r18,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r18.u32);
	// stw r10,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r10.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// stw r9,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r9.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cbc8
	ctx.lr = 0x82132C24;
	sub_8222CBC8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x822381f8
	ctx.lr = 0x82132C38;
	sub_822381F8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x822381f8
	ctx.lr = 0x82132C48;
	sub_822381F8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x822381f8
	ctx.lr = 0x82132C58;
	sub_822381F8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x822381f8
	ctx.lr = 0x82132C68;
	sub_822381F8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,108
	ctx.r5.s64 = ctx.r1.s64 + 108;
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x822381f8
	ctx.lr = 0x82132C78;
	sub_822381F8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// li r4,5
	ctx.r4.s64 = 5;
	// bl 0x822381f8
	ctx.lr = 0x82132C88;
	sub_822381F8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,7
	ctx.r4.s64 = 7;
	// bl 0x822381f8
	ctx.lr = 0x82132C98;
	sub_822381F8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,8
	ctx.r4.s64 = 8;
	// bl 0x822381f8
	ctx.lr = 0x82132CA8;
	sub_822381F8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// li r4,9
	ctx.r4.s64 = 9;
	// bl 0x822381f8
	ctx.lr = 0x82132CB8;
	sub_822381F8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,100
	ctx.r5.s64 = ctx.r1.s64 + 100;
	// li r4,10
	ctx.r4.s64 = 10;
	// bl 0x822381f8
	ctx.lr = 0x82132CC8;
	sub_822381F8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// li r4,11
	ctx.r4.s64 = 11;
	// bl 0x822381f8
	ctx.lr = 0x82132CD8;
	sub_822381F8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// li r4,12
	ctx.r4.s64 = 12;
	// bl 0x822381f8
	ctx.lr = 0x82132CE8;
	sub_822381F8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82132CF4;
	sub_821112B0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x82132CF8;
	sub_8210B0D8(ctx, base);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x82133908
	ctx.lr = 0x82132D00;
	sub_82133908(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x82132D0C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x82132D18;
	sub_82111340(ctx, base);
	// addi r1,r1,416
	ctx.r1.s64 = ctx.r1.s64 + 416;
	// addi r12,r1,-136
	ctx.r12.s64 = ctx.r1.s64 + -136;
	// bl 0x8233fa60
	ctx.lr = 0x82132D24;
	__savefpr_19(ctx, base);
	// b 0x8233e488
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82132D28"))) PPC_WEAK_FUNC(sub_82132D28);
PPC_FUNC_IMPL(__imp__sub_82132D28) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82132D30;
	__restfpr_28(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x822365d8
	ctx.lr = 0x82132D48;
	sub_822365D8(ctx, base);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x822365d8
	ctx.lr = 0x82132D58;
	sub_822365D8(ctx, base);
	// lwz r11,108(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// clrlwi r30,r31,24
	ctx.r30.u64 = ctx.r31.u32 & 0xFF;
	// lwz r8,140(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lwz r7,136(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// mullw r9,r11,r10
	ctx.r9.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r10.s32);
	// mullw r6,r8,r7
	ctx.r6.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r7.s32);
	// cmplw cr6,r9,r6
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x82132dcc
	if (!ctx.cr6.eq) goto loc_82132DCC;
	// rlwinm r10,r31,2,22,29
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0x3FC;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// add r10,r30,r10
	ctx.r10.u64 = ctx.r30.u64 + ctx.r10.u64;
	// addi r29,r11,28184
	ctx.r29.s64 = ctx.r11.s64 + 28184;
	// rlwinm r11,r10,6,0,25
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xFFFFFFC0;
	// li r28,0
	ctx.r28.s64 = 0;
	// add r31,r11,r29
	ctx.r31.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lwz r9,2052(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82132db8
	if (ctx.cr6.eq) goto loc_82132DB8;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x8222c0a0
	ctx.lr = 0x82132DB4;
	sub_8222C0A0(ctx, base);
	// stw r28,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r28.u32);
loc_82132DB8:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82132e28
	if (ctx.cr6.eq) goto loc_82132E28;
	// li r5,0
	ctx.r5.s64 = 0;
	// b 0x82132e18
	goto loc_82132E18;
loc_82132DCC:
	// rlwinm r11,r31,2,22,29
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0x3FC;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// addi r29,r10,28184
	ctx.r29.s64 = ctx.r10.s64 + 28184;
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// li r28,1
	ctx.r28.s64 = 1;
	// add r31,r11,r29
	ctx.r31.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lwz r10,2052(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// beq cr6,0x82132e08
	if (ctx.cr6.eq) goto loc_82132E08;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x8222c0a0
	ctx.lr = 0x82132E04;
	sub_8222C0A0(ctx, base);
	// stw r28,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r28.u32);
loc_82132E08:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82132e28
	if (ctx.cr6.eq) goto loc_82132E28;
	// li r5,1
	ctx.r5.s64 = 1;
loc_82132E18:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// bl 0x8222c248
	ctx.lr = 0x82132E24;
	sub_8222C248(ctx, base);
	// stw r28,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r28.u32);
loc_82132E28:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82132E30"))) PPC_WEAK_FUNC(sub_82132E30);
PPC_FUNC_IMPL(__imp__sub_82132E30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x82132E38;
	__restfpr_25(ctx, base);
	// stfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, ctx.f31.u64);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,1676(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r25,r4
	ctx.r25.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// li r27,0
	ctx.r27.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x82132E5C;
	sub_82113BC0(ctx, base);
	// addi r4,r25,76
	ctx.r4.s64 = ctx.r25.s64 + 76;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lbz r5,72(r25)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r25.u32 + 72);
	// bl 0x82133aa8
	ctx.lr = 0x82132E6C;
	sub_82133AA8(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r26,1
	ctx.r26.s64 = 1;
	// addi r30,r11,28184
	ctx.r30.s64 = ctx.r11.s64 + 28184;
	// lwz r11,16(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 16);
	// rlwinm r10,r11,0,20,20
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x800;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213300c
	if (ctx.cr6.eq) goto loc_8213300C;
	// lwz r11,12(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// clrlwi r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213300c
	if (ctx.cr6.eq) goto loc_8213300C;
	// lfs f0,13008(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13008);
	ctx.f0.f64 = double(temp.f32);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// lfs f13,13012(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13012);
	ctx.f13.f64 = double(temp.f32);
	// fctidz f12,f0
	ctx.f12.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// lfs f11,13000(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13000);
	ctx.f11.f64 = double(temp.f32);
	// fctidz f10,f13
	ctx.f10.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// lfs f8,13004(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13004);
	ctx.f8.f64 = double(temp.f32);
	// fctidz f9,f11
	ctx.f9.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// stfd f12,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f12.u64);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f9.u64);
	// stfd f7,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f7.u64);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lfs f6,13016(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13016);
	ctx.f6.f64 = double(temp.f32);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// lfs f5,13020(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13020);
	ctx.f5.f64 = double(temp.f32);
	// mr r27,r26
	ctx.r27.u64 = ctx.r26.u64;
	// stfs f6,112(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stw r10,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r10.u32);
	// stfs f5,116(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
	// stw r8,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r8.u32);
	// bl 0x82133360
	ctx.lr = 0x82132F08;
	sub_82133360(ctx, base);
	// lwz r11,2372(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2372);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82132f2c
	if (ctx.cr6.eq) goto loc_82132F2C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x82132F24;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2372(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2372, ctx.r11.u32);
loc_82132F2C:
	// lwz r11,2356(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2356);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82132f50
	if (ctx.cr6.eq) goto loc_82132F50;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82132F48;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2356(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2356, ctx.r11.u32);
loc_82132F50:
	// lwz r11,2292(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2292);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82132f84
	if (ctx.cr6.eq) goto loc_82132F84;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r26,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r26.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2292, ctx.r10.u32);
loc_82132F84:
	// lwz r11,2308(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82132fb8
	if (ctx.cr6.eq) goto loc_82132FB8;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r26,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r26.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2308, ctx.r10.u32);
loc_82132FB8:
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// li r3,2
	ctx.r3.s64 = 2;
	// addi r4,r11,380
	ctx.r4.s64 = ctx.r11.s64 + 380;
	// bl 0x82111400
	ctx.lr = 0x82132FC8;
	sub_82111400(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r9,1680(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// addi r5,r9,1932
	ctx.r5.s64 = ctx.r9.s64 + 1932;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82132ff4
	if (ctx.cr6.eq) goto loc_82132FF4;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82132FF4;
	sub_8222CDF8(ctx, base);
loc_82132FF4:
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// addi r3,r11,1980
	ctx.r3.s64 = ctx.r11.s64 + 1980;
	// bl 0x8210b080
	ctx.lr = 0x82133000;
	sub_8210B080(ctx, base);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cbc8
	ctx.lr = 0x8213300C;
	sub_8222CBC8(ctx, base);
loc_8213300C:
	// lwz r11,10128(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10128);
	// li r10,1
	ctx.r10.s64 = 1;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// rlwimi r11,r27,12,19,19
	ctx.r11.u64 = (rotl32(ctx.r27.u32, 12) & 0x1000) | (ctx.r11.u64 & 0xFFFFFFFFFFFFEFFF);
	// rldicr r29,r10,56,63
	ctx.r29.u64 = rotl64(ctx.r10.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// stw r11,10128(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10128, ctx.r11.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// ld r9,32(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r8,r9,r29
	ctx.r8.u64 = ctx.r9.u64 | ctx.r29.u64;
	// std r8,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r8.u64);
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// addi r3,r11,120
	ctx.r3.s64 = ctx.r11.s64 + 120;
	// bl 0x822365d8
	ctx.lr = 0x82133040;
	sub_822365D8(ctx, base);
	// lfs f13,13012(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13012);
	ctx.f13.f64 = double(temp.f32);
	// lis r7,-32250
	ctx.r7.s64 = -2113536000;
	// fctidz f12,f13
	ctx.f12.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// stfd f12,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f12.u64);
	// lwz r11,124(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// addi r6,r7,31376
	ctx.r6.s64 = ctx.r7.s64 + 31376;
	// lwz r7,92(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// lfs f11,13008(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13008);
	ctx.f11.f64 = double(temp.f32);
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lfd f9,88(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fctidz f10,f11
	ctx.f10.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// lfs f0,48(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// fcfid f4,f9
	ctx.f4.f64 = double(ctx.f9.s64);
	// stfs f0,3896(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3896, temp.u32);
	// stfs f0,3900(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3900, temp.u32);
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f31,36(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f8,88(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// std r8,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r8.u64);
	// fcfid f6,f8
	ctx.f6.f64 = double(ctx.f8.s64);
	// lfd f7,88(r1)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r7,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r7.u64);
	// lfd f5,88(r1)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f3,f7
	ctx.f3.f64 = double(ctx.f7.s64);
	// fcfid f2,f5
	ctx.f2.f64 = double(ctx.f5.s64);
	// rldicr r12,r12,33,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 33) & 0xFFFFFFFFFFFFFFFF;
	// frsp f1,f6
	ctx.f1.f64 = double(float(ctx.f6.f64));
	// frsp f13,f3
	ctx.f13.f64 = double(float(ctx.f3.f64));
	// frsp f12,f4
	ctx.f12.f64 = double(float(ctx.f4.f64));
	// frsp f11,f2
	ctx.f11.f64 = double(float(ctx.f2.f64));
	// fdivs f10,f13,f1
	ctx.f10.f64 = double(float(ctx.f13.f64 / ctx.f1.f64));
	// stfs f10,3888(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3888, temp.u32);
	// fdivs f9,f11,f12
	ctx.f9.f64 = double(float(ctx.f11.f64 / ctx.f12.f64));
	// stfs f9,3892(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3892, temp.u32);
	// ld r6,0(r31)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r5,r6,r12
	ctx.r5.u64 = ctx.r6.u64 | ctx.r12.u64;
	// std r5,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r5.u64);
	// lfs f8,1492(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 1492);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,1488(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 1488);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f8,f7
	ctx.f6.f64 = static_cast<float>(ctx.f8.f64 - ctx.f7.f64);
	// fdivs f5,f8,f6
	ctx.f5.f64 = double(float(ctx.f8.f64 / ctx.f6.f64));
	// stfs f31,8072(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 8072, temp.u32);
	// stfs f0,8076(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 8076, temp.u32);
	// stfs f5,8068(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 8068, temp.u32);
	// fmuls f4,f7,f5
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f5.f64));
	// fneg f3,f4
	ctx.f3.u64 = ctx.f4.u64 ^ 0x8000000000000000;
	// stfs f3,8064(r31)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + 8064, temp.u32);
	// ld r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// oris r3,r4,32768
	ctx.r3.u64 = ctx.r4.u64 | 2147483648;
	// std r3,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r3.u64);
	// lbz r11,1484(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 1484);
	// lwz r10,10128(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10128);
	// rlwimi r10,r11,10,21,21
	ctx.r10.u64 = (rotl32(ctx.r11.u32, 10) & 0x400) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFBFF);
	// stw r10,10128(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10128, ctx.r10.u32);
	// ld r9,32(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r8,r9,r29
	ctx.r8.u64 = ctx.r9.u64 | ctx.r29.u64;
	// std r8,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r8.u64);
	// lbz r7,1476(r28)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r28.u32 + 1476);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x8213314c
	if (ctx.cr6.eq) goto loc_8213314C;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// bne cr6,0x82133150
	if (!ctx.cr6.eq) goto loc_82133150;
loc_8213314C:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82133150:
	// lwz r10,10128(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10128);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// rlwimi r10,r11,11,20,20
	ctx.r10.u64 = (rotl32(ctx.r11.u32, 11) & 0x800) | (ctx.r10.u64 & 0xFFFFFFFFFFFFF7FF);
	// stw r10,10128(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10128, ctx.r10.u32);
	// lwz r3,26056(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 26056);
	// ld r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r7,r8,r29
	ctx.r7.u64 = ctx.r8.u64 | ctx.r29.u64;
	// std r7,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r7.u64);
	// bl 0x8211c5f0
	ctx.lr = 0x82133174;
	sub_8211C5F0(ctx, base);
	// lwz r11,2052(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82133198
	if (ctx.cr6.eq) goto loc_82133198;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82133190;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r11.u32);
loc_82133198:
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821331bc
	if (ctx.cr6.eq) goto loc_821331BC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x821331B4;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r11.u32);
loc_821331BC:
	// lwz r11,1972(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821331f0
	if (ctx.cr6.eq) goto loc_821331F0;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r26,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r26.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1972, ctx.r10.u32);
loc_821331F0:
	// lwz r11,1988(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82133224
	if (ctx.cr6.eq) goto loc_82133224;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r26,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r26.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1988, ctx.r10.u32);
loc_82133224:
	// lwz r11,2372(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2372);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82133248
	if (ctx.cr6.eq) goto loc_82133248;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x82133240;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2372(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2372, ctx.r11.u32);
loc_82133248:
	// lwz r11,2356(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2356);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213326c
	if (ctx.cr6.eq) goto loc_8213326C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82133264;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2356(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2356, ctx.r11.u32);
loc_8213326C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111390
	ctx.lr = 0x8213327C;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111390
	ctx.lr = 0x8213328C;
	sub_82111390(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82133298;
	sub_82111340(ctx, base);
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r4,r11,120
	ctx.r4.s64 = ctx.r11.s64 + 120;
	// bl 0x82111400
	ctx.lr = 0x821332A8;
	sub_82111400(ctx, base);
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r4,r11,16
	ctx.r4.s64 = ctx.r11.s64 + 16;
	// bl 0x82111400
	ctx.lr = 0x821332B8;
	sub_82111400(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x821332C4;
	sub_821112B0(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x821332D0;
	sub_82111340(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x821332D4;
	sub_8210B0D8(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x821332E0;
	sub_821112B0(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x821332EC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x821332F8;
	sub_82111400(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111400
	ctx.lr = 0x82133304;
	sub_82111400(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82133310;
	sub_82111340(ctx, base);
	// lwz r11,12(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// rlwinm r10,r11,0,30,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82133350
	if (ctx.cr6.eq) goto loc_82133350;
	// lbz r11,1484(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 1484);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82133350
	if (ctx.cr6.eq) goto loc_82133350;
	// lwz r11,1680(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,120
	ctx.r5.s64 = ctx.r11.s64 + 120;
	// li r4,0
	ctx.r4.s64 = 0;
	// lis r3,11264
	ctx.r3.s64 = 738197504;
	// bl 0x8210af50
	ctx.lr = 0x82133350;
	sub_8210AF50(ctx, base);
loc_82133350:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// lfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213335C"))) PPC_WEAK_FUNC(sub_8213335C);
PPC_FUNC_IMPL(__imp__sub_8213335C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82133360"))) PPC_WEAK_FUNC(sub_82133360);
PPC_FUNC_IMPL(__imp__sub_82133360) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82133368;
	__restfpr_26(ctx, base);
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f31.u64);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r9,9
	ctx.r9.s64 = 9;
	// lwz r31,1676(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// addi r10,r1,124
	ctx.r10.s64 = ctx.r1.s64 + 124;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r11,r4,16
	ctx.r11.s64 = ctx.r4.s64 + 16;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82133388:
	// lwzu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	ctx.r9.u64 = PPC_LOAD_U32(ea);
	ctx.r11.u32 = ea;
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x82133388
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82133388;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,1680(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,2460
	ctx.r5.s64 = ctx.r10.s64 + 2460;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x821333c0
	if (ctx.cr6.eq) goto loc_821333C0;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x821333C0;
	sub_8222CDF8(ctx, base);
loc_821333C0:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x821333CC;
	sub_821112B0(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x821333D8;
	sub_82111340(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,1680(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// addi r30,r11,28184
	ctx.r30.s64 = ctx.r11.s64 + 28184;
	// addi r26,r10,224
	ctx.r26.s64 = ctx.r10.s64 + 224;
	// lwz r11,292(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 292);
	// cmplw cr6,r11,r26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r26.u32, ctx.xer);
	// beq cr6,0x82133410
	if (ctx.cr6.eq) goto loc_82133410;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x8213340C;
	sub_82237A38(ctx, base);
	// stw r26,292(r30)
	PPC_STORE_U32(ctx.r30.u32 + 292, ctx.r26.u32);
loc_82133410:
	// lwz r11,2052(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// li r27,1
	ctx.r27.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82133438
	if (ctx.cr6.eq) goto loc_82133438;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82133430;
	sub_8222C0A0(ctx, base);
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r27.u32);
loc_82133438:
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8213345c
	if (ctx.cr6.eq) goto loc_8213345C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82133454;
	sub_8222C248(ctx, base);
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r27.u32);
loc_8213345C:
	// lwz r11,1972(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82133490
	if (ctx.cr6.eq) goto loc_82133490;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r27,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r27.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1972, ctx.r10.u32);
loc_82133490:
	// lwz r11,1988(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821334c4
	if (ctx.cr6.eq) goto loc_821334C4;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r27,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r27.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1988, ctx.r10.u32);
loc_821334C4:
	// lwz r11,1680(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r28,r11,16
	ctx.r28.s64 = ctx.r11.s64 + 16;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x82111400
	ctx.lr = 0x821334D8;
	sub_82111400(ctx, base);
	// lwz r11,2372(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2372);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821334fc
	if (ctx.cr6.eq) goto loc_821334FC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x821334F4;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2372(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2372, ctx.r11.u32);
loc_821334FC:
	// lwz r11,2356(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2356);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82133520
	if (ctx.cr6.eq) goto loc_82133520;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82133518;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2356(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2356, ctx.r11.u32);
loc_82133520:
	// lwz r11,2292(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2292);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82133554
	if (ctx.cr6.eq) goto loc_82133554;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r27,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r27.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2292, ctx.r10.u32);
loc_82133554:
	// lwz r11,2308(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82133588
	if (ctx.cr6.eq) goto loc_82133588;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r27,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r27.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2308, ctx.r10.u32);
loc_82133588:
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x822365d8
	ctx.lr = 0x82133598;
	sub_822365D8(ctx, base);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x822365d8
	ctx.lr = 0x821335A8;
	sub_822365D8(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f13,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// li r10,1
	ctx.r10.s64 = 1;
	// addi r9,r11,31376
	ctx.r9.s64 = ctx.r11.s64 + 31376;
	// lfs f3,1492(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 1492);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,1488(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 1488);
	ctx.f2.f64 = double(temp.f32);
	// rldicr r11,r10,36,63
	ctx.r11.u64 = rotl64(ctx.r10.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// fsubs f1,f3,f2
	ctx.f1.f64 = static_cast<float>(ctx.f3.f64 - ctx.f2.f64);
	// lfs f12,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f11.f64 = double(temp.f32);
	// lis r8,-32178
	ctx.r8.s64 = -2108817408;
	// lfs f10,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f10.f64 = double(temp.f32);
	// lfs f0,328(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 328);
	ctx.f0.f64 = double(temp.f32);
	// fadds f7,f13,f0
	ctx.f7.f64 = double(float(ctx.f13.f64 + ctx.f0.f64));
	// lfs f31,36(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// lfs f0,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,7752(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7752, temp.u32);
	// lwz r3,26060(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 26060);
	// stfs f0,7756(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7756, temp.u32);
	// lfs f9,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f5.f64 = double(temp.f32);
	// fdivs f4,f31,f7
	ctx.f4.f64 = double(float(ctx.f31.f64 / ctx.f7.f64));
	// fdivs f7,f3,f1
	ctx.f7.f64 = double(float(ctx.f3.f64 / ctx.f1.f64));
	// stfs f7,7748(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7748, temp.u32);
	// fmuls f3,f2,f7
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fneg f2,f3
	ctx.f2.u64 = ctx.f3.u64 ^ 0x8000000000000000;
	// stfs f2,7744(r31)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7744, temp.u32);
	// ld r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r6,r7,r11
	ctx.r6.u64 = ctx.r7.u64 | ctx.r11.u64;
	// std r6,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r6.u64);
	// stfs f13,7760(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7760, temp.u32);
	// stfs f4,7764(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7764, temp.u32);
	// stfs f12,7768(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7768, temp.u32);
	// stfs f11,7772(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7772, temp.u32);
	// ld r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r4,r5,r11
	ctx.r4.u64 = ctx.r5.u64 | ctx.r11.u64;
	// std r4,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r4.u64);
	// stfs f10,7776(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7776, temp.u32);
	// stfs f9,7780(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7780, temp.u32);
	// stfs f8,7784(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7784, temp.u32);
	// stfs f6,7788(r31)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7788, temp.u32);
	// ld r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 | ctx.r11.u64;
	// std r9,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r9.u64);
	// stfs f5,7792(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7792, temp.u32);
	// stfs f0,7796(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7796, temp.u32);
	// stfs f0,7800(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7800, temp.u32);
	// stfs f0,7804(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7804, temp.u32);
	// ld r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r7,r8,r11
	ctx.r7.u64 = ctx.r8.u64 | ctx.r11.u64;
	// std r7,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r7.u64);
	// bl 0x8211c5f0
	ctx.lr = 0x82133680;
	sub_8211C5F0(ctx, base);
	// lwz r6,1680(r29)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r5,2496(r6)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r6.u32 + 2496);
	// rlwinm r3,r5,14,18,31
	ctx.r3.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 14) & 0x3FFF;
	// bl 0x8210c6e0
	ctx.lr = 0x82133694;
	sub_8210C6E0(ctx, base);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,16
	ctx.r7.s64 = 16;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x821336B4;
	sub_8222CC48(ctx, base);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// li r4,8
	ctx.r4.s64 = 8;
	// add r26,r11,r10
	ctx.r26.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x821336D4;
	sub_8222DFC8(ctx, base);
	// lwz r11,1680(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1680);
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// addi r29,r11,380
	ctx.r29.s64 = ctx.r11.s64 + 380;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210af50
	ctx.lr = 0x821336FC;
	sub_8210AF50(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x82133708;
	sub_82111400(ctx, base);
	// lwz r11,2052(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213372c
	if (ctx.cr6.eq) goto loc_8213372C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82133724;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r11.u32);
loc_8213372C:
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82133750
	if (ctx.cr6.eq) goto loc_82133750;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82133748;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r11.u32);
loc_82133750:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111390
	ctx.lr = 0x82133760;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111390
	ctx.lr = 0x82133770;
	sub_82111390(ctx, base);
	// lis r28,-32178
	ctx.r28.s64 = -2108817408;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,26064(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 26064);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82133798;
	sub_82238728(ctx, base);
	// lwz r11,26064(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 26064);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x821337A8;
	sub_82238380(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,16
	ctx.r7.s64 = 16;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x821337C4;
	sub_8222CC48(ctx, base);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x821337D8;
	sub_8222DFC8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210af50
	ctx.lr = 0x821337F8;
	sub_8210AF50(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x82133804;
	sub_82111400(ctx, base);
	// lwz r11,2052(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82133828
	if (ctx.cr6.eq) goto loc_82133828;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82133820;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r11.u32);
loc_82133828:
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213384c
	if (ctx.cr6.eq) goto loc_8213384C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82133844;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r11.u32);
loc_8213384C:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111390
	ctx.lr = 0x8213385C;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111390
	ctx.lr = 0x8213386C;
	sub_82111390(ctx, base);
	// lwz r11,26064(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 26064);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82133890;
	sub_82238728(ctx, base);
	// lwz r11,26064(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 26064);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x821338A0;
	sub_82238380(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,16
	ctx.r7.s64 = 16;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x821338BC;
	sub_8222CC48(ctx, base);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x821338D0;
	sub_8222DFC8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210af50
	ctx.lr = 0x821338F0;
	sub_8210AF50(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x821338FC;
	sub_82111340(ctx, base);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82133908"))) PPC_WEAK_FUNC(sub_82133908);
PPC_FUNC_IMPL(__imp__sub_82133908) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x82133910;
	__restfpr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r28,1676(r3)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// li r24,0
	ctx.r24.s64 = 0;
	// addi r30,r11,28184
	ctx.r30.s64 = ctx.r11.s64 + 28184;
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r31,r24
	ctx.r31.u64 = ctx.r24.u64;
	// addi r29,r30,2036
	ctx.r29.s64 = ctx.r30.s64 + 2036;
	// addi r27,r30,292
	ctx.r27.s64 = ctx.r30.s64 + 292;
	// li r26,1
	ctx.r26.s64 = 1;
	// rldicr r25,r11,63,63
	ctx.r25.u64 = rotl64(ctx.r11.u64, 63) & 0xFFFFFFFFFFFFFFFF;
loc_8213393C:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82133968
	if (ctx.cr6.eq) goto loc_82133968;
	// addi r11,r31,32
	ctx.r11.s64 = ctx.r31.s64 + 32;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// clrldi r10,r11,32
	ctx.r10.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// srd r6,r25,r10
	ctx.r6.u64 = ctx.r10.u8 & 0x40 ? 0 : (ctx.r25.u64 >> (ctx.r10.u8 & 0x7F));
	// bl 0x82237a38
	ctx.lr = 0x82133964;
	sub_82237A38(ctx, base);
	// stw r24,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r24.u32);
loc_82133968:
	// lwz r11,16(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82133988
	if (ctx.cr6.eq) goto loc_82133988;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8222c0a0
	ctx.lr = 0x82133984;
	sub_8222C0A0(ctx, base);
	// stw r26,16(r29)
	PPC_STORE_U32(ctx.r29.u32 + 16, ctx.r26.u32);
loc_82133988:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821339a8
	if (ctx.cr6.eq) goto loc_821339A8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8222c248
	ctx.lr = 0x821339A4;
	sub_8222C248(ctx, base);
	// stw r26,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r26.u32);
loc_821339A8:
	// addi r27,r27,4
	ctx.r27.s64 = ctx.r27.s64 + 4;
	// addi r11,r30,328
	ctx.r11.s64 = ctx.r30.s64 + 328;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r29,r29,320
	ctx.r29.s64 = ctx.r29.s64 + 320;
	// cmpw cr6,r27,r11
	ctx.cr6.compare<int32_t>(ctx.r27.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x8213393c
	if (ctx.cr6.lt) goto loc_8213393C;
	// lwz r11,10128(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 10128);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwinm r9,r11,0,0,30
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFE;
	// rldicr r11,r10,56,63
	ctx.r11.u64 = rotl64(ctx.r10.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// stw r9,10128(r28)
	PPC_STORE_U32(ctx.r28.u32 + 10128, ctx.r9.u32);
	// ld r8,32(r28)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r28.u32 + 32);
	// or r7,r8,r11
	ctx.r7.u64 = ctx.r8.u64 | ctx.r11.u64;
	// std r7,32(r28)
	PPC_STORE_U64(ctx.r28.u32 + 32, ctx.r7.u64);
	// lwz r6,10128(r28)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r28.u32 + 10128);
	// rlwinm r5,r6,0,31,29
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
	// stw r5,10128(r28)
	PPC_STORE_U32(ctx.r28.u32 + 10128, ctx.r5.u32);
	// ld r4,32(r28)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r28.u32 + 32);
	// or r3,r4,r11
	ctx.r3.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r3,32(r28)
	PPC_STORE_U64(ctx.r28.u32 + 32, ctx.r3.u64);
	// lwz r10,10128(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 10128);
	// rlwinm r9,r10,0,30,28
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// stw r9,10128(r28)
	PPC_STORE_U32(ctx.r28.u32 + 10128, ctx.r9.u32);
	// ld r8,32(r28)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r28.u32 + 32);
	// or r7,r8,r11
	ctx.r7.u64 = ctx.r8.u64 | ctx.r11.u64;
	// std r7,32(r28)
	PPC_STORE_U64(ctx.r28.u32 + 32, ctx.r7.u64);
	// lwz r6,10128(r28)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r28.u32 + 10128);
	// rlwinm r5,r6,0,29,27
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// stw r5,10128(r28)
	PPC_STORE_U32(ctx.r28.u32 + 10128, ctx.r5.u32);
	// ld r4,32(r28)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r28.u32 + 32);
	// or r3,r4,r11
	ctx.r3.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r3,32(r28)
	PPC_STORE_U64(ctx.r28.u32 + 32, ctx.r3.u64);
	// lwz r10,10128(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 10128);
	// rlwinm r9,r10,0,28,26
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFEF;
	// stw r9,10128(r28)
	PPC_STORE_U32(ctx.r28.u32 + 10128, ctx.r9.u32);
	// ld r8,32(r28)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r28.u32 + 32);
	// or r7,r8,r11
	ctx.r7.u64 = ctx.r8.u64 | ctx.r11.u64;
	// std r7,32(r28)
	PPC_STORE_U64(ctx.r28.u32 + 32, ctx.r7.u64);
	// lwz r6,10128(r28)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r28.u32 + 10128);
	// rlwinm r5,r6,0,27,25
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFFFFFFFFDF;
	// stw r5,10128(r28)
	PPC_STORE_U32(ctx.r28.u32 + 10128, ctx.r5.u32);
	// ld r4,32(r28)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r28.u32 + 32);
	// or r3,r4,r11
	ctx.r3.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r3,32(r28)
	PPC_STORE_U64(ctx.r28.u32 + 32, ctx.r3.u64);
	// lwz r10,10128(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 10128);
	// rlwinm r9,r10,0,26,24
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFBF;
	// stw r9,10128(r28)
	PPC_STORE_U32(ctx.r28.u32 + 10128, ctx.r9.u32);
	// ld r8,32(r28)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r28.u32 + 32);
	// or r7,r8,r11
	ctx.r7.u64 = ctx.r8.u64 | ctx.r11.u64;
	// std r7,32(r28)
	PPC_STORE_U64(ctx.r28.u32 + 32, ctx.r7.u64);
	// lwz r6,10128(r28)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r28.u32 + 10128);
	// rlwinm r5,r6,0,25,23
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
	// stw r5,10128(r28)
	PPC_STORE_U32(ctx.r28.u32 + 10128, ctx.r5.u32);
	// ld r4,32(r28)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r28.u32 + 32);
	// or r3,r4,r11
	ctx.r3.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r3,32(r28)
	PPC_STORE_U64(ctx.r28.u32 + 32, ctx.r3.u64);
	// lwz r10,10128(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 10128);
	// rlwinm r9,r10,0,24,22
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// stw r9,10128(r28)
	PPC_STORE_U32(ctx.r28.u32 + 10128, ctx.r9.u32);
	// ld r8,32(r28)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r28.u32 + 32);
	// or r7,r8,r11
	ctx.r7.u64 = ctx.r8.u64 | ctx.r11.u64;
	// std r7,32(r28)
	PPC_STORE_U64(ctx.r28.u32 + 32, ctx.r7.u64);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82133AA8"))) PPC_WEAK_FUNC(sub_82133AA8);
PPC_FUNC_IMPL(__imp__sub_82133AA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// li r8,8
	ctx.r8.s64 = 8;
	// lwz r11,1676(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1676);
	// addi r7,r3,1452
	ctx.r7.s64 = ctx.r3.s64 + 1452;
	// addi r10,r4,-4
	ctx.r10.s64 = ctx.r4.s64 + -4;
	// addi r9,r7,-4
	ctx.r9.s64 = ctx.r7.s64 + -4;
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_82133AC0:
	// lwzu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	ctx.r8.u64 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	// stwu r8,4(r9)
	ea = 4 + ctx.r9.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r9.u32 = ea;
	// bdnz 0x82133ac0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82133AC0;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lfs f12,1472(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 1472);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r10,31376
	ctx.r10.s64 = ctx.r10.s64 + 31376;
	// lfs f13,48(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f12,f13
	ctx.cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// bne cr6,0x82133af0
	if (!ctx.cr6.eq) goto loc_82133AF0;
	// li r9,0
	ctx.r9.s64 = 0;
	// stb r9,1484(r3)
	PPC_STORE_U8(ctx.r3.u32 + 1484, ctx.r9.u8);
	// b 0x82133af4
	goto loc_82133AF4;
loc_82133AF0:
	// stb r5,1484(r3)
	PPC_STORE_U8(ctx.r3.u32 + 1484, ctx.r5.u8);
loc_82133AF4:
	// lbz r9,1484(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1484);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82133ba0
	if (ctx.cr6.eq) goto loc_82133BA0;
	// lbz r9,1476(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1476);
	// lfs f0,1492(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 1492);
	ctx.f0.f64 = double(temp.f32);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82133b14
	if (ctx.cr6.eq) goto loc_82133B14;
	// lfs f0,92(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
loc_82133B14:
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f13,0(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,1456(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 1456);
	ctx.f11.f64 = double(temp.f32);
	// li r10,1
	ctx.r10.s64 = 1;
	// fsubs f9,f11,f13
	ctx.f9.f64 = static_cast<float>(ctx.f11.f64 - ctx.f13.f64);
	// rldicr r12,r12,60,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 60) & 0xFFFFFFFFFFFFFFFF;
	// stfs f0,2172(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2172, temp.u32);
	// rldicr r10,r10,49,63
	ctx.r10.u64 = rotl64(ctx.r10.u64, 49) & 0xFFFFFFFFFFFFFFFF;
	// stfs f12,2160(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2160, temp.u32);
	// fmr f10,f13
	ctx.f10.f64 = ctx.f13.f64;
	// stfs f13,2164(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2164, temp.u32);
	// stfs f9,2168(r11)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2168, temp.u32);
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// or r8,r9,r12
	ctx.r8.u64 = ctx.r9.u64 | ctx.r12.u64;
	// std r8,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r8.u64);
	// lfs f8,1480(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 1480);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,6912(r11)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6912, temp.u32);
	// stfs f13,6916(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6916, temp.u32);
	// stfs f9,6920(r11)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6920, temp.u32);
	// stfs f0,6924(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6924, temp.u32);
	// ld r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// or r6,r7,r10
	ctx.r6.u64 = ctx.r7.u64 | ctx.r10.u64;
	// std r6,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r6.u64);
	// lfs f7,1460(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 1460);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,6928(r11)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6928, temp.u32);
	// lfs f6,1464(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 1464);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,6932(r11)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6932, temp.u32);
	// lfs f5,1468(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 1468);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,6936(r11)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6936, temp.u32);
	// lfs f4,1472(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 1472);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,6940(r11)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6940, temp.u32);
	// ld r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// or r4,r5,r10
	ctx.r4.u64 = ctx.r5.u64 | ctx.r10.u64;
	// std r4,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r4.u64);
	// blr 
	return;
loc_82133BA0:
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f0,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stfs f13,2160(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2160, temp.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// rldicr r12,r12,60,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 60) & 0xFFFFFFFFFFFFFFFF;
	// stfs f0,2164(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2164, temp.u32);
	// stfs f0,2168(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2168, temp.u32);
	// rldicr r10,r10,49,63
	ctx.r10.u64 = rotl64(ctx.r10.u64, 49) & 0xFFFFFFFFFFFFFFFF;
	// stfs f13,2172(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2172, temp.u32);
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// or r8,r9,r12
	ctx.r8.u64 = ctx.r9.u64 | ctx.r12.u64;
	// std r8,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r8.u64);
	// stfs f0,6916(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6916, temp.u32);
	// stfs f0,6920(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6920, temp.u32);
	// stfs f13,6924(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6924, temp.u32);
	// stfs f0,6912(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6912, temp.u32);
	// ld r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// or r6,r7,r10
	ctx.r6.u64 = ctx.r7.u64 | ctx.r10.u64;
	// std r6,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r6.u64);
	// stfs f0,6936(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6936, temp.u32);
	// stfs f13,6940(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6940, temp.u32);
	// stfs f0,6928(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6928, temp.u32);
	// stfs f0,6932(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6932, temp.u32);
	// ld r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// or r4,r5,r10
	ctx.r4.u64 = ctx.r5.u64 | ctx.r10.u64;
	// std r4,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r4.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82133C0C"))) PPC_WEAK_FUNC(sub_82133C0C);
PPC_FUNC_IMPL(__imp__sub_82133C0C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82133C10"))) PPC_WEAK_FUNC(sub_82133C10);
PPC_FUNC_IMPL(__imp__sub_82133C10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// li r9,2
	ctx.r9.s64 = 2;
	// addi r10,r4,-4
	ctx.r10.s64 = ctx.r4.s64 + -4;
	// addi r11,r3,-8
	ctx.r11.s64 = ctx.r3.s64 + -8;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_82133C20:
	// lfd f0,8(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// lfd f13,16(r11)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// frsp f12,f0
	ctx.f12.f64 = double(float(ctx.f0.f64));
	// lfd f11,24(r11)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// frsp f10,f13
	ctx.f10.f64 = double(float(ctx.f13.f64));
	// lfd f9,32(r11)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r11.u32 + 32);
	// frsp f8,f11
	ctx.f8.f64 = double(float(ctx.f11.f64));
	// lfd f7,40(r11)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 40);
	// frsp f6,f9
	ctx.f6.f64 = double(float(ctx.f9.f64));
	// lfd f5,48(r11)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r11.u32 + 48);
	// frsp f4,f7
	ctx.f4.f64 = double(float(ctx.f7.f64));
	// lfd f3,56(r11)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r11.u32 + 56);
	// frsp f2,f5
	ctx.f2.f64 = double(float(ctx.f5.f64));
	// lfdu f0,64(r11)
	ea = 64 + ctx.r11.u32;
	ctx.r0.u64 = PPC_LOAD_U64(ea);
	ctx.r11.u32 = ea;
	// frsp f1,f3
	ctx.f1.f64 = double(float(ctx.f3.f64));
	// stfs f12,4(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// stfs f10,8(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// stfs f8,12(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
	// stfs f6,16(r10)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + 16, temp.u32);
	// stfs f4,20(r10)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r10.u32 + 20, temp.u32);
	// stfs f2,24(r10)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + 24, temp.u32);
	// stfs f1,28(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 28, temp.u32);
	// stfsu f0,32(r10)
	temp.f32 = float(ctx.f0.f64);
	ea = 32 + ctx.r10.u32;
	PPC_STORE_U32(ea, temp.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x82133c20
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82133C20;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82133C88"))) PPC_WEAK_FUNC(sub_82133C88);
PPC_FUNC_IMPL(__imp__sub_82133C88) {
	PPC_FUNC_PROLOGUE();
	// lfd f0,32(r5)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 32);
	// lfd f13,8(r3)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// fmul f12,f0,f13
	ctx.f12.f64 = ctx.f0.f64 * ctx.f13.f64;
	// lfd f11,64(r5)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r5.u32 + 64);
	// lfd f10,16(r3)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// lfd f9,0(r5)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r5.u32 + 0);
	// lfd f8,0(r3)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// lfd f7,24(r3)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r3.u32 + 24);
	// lfd f6,96(r5)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r5.u32 + 96);
	// fmadd f5,f11,f10,f12
	ctx.f5.f64 = ctx.f11.f64 * ctx.f10.f64 + ctx.f12.f64;
	// fmadd f4,f9,f8,f5
	ctx.f4.f64 = ctx.f9.f64 * ctx.f8.f64 + ctx.f5.f64;
	// fmadd f3,f7,f6,f4
	ctx.f3.f64 = ctx.f7.f64 * ctx.f6.f64 + ctx.f4.f64;
	// stfd f3,0(r4)
	PPC_STORE_U64(ctx.r4.u32 + 0, ctx.f3.u64);
	// lfd f2,40(r5)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r5.u32 + 40);
	// lfd f1,8(r3)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// lfd f0,0(r3)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// lfd f13,8(r5)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r5.u32 + 8);
	// lfd f12,104(r5)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r5.u32 + 104);
	// lfd f11,24(r3)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 24);
	// lfd f10,72(r5)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r5.u32 + 72);
	// lfd f9,16(r3)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// fmul f8,f10,f9
	ctx.f8.f64 = ctx.f10.f64 * ctx.f9.f64;
	// fmadd f7,f2,f1,f8
	ctx.f7.f64 = ctx.f2.f64 * ctx.f1.f64 + ctx.f8.f64;
	// fmadd f6,f0,f13,f7
	ctx.f6.f64 = ctx.f0.f64 * ctx.f13.f64 + ctx.f7.f64;
	// fmadd f5,f12,f11,f6
	ctx.f5.f64 = ctx.f12.f64 * ctx.f11.f64 + ctx.f6.f64;
	// stfd f5,8(r4)
	PPC_STORE_U64(ctx.r4.u32 + 8, ctx.f5.u64);
	// lfd f4,80(r5)
	ctx.f4.u64 = PPC_LOAD_U64(ctx.r5.u32 + 80);
	// lfd f3,16(r3)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// lfd f2,112(r5)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r5.u32 + 112);
	// lfd f1,24(r3)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r3.u32 + 24);
	// lfd f0,48(r5)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 48);
	// lfd f13,8(r3)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// lfd f12,16(r5)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r5.u32 + 16);
	// lfd f11,0(r3)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// fmul f10,f12,f11
	ctx.f10.f64 = ctx.f12.f64 * ctx.f11.f64;
	// fmadd f9,f4,f3,f10
	ctx.f9.f64 = ctx.f4.f64 * ctx.f3.f64 + ctx.f10.f64;
	// fmadd f8,f2,f1,f9
	ctx.f8.f64 = ctx.f2.f64 * ctx.f1.f64 + ctx.f9.f64;
	// fmadd f7,f0,f13,f8
	ctx.f7.f64 = ctx.f0.f64 * ctx.f13.f64 + ctx.f8.f64;
	// stfd f7,16(r4)
	PPC_STORE_U64(ctx.r4.u32 + 16, ctx.f7.u64);
	// lfd f6,24(r5)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r5.u32 + 24);
	// lfd f5,0(r3)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// lfd f4,56(r5)
	ctx.f4.u64 = PPC_LOAD_U64(ctx.r5.u32 + 56);
	// lfd f3,8(r3)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// lfd f2,88(r5)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r5.u32 + 88);
	// lfd f1,16(r3)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// lfd f0,24(r3)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r3.u32 + 24);
	// lfd f13,120(r5)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r5.u32 + 120);
	// fmul f12,f0,f13
	ctx.f12.f64 = ctx.f0.f64 * ctx.f13.f64;
	// fmadd f11,f6,f5,f12
	ctx.f11.f64 = ctx.f6.f64 * ctx.f5.f64 + ctx.f12.f64;
	// fmadd f10,f4,f3,f11
	ctx.f10.f64 = ctx.f4.f64 * ctx.f3.f64 + ctx.f11.f64;
	// fmadd f9,f2,f1,f10
	ctx.f9.f64 = ctx.f2.f64 * ctx.f1.f64 + ctx.f10.f64;
	// stfd f9,24(r4)
	PPC_STORE_U64(ctx.r4.u32 + 24, ctx.f9.u64);
	// lfd f8,32(r5)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r5.u32 + 32);
	// lfd f7,40(r3)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r3.u32 + 40);
	// lfd f6,64(r5)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r5.u32 + 64);
	// lfd f5,48(r3)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r3.u32 + 48);
	// lfd f4,32(r3)
	ctx.f4.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// lfd f3,0(r5)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r5.u32 + 0);
	// lfd f2,56(r3)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r3.u32 + 56);
	// lfd f1,96(r5)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r5.u32 + 96);
	// fmul f0,f2,f1
	ctx.f0.f64 = ctx.f2.f64 * ctx.f1.f64;
	// fmadd f13,f8,f7,f0
	ctx.f13.f64 = ctx.f8.f64 * ctx.f7.f64 + ctx.f0.f64;
	// fmadd f12,f6,f5,f13
	ctx.f12.f64 = ctx.f6.f64 * ctx.f5.f64 + ctx.f13.f64;
	// fmadd f11,f4,f3,f12
	ctx.f11.f64 = ctx.f4.f64 * ctx.f3.f64 + ctx.f12.f64;
	// stfd f11,32(r4)
	PPC_STORE_U64(ctx.r4.u32 + 32, ctx.f11.u64);
	// lfd f10,40(r5)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r5.u32 + 40);
	// lfd f9,40(r3)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r3.u32 + 40);
	// lfd f8,104(r5)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r5.u32 + 104);
	// lfd f7,56(r3)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r3.u32 + 56);
	// lfd f6,72(r5)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r5.u32 + 72);
	// lfd f5,48(r3)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r3.u32 + 48);
	// lfd f4,32(r3)
	ctx.f4.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// lfd f3,8(r5)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r5.u32 + 8);
	// fmul f2,f4,f3
	ctx.f2.f64 = ctx.f4.f64 * ctx.f3.f64;
	// fmadd f1,f10,f9,f2
	ctx.f1.f64 = ctx.f10.f64 * ctx.f9.f64 + ctx.f2.f64;
	// fmadd f0,f8,f7,f1
	ctx.f0.f64 = ctx.f8.f64 * ctx.f7.f64 + ctx.f1.f64;
	// fmadd f13,f6,f5,f0
	ctx.f13.f64 = ctx.f6.f64 * ctx.f5.f64 + ctx.f0.f64;
	// stfd f13,40(r4)
	PPC_STORE_U64(ctx.r4.u32 + 40, ctx.f13.u64);
	// lfd f12,40(r3)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r3.u32 + 40);
	// lfd f11,48(r5)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r5.u32 + 48);
	// lfd f10,80(r5)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r5.u32 + 80);
	// lfd f9,112(r5)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r5.u32 + 112);
	// lfd f8,56(r3)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r3.u32 + 56);
	// fmul f7,f9,f8
	ctx.f7.f64 = ctx.f9.f64 * ctx.f8.f64;
	// lfd f6,48(r3)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r3.u32 + 48);
	// lfd f5,32(r3)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// lfd f4,16(r5)
	ctx.f4.u64 = PPC_LOAD_U64(ctx.r5.u32 + 16);
	// fmadd f3,f12,f11,f7
	ctx.f3.f64 = ctx.f12.f64 * ctx.f11.f64 + ctx.f7.f64;
	// fmadd f2,f10,f6,f3
	ctx.f2.f64 = ctx.f10.f64 * ctx.f6.f64 + ctx.f3.f64;
	// fmadd f1,f5,f4,f2
	ctx.f1.f64 = ctx.f5.f64 * ctx.f4.f64 + ctx.f2.f64;
	// stfd f1,48(r4)
	PPC_STORE_U64(ctx.r4.u32 + 48, ctx.f1.u64);
	// lfd f0,32(r3)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// lfd f6,24(r5)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r5.u32 + 24);
	// lfd f13,48(r3)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r3.u32 + 48);
	// lfd f12,88(r5)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r5.u32 + 88);
	// lfd f11,40(r3)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 40);
	// lfd f10,56(r5)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r5.u32 + 56);
	// lfd f9,56(r3)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r3.u32 + 56);
	// lfd f8,120(r5)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r5.u32 + 120);
	// fmul f7,f9,f8
	ctx.f7.f64 = ctx.f9.f64 * ctx.f8.f64;
	// fmadd f5,f0,f6,f7
	ctx.f5.f64 = ctx.f0.f64 * ctx.f6.f64 + ctx.f7.f64;
	// fmadd f4,f13,f12,f5
	ctx.f4.f64 = ctx.f13.f64 * ctx.f12.f64 + ctx.f5.f64;
	// fmadd f3,f11,f10,f4
	ctx.f3.f64 = ctx.f11.f64 * ctx.f10.f64 + ctx.f4.f64;
	// stfd f3,56(r4)
	PPC_STORE_U64(ctx.r4.u32 + 56, ctx.f3.u64);
	// lfd f2,32(r5)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r5.u32 + 32);
	// lfd f8,72(r3)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r3.u32 + 72);
	// lfd f1,88(r3)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r3.u32 + 88);
	// lfd f0,96(r5)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 96);
	// lfd f13,64(r3)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r3.u32 + 64);
	// lfd f12,0(r5)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r5.u32 + 0);
	// lfd f11,80(r3)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 80);
	// lfd f10,64(r5)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r5.u32 + 64);
	// fmul f9,f10,f11
	ctx.f9.f64 = ctx.f10.f64 * ctx.f11.f64;
	// fmadd f7,f2,f8,f9
	ctx.f7.f64 = ctx.f2.f64 * ctx.f8.f64 + ctx.f9.f64;
	// fmadd f6,f1,f0,f7
	ctx.f6.f64 = ctx.f1.f64 * ctx.f0.f64 + ctx.f7.f64;
	// fmadd f5,f13,f12,f6
	ctx.f5.f64 = ctx.f13.f64 * ctx.f12.f64 + ctx.f6.f64;
	// stfd f5,64(r4)
	PPC_STORE_U64(ctx.r4.u32 + 64, ctx.f5.u64);
	// lfd f1,64(r3)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r3.u32 + 64);
	// lfd f4,104(r5)
	ctx.f4.u64 = PPC_LOAD_U64(ctx.r5.u32 + 104);
	// lfd f3,88(r3)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r3.u32 + 88);
	// lfd f2,72(r5)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r5.u32 + 72);
	// lfd f10,80(r3)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 80);
	// lfd f0,8(r5)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 8);
	// lfd f13,40(r5)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r5.u32 + 40);
	// lfd f12,72(r3)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r3.u32 + 72);
	// fmul f11,f13,f12
	ctx.f11.f64 = ctx.f13.f64 * ctx.f12.f64;
	// fmadd f9,f1,f0,f11
	ctx.f9.f64 = ctx.f1.f64 * ctx.f0.f64 + ctx.f11.f64;
	// fmadd f8,f4,f3,f9
	ctx.f8.f64 = ctx.f4.f64 * ctx.f3.f64 + ctx.f9.f64;
	// fmadd f7,f2,f10,f8
	ctx.f7.f64 = ctx.f2.f64 * ctx.f10.f64 + ctx.f8.f64;
	// stfd f7,72(r4)
	PPC_STORE_U64(ctx.r4.u32 + 72, ctx.f7.u64);
	// lfd f6,72(r3)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r3.u32 + 72);
	// lfd f5,48(r5)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r5.u32 + 48);
	// lfd f13,80(r3)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r3.u32 + 80);
	// lfd f12,16(r5)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r5.u32 + 16);
	// lfd f11,64(r3)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 64);
	// lfd f4,112(r5)
	ctx.f4.u64 = PPC_LOAD_U64(ctx.r5.u32 + 112);
	// lfd f3,88(r3)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r3.u32 + 88);
	// fmul f2,f4,f3
	ctx.f2.f64 = ctx.f4.f64 * ctx.f3.f64;
	// fmadd f1,f6,f5,f2
	ctx.f1.f64 = ctx.f6.f64 * ctx.f5.f64 + ctx.f2.f64;
	// lfd f0,80(r5)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 80);
	// fmadd f10,f0,f13,f1
	ctx.f10.f64 = ctx.f0.f64 * ctx.f13.f64 + ctx.f1.f64;
	// fmadd f9,f11,f12,f10
	ctx.f9.f64 = ctx.f11.f64 * ctx.f12.f64 + ctx.f10.f64;
	// stfd f9,80(r4)
	PPC_STORE_U64(ctx.r4.u32 + 80, ctx.f9.u64);
	// lfd f1,64(r3)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r3.u32 + 64);
	// lfd f0,24(r5)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 24);
	// lfd f8,80(r3)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r3.u32 + 80);
	// lfd f7,88(r5)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r5.u32 + 88);
	// lfd f6,72(r3)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r3.u32 + 72);
	// lfd f5,56(r5)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r5.u32 + 56);
	// lfd f4,88(r3)
	ctx.f4.u64 = PPC_LOAD_U64(ctx.r3.u32 + 88);
	// lfd f3,120(r5)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r5.u32 + 120);
	// fmul f2,f4,f3
	ctx.f2.f64 = ctx.f4.f64 * ctx.f3.f64;
	// fmadd f13,f1,f0,f2
	ctx.f13.f64 = ctx.f1.f64 * ctx.f0.f64 + ctx.f2.f64;
	// fmadd f12,f8,f7,f13
	ctx.f12.f64 = ctx.f8.f64 * ctx.f7.f64 + ctx.f13.f64;
	// fmadd f11,f6,f5,f12
	ctx.f11.f64 = ctx.f6.f64 * ctx.f5.f64 + ctx.f12.f64;
	// stfd f11,88(r4)
	PPC_STORE_U64(ctx.r4.u32 + 88, ctx.f11.u64);
	// lfd f10,96(r3)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 96);
	// lfd f9,32(r5)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r5.u32 + 32);
	// lfd f8,104(r3)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r3.u32 + 104);
	// lfd f7,96(r5)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r5.u32 + 96);
	// lfd f6,64(r5)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r5.u32 + 64);
	// lfd f5,112(r3)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r3.u32 + 112);
	// fmul f4,f6,f5
	ctx.f4.f64 = ctx.f6.f64 * ctx.f5.f64;
	// lfd f3,120(r3)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r3.u32 + 120);
	// lfd f2,0(r5)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r5.u32 + 0);
	// fmadd f1,f9,f8,f4
	ctx.f1.f64 = ctx.f9.f64 * ctx.f8.f64 + ctx.f4.f64;
	// fmadd f0,f3,f7,f1
	ctx.f0.f64 = ctx.f3.f64 * ctx.f7.f64 + ctx.f1.f64;
	// fmadd f13,f10,f2,f0
	ctx.f13.f64 = ctx.f10.f64 * ctx.f2.f64 + ctx.f0.f64;
	// stfd f13,96(r4)
	PPC_STORE_U64(ctx.r4.u32 + 96, ctx.f13.u64);
	// lfd f12,8(r5)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r5.u32 + 8);
	// lfd f11,96(r3)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 96);
	// lfd f3,120(r3)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r3.u32 + 120);
	// lfd f10,112(r3)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 112);
	// lfd f9,72(r5)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r5.u32 + 72);
	// lfd f8,40(r5)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r5.u32 + 40);
	// lfd f7,104(r3)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r3.u32 + 104);
	// fmul f6,f8,f7
	ctx.f6.f64 = ctx.f8.f64 * ctx.f7.f64;
	// lfd f4,104(r5)
	ctx.f4.u64 = PPC_LOAD_U64(ctx.r5.u32 + 104);
	// fmadd f5,f11,f12,f6
	ctx.f5.f64 = ctx.f11.f64 * ctx.f12.f64 + ctx.f6.f64;
	// fmadd f2,f4,f3,f5
	ctx.f2.f64 = ctx.f4.f64 * ctx.f3.f64 + ctx.f5.f64;
	// fmadd f1,f9,f10,f2
	ctx.f1.f64 = ctx.f9.f64 * ctx.f10.f64 + ctx.f2.f64;
	// stfd f1,104(r4)
	PPC_STORE_U64(ctx.r4.u32 + 104, ctx.f1.u64);
	// lfd f6,48(r5)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r5.u32 + 48);
	// lfd f0,120(r3)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r3.u32 + 120);
	// lfd f13,112(r5)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r5.u32 + 112);
	// lfd f12,16(r5)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r5.u32 + 16);
	// lfd f11,96(r3)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 96);
	// lfd f10,112(r3)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 112);
	// lfd f9,80(r5)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r5.u32 + 80);
	// fmul f8,f9,f10
	ctx.f8.f64 = ctx.f9.f64 * ctx.f10.f64;
	// lfd f7,104(r3)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r3.u32 + 104);
	// fmadd f5,f7,f6,f8
	ctx.f5.f64 = ctx.f7.f64 * ctx.f6.f64 + ctx.f8.f64;
	// fmadd f4,f13,f0,f5
	ctx.f4.f64 = ctx.f13.f64 * ctx.f0.f64 + ctx.f5.f64;
	// fmadd f3,f11,f12,f4
	ctx.f3.f64 = ctx.f11.f64 * ctx.f12.f64 + ctx.f4.f64;
	// stfd f3,112(r4)
	PPC_STORE_U64(ctx.r4.u32 + 112, ctx.f3.u64);
	// lfd f8,24(r5)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r5.u32 + 24);
	// lfd f2,88(r5)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r5.u32 + 88);
	// lfd f1,112(r3)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r3.u32 + 112);
	// lfd f0,56(r5)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r5.u32 + 56);
	// lfd f13,104(r3)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r3.u32 + 104);
	// lfd f11,120(r3)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 120);
	// lfd f9,96(r3)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r3.u32 + 96);
	// lfd f12,120(r5)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r5.u32 + 120);
	// fmul f10,f11,f12
	ctx.f10.f64 = ctx.f11.f64 * ctx.f12.f64;
	// fmadd f7,f9,f8,f10
	ctx.f7.f64 = ctx.f9.f64 * ctx.f8.f64 + ctx.f10.f64;
	// fmadd f6,f1,f2,f7
	ctx.f6.f64 = ctx.f1.f64 * ctx.f2.f64 + ctx.f7.f64;
	// fmadd f5,f13,f0,f6
	ctx.f5.f64 = ctx.f13.f64 * ctx.f0.f64 + ctx.f6.f64;
	// stfd f5,120(r4)
	PPC_STORE_U64(ctx.r4.u32 + 120, ctx.f5.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82133FCC"))) PPC_WEAK_FUNC(sub_82133FCC);
PPC_FUNC_IMPL(__imp__sub_82133FCC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82133FD0"))) PPC_WEAK_FUNC(sub_82133FD0);
PPC_FUNC_IMPL(__imp__sub_82133FD0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x8233fa00
	ctx.lr = 0x82133FE0;
	sub_8233FA00(ctx, base);
	// lfd f0,16(r3)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// addi r11,r4,16
	ctx.r11.s64 = ctx.r4.s64 + 16;
	// lfd f5,120(r3)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r3.u32 + 120);
	// lfd f13,24(r3)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r3.u32 + 24);
	// fmul f2,f0,f5
	ctx.f2.f64 = ctx.f0.f64 * ctx.f5.f64;
	// lfd f7,112(r3)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r3.u32 + 112);
	// lfd f3,88(r3)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r3.u32 + 88);
	// fmul f30,f13,f7
	ctx.f30.f64 = ctx.f13.f64 * ctx.f7.f64;
	// lfd f1,96(r3)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r3.u32 + 96);
	// fmul f22,f3,f7
	ctx.f22.f64 = ctx.f3.f64 * ctx.f7.f64;
	// lfd f9,80(r3)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r3.u32 + 80);
	// stfd f1,-416(r1)
	PPC_STORE_U64(ctx.r1.u32 + -416, ctx.f1.u64);
	// fmul f1,f0,f3
	ctx.f1.f64 = ctx.f0.f64 * ctx.f3.f64;
	// lfd f11,56(r3)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 56);
	// fmul f6,f13,f9
	ctx.f6.f64 = ctx.f13.f64 * ctx.f9.f64;
	// lfd f12,48(r3)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r3.u32 + 48);
	// fmul f4,f11,f7
	ctx.f4.f64 = ctx.f11.f64 * ctx.f7.f64;
	// fmul f31,f12,f5
	ctx.f31.f64 = ctx.f12.f64 * ctx.f5.f64;
	// lfd f29,40(r3)
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r3.u32 + 40);
	// fmul f23,f5,f9
	ctx.f23.f64 = ctx.f5.f64 * ctx.f9.f64;
	// stfd f5,-224(r1)
	PPC_STORE_U64(ctx.r1.u32 + -224, ctx.f5.u64);
	// fmul f25,f11,f9
	ctx.f25.f64 = ctx.f11.f64 * ctx.f9.f64;
	// stfd f0,-376(r1)
	PPC_STORE_U64(ctx.r1.u32 + -376, ctx.f0.u64);
	// fmul f10,f13,f12
	ctx.f10.f64 = ctx.f13.f64 * ctx.f12.f64;
	// stfd f11,-368(r1)
	PPC_STORE_U64(ctx.r1.u32 + -368, ctx.f11.u64);
	// fmul f8,f0,f11
	ctx.f8.f64 = ctx.f0.f64 * ctx.f11.f64;
	// lfd f26,64(r3)
	ctx.f26.u64 = PPC_LOAD_U64(ctx.r3.u32 + 64);
	// fmul f5,f29,f2
	ctx.f5.f64 = ctx.f29.f64 * ctx.f2.f64;
	// lfd f28,72(r3)
	ctx.f28.u64 = PPC_LOAD_U64(ctx.r3.u32 + 72);
	// fmul f11,f29,f30
	ctx.f11.f64 = ctx.f29.f64 * ctx.f30.f64;
	// stfd f7,-296(r1)
	PPC_STORE_U64(ctx.r1.u32 + -296, ctx.f7.u64);
	// fmul f0,f29,f1
	ctx.f0.f64 = ctx.f29.f64 * ctx.f1.f64;
	// stfd f13,-392(r1)
	PPC_STORE_U64(ctx.r1.u32 + -392, ctx.f13.u64);
	// fmul f20,f29,f6
	ctx.f20.f64 = ctx.f29.f64 * ctx.f6.f64;
	// stfd f12,-328(r1)
	PPC_STORE_U64(ctx.r1.u32 + -328, ctx.f12.u64);
	// fmul f27,f12,f3
	ctx.f27.f64 = ctx.f12.f64 * ctx.f3.f64;
	// stfd f9,-280(r1)
	PPC_STORE_U64(ctx.r1.u32 + -280, ctx.f9.u64);
	// fmul f7,f26,f4
	ctx.f7.f64 = ctx.f26.f64 * ctx.f4.f64;
	// lfd f24,104(r3)
	ctx.f24.u64 = PPC_LOAD_U64(ctx.r3.u32 + 104);
	// fmul f15,f26,f30
	ctx.f15.f64 = ctx.f26.f64 * ctx.f30.f64;
	// stfd f3,-312(r1)
	PPC_STORE_U64(ctx.r1.u32 + -312, ctx.f3.u64);
	// fmul f18,f28,f4
	ctx.f18.f64 = ctx.f28.f64 * ctx.f4.f64;
	// stfd f8,-360(r1)
	PPC_STORE_U64(ctx.r1.u32 + -360, ctx.f8.u64);
	// fmul f16,f28,f2
	ctx.f16.f64 = ctx.f28.f64 * ctx.f2.f64;
	// lfd f21,8(r3)
	ctx.f21.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// fmul f13,f28,f31
	ctx.f13.f64 = ctx.f28.f64 * ctx.f31.f64;
	// stfd f4,-256(r1)
	PPC_STORE_U64(ctx.r1.u32 + -256, ctx.f4.u64);
	// fmul f9,f26,f31
	ctx.f9.f64 = ctx.f26.f64 * ctx.f31.f64;
	// lfd f19,32(r3)
	ctx.f19.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// fmul f14,f26,f2
	ctx.f14.f64 = ctx.f26.f64 * ctx.f2.f64;
	// lfd f17,0(r3)
	ctx.f17.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// fmul f12,f28,f30
	ctx.f12.f64 = ctx.f28.f64 * ctx.f30.f64;
	// lfd f3,-416(r1)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r1.u32 + -416);
	// fmadd f5,f24,f10,f5
	ctx.f5.f64 = ctx.f24.f64 * ctx.f10.f64 + ctx.f5.f64;
	// stfd f31,-232(r1)
	PPC_STORE_U64(ctx.r1.u32 + -232, ctx.f31.u64);
	// fmadd f11,f24,f8,f11
	ctx.f11.f64 = ctx.f24.f64 * ctx.f8.f64 + ctx.f11.f64;
	// stfd f25,-200(r1)
	PPC_STORE_U64(ctx.r1.u32 + -200, ctx.f25.u64);
	// fmadd f0,f28,f10,f0
	ctx.f0.f64 = ctx.f28.f64 * ctx.f10.f64 + ctx.f0.f64;
	// stfd f27,-216(r1)
	PPC_STORE_U64(ctx.r1.u32 + -216, ctx.f27.u64);
	// fmadd f8,f28,f8,f20
	ctx.f8.f64 = ctx.f28.f64 * ctx.f8.f64 + ctx.f20.f64;
	// fmadd f7,f3,f27,f7
	ctx.f7.f64 = ctx.f3.f64 * ctx.f27.f64 + ctx.f7.f64;
	// fmadd f20,f3,f1,f15
	ctx.f20.f64 = ctx.f3.f64 * ctx.f1.f64 + ctx.f15.f64;
	// fmadd f16,f24,f6,f16
	ctx.f16.f64 = ctx.f24.f64 * ctx.f6.f64 + ctx.f16.f64;
	// fmadd f18,f24,f27,f18
	ctx.f18.f64 = ctx.f24.f64 * ctx.f27.f64 + ctx.f18.f64;
	// fmadd f13,f24,f25,f13
	ctx.f13.f64 = ctx.f24.f64 * ctx.f25.f64 + ctx.f13.f64;
	// fmadd f12,f24,f1,f12
	ctx.f12.f64 = ctx.f24.f64 * ctx.f1.f64 + ctx.f12.f64;
	// fmadd f9,f3,f25,f9
	ctx.f9.f64 = ctx.f3.f64 * ctx.f25.f64 + ctx.f9.f64;
	// fmadd f15,f3,f6,f14
	ctx.f15.f64 = ctx.f3.f64 * ctx.f6.f64 + ctx.f14.f64;
	// fmadd f5,f21,f4,f5
	ctx.f5.f64 = ctx.f21.f64 * ctx.f4.f64 + ctx.f5.f64;
	// fmadd f4,f21,f25,f0
	ctx.f4.f64 = ctx.f21.f64 * ctx.f25.f64 + ctx.f0.f64;
	// fmadd f0,f21,f27,f8
	ctx.f0.f64 = ctx.f21.f64 * ctx.f27.f64 + ctx.f8.f64;
	// fmadd f11,f21,f31,f11
	ctx.f11.f64 = ctx.f21.f64 * ctx.f31.f64 + ctx.f11.f64;
	// fmadd f8,f19,f23,f7
	ctx.f8.f64 = ctx.f19.f64 * ctx.f23.f64 + ctx.f7.f64;
	// fmadd f18,f29,f23,f18
	ctx.f18.f64 = ctx.f29.f64 * ctx.f23.f64 + ctx.f18.f64;
	// fmadd f13,f29,f22,f13
	ctx.f13.f64 = ctx.f29.f64 * ctx.f22.f64 + ctx.f13.f64;
	// fmadd f16,f21,f22,f16
	ctx.f16.f64 = ctx.f21.f64 * ctx.f22.f64 + ctx.f16.f64;
	// fmadd f12,f21,f23,f12
	ctx.f12.f64 = ctx.f21.f64 * ctx.f23.f64 + ctx.f12.f64;
	// fmadd f9,f19,f22,f9
	ctx.f9.f64 = ctx.f19.f64 * ctx.f22.f64 + ctx.f9.f64;
	// fmadd f7,f17,f23,f20
	ctx.f7.f64 = ctx.f17.f64 * ctx.f23.f64 + ctx.f20.f64;
	// fmadd f31,f17,f22,f15
	ctx.f31.f64 = ctx.f17.f64 * ctx.f22.f64 + ctx.f15.f64;
	// fmul f2,f19,f2
	ctx.f2.f64 = ctx.f19.f64 * ctx.f2.f64;
	// fmul f25,f3,f29
	ctx.f25.f64 = ctx.f3.f64 * ctx.f29.f64;
	// stfd f25,-344(r1)
	PPC_STORE_U64(ctx.r1.u32 + -344, ctx.f25.u64);
	// fmul f25,f3,f21
	ctx.f25.f64 = ctx.f3.f64 * ctx.f21.f64;
	// stfd f25,-408(r1)
	PPC_STORE_U64(ctx.r1.u32 + -408, ctx.f25.u64);
	// fmul f27,f17,f28
	ctx.f27.f64 = ctx.f17.f64 * ctx.f28.f64;
	// lfd f15,-376(r1)
	ctx.f15.u64 = PPC_LOAD_U64(ctx.r1.u32 + -376);
	// fmul f25,f19,f28
	ctx.f25.f64 = ctx.f19.f64 * ctx.f28.f64;
	// stfd f25,-400(r1)
	PPC_STORE_U64(ctx.r1.u32 + -400, ctx.f25.u64);
	// fmul f25,f26,f24
	ctx.f25.f64 = ctx.f26.f64 * ctx.f24.f64;
	// stfd f27,-384(r1)
	PPC_STORE_U64(ctx.r1.u32 + -384, ctx.f27.u64);
	// fsub f13,f18,f13
	ctx.f13.f64 = ctx.f18.f64 - ctx.f13.f64;
	// stfd f13,0(r4)
	PPC_STORE_U64(ctx.r4.u32 + 0, ctx.f13.u64);
	// fmul f23,f17,f24
	ctx.f23.f64 = ctx.f17.f64 * ctx.f24.f64;
	// stfd f21,-376(r1)
	PPC_STORE_U64(ctx.r1.u32 + -376, ctx.f21.u64);
	// fmul f13,f3,f28
	ctx.f13.f64 = ctx.f3.f64 * ctx.f28.f64;
	// lfd f28,-368(r1)
	ctx.f28.u64 = PPC_LOAD_U64(ctx.r1.u32 + -368);
	// fmul f18,f26,f21
	ctx.f18.f64 = ctx.f26.f64 * ctx.f21.f64;
	// lfd f22,-392(r1)
	ctx.f22.u64 = PPC_LOAD_U64(ctx.r1.u32 + -392);
	// lfd f21,-296(r1)
	ctx.f21.u64 = PPC_LOAD_U64(ctx.r1.u32 + -296);
	// fmul f14,f26,f29
	ctx.f14.f64 = ctx.f26.f64 * ctx.f29.f64;
	// stfd f21,-192(r1)
	PPC_STORE_U64(ctx.r1.u32 + -192, ctx.f21.u64);
	// fmul f24,f19,f24
	ctx.f24.f64 = ctx.f19.f64 * ctx.f24.f64;
	// lfd f21,-360(r1)
	ctx.f21.u64 = PPC_LOAD_U64(ctx.r1.u32 + -360);
	// fsub f12,f16,f12
	ctx.f12.f64 = ctx.f16.f64 - ctx.f12.f64;
	// fmul f27,f27,f28
	ctx.f27.f64 = ctx.f27.f64 * ctx.f28.f64;
	// stfd f27,-392(r1)
	PPC_STORE_U64(ctx.r1.u32 + -392, ctx.f27.u64);
	// stfd f14,-288(r1)
	PPC_STORE_U64(ctx.r1.u32 + -288, ctx.f14.u64);
	// fsub f11,f11,f5
	ctx.f11.f64 = ctx.f11.f64 - ctx.f5.f64;
	// fmul f27,f28,f25
	ctx.f27.f64 = ctx.f28.f64 * ctx.f25.f64;
	// stfd f27,-360(r1)
	PPC_STORE_U64(ctx.r1.u32 + -360, ctx.f27.u64);
	// stfd f14,-368(r1)
	PPC_STORE_U64(ctx.r1.u32 + -368, ctx.f14.u64);
	// fmul f27,f22,f25
	ctx.f27.f64 = ctx.f22.f64 * ctx.f25.f64;
	// lfd f14,-312(r1)
	ctx.f14.u64 = PPC_LOAD_U64(ctx.r1.u32 + -312);
	// fsub f5,f4,f0
	ctx.f5.f64 = ctx.f4.f64 - ctx.f0.f64;
	// stfd f27,-296(r1)
	PPC_STORE_U64(ctx.r1.u32 + -296, ctx.f27.u64);
	// fmul f27,f23,f14
	ctx.f27.f64 = ctx.f23.f64 * ctx.f14.f64;
	// stfd f27,-312(r1)
	PPC_STORE_U64(ctx.r1.u32 + -312, ctx.f27.u64);
	// fmul f27,f23,f28
	ctx.f27.f64 = ctx.f23.f64 * ctx.f28.f64;
	// stfd f28,-208(r1)
	PPC_STORE_U64(ctx.r1.u32 + -208, ctx.f28.u64);
	// fmul f28,f18,f28
	ctx.f28.f64 = ctx.f18.f64 * ctx.f28.f64;
	// lfd f20,-328(r1)
	ctx.f20.u64 = PPC_LOAD_U64(ctx.r1.u32 + -328);
	// fsub f4,f9,f8
	ctx.f4.f64 = ctx.f9.f64 - ctx.f8.f64;
	// stfd f28,-328(r1)
	PPC_STORE_U64(ctx.r1.u32 + -328, ctx.f28.u64);
	// fmul f28,f20,f25
	ctx.f28.f64 = ctx.f20.f64 * ctx.f25.f64;
	// stfd f10,-416(r1)
	PPC_STORE_U64(ctx.r1.u32 + -416, ctx.f10.u64);
	// fmul f25,f15,f25
	ctx.f25.f64 = ctx.f15.f64 * ctx.f25.f64;
	// stfd f28,-416(r1)
	PPC_STORE_U64(ctx.r1.u32 + -416, ctx.f28.u64);
	// fsub f0,f7,f31
	ctx.f0.f64 = ctx.f7.f64 - ctx.f31.f64;
	// lfd f28,-344(r1)
	ctx.f28.u64 = PPC_LOAD_U64(ctx.r1.u32 + -344);
	// fmul f30,f19,f30
	ctx.f30.f64 = ctx.f19.f64 * ctx.f30.f64;
	// stfd f25,-344(r1)
	PPC_STORE_U64(ctx.r1.u32 + -344, ctx.f25.u64);
	// fmul f6,f19,f6
	ctx.f6.f64 = ctx.f19.f64 * ctx.f6.f64;
	// lfd f25,-408(r1)
	ctx.f25.u64 = PPC_LOAD_U64(ctx.r1.u32 + -408);
	// fmul f1,f19,f1
	ctx.f1.f64 = ctx.f19.f64 * ctx.f1.f64;
	// stfd f27,-408(r1)
	PPC_STORE_U64(ctx.r1.u32 + -408, ctx.f27.u64);
	// fmul f27,f15,f13
	ctx.f27.f64 = ctx.f15.f64 * ctx.f13.f64;
	// stfd f27,-264(r1)
	PPC_STORE_U64(ctx.r1.u32 + -264, ctx.f27.u64);
	// lfd f27,-400(r1)
	ctx.f27.u64 = PPC_LOAD_U64(ctx.r1.u32 + -400);
	// stfd f27,-400(r1)
	PPC_STORE_U64(ctx.r1.u32 + -400, ctx.f27.u64);
	// fmul f27,f24,f14
	ctx.f27.f64 = ctx.f24.f64 * ctx.f14.f64;
	// stfd f27,-352(r1)
	PPC_STORE_U64(ctx.r1.u32 + -352, ctx.f27.u64);
	// lfd f27,-384(r1)
	ctx.f27.u64 = PPC_LOAD_U64(ctx.r1.u32 + -384);
	// stfd f18,-176(r1)
	PPC_STORE_U64(ctx.r1.u32 + -176, ctx.f18.u64);
	// fmul f18,f20,f13
	ctx.f18.f64 = ctx.f20.f64 * ctx.f13.f64;
	// stfd f27,-384(r1)
	PPC_STORE_U64(ctx.r1.u32 + -384, ctx.f27.u64);
	// fmul f27,f22,f24
	ctx.f27.f64 = ctx.f22.f64 * ctx.f24.f64;
	// stfd f12,8(r4)
	PPC_STORE_U64(ctx.r4.u32 + 8, ctx.f12.u64);
	// fmadd f12,f3,f10,f2
	ctx.f12.f64 = ctx.f3.f64 * ctx.f10.f64 + ctx.f2.f64;
	// stfd f18,-240(r1)
	PPC_STORE_U64(ctx.r1.u32 + -240, ctx.f18.u64);
	// fmr f18,f10
	ctx.f18.f64 = ctx.f10.f64;
	// stfd f27,-336(r1)
	PPC_STORE_U64(ctx.r1.u32 + -336, ctx.f27.u64);
	// lfd f27,0(r4)
	ctx.f27.u64 = PPC_LOAD_U64(ctx.r4.u32 + 0);
	// stfd f23,-184(r1)
	PPC_STORE_U64(ctx.r1.u32 + -184, ctx.f23.u64);
	// stfd f19,-168(r1)
	PPC_STORE_U64(ctx.r1.u32 + -168, ctx.f19.u64);
	// stfd f3,-304(r1)
	PPC_STORE_U64(ctx.r1.u32 + -304, ctx.f3.u64);
	// stfd f26,-272(r1)
	PPC_STORE_U64(ctx.r1.u32 + -272, ctx.f26.u64);
	// stfd f11,16(r4)
	PPC_STORE_U64(ctx.r4.u32 + 16, ctx.f11.u64);
	// stfd f5,24(r4)
	PPC_STORE_U64(ctx.r4.u32 + 24, ctx.f5.u64);
	// stfd f4,32(r4)
	PPC_STORE_U64(ctx.r4.u32 + 32, ctx.f4.u64);
	// stfd f0,40(r4)
	PPC_STORE_U64(ctx.r4.u32 + 40, ctx.f0.u64);
	// stfd f12,-248(r1)
	PPC_STORE_U64(ctx.r1.u32 + -248, ctx.f12.u64);
	// stfd f27,-320(r1)
	PPC_STORE_U64(ctx.r1.u32 + -320, ctx.f27.u64);
	// fmadd f5,f3,f21,f30
	ctx.f5.f64 = ctx.f3.f64 * ctx.f21.f64 + ctx.f30.f64;
	// lfd f8,-376(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + -376);
	// fmadd f3,f26,f18,f1
	ctx.f3.f64 = ctx.f26.f64 * ctx.f18.f64 + ctx.f1.f64;
	// lfd f2,-360(r1)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r1.u32 + -360);
	// fmul f7,f19,f8
	ctx.f7.f64 = ctx.f19.f64 * ctx.f8.f64;
	// lfd f0,-312(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -312);
	// fmadd f1,f28,f14,f2
	ctx.f1.f64 = ctx.f28.f64 * ctx.f14.f64 + ctx.f2.f64;
	// lfd f18,-352(r1)
	ctx.f18.u64 = PPC_LOAD_U64(ctx.r1.u32 + -352);
	// fmadd f12,f22,f13,f0
	ctx.f12.f64 = ctx.f22.f64 * ctx.f13.f64 + ctx.f0.f64;
	// lfd f19,-208(r1)
	ctx.f19.u64 = PPC_LOAD_U64(ctx.r1.u32 + -208);
	// fmadd f4,f26,f21,f6
	ctx.f4.f64 = ctx.f26.f64 * ctx.f21.f64 + ctx.f6.f64;
	// lfd f8,-296(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + -296);
	// fmadd f13,f19,f13,f18
	ctx.f13.f64 = ctx.f19.f64 * ctx.f13.f64 + ctx.f18.f64;
	// lfd f2,-408(r1)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r1.u32 + -408);
	// fmadd f6,f25,f14,f8
	ctx.f6.f64 = ctx.f25.f64 * ctx.f14.f64 + ctx.f8.f64;
	// lfd f30,-368(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -368);
	// fmadd f0,f22,f28,f2
	ctx.f0.f64 = ctx.f22.f64 * ctx.f28.f64 + ctx.f2.f64;
	// lfd f31,-392(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -392);
	// fmul f10,f15,f24
	ctx.f10.f64 = ctx.f15.f64 * ctx.f24.f64;
	// lfd f18,-336(r1)
	ctx.f18.u64 = PPC_LOAD_U64(ctx.r1.u32 + -336);
	// fmadd f31,f22,f30,f31
	ctx.f31.f64 = ctx.f22.f64 * ctx.f30.f64 + ctx.f31.f64;
	// lfd f2,-400(r1)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r1.u32 + -400);
	// fmadd f19,f25,f19,f18
	ctx.f19.f64 = ctx.f25.f64 * ctx.f19.f64 + ctx.f18.f64;
	// lfd f8,-328(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + -328);
	// fmul f9,f17,f29
	ctx.f9.f64 = ctx.f17.f64 * ctx.f29.f64;
	// fmadd f8,f22,f2,f8
	ctx.f8.f64 = ctx.f22.f64 * ctx.f2.f64 + ctx.f8.f64;
	// lfd f29,-192(r1)
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -192);
	// fmul f11,f23,f20
	ctx.f11.f64 = ctx.f23.f64 * ctx.f20.f64;
	// lfd f23,-384(r1)
	ctx.f23.u64 = PPC_LOAD_U64(ctx.r1.u32 + -384);
	// lfd f26,-344(r1)
	ctx.f26.u64 = PPC_LOAD_U64(ctx.r1.u32 + -344);
	// lis r9,-32250
	ctx.r9.s64 = -2113536000;
	// lfd f22,-176(r1)
	ctx.f22.u64 = PPC_LOAD_U64(ctx.r1.u32 + -176);
	// fmadd f26,f23,f29,f26
	ctx.f26.f64 = ctx.f23.f64 * ctx.f29.f64 + ctx.f26.f64;
	// lfd f27,-240(r1)
	ctx.f27.u64 = PPC_LOAD_U64(ctx.r1.u32 + -240);
	// fmul f16,f22,f20
	ctx.f16.f64 = ctx.f22.f64 * ctx.f20.f64;
	// fmadd f30,f30,f29,f27
	ctx.f30.f64 = ctx.f30.f64 * ctx.f29.f64 + ctx.f27.f64;
	// lfd f21,-264(r1)
	ctx.f21.u64 = PPC_LOAD_U64(ctx.r1.u32 + -264);
	// lfd f27,-416(r1)
	ctx.f27.u64 = PPC_LOAD_U64(ctx.r1.u32 + -416);
	// fmadd f10,f25,f20,f10
	ctx.f10.f64 = ctx.f25.f64 * ctx.f20.f64 + ctx.f10.f64;
	// lfd f18,-320(r1)
	ctx.f18.u64 = PPC_LOAD_U64(ctx.r1.u32 + -320);
	// fmadd f21,f22,f29,f21
	ctx.f21.f64 = ctx.f22.f64 * ctx.f29.f64 + ctx.f21.f64;
	// fmul f18,f18,f17
	ctx.f18.f64 = ctx.f18.f64 * ctx.f17.f64;
	// stfd f26,-320(r1)
	PPC_STORE_U64(ctx.r1.u32 + -320, ctx.f26.u64);
	// fmul f26,f23,f20
	ctx.f26.f64 = ctx.f23.f64 * ctx.f20.f64;
	// lfd f20,-272(r1)
	ctx.f20.u64 = PPC_LOAD_U64(ctx.r1.u32 + -272);
	// fmadd f31,f7,f14,f31
	ctx.f31.f64 = ctx.f7.f64 * ctx.f14.f64 + ctx.f31.f64;
	// stfd f21,-336(r1)
	PPC_STORE_U64(ctx.r1.u32 + -336, ctx.f21.u64);
	// fmadd f27,f2,f29,f27
	ctx.f27.f64 = ctx.f2.f64 * ctx.f29.f64 + ctx.f27.f64;
	// stfd f29,-352(r1)
	PPC_STORE_U64(ctx.r1.u32 + -352, ctx.f29.u64);
	// stfd f31,-272(r1)
	PPC_STORE_U64(ctx.r1.u32 + -272, ctx.f31.u64);
	// fmadd f8,f9,f14,f8
	ctx.f8.f64 = ctx.f9.f64 * ctx.f14.f64 + ctx.f8.f64;
	// lfd f31,-224(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -224);
	// fmadd f11,f15,f28,f11
	ctx.f11.f64 = ctx.f15.f64 * ctx.f28.f64 + ctx.f11.f64;
	// lfd f21,-304(r1)
	ctx.f21.u64 = PPC_LOAD_U64(ctx.r1.u32 + -304);
	// fmadd f12,f22,f31,f12
	ctx.f12.f64 = ctx.f22.f64 * ctx.f31.f64 + ctx.f12.f64;
	// lfd f29,24(r4)
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r4.u32 + 24);
	// fmadd f6,f23,f31,f6
	ctx.f6.f64 = ctx.f23.f64 * ctx.f31.f64 + ctx.f6.f64;
	// lfd f14,-280(r1)
	ctx.f14.u64 = PPC_LOAD_U64(ctx.r1.u32 + -280);
	// fmadd f1,f2,f31,f1
	ctx.f1.f64 = ctx.f2.f64 * ctx.f31.f64 + ctx.f1.f64;
	// stfd f8,-280(r1)
	PPC_STORE_U64(ctx.r1.u32 + -280, ctx.f8.u64);
	// fmadd f2,f15,f2,f16
	ctx.f2.f64 = ctx.f15.f64 * ctx.f2.f64 + ctx.f16.f64;
	// fmadd f29,f29,f21,f18
	ctx.f29.f64 = ctx.f29.f64 * ctx.f21.f64 + ctx.f18.f64;
	// lfd f22,-248(r1)
	ctx.f22.u64 = PPC_LOAD_U64(ctx.r1.u32 + -248);
	// lfd f23,-232(r1)
	ctx.f23.u64 = PPC_LOAD_U64(ctx.r1.u32 + -232);
	// lfd f21,-216(r1)
	ctx.f21.u64 = PPC_LOAD_U64(ctx.r1.u32 + -216);
	// fmadd f5,f17,f23,f5
	ctx.f5.f64 = ctx.f17.f64 * ctx.f23.f64 + ctx.f5.f64;
	// lfd f8,-256(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + -256);
	// fmadd f4,f17,f21,f4
	ctx.f4.f64 = ctx.f17.f64 * ctx.f21.f64 + ctx.f4.f64;
	// stfd f27,-304(r1)
	PPC_STORE_U64(ctx.r1.u32 + -304, ctx.f27.u64);
	// fmadd f8,f17,f8,f22
	ctx.f8.f64 = ctx.f17.f64 * ctx.f8.f64 + ctx.f22.f64;
	// lfd f27,-288(r1)
	ctx.f27.u64 = PPC_LOAD_U64(ctx.r1.u32 + -288);
	// fmadd f21,f7,f31,f0
	ctx.f21.f64 = ctx.f7.f64 * ctx.f31.f64 + ctx.f0.f64;
	// lfd f18,-200(r1)
	ctx.f18.u64 = PPC_LOAD_U64(ctx.r1.u32 + -200);
	// fmadd f26,f15,f27,f26
	ctx.f26.f64 = ctx.f15.f64 * ctx.f27.f64 + ctx.f26.f64;
	// stfd f11,-288(r1)
	PPC_STORE_U64(ctx.r1.u32 + -288, ctx.f11.u64);
	// fmadd f3,f17,f18,f3
	ctx.f3.f64 = ctx.f17.f64 * ctx.f18.f64 + ctx.f3.f64;
	// lfd f11,16(r4)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r4.u32 + 16);
	// lfd f16,-184(r1)
	ctx.f16.u64 = PPC_LOAD_U64(ctx.r1.u32 + -184);
	// lfd f22,8(r4)
	ctx.f22.u64 = PPC_LOAD_U64(ctx.r4.u32 + 8);
	// lfd f23,-168(r1)
	ctx.f23.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// fmadd f11,f11,f20,f29
	ctx.f11.f64 = ctx.f11.f64 * ctx.f20.f64 + ctx.f29.f64;
	// lfd f0,-304(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -304);
	// fmadd f29,f28,f14,f0
	ctx.f29.f64 = ctx.f28.f64 * ctx.f14.f64 + ctx.f0.f64;
	// lfd f0,-320(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -320);
	// fmadd f28,f25,f14,f0
	ctx.f28.f64 = ctx.f25.f64 * ctx.f14.f64 + ctx.f0.f64;
	// lfd f25,-352(r1)
	ctx.f25.u64 = PPC_LOAD_U64(ctx.r1.u32 + -352);
	// fmadd f30,f24,f14,f30
	ctx.f30.f64 = ctx.f24.f64 * ctx.f14.f64 + ctx.f30.f64;
	// lfd f24,-288(r1)
	ctx.f24.u64 = PPC_LOAD_U64(ctx.r1.u32 + -288);
	// fmadd f13,f27,f31,f13
	ctx.f13.f64 = ctx.f27.f64 * ctx.f31.f64 + ctx.f13.f64;
	// lfd f27,-336(r1)
	ctx.f27.u64 = PPC_LOAD_U64(ctx.r1.u32 + -336);
	// fmadd f31,f9,f31,f19
	ctx.f31.f64 = ctx.f9.f64 * ctx.f31.f64 + ctx.f19.f64;
	// addi r8,r9,31376
	ctx.r8.s64 = ctx.r9.s64 + 31376;
	// fmadd f24,f7,f25,f24
	ctx.f24.f64 = ctx.f7.f64 * ctx.f25.f64 + ctx.f24.f64;
	// li r10,2
	ctx.r10.s64 = 2;
	// fmadd f10,f9,f25,f10
	ctx.f10.f64 = ctx.f9.f64 * ctx.f25.f64 + ctx.f10.f64;
	// addi r11,r11,-24
	ctx.r11.s64 = ctx.r11.s64 + -24;
	// fsub f4,f4,f3
	ctx.f4.f64 = ctx.f4.f64 - ctx.f3.f64;
	// stfd f4,56(r4)
	PPC_STORE_U64(ctx.r4.u32 + 56, ctx.f4.u64);
	// fmadd f9,f9,f14,f2
	ctx.f9.f64 = ctx.f9.f64 * ctx.f14.f64 + ctx.f2.f64;
	// fmadd f27,f16,f14,f27
	ctx.f27.f64 = ctx.f16.f64 * ctx.f14.f64 + ctx.f27.f64;
	// lfd f0,168(r8)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + 168);
	// fmadd f7,f7,f14,f26
	ctx.f7.f64 = ctx.f7.f64 * ctx.f14.f64 + ctx.f26.f64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// fmadd f3,f23,f22,f11
	ctx.f3.f64 = ctx.f23.f64 * ctx.f22.f64 + ctx.f11.f64;
	// lfd f11,-280(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + -280);
	// fsub f2,f12,f6
	ctx.f2.f64 = ctx.f12.f64 - ctx.f6.f64;
	// lfd f12,-272(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -272);
	// fsub f5,f8,f5
	ctx.f5.f64 = ctx.f8.f64 - ctx.f5.f64;
	// stfd f5,48(r4)
	PPC_STORE_U64(ctx.r4.u32 + 48, ctx.f5.u64);
	// fsub f1,f1,f13
	ctx.f1.f64 = ctx.f1.f64 - ctx.f13.f64;
	// stfd f2,72(r4)
	PPC_STORE_U64(ctx.r4.u32 + 72, ctx.f2.u64);
	// fsub f13,f31,f21
	ctx.f13.f64 = ctx.f31.f64 - ctx.f21.f64;
	// stfd f1,64(r4)
	PPC_STORE_U64(ctx.r4.u32 + 64, ctx.f1.u64);
	// fsub f8,f12,f11
	ctx.f8.f64 = ctx.f12.f64 - ctx.f11.f64;
	// stfd f13,80(r4)
	PPC_STORE_U64(ctx.r4.u32 + 80, ctx.f13.u64);
	// fsub f6,f30,f29
	ctx.f6.f64 = ctx.f30.f64 - ctx.f29.f64;
	// stfd f8,88(r4)
	PPC_STORE_U64(ctx.r4.u32 + 88, ctx.f8.u64);
	// fsub f4,f24,f10
	ctx.f4.f64 = ctx.f24.f64 - ctx.f10.f64;
	// stfd f6,96(r4)
	PPC_STORE_U64(ctx.r4.u32 + 96, ctx.f6.u64);
	// fsub f5,f28,f27
	ctx.f5.f64 = ctx.f28.f64 - ctx.f27.f64;
	// stfd f5,104(r4)
	PPC_STORE_U64(ctx.r4.u32 + 104, ctx.f5.u64);
	// fsub f2,f9,f7
	ctx.f2.f64 = ctx.f9.f64 - ctx.f7.f64;
	// stfd f4,112(r4)
	PPC_STORE_U64(ctx.r4.u32 + 112, ctx.f4.u64);
	// stfd f2,120(r4)
	PPC_STORE_U64(ctx.r4.u32 + 120, ctx.f2.u64);
	// fdiv f0,f0,f3
	ctx.f0.f64 = ctx.f0.f64 / ctx.f3.f64;
loc_82134460:
	// lfd f13,8(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// lfd f12,16(r11)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// fmul f11,f0,f13
	ctx.f11.f64 = ctx.f0.f64 * ctx.f13.f64;
	// lfd f10,24(r11)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// fmul f9,f0,f12
	ctx.f9.f64 = ctx.f0.f64 * ctx.f12.f64;
	// lfd f8,32(r11)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 32);
	// fmul f7,f0,f10
	ctx.f7.f64 = ctx.f0.f64 * ctx.f10.f64;
	// lfd f6,40(r11)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 40);
	// fmul f5,f0,f8
	ctx.f5.f64 = ctx.f0.f64 * ctx.f8.f64;
	// lfd f4,48(r11)
	ctx.f4.u64 = PPC_LOAD_U64(ctx.r11.u32 + 48);
	// fmul f3,f0,f6
	ctx.f3.f64 = ctx.f0.f64 * ctx.f6.f64;
	// lfd f2,56(r11)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r11.u32 + 56);
	// fmul f1,f4,f0
	ctx.f1.f64 = ctx.f4.f64 * ctx.f0.f64;
	// lfd f13,64(r11)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r11.u32 + 64);
	// fmul f12,f2,f0
	ctx.f12.f64 = ctx.f2.f64 * ctx.f0.f64;
	// stfd f11,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.f11.u64);
	// fmul f11,f13,f0
	ctx.f11.f64 = ctx.f13.f64 * ctx.f0.f64;
	// stfd f9,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.f9.u64);
	// stfd f7,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.f7.u64);
	// stfd f5,32(r11)
	PPC_STORE_U64(ctx.r11.u32 + 32, ctx.f5.u64);
	// stfd f3,40(r11)
	PPC_STORE_U64(ctx.r11.u32 + 40, ctx.f3.u64);
	// stfd f1,48(r11)
	PPC_STORE_U64(ctx.r11.u32 + 48, ctx.f1.u64);
	// stfd f12,56(r11)
	PPC_STORE_U64(ctx.r11.u32 + 56, ctx.f12.u64);
	// stfdu f11,64(r11)
	ea = 64 + ctx.r11.u32;
	PPC_STORE_U64(ea, ctx.r11.u64);
	ctx.r11.u32 = ea;
	// bdnz 0x82134460
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82134460;
	// addi r12,r1,-8
	ctx.r12.s64 = ctx.r1.s64 + -8;
	// bl 0x8233fa4c
	ctx.lr = 0x821344CC;
	__savefpr_14(ctx, base);
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821344D8"))) PPC_WEAK_FUNC(sub_821344D8);
PPC_FUNC_IMPL(__imp__sub_821344D8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x821344E0;
	__restfpr_26(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32179
	ctx.r11.s64 = -2108882944;
	// lis r10,0
	ctx.r10.s64 = 0;
	// addi r8,r11,20000
	ctx.r8.s64 = ctx.r11.s64 + 20000;
	// ori r7,r10,65512
	ctx.r7.u64 = ctx.r10.u64 | 65512;
	// lis r6,0
	ctx.r6.s64 = 0;
	// li r5,80
	ctx.r5.s64 = 80;
	// ori r4,r6,65516
	ctx.r4.u64 = ctx.r6.u64 | 65516;
	// li r9,5120
	ctx.r9.s64 = 5120;
	// lwzx r11,r8,r7
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// lis r7,-32178
	ctx.r7.s64 = -2108817408;
	// li r29,0
	ctx.r29.s64 = 0;
	// addi r6,r11,79
	ctx.r6.s64 = ctx.r11.s64 + 79;
	// lwzx r10,r8,r4
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	// lis r4,6184
	ctx.r4.s64 = 405274624;
	// divwu r11,r6,r5
	ctx.r11.u32 = ctx.r6.u32 / ctx.r5.u32;
	// stw r29,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r29.u32);
	// addi r8,r10,15
	ctx.r8.s64 = ctx.r10.s64 + 15;
	// stw r3,26084(r7)
	PPC_STORE_U32(ctx.r7.u32 + 26084, ctx.r3.u32);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r29,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r29.u32);
	// ori r28,r4,134
	ctx.r28.u64 = ctx.r4.u64 | 134;
	// stw r29,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r29.u32);
	// add r6,r11,r10
	ctx.r6.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r7,r8,0,0,27
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFF0;
	// rlwinm r4,r6,4,0,27
	ctx.r4.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mullw r3,r7,r4
	ctx.r3.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r4.s32);
	// mullw r11,r7,r4
	ctx.r11.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r4.s32);
	// rlwinm r10,r3,3,0,28
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// divwu r11,r10,r9
	ctx.r11.u32 = ctx.r10.u32 / ctx.r9.u32;
	// divwu r10,r8,r9
	ctx.r10.u32 = ctx.r8.u32 / ctx.r9.u32;
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// add r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + ctx.r11.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r4,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r4.u32);
	// li r4,256
	ctx.r4.s64 = 256;
	// li r3,256
	ctx.r3.s64 = 256;
	// bl 0x82237798
	ctx.lr = 0x82134580;
	sub_82237798(ctx, base);
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,128
	ctx.r4.s64 = 128;
	// stw r3,-25564(r11)
	PPC_STORE_U32(ctx.r11.u32 + -25564, ctx.r3.u32);
	// li r3,128
	ctx.r3.s64 = 128;
	// addi r30,r11,-25564
	ctx.r30.s64 = ctx.r11.s64 + -25564;
	// bl 0x82237798
	ctx.lr = 0x821345A4;
	sub_82237798(ctx, base);
	// addi r27,r30,4
	ctx.r27.s64 = ctx.r30.s64 + 4;
	// stw r3,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r3.u32);
	// li r31,64
	ctx.r31.s64 = 64;
	// li r30,3
	ctx.r30.s64 = 3;
loc_821345B4:
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82237798
	ctx.lr = 0x821345CC;
	sub_82237798(ctx, base);
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// stwu r3,4(r27)
	ea = 4 + ctx.r27.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r27.u32 = ea;
	// rlwinm r31,r31,31,1,31
	ctx.r31.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 31) & 0x7FFFFFFF;
	// bne 0x821345b4
	if (!ctx.cr0.eq) goto loc_821345B4;
	// lis r11,1168
	ctx.r11.s64 = 76546048;
	// li r10,3
	ctx.r10.s64 = 3;
	// ori r26,r11,258
	ctx.r26.u64 = ctx.r11.u64 | 258;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// li r7,8
	ctx.r7.s64 = 8;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,256
	ctx.r4.s64 = 256;
	// li r3,256
	ctx.r3.s64 = 256;
	// bl 0x82237678
	ctx.lr = 0x82134608;
	sub_82237678(ctx, base);
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// li r31,128
	ctx.r31.s64 = 128;
	// addi r27,r11,-25584
	ctx.r27.s64 = ctx.r11.s64 + -25584;
	// li r28,4
	ctx.r28.s64 = 4;
	// mr r30,r27
	ctx.r30.u64 = ctx.r27.u64;
	// stw r3,-25584(r11)
	PPC_STORE_U32(ctx.r11.u32 + -25584, ctx.r3.u32);
loc_82134620:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x82082030
	ctx.lr = 0x82134634;
	sub_82082030(ctx, base);
	// addi r8,r1,132
	ctx.r8.s64 = ctx.r1.s64 + 132;
	// addi r11,r1,128
	ctx.r11.s64 = ctx.r1.s64 + 128;
	// stw r3,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r3.u32);
	// stw r8,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r8.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r3,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r3.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// li r6,8
	ctx.r6.s64 = 8;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82298488
	ctx.lr = 0x82134678;
	sub_82298488(ctx, base);
	// lwz r7,4(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// lwzu r11,4(r30)
	ea = 4 + ctx.r30.u32;
	ctx.r11.u64 = PPC_LOAD_U32(ea);
	ctx.r30.u32 = ea;
	// rlwinm r31,r31,31,1,31
	ctx.r31.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 31) & 0x7FFFFFFF;
	// lwz r6,32(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	// lwz r5,32(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// rlwimi r5,r6,0,0,19
	ctx.r5.u64 = (rotl32(ctx.r6.u32, 0) & 0xFFFFF000) | (ctx.r5.u64 & 0xFFFFFFFF00000FFF);
	// stw r5,32(r7)
	PPC_STORE_U32(ctx.r7.u32 + 32, ctx.r5.u32);
	// bne 0x82134620
	if (!ctx.cr0.eq) goto loc_82134620;
	// lis r11,42
	ctx.r11.s64 = 2752512;
	// stb r29,153(r1)
	PPC_STORE_U8(ctx.r1.u32 + 153, ctx.r29.u8);
	// li r4,2
	ctx.r4.s64 = 2;
	// ori r10,r11,9145
	ctx.r10.u64 = ctx.r11.u64 | 9145;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// stw r10,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r10.u32);
	// bl 0x821160a8
	ctx.lr = 0x821346BC;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x821346C0;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821346f0
	if (ctx.cr6.eq) goto loc_821346F0;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,-2304
	ctx.r6.s64 = ctx.r11.s64 + -2304;
	// addi r5,r10,-1808
	ctx.r5.s64 = ctx.r10.s64 + -1808;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// bl 0x8211c770
	ctx.lr = 0x821346E0;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,26080(r9)
	PPC_STORE_U32(ctx.r9.u32 + 26080, ctx.r3.u32);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_821346F0:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// stw r29,26080(r11)
	PPC_STORE_U32(ctx.r11.u32 + 26080, ctx.r29.u32);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82134700"))) PPC_WEAK_FUNC(sub_82134700);
PPC_FUNC_IMPL(__imp__sub_82134700) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x82134708;
	__restfpr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// li r31,5
	ctx.r31.s64 = 5;
	// addi r11,r11,-25564
	ctx.r11.s64 = ctx.r11.s64 + -25564;
	// li r29,0
	ctx.r29.s64 = 0;
	// addi r30,r11,-4
	ctx.r30.s64 = ctx.r11.s64 + -4;
loc_82134720:
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// bl 0x8222f0f8
	ctx.lr = 0x82134728;
	sub_8222F0F8(ctx, base);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// stwu r29,4(r30)
	ea = 4 + ctx.r30.u32;
	PPC_STORE_U32(ea, ctx.r29.u32);
	ctx.r30.u32 = ea;
	// bne 0x82134720
	if (!ctx.cr0.eq) goto loc_82134720;
	// lis r30,-32182
	ctx.r30.s64 = -2109079552;
	// addi r31,r30,-25584
	ctx.r31.s64 = ctx.r30.s64 + -25584;
	// lwz r3,-25584(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + -25584);
	// bl 0x8222f0f8
	ctx.lr = 0x82134744;
	sub_8222F0F8(ctx, base);
	// stw r29,-25584(r30)
	PPC_STORE_U32(ctx.r30.u32 + -25584, ctx.r29.u32);
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// li r30,4
	ctx.r30.s64 = 4;
loc_82134750:
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82134768
	if (ctx.cr6.eq) goto loc_82134768;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82134768;
	sub_82080000(ctx, base);
loc_82134768:
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// stwu r29,4(r31)
	ea = 4 + ctx.r31.u32;
	PPC_STORE_U32(ea, ctx.r29.u32);
	ctx.r31.u32 = ea;
	// bne 0x82134750
	if (!ctx.cr0.eq) goto loc_82134750;
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// lwz r31,26080(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 26080);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x821347bc
	if (ctx.cr6.eq) goto loc_821347BC;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82134794
	if (ctx.cr6.eq) goto loc_82134794;
	// bl 0x8222f0f8
	ctx.lr = 0x82134794;
	sub_8222F0F8(ctx, base);
loc_82134794:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821347a4
	if (ctx.cr6.eq) goto loc_821347A4;
	// bl 0x8222f0f8
	ctx.lr = 0x821347A4;
	sub_8222F0F8(ctx, base);
loc_821347A4:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821347b4
	if (ctx.cr6.eq) goto loc_821347B4;
	// bl 0x8222f0f8
	ctx.lr = 0x821347B4;
	sub_8222F0F8(ctx, base);
loc_821347B4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82116248
	ctx.lr = 0x821347BC;
	sub_82116248(ctx, base);
loc_821347BC:
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,26080(r30)
	PPC_STORE_U32(ctx.r30.u32 + 26080, ctx.r29.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821347CC"))) PPC_WEAK_FUNC(sub_821347CC);
PPC_FUNC_IMPL(__imp__sub_821347CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821347D0"))) PPC_WEAK_FUNC(sub_821347D0);
PPC_FUNC_IMPL(__imp__sub_821347D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e43c
	ctx.lr = 0x821347D8;
	__restfpr_17(ctx, base);
	// stfd f30,-144(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -144, ctx.f30.u64);
	// stfd f31,-136(r1)
	PPC_STORE_U64(ctx.r1.u32 + -136, ctx.f31.u64);
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// lwz r11,36(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	// mr r17,r3
	ctx.r17.u64 = ctx.r3.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// cmplwi cr6,r11,4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4, ctx.xer);
	// mr r18,r11
	ctx.r18.u64 = ctx.r11.u64;
	// lwz r28,26084(r10)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + 26084);
	// blt cr6,0x82134808
	if (ctx.cr6.lt) goto loc_82134808;
	// li r18,4
	ctx.r18.s64 = 4;
loc_82134808:
	// mr r10,r18
	ctx.r10.u64 = ctx.r18.u64;
	// li r23,1
	ctx.r23.s64 = 1;
	// cmplwi cr6,r18,1
	ctx.cr6.compare<uint32_t>(ctx.r18.u32, 1, ctx.xer);
	// ble cr6,0x8213481c
	if (!ctx.cr6.gt) goto loc_8213481C;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
loc_8213481C:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lfs f0,13000(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13000);
	ctx.f0.f64 = double(temp.f32);
	// lis r9,-32182
	ctx.r9.s64 = -2109079552;
	// lfs f13,13004(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13004);
	ctx.f13.f64 = double(temp.f32);
	// addi r30,r11,27648
	ctx.r30.s64 = ctx.r11.s64 + 27648;
	// lfs f12,13008(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13008);
	ctx.f12.f64 = double(temp.f32);
	// addi r8,r9,-25564
	ctx.r8.s64 = ctx.r9.s64 + -25564;
	// lfs f11,13012(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13012);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r7,r10,2,0,29
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// fctidz f10,f0
	ctx.f10.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// lwz r22,92(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fctidz f9,f13
	ctx.f9.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// stfd f9,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.f9.u64);
	// lwz r6,52(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// fctidz f8,f12
	ctx.f8.s64 = (ctx.f12.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f12.f64);
	// fctidz f7,f11
	ctx.f7.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// stfd f8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f8.u64);
	// stfd f7,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f7.u64);
	// lwzx r29,r7,r8
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lfs f31,13016(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13016);
	ctx.f31.f64 = double(temp.f32);
	// lwz r21,116(r1)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lfs f30,13020(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13020);
	ctx.f30.f64 = double(temp.f32);
	// lwz r20,84(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r19,92(r1)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rotlwi r25,r6,0
	ctx.r25.u64 = rotl32(ctx.r6.u32, 0);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82134894
	if (ctx.cr6.eq) goto loc_82134894;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x8222f080
	ctx.lr = 0x82134894;
	sub_8222F080(ctx, base);
loc_82134894:
	// lwz r31,36(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// mr r26,r31
	ctx.r26.u64 = ctx.r31.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x821348b0
	if (ctx.cr6.eq) goto loc_821348B0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222f080
	ctx.lr = 0x821348AC;
	sub_8222F080(ctx, base);
	// lwz r31,36(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
loc_821348B0:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// addi r24,r11,28184
	ctx.r24.s64 = ctx.r11.s64 + 28184;
	// li r5,64
	ctx.r5.s64 = 64;
	// addi r4,r24,100
	ctx.r4.s64 = ctx.r24.s64 + 100;
	// bl 0x8233e4e0
	ctx.lr = 0x821348C8;
	sub_8233E4E0(ctx, base);
	// addi r4,r24,164
	ctx.r4.s64 = ctx.r24.s64 + 164;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// li r5,64
	ctx.r5.s64 = 64;
	// bl 0x8233e4e0
	ctx.lr = 0x821348D8;
	sub_8233E4E0(ctx, base);
	// cmplw cr6,r29,r31
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x821348f4
	if (ctx.cr6.eq) goto loc_821348F4;
	// stw r29,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r29.u32);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x821348F4;
	sub_8222CDF8(ctx, base);
loc_821348F4:
	// lwz r11,52(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// li r31,0
	ctx.r31.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82134918
	if (ctx.cr6.eq) goto loc_82134918;
	// stw r31,52(r30)
	PPC_STORE_U32(ctx.r30.u32 + 52, ctx.r31.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// bl 0x8222d188
	ctx.lr = 0x82134918;
	sub_8222D188(ctx, base);
loc_82134918:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x82134924;
	sub_82113BC0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82134930;
	sub_821112B0(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8213493C;
	sub_82111340(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,31
	ctx.r3.s64 = 31;
	// lfs f1,48(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210afd8
	ctx.lr = 0x82134958;
	sub_8210AFD8(ctx, base);
	// addi r4,r27,104
	ctx.r4.s64 = ctx.r27.s64 + 104;
	// addi r3,r27,40
	ctx.r3.s64 = ctx.r27.s64 + 40;
	// bl 0x821139a8
	ctx.lr = 0x82134964;
	sub_821139A8(ctx, base);
	// lwz r11,24(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82134a14
	if (ctx.cr6.eq) goto loc_82134A14;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r10,32(r27)
	PPC_STORE_U32(ctx.r27.u32 + 32, ctx.r10.u32);
	// stw r10,24(r27)
	PPC_STORE_U32(ctx.r27.u32 + 24, ctx.r10.u32);
	// bne cr6,0x82134988
	if (!ctx.cr6.eq) goto loc_82134988;
	// stw r31,28(r27)
	PPC_STORE_U32(ctx.r27.u32 + 28, ctx.r31.u32);
loc_82134988:
	// stw r31,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r31.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stb r31,8(r11)
	PPC_STORE_U8(ctx.r11.u32 + 8, ctx.r31.u8);
	// beq cr6,0x82134a14
	if (ctx.cr6.eq) goto loc_82134A14;
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// addi r29,r10,-27800
	ctx.r29.s64 = ctx.r10.s64 + -27800;
loc_821349A0:
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r31.u32);
	// stw r31,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r31.u32);
	// stw r31,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r31.u32);
	// stw r31,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r31.u32);
	// stb r23,8(r11)
	PPC_STORE_U8(ctx.r11.u32 + 8, ctx.r23.u8);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821349c8
	if (ctx.cr6.eq) goto loc_821349C8;
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r11.u32);
	// b 0x821349d0
	goto loc_821349D0;
loc_821349C8:
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
loc_821349D0:
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r11.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x8211e968
	ctx.lr = 0x821349E0;
	sub_8211E968(ctx, base);
	// lwz r11,24(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82134a14
	if (ctx.cr6.eq) goto loc_82134A14;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r10,32(r27)
	PPC_STORE_U32(ctx.r27.u32 + 32, ctx.r10.u32);
	// stw r10,24(r27)
	PPC_STORE_U32(ctx.r27.u32 + 24, ctx.r10.u32);
	// bne cr6,0x82134a04
	if (!ctx.cr6.eq) goto loc_82134A04;
	// stw r31,28(r27)
	PPC_STORE_U32(ctx.r27.u32 + 28, ctx.r31.u32);
loc_82134A04:
	// stw r31,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r31.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stb r31,8(r11)
	PPC_STORE_U8(ctx.r11.u32 + 8, ctx.r31.u8);
	// bne cr6,0x821349a0
	if (!ctx.cr6.eq) goto loc_821349A0;
loc_82134A14:
	// mr r4,r18
	ctx.r4.u64 = ctx.r18.u64;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x82135450
	ctx.lr = 0x82134A20;
	sub_82135450(ctx, base);
	// lwz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82134a40
	if (ctx.cr6.eq) goto loc_82134A40;
	// stw r26,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r26.u32);
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82134A40;
	sub_8222CDF8(ctx, base);
loc_82134A40:
	// lwz r11,52(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// cmplw cr6,r25,r11
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82134a68
	if (ctx.cr6.eq) goto loc_82134A68;
	// stw r25,52(r30)
	PPC_STORE_U32(ctx.r30.u32 + 52, ctx.r25.u32);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222d188
	ctx.lr = 0x82134A5C;
	sub_8222D188(ctx, base);
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x82134a68
	if (ctx.cr6.eq) goto loc_82134A68;
	// bl 0x82113790
	ctx.lr = 0x82134A68;
	sub_82113790(ctx, base);
loc_82134A68:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x82134A70;
	sub_8222F0F8(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x82134A78;
	sub_8222F0F8(ctx, base);
	// clrldi r11,r21,32
	ctx.r11.u64 = ctx.r21.u64 & 0xFFFFFFFF;
	// clrldi r10,r19,32
	ctx.r10.u64 = ctx.r19.u64 & 0xFFFFFFFF;
	// fmr f6,f30
	ctx.fpscr.disableFlushMode();
	ctx.f6.f64 = ctx.f30.f64;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// clrldi r9,r20,32
	ctx.r9.u64 = ctx.r20.u64 & 0xFFFFFFFF;
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// clrldi r8,r22,32
	ctx.r8.u64 = ctx.r22.u64 & 0xFFFFFFFF;
	// std r9,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r9.u64);
	// lfd f9,88(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f7,f9
	ctx.f7.f64 = double(ctx.f9.s64);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f11,112(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f10,f0
	ctx.f10.f64 = double(ctx.f0.s64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f12,f13
	ctx.f12.f64 = double(ctx.f13.s64);
	// fcfid f8,f11
	ctx.f8.f64 = double(ctx.f11.s64);
	// fmr f5,f31
	ctx.f5.f64 = ctx.f31.f64;
	// frsp f1,f12
	ctx.f1.f64 = double(float(ctx.f12.f64));
	// frsp f2,f10
	ctx.f2.f64 = double(float(ctx.f10.f64));
	// frsp f3,f7
	ctx.f3.f64 = double(float(ctx.f7.f64));
	// frsp f4,f8
	ctx.f4.f64 = double(float(ctx.f8.f64));
	// bl 0x8222a560
	ctx.lr = 0x82134AD8;
	sub_8222A560(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// bl 0x821139a8
	ctx.lr = 0x82134AE4;
	sub_821139A8(ctx, base);
	// lwz r11,532(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 532);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82134b28
	if (ctx.cr6.eq) goto loc_82134B28;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// li r9,3
	ctx.r9.s64 = 3;
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,10548(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 10548);
	// rlwimi r7,r9,5,25,27
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 5) & 0x70) | (ctx.r7.u64 & 0xFFFFFFFFFFFFFF8F);
	// stw r7,10548(r11)
	PPC_STORE_U32(ctx.r11.u32 + 10548, ctx.r7.u32);
	// ld r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// ori r5,r6,2048
	ctx.r5.u64 = ctx.r6.u64 | 2048;
	// oris r3,r5,2
	ctx.r3.u64 = ctx.r5.u64 | 131072;
	// std r5,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r5.u64);
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// std r3,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r3.u64);
	// stw r10,532(r24)
	PPC_STORE_U32(ctx.r24.u32 + 532, ctx.r10.u32);
loc_82134B28:
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82134B34;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82134B40;
	sub_821112B0(ctx, base);
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// lfd f30,-144(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -144);
	// lfd f31,-136(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -136);
	// b 0x8233e48c
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82134B50"))) PPC_WEAK_FUNC(sub_82134B50);
PPC_FUNC_IMPL(__imp__sub_82134B50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x82134B58;
	__restfpr_24(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lfs f0,144(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 144);
	ctx.f0.f64 = double(temp.f32);
	// li r11,12545
	ctx.r11.s64 = 12545;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// li r27,0
	ctx.r27.s64 = 0;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r11.u32);
	// li r24,0
	ctx.r24.s64 = 0;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r27.u32);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r24,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r24.u32);
	// lfs f13,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,36(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f12,96(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// ble cr6,0x82134bcc
	if (!ctx.cr6.gt) goto loc_82134BCC;
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r9,-32182
	ctx.r9.s64 = -2109079552;
	// lfs f13,140(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// li r11,1
	ctx.r11.s64 = 1;
	// addi r8,r9,-25584
	ctx.r8.s64 = ctx.r9.s64 + -25584;
	// fmuls f11,f13,f0
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// rlwinm r7,r10,2,0,29
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stfs f11,96(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lwzx r27,r7,r8
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r27.u32);
loc_82134BCC:
	// fcmpu cr6,f0,f12
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f12.f64);
	// bge cr6,0x82134c60
	if (!ctx.cr6.lt) goto loc_82134C60;
	// fsubs f0,f12,f0
	ctx.f0.f64 = static_cast<float>(ctx.f12.f64 - ctx.f0.f64);
	// lwz r10,36(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	// rlwinm r31,r11,2,0,29
	ctx.r31.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f13,140(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// rlwinm r8,r10,0,23,23
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// stfsx f12,r31,r9
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + ctx.r9.u32, temp.u32);
	// bne cr6,0x82134c08
	if (!ctx.cr6.eq) goto loc_82134C08;
	// addi r11,r1,104
	ctx.r11.s64 = ctx.r1.s64 + 104;
	// li r10,4353
	ctx.r10.s64 = 4353;
	// stwx r10,r31,r11
	PPC_STORE_U32(ctx.r31.u32 + ctx.r11.u32, ctx.r10.u32);
loc_82134C08:
	// lwz r11,120(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 120);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82134c60
	if (ctx.cr6.eq) goto loc_82134C60;
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82134c28
	if (ctx.cr6.eq) goto loc_82134C28;
	// bl 0x820b91d0
	ctx.lr = 0x82134C24;
	sub_820B91D0(ctx, base);
	// b 0x82134c44
	goto loc_82134C44;
loc_82134C28:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82134c3c
	if (ctx.cr6.eq) goto loc_82134C3C;
	// lwz r3,88(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x82134c44
	goto loc_82134C44;
loc_82134C3C:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x82134C44;
	sub_820B90A0(ctx, base);
loc_82134C44:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82134c60
	if (ctx.cr6.eq) goto loc_82134C60;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// stwx r11,r31,r10
	PPC_STORE_U32(ctx.r31.u32 + ctx.r10.u32, ctx.r11.u32);
	// lwz r24,84(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r27,80(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82134C60:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82134f98
	if (ctx.cr6.eq) goto loc_82134F98;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,3
	ctx.r6.s64 = 3;
	// rldicr r7,r7,50,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 50) & 0xFFFFFFFFFFFFFFFF;
	// addi r5,r29,40
	ctx.r5.s64 = ctx.r29.s64 + 40;
	// lwz r31,26084(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26084);
	// li r4,53
	ctx.r4.s64 = 53;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238048
	ctx.lr = 0x82134C8C;
	sub_82238048(ctx, base);
	// lwz r8,88(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 88);
	// lwz r6,96(r29)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r29.u32 + 96);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lwz r5,100(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 100);
	// li r9,1
	ctx.r9.s64 = 1;
	// lfs f0,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// li r12,1
	ctx.r12.s64 = 1;
	// rldicr r25,r9,49,63
	ctx.r25.u64 = rotl64(ctx.r9.u64, 49) & 0xFFFFFFFFFFFFFFFF;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// rldicr r12,r12,36,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// stw r6,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r6.u32);
	// addi r30,r11,28184
	ctx.r30.s64 = ctx.r11.s64 + 28184;
	// stw r5,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r5.u32);
	// addi r28,r29,88
	ctx.r28.s64 = ctx.r29.s64 + 88;
	// li r9,3
	ctx.r9.s64 = 3;
	// lwz r7,92(r29)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r29.u32 + 92);
	// stw r7,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r7.u32);
	// lfs f13,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f0,f10,f0
	ctx.f0.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// stfs f11,2816(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2816, temp.u32);
	// stfs f13,2820(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2820, temp.u32);
	// stfs f12,2824(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2824, temp.u32);
	// stfs f0,2828(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2828, temp.u32);
	// ld r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r3,r4,r25
	ctx.r3.u64 = ctx.r4.u64 | ctx.r25.u64;
	// std r3,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r3.u64);
	// lfs f9,104(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 104);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,7744(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7744, temp.u32);
	// lfs f8,108(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 108);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,7748(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7748, temp.u32);
	// lfs f7,112(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 112);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,7752(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7752, temp.u32);
	// lfs f6,116(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 116);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,7756(r31)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7756, temp.u32);
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// stfs f0,92(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lwz r11,1972(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1972);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82134d68
	if (ctx.cr6.eq) goto loc_82134D68;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,11,19,21
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 11) & 0x1C00) | (ctx.r7.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1972(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1972, ctx.r10.u32);
loc_82134D68:
	// lwz r11,1988(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1988);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82134d9c
	if (ctx.cr6.eq) goto loc_82134D9C;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,14,16,18
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 14) & 0xE000) | (ctx.r7.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1988(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1988, ctx.r10.u32);
loc_82134D9C:
	// lwz r11,2020(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2020);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82134dd0
	if (ctx.cr6.eq) goto loc_82134DD0;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1172(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// rlwinm r7,r8,0,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFC;
	// stw r7,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2020(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2020, ctx.r10.u32);
loc_82134DD0:
	// lwz r11,2052(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82134df4
	if (ctx.cr6.eq) goto loc_82134DF4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82134DEC;
	sub_8222C0A0(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r11.u32);
loc_82134DF4:
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82134e18
	if (ctx.cr6.eq) goto loc_82134E18;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82134E10;
	sub_8222C248(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r11.u32);
loc_82134E18:
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x82134E24;
	sub_82111400(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,104(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// bl 0x82113bc0
	ctx.lr = 0x82134E30;
	sub_82113BC0(ctx, base);
	// lis r4,14417
	ctx.r4.s64 = 944832512;
	// li r3,208
	ctx.r3.s64 = 208;
	// ori r4,r4,46871
	ctx.r4.u64 = ctx.r4.u64 | 46871;
	// bl 0x82111340
	ctx.lr = 0x82134E40;
	sub_82111340(ctx, base);
	// lis r4,16416
	ctx.r4.s64 = 1075838976;
	// li r3,204
	ctx.r3.s64 = 204;
	// bl 0x82111340
	ctx.lr = 0x82134E4C;
	sub_82111340(ctx, base);
	// lwz r11,132(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 132);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82134e64
	if (!ctx.cr6.gt) goto loc_82134E64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82135238
	ctx.lr = 0x82134E64;
	sub_82135238(ctx, base);
loc_82134E64:
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// addi r27,r29,24
	ctx.r27.s64 = ctx.r29.s64 + 24;
	// addi r26,r11,-27800
	ctx.r26.s64 = ctx.r11.s64 + -27800;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8211e968
	ctx.lr = 0x82134E7C;
	sub_8211E968(ctx, base);
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82134f18
	if (ctx.cr6.eq) goto loc_82134F18;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lwz r9,4(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// lfs f0,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// lwz r8,8(r28)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// lwz r7,12(r28)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r11.u32);
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r8,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r8.u32);
	// stw r7,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r7.u32);
	// lfs f12,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,2816(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2816, temp.u32);
	// lfs f10,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f0
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// stfs f11,2820(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2820, temp.u32);
	// stfs f12,2824(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2824, temp.u32);
	// stfs f9,2828(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2828, temp.u32);
	// ld r6,0(r31)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r5,r6,r25
	ctx.r5.u64 = ctx.r6.u64 | ctx.r25.u64;
	// std r5,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r5.u64);
	// bl 0x82111400
	ctx.lr = 0x82134EE8;
	sub_82111400(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,108(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// bl 0x82113bc0
	ctx.lr = 0x82134EF4;
	sub_82113BC0(ctx, base);
	// lwz r4,132(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 132);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// ble cr6,0x82134f0c
	if (!ctx.cr6.gt) goto loc_82134F0C;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82135238
	ctx.lr = 0x82134F0C;
	sub_82135238(ctx, base);
loc_82134F0C:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x8211e968
	ctx.lr = 0x82134F18;
	sub_8211E968(ctx, base);
loc_82134F18:
	// lwz r11,1972(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1972);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82134f4c
	if (ctx.cr6.eq) goto loc_82134F4C;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwinm r7,r8,0,22,18
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFE3FF;
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1972(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1972, ctx.r10.u32);
loc_82134F4C:
	// lwz r11,1988(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1988);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82134f80
	if (ctx.cr6.eq) goto loc_82134F80;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwinm r7,r8,0,19,15
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFF1FFF;
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1988(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1988, ctx.r10.u32);
loc_82134F80:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,208
	ctx.r3.s64 = 208;
	// bl 0x82111340
	ctx.lr = 0x82134F8C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,204
	ctx.r3.s64 = 204;
	// bl 0x82111340
	ctx.lr = 0x82134F98;
	sub_82111340(ctx, base);
loc_82134F98:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82134FA0"))) PPC_WEAK_FUNC(sub_82134FA0);
PPC_FUNC_IMPL(__imp__sub_82134FA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82134FA8;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// lwz r11,120(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 120);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// li r28,12545
	ctx.r28.s64 = 12545;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r29,26084(r10)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 26084);
	// bne cr6,0x82134fe0
	if (!ctx.cr6.eq) goto loc_82134FE0;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// addi r9,r10,-25584
	ctx.r9.s64 = ctx.r10.s64 + -25584;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r8,r9
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r9.u32);
	// b 0x82135020
	goto loc_82135020;
loc_82134FE0:
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82134ff4
	if (ctx.cr6.eq) goto loc_82134FF4;
	// bl 0x820b91d0
	ctx.lr = 0x82134FF0;
	sub_820B91D0(ctx, base);
	// b 0x82135010
	goto loc_82135010;
loc_82134FF4:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82135008
	if (ctx.cr6.eq) goto loc_82135008;
	// lwz r3,88(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x82135010
	goto loc_82135010;
loc_82135008:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x82135010;
	sub_820B90A0(ctx, base);
loc_82135010:
	// lwz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// lwz r4,4(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwinm r10,r11,5,18,18
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0x2000;
	// ori r28,r10,4353
	ctx.r28.u64 = ctx.r10.u64 | 4353;
loc_82135020:
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x8213522c
	if (ctx.cr6.eq) goto loc_8213522C;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x82135030;
	sub_82111400(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r9,3
	ctx.r9.s64 = 3;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82135070
	if (ctx.cr6.eq) goto loc_82135070;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,11,19,21
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 11) & 0x1C00) | (ctx.r7.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82135070:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x821350a4
	if (ctx.cr6.eq) goto loc_821350A4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,14,16,18
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 14) & 0xE000) | (ctx.r7.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_821350A4:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821350c8
	if (ctx.cr6.eq) goto loc_821350C8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x821350C0;
	sub_8222C248(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r11.u32);
loc_821350C8:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821350ec
	if (ctx.cr6.eq) goto loc_821350EC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x821350E4;
	sub_8222C0A0(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
loc_821350EC:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82135124
	if (ctx.cr6.eq) goto loc_82135124;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r9,1
	ctx.r9.s64 = 1;
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1164(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r7,r9,24,7,8
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 24) & 0x1800000) | (ctx.r7.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r7,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r10.u32);
loc_82135124:
	// lwz r11,2020(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2020);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82135158
	if (ctx.cr6.eq) goto loc_82135158;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1172(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// rlwinm r7,r8,0,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFC;
	// stw r7,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2020, ctx.r10.u32);
loc_82135158:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82113bc0
	ctx.lr = 0x82135164;
	sub_82113BC0(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,3
	ctx.r6.s64 = 3;
	// rldicr r7,r7,50,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 50) & 0xFFFFFFFFFFFFFFFF;
	// addi r5,r30,40
	ctx.r5.s64 = ctx.r30.s64 + 40;
	// li r4,53
	ctx.r4.s64 = 53;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82238048
	ctx.lr = 0x82135180;
	sub_82238048(ctx, base);
	// li r12,1
	ctx.r12.s64 = 1;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// rldicr r12,r12,49,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 49) & 0xFFFFFFFFFFFFFFFF;
	// addi r4,r30,24
	ctx.r4.s64 = ctx.r30.s64 + 24;
	// addi r3,r11,-27800
	ctx.r3.s64 = ctx.r11.s64 + -27800;
	// lfs f0,88(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,2816(r29)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r29.u32 + 2816, temp.u32);
	// lfs f13,92(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,2820(r29)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r29.u32 + 2820, temp.u32);
	// lfs f12,96(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,2824(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r29.u32 + 2824, temp.u32);
	// lfs f11,100(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 100);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,2828(r29)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r29.u32 + 2828, temp.u32);
	// ld r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r29.u32 + 0);
	// or r9,r10,r12
	ctx.r9.u64 = ctx.r10.u64 | ctx.r12.u64;
	// std r9,0(r29)
	PPC_STORE_U64(ctx.r29.u32 + 0, ctx.r9.u64);
	// bl 0x8211e968
	ctx.lr = 0x821351C4;
	sub_8211E968(ctx, base);
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821351f8
	if (ctx.cr6.eq) goto loc_821351F8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwinm r7,r8,0,22,18
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFE3FF;
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_821351F8:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213522c
	if (ctx.cr6.eq) goto loc_8213522C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwinm r7,r8,0,19,15
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFF1FFF;
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8213522C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82135234"))) PPC_WEAK_FUNC(sub_82135234);
PPC_FUNC_IMPL(__imp__sub_82135234) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82135238"))) PPC_WEAK_FUNC(sub_82135238);
PPC_FUNC_IMPL(__imp__sub_82135238) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82135240;
	__restfpr_28(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r30.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r28,26084(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26084);
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r30.u32);
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r30.u32);
	// bl 0x822365d8
	ctx.lr = 0x82135274;
	sub_822365D8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82135280;
	sub_821112B0(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x8213528C;
	sub_82111340(ctx, base);
	// lwz r11,132(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 132);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r3,r10,2,0,29
	ctx.r3.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8210b178
	ctx.lr = 0x821352A8;
	sub_8210B178(ctx, base);
	// lwz r11,132(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 132);
	// lwz r4,128(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 128);
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r5,r9,2,0,29
	ctx.r5.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8233e4e0
	ctx.lr = 0x821352C0;
	sub_8233E4E0(ctx, base);
	// lwz r11,132(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 132);
	// lis r7,-32183
	ctx.r7.s64 = -2109145088;
	// rlwinm r8,r11,3,0,28
	ctx.r8.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r31,r7,27648
	ctx.r31.s64 = ctx.r7.s64 + 27648;
	// add r6,r11,r8
	ctx.r6.u64 = ctx.r11.u64 + ctx.r8.u64;
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// rlwinm r11,r6,2,0,29
	ctx.r11.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r31,200
	ctx.r4.s64 = ctx.r31.s64 + 200;
	// lwz r9,272(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 272);
	// li r5,0
	ctx.r5.s64 = 0;
	// stb r30,264(r31)
	PPC_STORE_U8(ctx.r31.u32 + 264, ctx.r30.u8);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// addi r3,r11,31
	ctx.r3.s64 = ctx.r11.s64 + 31;
	// rlwinm r11,r3,0,0,26
	ctx.r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFE0;
	// stw r11,272(r31)
	PPC_STORE_U32(ctx.r31.u32 + 272, ctx.r11.u32);
	// lwz r10,268(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 268);
	// rlwinm r11,r10,2,0,29
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r4
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	// lwz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r4,r10,0,0,29
	ctx.r4.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// bl 0x8222ee68
	ctx.lr = 0x82135314;
	sub_8222EE68(ctx, base);
	// lwz r11,132(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 132);
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r3,r9,1,0,30
	ctx.r3.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// bl 0x8210b4d0
	ctx.lr = 0x82135330;
	sub_8210B4D0(ctx, base);
	// lwz r11,132(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 132);
	// lwz r4,124(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 124);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r8,r11,r10
	ctx.r8.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r5,r8,1,0,30
	ctx.r5.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 1) & 0xFFFFFFFE;
	// bl 0x8233e4e0
	ctx.lr = 0x82135348;
	sub_8233E4E0(ctx, base);
	// lwz r11,132(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 132);
	// lwz r10,348(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 348);
	// addi r4,r31,280
	ctx.r4.s64 = ctx.r31.s64 + 280;
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// stb r30,344(r31)
	PPC_STORE_U8(ctx.r31.u32 + 344, ctx.r30.u8);
	// rlwinm r7,r10,2,0,29
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r11,r9
	ctx.r6.u64 = ctx.r11.u64 + ctx.r9.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// rlwinm r10,r6,1,0,30
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,352(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 352);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r3,r11,31
	ctx.r3.s64 = ctx.r11.s64 + 31;
	// rlwinm r11,r3,0,0,26
	ctx.r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFE0;
	// stw r11,352(r31)
	PPC_STORE_U32(ctx.r31.u32 + 352, ctx.r11.u32);
	// lwzx r3,r7,r4
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	// lwz r4,24(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// bl 0x8222ee68
	ctx.lr = 0x8213538C;
	sub_8222EE68(ctx, base);
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r11,26080(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26080);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r28)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r28.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r28)
	PPC_STORE_U64(ctx.r28.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x821353B4;
	sub_82238728(ctx, base);
	// lwz r11,26080(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26080);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x821353C4;
	sub_82238380(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r7,12
	ctx.r7.s64 = 12;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cc48
	ctx.lr = 0x821353E0;
	sub_8222CC48(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// bl 0x8222cd68
	ctx.lr = 0x821353EC;
	sub_8222CD68(ctx, base);
	// lwz r11,132(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 132);
	// lwz r7,92(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r6,r7,31,1,31
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 31) & 0x7FFFFFFF;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// add r7,r11,r10
	ctx.r7.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x8222e3e0
	ctx.lr = 0x82135410;
	sub_8222E3E0(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cc48
	ctx.lr = 0x8213542C;
	sub_8222CC48(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8222cd68
	ctx.lr = 0x82135438;
	sub_8222CD68(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82135444;
	sub_821112B0(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213544C"))) PPC_WEAK_FUNC(sub_8213544C);
PPC_FUNC_IMPL(__imp__sub_8213544C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82135450"))) PPC_WEAK_FUNC(sub_82135450);
PPC_FUNC_IMPL(__imp__sub_82135450) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82135458;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// cmplwi cr6,r4,2
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 2, ctx.xer);
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// bge cr6,0x821354e0
	if (!ctx.cr6.lt) goto loc_821354E0;
	// addi r9,r11,-25584
	ctx.r9.s64 = ctx.r11.s64 + -25584;
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r9
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// clrlwi r30,r11,26
	ctx.r30.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r30,50
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 50, ctx.xer);
	// bne cr6,0x82135498
	if (!ctx.cr6.eq) goto loc_82135498;
	// li r10,3
	ctx.r10.s64 = 3;
	// rlwimi r11,r10,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r10.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_82135498:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// addi r6,r11,27648
	ctx.r6.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,31376
	ctx.r5.s64 = ctx.r10.s64 + 31376;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,188(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 188);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// lfs f1,48(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82227e30
	ctx.lr = 0x821354CC;
	sub_82227E30(ctx, base);
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// rlwimi r4,r30,0,26,31
	ctx.r4.u64 = (rotl32(ctx.r30.u32, 0) & 0x3F) | (ctx.r4.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r4,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r4.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_821354E0:
	// addi r27,r11,-25584
	ctx.r27.s64 = ctx.r11.s64 + -25584;
	// li r28,1
	ctx.r28.s64 = 1;
	// lwz r31,4(r27)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// clrlwi r30,r11,26
	ctx.r30.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r30,50
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 50, ctx.xer);
	// bne cr6,0x82135508
	if (!ctx.cr6.eq) goto loc_82135508;
	// li r10,3
	ctx.r10.s64 = 3;
	// rlwimi r11,r10,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r10.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_82135508:
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r5,r10,31376
	ctx.r5.s64 = ctx.r10.s64 + 31376;
	// addi r29,r11,27648
	ctx.r29.s64 = ctx.r11.s64 + 27648;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lfs f1,48(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82227e30
	ctx.lr = 0x8213553C;
	sub_82227E30(ctx, base);
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// rlwimi r30,r4,0,0,25
	ctx.r30.u64 = (rotl32(ctx.r4.u32, 0) & 0xFFFFFFC0) | (ctx.r30.u64 & 0xFFFFFFFF0000003F);
	// stw r30,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r30.u32);
	// lwz r3,52(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 52);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82135578
	if (ctx.cr6.eq) goto loc_82135578;
	// bl 0x8222f080
	ctx.lr = 0x82135558;
	sub_8222F080(ctx, base);
	// lwz r3,52(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 52);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82135578
	if (ctx.cr6.eq) goto loc_82135578;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,52(r29)
	PPC_STORE_U32(ctx.r29.u32 + 52, ctx.r11.u32);
	// bl 0x8222d188
	ctx.lr = 0x82135578;
	sub_8222D188(ctx, base);
loc_82135578:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x82135584;
	sub_82113BC0(ctx, base);
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// li r31,0
	ctx.r31.s64 = 0;
	// addi r30,r11,-25564
	ctx.r30.s64 = ctx.r11.s64 + -25564;
loc_82135590:
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r11,r30,4
	ctx.r11.s64 = ctx.r30.s64 + 4;
	// addi r10,r27,4
	ctx.r10.s64 = ctx.r27.s64 + 4;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// lwzx r3,r31,r27
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r27.u32);
	// lwzx r5,r31,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r11.u32);
	// lwzx r4,r31,r10
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r10.u32);
	// bl 0x8212e6d0
	ctx.lr = 0x821355B4;
	sub_8212E6D0(ctx, base);
	// cmplw cr6,r28,r26
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r26.u32, ctx.xer);
	// bne cr6,0x82135590
	if (!ctx.cr6.eq) goto loc_82135590;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821355C4"))) PPC_WEAK_FUNC(sub_821355C4);
PPC_FUNC_IMPL(__imp__sub_821355C4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821355C8"))) PPC_WEAK_FUNC(sub_821355C8);
PPC_FUNC_IMPL(__imp__sub_821355C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e454
	ctx.lr = 0x821355D0;
	__restfpr_23(ctx, base);
	// stfd f30,-96(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -96, ctx.f30.u64);
	// stfd f31,-88(r1)
	PPC_STORE_U64(ctx.r1.u32 + -88, ctx.f31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r27,0
	ctx.r27.s64 = 0;
	// lwz r30,0(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// lwz r4,20(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r27.u32);
	// lis r5,6184
	ctx.r5.s64 = 405274624;
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r27.u32);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// stw r27,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r27.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r27.u32);
	// ori r5,r5,390
	ctx.r5.u64 = ctx.r5.u64 | 390;
	// lwz r3,16(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// bl 0x82237798
	ctx.lr = 0x82135614;
	sub_82237798(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// addi r26,r11,27648
	ctx.r26.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 36);
	// mr r24,r11
	ctx.r24.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213563c
	if (ctx.cr6.eq) goto loc_8213563C;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x8222f080
	ctx.lr = 0x82135638;
	sub_8222F080(ctx, base);
	// lwz r11,36(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 36);
loc_8213563C:
	// cmplw cr6,r23,r11
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82135658
	if (ctx.cr6.eq) goto loc_82135658;
	// stw r23,36(r26)
	PPC_STORE_U32(ctx.r26.u32 + 36, ctx.r23.u32);
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82135658;
	sub_8222CDF8(ctx, base);
loc_82135658:
	// lwz r11,52(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 52);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82135678
	if (ctx.cr6.eq) goto loc_82135678;
	// stw r27,52(r26)
	PPC_STORE_U32(ctx.r26.u32 + 52, ctx.r27.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 188);
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// bl 0x8222d188
	ctx.lr = 0x82135678;
	sub_8222D188(ctx, base);
loc_82135678:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,172
	ctx.r3.s64 = 172;
	// bl 0x82111340
	ctx.lr = 0x82135684;
	sub_82111340(ctx, base);
	// li r4,8
	ctx.r4.s64 = 8;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82135690;
	sub_82111340(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r29,r11,31376
	ctx.r29.s64 = ctx.r11.s64 + 31376;
	// lis r4,-256
	ctx.r4.s64 = -16777216;
	// li r3,31
	ctx.r3.s64 = 31;
	// lfs f31,48(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x8210afd8
	ctx.lr = 0x821356B0;
	sub_8210AFD8(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x821356BC;
	sub_82111340(ctx, base);
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r11,26088(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26088);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r30.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r30)
	PPC_STORE_U64(ctx.r30.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x821356E4;
	sub_82238728(ctx, base);
	// lwz r11,26088(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 26088);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x821356F4;
	sub_82238380(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82135700;
	sub_821112B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r25,1
	ctx.r25.s64 = 1;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82135730
	if (ctx.cr6.eq) goto loc_82135730;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82135728;
	sub_8222C0A0(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r25,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r25.u32);
loc_82135730:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82135764
	if (ctx.cr6.eq) goto loc_82135764;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r25,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r25.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82135764:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82135798
	if (ctx.cr6.eq) goto loc_82135798;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r25,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r25.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_82135798:
	// lwz r11,16(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// lfs f30,36(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// lwz r10,20(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 20);
	// stfs f30,96(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f31,100(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r27.u32);
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r27.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x821357C8;
	sub_8222CBC8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x821357D4;
	sub_82113BC0(ctx, base);
	// lis r9,-32179
	ctx.r9.s64 = -2108882944;
	// lis r8,0
	ctx.r8.s64 = 0;
	// lfs f0,32(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 32);
	ctx.f0.f64 = double(temp.f32);
	// addi r7,r9,20000
	ctx.r7.s64 = ctx.r9.s64 + 20000;
	// stfs f0,112(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// ori r4,r8,65516
	ctx.r4.u64 = ctx.r8.u64 | 65516;
	// stfs f0,144(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lis r3,0
	ctx.r3.s64 = 0;
	// stfs f0,148(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// li r6,16
	ctx.r6.s64 = 16;
	// stfs f30,116(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// ori r10,r3,65512
	ctx.r10.u64 = ctx.r3.u64 | 65512;
	// stfs f31,120(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// li r5,3
	ctx.r5.s64 = 3;
	// stfs f31,124(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stfs f30,128(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f30,132(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stfs f31,140(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// stfs f31,152(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lwzx r9,r7,r4
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	// li r4,8
	ctx.r4.s64 = 8;
	// lwz r8,16(r28)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// lwzx r9,r7,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r10.u32);
	// mr r7,r8
	ctx.r7.u64 = ctx.r8.u64;
	// lwz r8,20(r28)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + 20);
	// fcfid f13,f0
	ctx.f13.f64 = double(ctx.f0.s64);
	// std r7,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r7.u64);
	// lfd f11,80(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lfd f10,80(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f9,80(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f8,f9
	ctx.f8.f64 = double(ctx.f9.s64);
	// fcfid f7,f10
	ctx.f7.f64 = double(ctx.f10.s64);
	// fcfid f6,f11
	ctx.f6.f64 = double(ctx.f11.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// frsp f5,f8
	ctx.f5.f64 = double(float(ctx.f8.f64));
	// frsp f4,f7
	ctx.f4.f64 = double(float(ctx.f7.f64));
	// frsp f3,f6
	ctx.f3.f64 = double(float(ctx.f6.f64));
	// fdivs f2,f5,f12
	ctx.f2.f64 = double(float(ctx.f5.f64 / ctx.f12.f64));
	// stfs f2,156(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// fdivs f1,f3,f4
	ctx.f1.f64 = double(float(ctx.f3.f64 / ctx.f4.f64));
	// stfs f1,136(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// bl 0x8222d600
	ctx.lr = 0x82135890;
	sub_8222D600(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821358ac
	if (ctx.cr6.eq) goto loc_821358AC;
	// li r5,48
	ctx.r5.s64 = 48;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x8233e4e0
	ctx.lr = 0x821358A4;
	sub_8233E4E0(ctx, base);
	// lwz r11,13828(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 13828);
	// stw r11,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r11.u32);
loc_821358AC:
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r5,24(r28)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,256
	ctx.r3.s64 = 256;
	// bl 0x8210af50
	ctx.lr = 0x821358CC;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 36);
	// cmplw cr6,r24,r11
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x821358ec
	if (ctx.cr6.eq) goto loc_821358EC;
	// stw r24,36(r26)
	PPC_STORE_U32(ctx.r26.u32 + 36, ctx.r24.u32);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x821358EC;
	sub_8222CDF8(ctx, base);
loc_821358EC:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x821358F4;
	sub_8222F0F8(ctx, base);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x821358FC;
	sub_8222F0F8(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82135908;
	sub_821112B0(ctx, base);
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lfd f30,-96(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// lfd f31,-88(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82135918"))) PPC_WEAK_FUNC(sub_82135918);
PPC_FUNC_IMPL(__imp__sub_82135918) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,44
	ctx.r11.s64 = 2883584;
	// li r10,5
	ctx.r10.s64 = 5;
	// ori r11,r11,9125
	ctx.r11.u64 = ctx.r11.u64 | 9125;
	// li r30,0
	ctx.r30.s64 = 0;
	// stb r10,101(r1)
	PPC_STORE_U8(ctx.r1.u32 + 101, ctx.r10.u8);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// li r4,3
	ctx.r4.s64 = 3;
	// stb r30,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, ctx.r30.u8);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// bl 0x821160a8
	ctx.lr = 0x82135958;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8213595C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82135988
	if (ctx.cr6.eq) goto loc_82135988;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,-1128
	ctx.r6.s64 = ctx.r11.s64 + -1128;
	// addi r5,r10,344
	ctx.r5.s64 = ctx.r10.s64 + 344;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8213597C;
	sub_8211C770(ctx, base);
	// lis r9,-32182
	ctx.r9.s64 = -2109079552;
	// stw r3,-25536(r9)
	PPC_STORE_U32(ctx.r9.u32 + -25536, ctx.r3.u32);
	// b 0x82135994
	goto loc_82135994;
loc_82135988:
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,-25536(r10)
	PPC_STORE_U32(ctx.r10.u32 + -25536, ctx.r30.u32);
loc_82135994:
	// lis r11,42
	ctx.r11.s64 = 2752512;
	// stb r30,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, ctx.r30.u8);
	// li r4,2
	ctx.r4.s64 = 2;
	// ori r31,r11,9145
	ctx.r31.u64 = ctx.r11.u64 | 9145;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// bl 0x821160a8
	ctx.lr = 0x821359B0;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x821359B4;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821359e0
	if (ctx.cr6.eq) goto loc_821359E0;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,736
	ctx.r6.s64 = ctx.r11.s64 + 736;
	// addi r5,r10,2136
	ctx.r5.s64 = ctx.r10.s64 + 2136;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x821359D4;
	sub_8211C770(ctx, base);
	// lis r9,-32182
	ctx.r9.s64 = -2109079552;
	// stw r3,-25540(r9)
	PPC_STORE_U32(ctx.r9.u32 + -25540, ctx.r3.u32);
	// b 0x821359ec
	goto loc_821359EC;
loc_821359E0:
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,-25540(r10)
	PPC_STORE_U32(ctx.r10.u32 + -25540, ctx.r30.u32);
loc_821359EC:
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// li r4,2
	ctx.r4.s64 = 2;
	// stb r30,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, ctx.r30.u8);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821160a8
	ctx.lr = 0x82135A00;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x82135A04;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82135a30
	if (ctx.cr6.eq) goto loc_82135A30;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,2800
	ctx.r6.s64 = ctx.r11.s64 + 2800;
	// addi r5,r10,3072
	ctx.r5.s64 = ctx.r10.s64 + 3072;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x82135A24;
	sub_8211C770(ctx, base);
	// lis r9,-32182
	ctx.r9.s64 = -2109079552;
	// stw r3,-25544(r9)
	PPC_STORE_U32(ctx.r9.u32 + -25544, ctx.r3.u32);
	// b 0x82135a38
	goto loc_82135A38;
loc_82135A30:
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// stw r30,-25544(r11)
	PPC_STORE_U32(ctx.r11.u32 + -25544, ctx.r30.u32);
loc_82135A38:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82135A50"))) PPC_WEAK_FUNC(sub_82135A50);
PPC_FUNC_IMPL(__imp__sub_82135A50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x82135A58;
	__restfpr_25(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lbz r25,120(r4)
	ctx.r25.u64 = PPC_LOAD_U8(ctx.r4.u32 + 120);
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r3,r10,-27800
	ctx.r3.s64 = ctx.r10.s64 + -27800;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r4,124(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 124);
	// lwz r31,26092(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26092);
	// bl 0x8211fa50
	ctx.lr = 0x82135A80;
	sub_8211FA50(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r26,0
	ctx.r26.s64 = 0;
	// addi r28,r11,27648
	ctx.r28.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82135ab0
	if (ctx.cr6.eq) goto loc_82135AB0;
	// stw r26,36(r28)
	PPC_STORE_U32(ctx.r28.u32 + 36, ctx.r26.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 188);
	// mr r11,r26
	ctx.r11.u64 = ctx.r26.u64;
	// bl 0x8222cdf8
	ctx.lr = 0x82135AB0;
	sub_8222CDF8(ctx, base);
loc_82135AB0:
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r11,52(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 52);
	// addi r27,r10,2028
	ctx.r27.s64 = ctx.r10.s64 + 2028;
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82135ae0
	if (ctx.cr6.eq) goto loc_82135AE0;
	// stw r27,52(r28)
	PPC_STORE_U32(ctx.r28.u32 + 52, ctx.r27.u32);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,188(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 188);
	// bl 0x8222d188
	ctx.lr = 0x82135AD4;
	sub_8222D188(ctx, base);
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82135ae0
	if (ctx.cr6.eq) goto loc_82135AE0;
	// bl 0x82113790
	ctx.lr = 0x82135AE0;
	sub_82113790(ctx, base);
loc_82135AE0:
	// addi r11,r29,4
	ctx.r11.s64 = ctx.r29.s64 + 4;
	// lfs f0,13000(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13000);
	ctx.f0.f64 = double(temp.f32);
	// li r10,4
	ctx.r10.s64 = 4;
	// fctidz f13,f0
	ctx.f13.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// li r9,8
	ctx.r9.s64 = 8;
	// li r8,12
	ctx.r8.s64 = 12;
	// li r4,0
	ctx.r4.s64 = 0;
	// stfiwx f13,0,r11
	PPC_STORE_U32(ctx.r11.u32, ctx.f13.u32);
	// li r3,212
	ctx.r3.s64 = 212;
	// lfs f12,13004(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13004);
	ctx.f12.f64 = double(temp.f32);
	// fctidz f11,f12
	ctx.f11.s64 = (ctx.f12.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f12.f64);
	// stfiwx f11,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.f11.u32);
	// lfs f10,13008(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13008);
	ctx.f10.f64 = double(temp.f32);
	// fctidz f9,f10
	ctx.f9.s64 = (ctx.f10.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f10.f64);
	// stfiwx f9,r11,r9
	PPC_STORE_U32(ctx.r11.u32 + ctx.r9.u32, ctx.f9.u32);
	// lfs f8,13012(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13012);
	ctx.f8.f64 = double(temp.f32);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfiwx f7,r11,r8
	PPC_STORE_U32(ctx.r11.u32 + ctx.r8.u32, ctx.f7.u32);
	// lfs f6,13016(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13016);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,20(r29)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + 20, temp.u32);
	// lfs f5,13020(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13020);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,24(r29)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + 24, temp.u32);
	// bl 0x82111340
	ctx.lr = 0x82135B3C;
	sub_82111340(ctx, base);
	// lis r7,-32250
	ctx.r7.s64 = -2113536000;
	// li r11,1024
	ctx.r11.s64 = 1024;
	// stw r26,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r26.u32);
	// addi r6,r7,31376
	ctx.r6.s64 = ctx.r7.s64 + 31376;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lfs f0,48(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,36(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x82135B74;
	sub_8222CBC8(ctx, base);
	// lwz r4,128(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 128);
	// lwz r3,124(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 124);
	// bl 0x82136708
	ctx.lr = 0x82135B80;
	sub_82136708(ctx, base);
	// li r4,3
	ctx.r4.s64 = 3;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x82135B8C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82135B98;
	sub_821112B0(ctx, base);
	// li r3,208
	ctx.r3.s64 = 208;
	// lwz r4,108(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 108);
	// bl 0x82111340
	ctx.lr = 0x82135BA4;
	sub_82111340(ctx, base);
	// li r3,204
	ctx.r3.s64 = 204;
	// lwz r4,112(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 112);
	// bl 0x82111340
	ctx.lr = 0x82135BB0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82135BBC;
	sub_82111340(ctx, base);
	// addi r3,r30,28
	ctx.r3.s64 = ctx.r30.s64 + 28;
	// bl 0x8211c6e8
	ctx.lr = 0x82135BC4;
	sub_8211C6E8(ctx, base);
	// clrlwi r11,r25,24
	ctx.r11.u64 = ctx.r25.u32 & 0xFF;
	// lfs f4,92(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 92);
	ctx.f4.f64 = double(temp.f32);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r11,r11,67
	ctx.r11.s64 = ctx.r11.s64 + 67;
	// rldicr r4,r5,63,63
	ctx.r4.u64 = rotl64(ctx.r5.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// addi r3,r11,376
	ctx.r3.s64 = ctx.r11.s64 + 376;
	// rlwinm r10,r11,4,0,27
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r9,r3,4,0,27
	ctx.r9.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 4) & 0xFFFFFFF0;
	// stfsx f4,r9,r31
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r9.u32 + ctx.r31.u32, temp.u32);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// rlwinm r8,r11,30,2,31
	ctx.r8.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// srd r7,r4,r8
	ctx.r7.u64 = ctx.r8.u8 & 0x40 ? 0 : (ctx.r4.u64 >> (ctx.r8.u8 & 0x7F));
	// lfs f3,96(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 96);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,6020(r10)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r10.u32 + 6020, temp.u32);
	// lfs f2,100(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 100);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,6024(r10)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + 6024, temp.u32);
	// lfs f1,104(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 104);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,6028(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 6028, temp.u32);
	// ld r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r5,r7,r6
	ctx.r5.u64 = ctx.r7.u64 | ctx.r6.u64;
	// std r5,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r5.u64);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82135C20"))) PPC_WEAK_FUNC(sub_82135C20);
PPC_FUNC_IMPL(__imp__sub_82135C20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82135C28;
	__restfpr_28(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r8,-32178
	ctx.r8.s64 = -2108817408;
	// lwz r7,12(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r31,r11,172
	ctx.r31.s64 = ctx.r11.s64 + 172;
	// lwz r6,16(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// li r10,1024
	ctx.r10.s64 = 1024;
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
	// rlwinm r5,r7,10,0,21
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 10) & 0xFFFFFC00;
	// stw r9,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r9.u32);
	// lwz r11,204(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 204);
	// rlwinm r4,r6,10,0,21
	ctx.r4.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 10) & 0xFFFFFC00;
	// lwz r28,26092(r8)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r8.u32 + 26092);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// clrlwi r29,r11,26
	ctx.r29.u64 = ctx.r11.u32 & 0x3F;
	// stw r5,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r5.u32);
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// stw r10,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r10.u32);
	// cmplwi cr6,r29,50
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 50, ctx.xer);
	// stw r10,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r10.u32);
	// bne cr6,0x82135c8c
	if (!ctx.cr6.eq) goto loc_82135C8C;
	// li r10,3
	ctx.r10.s64 = 3;
	// rlwimi r11,r10,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r10.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_82135C8C:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// addi r6,r11,27648
	ctx.r6.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,31376
	ctx.r5.s64 = ctx.r10.s64 + 31376;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// lwz r3,188(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 188);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// lfs f1,36(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x82227e30
	ctx.lr = 0x82135CC0;
	sub_82227E30(ctx, base);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// addi r4,r30,4
	ctx.r4.s64 = ctx.r30.s64 + 4;
	// rlwimi r11,r29,0,26,31
	ctx.r11.u64 = (rotl32(ctx.r29.u32, 0) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x82135CD8;
	sub_8222CBC8(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x82135CE4;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82135CF0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,208
	ctx.r3.s64 = 208;
	// bl 0x82111340
	ctx.lr = 0x82135CFC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,204
	ctx.r3.s64 = 204;
	// bl 0x82111340
	ctx.lr = 0x82135D08;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82135D14;
	sub_82111340(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82135D1C"))) PPC_WEAK_FUNC(sub_82135D1C);
PPC_FUNC_IMPL(__imp__sub_82135D1C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82135D20"))) PPC_WEAK_FUNC(sub_82135D20);
PPC_FUNC_IMPL(__imp__sub_82135D20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82135D28;
	__restfpr_26(ctx, base);
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,368
	ctx.r3.s64 = 368;
	// lwz r31,26092(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26092);
	// bl 0x82111340
	ctx.lr = 0x82135D4C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x82135D58;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,136
	ctx.r3.s64 = 136;
	// bl 0x82111340
	ctx.lr = 0x82135D64;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,140
	ctx.r3.s64 = 140;
	// bl 0x82111340
	ctx.lr = 0x82135D70;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x82111340
	ctx.lr = 0x82135D7C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x82135D88;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x82135D94;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,372
	ctx.r3.s64 = 372;
	// bl 0x82111340
	ctx.lr = 0x82135DA0;
	sub_82111340(ctx, base);
	// li r4,127
	ctx.r4.s64 = 127;
	// li r3,132
	ctx.r3.s64 = 132;
	// bl 0x82111340
	ctx.lr = 0x82135DAC;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82111340
	ctx.lr = 0x82135DB8;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x82135DC4;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82111340
	ctx.lr = 0x82135DD0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x82135DDC;
	sub_82113BC0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r9,0(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// addi r5,r9,2172
	ctx.r5.s64 = ctx.r9.s64 + 2172;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82135e08
	if (ctx.cr6.eq) goto loc_82135E08;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82135E08;
	sub_8222CDF8(ctx, base);
loc_82135E08:
	// lfs f0,13008(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13008);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f13,13012(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13012);
	ctx.f13.f64 = double(temp.f32);
	// fctidz f12,f0
	ctx.f12.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// lfs f11,13000(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13000);
	ctx.f11.f64 = double(temp.f32);
	// fctidz f10,f13
	ctx.f10.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// lfs f8,13004(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 13004);
	ctx.f8.f64 = double(temp.f32);
	// fctidz f9,f11
	ctx.f9.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// stfd f12,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f12.u64);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// lwz r9,92(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f9.u64);
	// stfd f7,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f7.u64);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r6,92(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r7,r11,31376
	ctx.r7.s64 = ctx.r11.s64 + 31376;
	// stw r10,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r10.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lfs f0,36(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stw r9,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r9.u32);
	// lfs f31,48(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stfs f31,116(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stw r8,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r8.u32);
	// stfs f0,112(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stw r6,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r6.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x82135E7C;
	sub_8222CBC8(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x8210afd8
	ctx.lr = 0x82135E90;
	sub_8210AFD8(ctx, base);
	// lis r5,-32182
	ctx.r5.s64 = -2109079552;
	// addi r28,r26,124
	ctx.r28.s64 = ctx.r26.s64 + 124;
	// addi r3,r5,-27800
	ctx.r3.s64 = ctx.r5.s64 + -27800;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x8211fe60
	ctx.lr = 0x82135EA4;
	sub_8211FE60(ctx, base);
	// lwz r4,16(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	// rlwinm r3,r4,0,29,29
	ctx.r3.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x821360dc
	if (!ctx.cr6.eq) goto loc_821360DC;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r4,r11,172
	ctx.r4.s64 = ctx.r11.s64 + 172;
	// bl 0x82111400
	ctx.lr = 0x82135EC0;
	sub_82111400(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82135eec
	if (ctx.cr6.eq) goto loc_82135EEC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82135EE4;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
loc_82135EEC:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82135f10
	if (ctx.cr6.eq) goto loc_82135F10;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82135F08;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r11.u32);
loc_82135F10:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// li r9,3
	ctx.r9.s64 = 3;
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82135f48
	if (ctx.cr6.eq) goto loc_82135F48;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,11,19,21
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 11) & 0x1C00) | (ctx.r7.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82135F48:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82135f7c
	if (ctx.cr6.eq) goto loc_82135F7C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,14,16,18
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 14) & 0xE000) | (ctx.r7.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_82135F7C:
	// lwz r11,2020(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2020);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x82135fb4
	if (ctx.cr6.eq) goto loc_82135FB4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1172(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// rlwimi r8,r30,0,30,31
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 0) & 0x3) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r8,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2020, ctx.r10.u32);
loc_82135FB4:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r4,r11,16
	ctx.r4.s64 = ctx.r11.s64 + 16;
	// bl 0x82111400
	ctx.lr = 0x82135FC4;
	sub_82111400(ctx, base);
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82135fe8
	if (ctx.cr6.eq) goto loc_82135FE8;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x82135FE0;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r11.u32);
loc_82135FE8:
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213600c
	if (ctx.cr6.eq) goto loc_8213600C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82136004;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r11.u32);
loc_8213600C:
	// lwz r11,2292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2292);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82136040
	if (ctx.cr6.eq) goto loc_82136040;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2292, ctx.r10.u32);
loc_82136040:
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82136074
	if (ctx.cr6.eq) goto loc_82136074;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r10.u32);
loc_82136074:
	// lbz r11,705(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 705);
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821360dc
	if (ctx.cr6.eq) goto loc_821360DC;
	// addi r30,r28,416
	ctx.r30.s64 = ctx.r28.s64 + 416;
	// addi r31,r28,112
	ctx.r31.s64 = ctx.r28.s64 + 112;
loc_8213608C:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x821360c4
	if (ctx.cr6.eq) goto loc_821360C4;
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// fctidz f13,f0
	ctx.f13.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// stfd f13,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f13.u64);
	// lwz r3,92(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// bne cr6,0x821360c0
	if (!ctx.cr6.eq) goto loc_821360C0;
	// bl 0x82136118
	ctx.lr = 0x821360BC;
	sub_82136118(ctx, base);
	// b 0x821360c4
	goto loc_821360C4;
loc_821360C0:
	// bl 0x82136540
	ctx.lr = 0x821360C4;
	sub_82136540(ctx, base);
loc_821360C4:
	// lbz r11,705(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 705);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// addi r30,r30,72
	ctx.r30.s64 = ctx.r30.s64 + 72;
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x8213608c
	if (ctx.cr6.lt) goto loc_8213608C;
loc_821360DC:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r11,328
	ctx.r5.s64 = ctx.r11.s64 + 328;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,256
	ctx.r3.s64 = 256;
	// bl 0x8210af50
	ctx.lr = 0x82136100;
	sub_8210AF50(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8213610C;
	sub_82111340(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82136118"))) PPC_WEAK_FUNC(sub_82136118);
PPC_FUNC_IMPL(__imp__sub_82136118) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e44c
	ctx.lr = 0x82136120;
	__restfpr_21(ctx, base);
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x8233fa20
	ctx.lr = 0x82136128;
	sub_8233FA20(ctx, base);
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// lwz r11,12(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// lbz r30,828(r4)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r4.u32 + 828);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r25,r4
	ctx.r25.u64 = ctx.r4.u64;
	// li r3,212
	ctx.r3.s64 = 212;
	// slw r4,r9,r22
	ctx.r4.u64 = ctx.r22.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r22.u8 & 0x3F));
	// lwz r31,26092(r10)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 26092);
	// addi r29,r25,124
	ctx.r29.s64 = ctx.r25.s64 + 124;
	// addi r23,r11,88
	ctx.r23.s64 = ctx.r11.s64 + 88;
	// bl 0x82111340
	ctx.lr = 0x8213615C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x82136168;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x82136174;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,368
	ctx.r3.s64 = 368;
	// bl 0x82111340
	ctx.lr = 0x82136180;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x8213618C;
	sub_82111340(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82111340
	ctx.lr = 0x82136198;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x821361A4;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82111340
	ctx.lr = 0x821361B0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x82111340
	ctx.lr = 0x821361BC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x821361C8;
	sub_821112B0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x821361D4;
	sub_82113BC0(ctx, base);
	// lis r28,-32182
	ctx.r28.s64 = -2109079552;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,-25536(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25536);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r8,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r8.u32);
	// ld r7,16(r31)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r6,r7,8
	ctx.r6.u64 = ctx.r7.u64 | 524288;
	// std r6,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r6.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x821361FC;
	sub_82238728(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238380
	ctx.lr = 0x82136208;
	sub_82238380(ctx, base);
	// rotlwi r11,r30,4
	ctx.r11.u64 = rotl32(ctx.r30.u32, 4);
	// lfs f12,40(r23)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// add r5,r11,r29
	ctx.r5.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lfs f11,56(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 56);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,44(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 44);
	ctx.f10.f64 = double(temp.f32);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r26,r11,31376
	ctx.r26.s64 = ctx.r11.s64 + 31376;
	// lfs f0,28(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 28);
	ctx.f0.f64 = double(temp.f32);
	// fmadds f9,f0,f12,f11
	ctx.f9.f64 = double(std::fma(float(ctx.f0.f64), float(ctx.f12.f64), float(ctx.f11.f64)));
	// fmuls f8,f10,f0
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f13,36(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f9,f8
	ctx.f0.f64 = double(float(ctx.f9.f64 / ctx.f8.f64));
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// ble cr6,0x82136244
	if (!ctx.cr6.gt) goto loc_82136244;
	// lfs f0,260(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 260);
	ctx.f0.f64 = double(temp.f32);
loc_82136244:
	// li r11,1
	ctx.r11.s64 = 1;
	// lfs f28,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f28.f64 = double(temp.f32);
	// lfs f27,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f27.f64 = double(temp.f32);
	// lfs f26,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f26.f64 = double(temp.f32);
	// rldicr r21,r11,36,63
	ctx.r21.u64 = rotl64(ctx.r11.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// stfs f0,3648(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3648, temp.u32);
	// stfs f28,3652(r31)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3652, temp.u32);
	// stfs f27,3656(r31)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3656, temp.u32);
	// stfs f26,3660(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3660, temp.u32);
	// ld r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r9,r10,r21
	ctx.r9.u64 = ctx.r10.u64 | ctx.r21.u64;
	// std r9,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r9.u64);
	// bl 0x8210b0d8
	ctx.lr = 0x82136278;
	sub_8210B0D8(ctx, base);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r8,56(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// ble cr6,0x82136294
	if (!ctx.cr6.gt) goto loc_82136294;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82231210
	ctx.lr = 0x82136290;
	sub_82231210(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82136294:
	// lis r9,-16384
	ctx.r9.s64 = -1073741824;
	// lwz r10,-25536(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + -25536);
	// li r8,15
	ctx.r8.s64 = 15;
	// ori r7,r9,17920
	ctx.r7.u64 = ctx.r9.u64 | 17920;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// lbz r6,11069(r31)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r31.u32 + 11069);
	// clrlwi r5,r6,24
	ctx.r5.u64 = ctx.r6.u32 & 0xFF;
	// rlwinm r5,r5,0,30,28
	ctx.r5.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// stb r5,11069(r31)
	PPC_STORE_U8(ctx.r31.u32 + 11069, ctx.r5.u8);
	// lwz r4,0(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x821362CC;
	sub_82238380(ctx, base);
	// mr r28,r30
	ctx.r28.u64 = ctx.r30.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82136524
	if (ctx.cr6.eq) goto loc_82136524;
	// addi r11,r30,2
	ctx.r11.s64 = ctx.r30.s64 + 2;
	// lfs f25,48(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 48);
	ctx.f25.f64 = double(temp.f32);
	// addi r10,r30,15
	ctx.r10.s64 = ctx.r30.s64 + 15;
	// lfs f24,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f24.f64 = double(temp.f32);
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f23,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f23.f64 = double(temp.f32);
	// rlwinm r10,r10,6,0,25
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f22,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f22.f64 = double(temp.f32);
	// add r30,r11,r29
	ctx.r30.u64 = ctx.r11.u64 + ctx.r29.u64;
	// add r27,r10,r25
	ctx.r27.u64 = ctx.r10.u64 + ctx.r25.u64;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// rldicr r24,r10,35,63
	ctx.r24.u64 = rotl64(ctx.r10.u64, 35) & 0xFFFFFFFFFFFFFFFF;
	// rldicr r26,r9,34,63
	ctx.r26.u64 = rotl64(ctx.r9.u64, 34) & 0xFFFFFFFFFFFFFFFF;
	// addi r29,r11,28184
	ctx.r29.s64 = ctx.r11.s64 + 28184;
loc_82136318:
	// addi r27,r27,-64
	ctx.r27.s64 = ctx.r27.s64 + -64;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,4
	ctx.r6.s64 = 4;
	// rldicr r7,r7,35,28
	ctx.r7.u64 = rotl64(ctx.r7.u64, 35) & 0xFFFFFFF800000000;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// li r4,111
	ctx.r4.s64 = 111;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r28,r28,-1
	ctx.r28.s64 = ctx.r28.s64 + -1;
	// addi r30,r30,-16
	ctx.r30.s64 = ctx.r30.s64 + -16;
	// bl 0x82238120
	ctx.lr = 0x82136340;
	sub_82238120(ctx, base);
	// li r11,257
	ctx.r11.s64 = 257;
	// stw r11,288(r29)
	PPC_STORE_U32(ctx.r29.u32 + 288, ctx.r11.u32);
	// lwz r11,756(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 756);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82136374
	if (ctx.cr6.eq) goto loc_82136374;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// stfs f25,10500(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r11.u32 + 10500, temp.u32);
	// ld r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// oris r7,r8,2048
	ctx.r7.u64 = ctx.r8.u64 | 134217728;
	// std r7,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r7.u64);
	// stw r10,756(r29)
	PPC_STORE_U32(ctx.r29.u32 + 756, ctx.r10.u32);
loc_82136374:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82111340
	ctx.lr = 0x82136380;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x8213638C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x82136398;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x821363A4;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x821363B0;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x82111340
	ctx.lr = 0x821363BC;
	sub_82111340(ctx, base);
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r7,12(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// lwz r6,0(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r10,r28,r22
	ctx.r10.u64 = ctx.r28.u64 + ctx.r22.u64;
	// lwz r5,4(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// stfs f23,7864(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7864, temp.u32);
	// clrldi r9,r10,32
	ctx.r9.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// stfs f22,7860(r31)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7860, temp.u32);
	// stfs f24,7868(r31)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7868, temp.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
	// li r3,364
	ctx.r3.s64 = 364;
	// stw r7,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r7.u32);
	// fmr f30,f25
	ctx.f30.f64 = ctx.f25.f64;
	// stw r6,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r6.u32);
	// stw r5,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r5.u32);
	// lfs f11,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f10.f64 = double(temp.f32);
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lfs f29,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f29.f64 = double(temp.f32);
	// lfs f31,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f31.f64 = double(temp.f32);
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f0
	ctx.f13.f64 = double(ctx.f0.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// stfs f12,7856(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7856, temp.u32);
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r10,r11,r24
	ctx.r10.u64 = ctx.r11.u64 | ctx.r24.u64;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// stfs f29,7872(r31)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7872, temp.u32);
	// stfs f31,7876(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7876, temp.u32);
	// stfs f10,7880(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7880, temp.u32);
	// stfs f11,7884(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7884, temp.u32);
	// ld r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r8,r9,r26
	ctx.r8.u64 = ctx.r9.u64 | ctx.r26.u64;
	// std r8,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r8.u64);
	// bl 0x82111340
	ctx.lr = 0x82136450;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x8213645C;
	sub_82111340(ctx, base);
	// lfs f9,120(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 120);
	ctx.f9.f64 = double(temp.f32);
	// fcmpu cr6,f31,f9
	ctx.cr6.compare(ctx.f31.f64, ctx.f9.f64);
	// ble cr6,0x82136480
	if (!ctx.cr6.gt) goto loc_82136480;
	// lfs f0,40(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 40);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,56(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,44(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 44);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f11,f31,f0,f13
	ctx.f11.f64 = double(std::fma(float(ctx.f31.f64), float(ctx.f0.f64), float(ctx.f13.f64)));
	// fmuls f10,f12,f31
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// fdivs f30,f11,f10
	ctx.f30.f64 = double(float(ctx.f11.f64 / ctx.f10.f64));
loc_82136480:
	// stfs f27,3656(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3656, temp.u32);
	// stfs f26,3660(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3660, temp.u32);
	// stfs f30,3648(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3648, temp.u32);
	// stfs f28,3652(r31)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3652, temp.u32);
	// ld r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r10,r11,r21
	ctx.r10.u64 = ctx.r11.u64 | ctx.r21.u64;
	// std r10,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r10.u64);
	// bl 0x8210b0d8
	ctx.lr = 0x821364A0;
	sub_8210B0D8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82232270
	ctx.lr = 0x821364AC;
	sub_82232270(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x821364B8;
	sub_82111340(ctx, base);
	// fcmpu cr6,f29,f31
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f29.f64, ctx.f31.f64);
	// beq cr6,0x8213651c
	if (ctx.cr6.eq) goto loc_8213651C;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x821364CC;
	sub_82113BC0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x821364D8;
	sub_82111340(ctx, base);
	// lfs f0,120(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 120);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f29,f0
	ctx.cr6.compare(ctx.f29.f64, ctx.f0.f64);
	// ble cr6,0x821364fc
	if (!ctx.cr6.gt) goto loc_821364FC;
	// lfs f0,40(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 40);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,56(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,44(r23)
	temp.u32 = PPC_LOAD_U32(ctx.r23.u32 + 44);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f11,f29,f0,f13
	ctx.f11.f64 = double(std::fma(float(ctx.f29.f64), float(ctx.f0.f64), float(ctx.f13.f64)));
	// fmuls f10,f12,f29
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f29.f64));
	// fdivs f30,f11,f10
	ctx.f30.f64 = double(float(ctx.f11.f64 / ctx.f10.f64));
loc_821364FC:
	// stfs f27,3656(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3656, temp.u32);
	// stfs f26,3660(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3660, temp.u32);
	// stfs f28,3652(r31)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3652, temp.u32);
	// stfs f30,3648(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3648, temp.u32);
	// ld r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r10,r11,r21
	ctx.r10.u64 = ctx.r11.u64 | ctx.r21.u64;
	// std r10,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r10.u64);
	// bl 0x8210b0d8
	ctx.lr = 0x8213651C;
	sub_8210B0D8(ctx, base);
loc_8213651C:
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// bne cr6,0x82136318
	if (!ctx.cr6.eq) goto loc_82136318;
loc_82136524:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x82136530;
	sub_82113BC0(ctx, base);
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// addi r12,r1,-96
	ctx.r12.s64 = ctx.r1.s64 + -96;
	// bl 0x8233fa6c
	ctx.lr = 0x8213653C;
	__savefpr_22(ctx, base);
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82136540"))) PPC_WEAK_FUNC(sub_82136540);
PPC_FUNC_IMPL(__imp__sub_82136540) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82136548;
	__restfpr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// lwz r29,-25540(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + -25540);
	// lwz r31,26092(r10)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 26092);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r9,4(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// stw r9,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r9.u32);
	// ld r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r7,r8,8
	ctx.r7.u64 = ctx.r8.u64 | 524288;
	// std r7,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r7.u64);
	// lwz r4,8(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82136584;
	sub_82238728(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// slw r4,r6,r30
	ctx.r4.u64 = ctx.r30.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r30.u8 & 0x3F));
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82136594;
	sub_82111340(ctx, base);
	// clrldi r5,r30,32
	ctx.r5.u64 = ctx.r30.u64 & 0xFFFFFFFF;
	// addi r4,r30,15
	ctx.r4.s64 = ctx.r30.s64 + 15;
	// std r5,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r5.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f0
	ctx.f13.f64 = double(ctx.f0.s64);
	// rlwinm r11,r4,6,0,25
	ctx.r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 6) & 0xFFFFFFC0;
	// li r7,3
	ctx.r7.s64 = 3;
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// rldicr r7,r7,35,28
	ctx.r7.u64 = rotl64(ctx.r7.u64, 35) & 0xFFFFFFF800000000;
	// li r6,4
	ctx.r6.s64 = 4;
	// add r5,r11,r28
	ctx.r5.u64 = ctx.r11.u64 + ctx.r28.u64;
	// li r4,111
	ctx.r4.s64 = 111;
	// bl 0x82238120
	ctx.lr = 0x821365CC;
	sub_82238120(ctx, base);
	// rlwinm r11,r30,3,0,28
	ctx.r11.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 3) & 0xFFFFFFF8;
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f11,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// add r3,r30,r11
	ctx.r3.u64 = ctx.r30.u64 + ctx.r11.u64;
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f9.f64 = double(temp.f32);
	// rldicr r12,r12,35,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 35) & 0xFFFFFFFFFFFFFFFF;
	// rlwinm r11,r3,3,0,28
	ctx.r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 3) & 0xFFFFFFF8;
	// stfs f12,7856(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7856, temp.u32);
	// stfs f11,7860(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7860, temp.u32);
	// add r28,r11,r28
	ctx.r28.u64 = ctx.r11.u64 + ctx.r28.u64;
	// stfs f10,7864(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7864, temp.u32);
	// stfs f9,7868(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7868, temp.u32);
	// addi r11,r28,540
	ctx.r11.s64 = ctx.r28.s64 + 540;
	// addi r3,r11,8
	ctx.r3.s64 = ctx.r11.s64 + 8;
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// bl 0x82113ab8
	ctx.lr = 0x82136618;
	sub_82113AB8(ctx, base);
	// lis r9,-32182
	ctx.r9.s64 = -2109079552;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r30,r9,-27800
	ctx.r30.s64 = ctx.r9.s64 + -27800;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,12
	ctx.r7.s64 = 12;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,1792(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1792);
	// bl 0x8222cc48
	ctx.lr = 0x8213663C;
	sub_8222CC48(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82136648;
	sub_821112B0(ctx, base);
	// lwz r11,1784(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1784);
	// li r8,3
	ctx.r8.s64 = 3;
	// divwu r27,r11,r8
	ctx.r27.u32 = ctx.r11.u32 / ctx.r8.u32;
	// bl 0x8211c4a0
	ctx.lr = 0x82136658;
	sub_8211C4A0(ctx, base);
	// li r4,3
	ctx.r4.s64 = 3;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x82136664;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82136670;
	sub_82111340(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82238380
	ctx.lr = 0x8213667C;
	sub_82238380(ctx, base);
	// rlwinm r11,r27,1,0,30
	ctx.r11.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 1) & 0xFFFFFFFE;
	// li r5,0
	ctx.r5.s64 = 0;
	// add r27,r27,r11
	ctx.r27.u64 = ctx.r27.u64 + ctx.r11.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x82136698;
	sub_8222DFC8(ctx, base);
	// addi r3,r30,1776
	ctx.r3.s64 = ctx.r30.s64 + 1776;
	// bl 0x8211c510
	ctx.lr = 0x821366A0;
	sub_8211C510(ctx, base);
	// lwz r7,544(r28)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r28.u32 + 544);
	// li r4,6
	ctx.r4.s64 = 6;
	// rlwinm r6,r7,0,30,30
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne cr6,0x821366c0
	if (!ctx.cr6.eq) goto loc_821366C0;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x821366BC;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
loc_821366C0:
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x821366C8;
	sub_82111340(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x821366D4;
	sub_82238380(ctx, base);
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x821366E8;
	sub_8222DFC8(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x821366F4;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x82136700;
	sub_82111340(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82136708"))) PPC_WEAK_FUNC(sub_82136708);
PPC_FUNC_IMPL(__imp__sub_82136708) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x82136710;
	__restfpr_25(ctx, base);
	// stfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, ctx.f31.u64);
	// stwu r1,-512(r1)
	ea = -512 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lbz r10,709(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 709);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r31,26092(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 26092);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,176
	ctx.r4.s64 = 176;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bne cr6,0x82136764
	if (!ctx.cr6.eq) goto loc_82136764;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// lfs f1,36(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82229fb8
	ctx.lr = 0x82136758;
	sub_82229FB8(ctx, base);
	// addi r1,r1,512
	ctx.r1.s64 = ctx.r1.s64 + 512;
	// lfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
loc_82136764:
	// addi r26,r11,31376
	ctx.r26.s64 = ctx.r11.s64 + 31376;
	// lfs f31,48(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82229fb8
	ctx.lr = 0x82136774;
	sub_82229FB8(ctx, base);
	// addi r5,r29,24
	ctx.r5.s64 = ctx.r29.s64 + 24;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,368
	ctx.r3.s64 = ctx.r1.s64 + 368;
	// bl 0x82257cb8
	ctx.lr = 0x82136784;
	sub_82257CB8(ctx, base);
	// li r27,0
	ctx.r27.s64 = 0;
	// addi r5,r1,180
	ctx.r5.s64 = ctx.r1.s64 + 180;
	// stw r27,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r27.u32);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// stw r27,180(r1)
	PPC_STORE_U32(ctx.r1.u32 + 180, ctx.r27.u32);
	// li r3,576
	ctx.r3.s64 = 576;
	// bl 0x8210b178
	ctx.lr = 0x821367A0;
	sub_8210B178(ctx, base);
	// lfs f0,732(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 732);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,376(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 376, temp.u32);
	// addi r28,r29,88
	ctx.r28.s64 = ctx.r29.s64 + 88;
	// lfs f13,728(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 728);
	ctx.f13.f64 = double(temp.f32);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// lfs f0,36(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// stfs f31,184(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stfs f31,188(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// addi r3,r1,304
	ctx.r3.s64 = ctx.r1.s64 + 304;
	// stfs f13,380(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r30.u32 + 380, temp.u32);
	// stfs f0,192(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// bl 0x82257cb8
	ctx.lr = 0x821367D8;
	sub_82257CB8(ctx, base);
	// addi r5,r1,304
	ctx.r5.s64 = ctx.r1.s64 + 304;
	// addi r4,r1,184
	ctx.r4.s64 = ctx.r1.s64 + 184;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x82257540
	ctx.lr = 0x821367E8;
	sub_82257540(ctx, base);
	// lfs f0,1444(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 1444);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,184(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// addi r5,r1,304
	ctx.r5.s64 = ctx.r1.s64 + 304;
	// stfs f0,188(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// addi r4,r1,184
	ctx.r4.s64 = ctx.r1.s64 + 184;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x82257540
	ctx.lr = 0x82136804;
	sub_82257540(ctx, base);
	// lfs f12,228(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f11.f64 = double(temp.f32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// fsubs f10,f11,f12
	ctx.f10.f64 = static_cast<float>(ctx.f11.f64 - ctx.f12.f64);
	// lfs f9,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f8.f64 = double(temp.f32);
	// addi r3,r30,24
	ctx.r3.s64 = ctx.r30.s64 + 24;
	// fsubs f7,f8,f9
	ctx.f7.f64 = static_cast<float>(ctx.f8.f64 - ctx.f9.f64);
	// lfs f5,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f0,f5,f6
	ctx.f0.f64 = static_cast<float>(ctx.f5.f64 - ctx.f6.f64);
	// lfs f4,380(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 380);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,376(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 376);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,372(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 372);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,368(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 368);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f13,f10,f10
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// fmadds f12,f7,f7,f13
	ctx.f12.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f7.f64), float(ctx.f13.f64)));
	// fmadds f11,f0,f0,f12
	ctx.f11.f64 = double(std::fma(float(ctx.f0.f64), float(ctx.f0.f64), float(ctx.f12.f64)));
	// fsqrts f5,f11
	ctx.f5.f64 = double(simd::sqrt_f32(float(ctx.f11.f64)));
	// bl 0x82306068
	ctx.lr = 0x82136854;
	sub_82306068(ctx, base);
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r9,120(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r8,124(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// stw r10,0(r25)
	PPC_STORE_U32(ctx.r25.u32 + 0, ctx.r10.u32);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// stw r9,4(r25)
	PPC_STORE_U32(ctx.r25.u32 + 4, ctx.r9.u32);
	// stw r8,8(r25)
	PPC_STORE_U32(ctx.r25.u32 + 8, ctx.r8.u32);
	// lwz r7,104(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r6,108(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lwz r5,112(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r7,12(r25)
	PPC_STORE_U32(ctx.r25.u32 + 12, ctx.r7.u32);
	// stw r6,16(r25)
	PPC_STORE_U32(ctx.r25.u32 + 16, ctx.r6.u32);
	// stw r5,20(r25)
	PPC_STORE_U32(ctx.r25.u32 + 20, ctx.r5.u32);
	// lwz r4,92(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r11,100(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stw r4,24(r25)
	PPC_STORE_U32(ctx.r25.u32 + 24, ctx.r4.u32);
	// stw r3,28(r25)
	PPC_STORE_U32(ctx.r25.u32 + 28, ctx.r3.u32);
	// stw r11,32(r25)
	PPC_STORE_U32(ctx.r25.u32 + 32, ctx.r11.u32);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r7,88(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stw r8,40(r25)
	PPC_STORE_U32(ctx.r25.u32 + 40, ctx.r8.u32);
	// stw r9,36(r25)
	PPC_STORE_U32(ctx.r25.u32 + 36, ctx.r9.u32);
	// stw r7,44(r25)
	PPC_STORE_U32(ctx.r25.u32 + 44, ctx.r7.u32);
	// lwz r6,164(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lwz r5,168(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lwz r4,172(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// stw r5,52(r25)
	PPC_STORE_U32(ctx.r25.u32 + 52, ctx.r5.u32);
	// stw r6,48(r25)
	PPC_STORE_U32(ctx.r25.u32 + 48, ctx.r6.u32);
	// stw r4,56(r25)
	PPC_STORE_U32(ctx.r25.u32 + 56, ctx.r4.u32);
	// lwz r3,152(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lwz r11,156(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// lwz r9,160(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// stw r11,64(r25)
	PPC_STORE_U32(ctx.r25.u32 + 64, ctx.r11.u32);
	// stw r3,60(r25)
	PPC_STORE_U32(ctx.r25.u32 + 60, ctx.r3.u32);
	// stw r9,68(r25)
	PPC_STORE_U32(ctx.r25.u32 + 68, ctx.r9.u32);
	// lwz r8,140(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lwz r6,148(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// stw r8,72(r25)
	PPC_STORE_U32(ctx.r25.u32 + 72, ctx.r8.u32);
	// stw r7,76(r25)
	PPC_STORE_U32(ctx.r25.u32 + 76, ctx.r7.u32);
	// stw r6,80(r25)
	PPC_STORE_U32(ctx.r25.u32 + 80, ctx.r6.u32);
	// lwz r5,128(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r4,132(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r3,136(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stw r5,84(r25)
	PPC_STORE_U32(ctx.r25.u32 + 84, ctx.r5.u32);
	// stw r4,88(r25)
	PPC_STORE_U32(ctx.r25.u32 + 88, ctx.r4.u32);
	// stw r3,92(r25)
	PPC_STORE_U32(ctx.r25.u32 + 92, ctx.r3.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r8,88(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stw r11,96(r25)
	PPC_STORE_U32(ctx.r25.u32 + 96, ctx.r11.u32);
	// stw r8,104(r25)
	PPC_STORE_U32(ctx.r25.u32 + 104, ctx.r8.u32);
	// stw r9,100(r25)
	PPC_STORE_U32(ctx.r25.u32 + 100, ctx.r9.u32);
	// lwz r7,128(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r6,132(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r5,136(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stw r5,116(r25)
	PPC_STORE_U32(ctx.r25.u32 + 116, ctx.r5.u32);
	// stw r7,108(r25)
	PPC_STORE_U32(ctx.r25.u32 + 108, ctx.r7.u32);
	// stw r6,112(r25)
	PPC_STORE_U32(ctx.r25.u32 + 112, ctx.r6.u32);
	// lwz r4,164(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lwz r3,168(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// lwz r11,172(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// stw r11,128(r25)
	PPC_STORE_U32(ctx.r25.u32 + 128, ctx.r11.u32);
	// stw r4,120(r25)
	PPC_STORE_U32(ctx.r25.u32 + 120, ctx.r4.u32);
	// stw r3,124(r25)
	PPC_STORE_U32(ctx.r25.u32 + 124, ctx.r3.u32);
	// lwz r9,116(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r8,120(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r7,124(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// stw r8,136(r25)
	PPC_STORE_U32(ctx.r25.u32 + 136, ctx.r8.u32);
	// stw r9,132(r25)
	PPC_STORE_U32(ctx.r25.u32 + 132, ctx.r9.u32);
	// stw r7,140(r25)
	PPC_STORE_U32(ctx.r25.u32 + 140, ctx.r7.u32);
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r4,88(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stw r5,148(r25)
	PPC_STORE_U32(ctx.r25.u32 + 148, ctx.r5.u32);
	// stw r6,144(r25)
	PPC_STORE_U32(ctx.r25.u32 + 144, ctx.r6.u32);
	// stw r4,152(r25)
	PPC_STORE_U32(ctx.r25.u32 + 152, ctx.r4.u32);
	// lwz r3,128(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// lwz r11,132(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lwz r9,136(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stw r11,160(r25)
	PPC_STORE_U32(ctx.r25.u32 + 160, ctx.r11.u32);
	// addi r11,r10,27648
	ctx.r11.s64 = ctx.r10.s64 + 27648;
	// stw r3,156(r25)
	PPC_STORE_U32(ctx.r25.u32 + 156, ctx.r3.u32);
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// stw r9,164(r25)
	PPC_STORE_U32(ctx.r25.u32 + 164, ctx.r9.u32);
	// lwz r8,140(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lwz r7,144(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lwz r6,148(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// stw r8,168(r25)
	PPC_STORE_U32(ctx.r25.u32 + 168, ctx.r8.u32);
	// addi r8,r11,200
	ctx.r8.s64 = ctx.r11.s64 + 200;
	// stw r7,172(r25)
	PPC_STORE_U32(ctx.r25.u32 + 172, ctx.r7.u32);
	// stw r6,176(r25)
	PPC_STORE_U32(ctx.r25.u32 + 176, ctx.r6.u32);
	// lwz r5,92(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stw r5,180(r25)
	PPC_STORE_U32(ctx.r25.u32 + 180, ctx.r5.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r4,184(r25)
	PPC_STORE_U32(ctx.r25.u32 + 184, ctx.r4.u32);
	// stw r3,188(r25)
	PPC_STORE_U32(ctx.r25.u32 + 188, ctx.r3.u32);
	// lwz r9,92(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r7,96(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r6,100(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stw r9,192(r25)
	PPC_STORE_U32(ctx.r25.u32 + 192, ctx.r9.u32);
	// stw r7,196(r25)
	PPC_STORE_U32(ctx.r25.u32 + 196, ctx.r7.u32);
	// stw r6,200(r25)
	PPC_STORE_U32(ctx.r25.u32 + 200, ctx.r6.u32);
	// lwz r9,144(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lwz r4,140(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// lwz r3,148(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// stw r4,204(r25)
	PPC_STORE_U32(ctx.r25.u32 + 204, ctx.r4.u32);
	// stw r9,208(r25)
	PPC_STORE_U32(ctx.r25.u32 + 208, ctx.r9.u32);
	// stw r3,212(r25)
	PPC_STORE_U32(ctx.r25.u32 + 212, ctx.r3.u32);
	// lwz r4,160(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// lwz r7,152(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lwz r6,156(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// stw r4,224(r25)
	PPC_STORE_U32(ctx.r25.u32 + 224, ctx.r4.u32);
	// stw r7,216(r25)
	PPC_STORE_U32(ctx.r25.u32 + 216, ctx.r7.u32);
	// stw r6,220(r25)
	PPC_STORE_U32(ctx.r25.u32 + 220, ctx.r6.u32);
	// lwz r7,112(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r3,104(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r9,108(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// stw r3,228(r25)
	PPC_STORE_U32(ctx.r25.u32 + 228, ctx.r3.u32);
	// stw r7,236(r25)
	PPC_STORE_U32(ctx.r25.u32 + 236, ctx.r7.u32);
	// stw r9,232(r25)
	PPC_STORE_U32(ctx.r25.u32 + 232, ctx.r9.u32);
	// lwz r3,124(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lwz r6,116(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r4,120(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// stw r4,244(r25)
	PPC_STORE_U32(ctx.r25.u32 + 244, ctx.r4.u32);
	// stw r3,248(r25)
	PPC_STORE_U32(ctx.r25.u32 + 248, ctx.r3.u32);
	// stw r6,240(r25)
	PPC_STORE_U32(ctx.r25.u32 + 240, ctx.r6.u32);
	// lwz r6,172(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	// lwz r9,164(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// lwz r7,168(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// stw r9,252(r25)
	PPC_STORE_U32(ctx.r25.u32 + 252, ctx.r9.u32);
	// stw r6,260(r25)
	PPC_STORE_U32(ctx.r25.u32 + 260, ctx.r6.u32);
	// stw r7,256(r25)
	PPC_STORE_U32(ctx.r25.u32 + 256, ctx.r7.u32);
	// lwz r9,160(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// lwz r4,152(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// lwz r3,156(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// stw r4,264(r25)
	PPC_STORE_U32(ctx.r25.u32 + 264, ctx.r4.u32);
	// stw r9,272(r25)
	PPC_STORE_U32(ctx.r25.u32 + 272, ctx.r9.u32);
	// stw r3,268(r25)
	PPC_STORE_U32(ctx.r25.u32 + 268, ctx.r3.u32);
	// lwz r4,112(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r7,104(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r6,108(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// stw r4,284(r25)
	PPC_STORE_U32(ctx.r25.u32 + 284, ctx.r4.u32);
	// stw r7,276(r25)
	PPC_STORE_U32(ctx.r25.u32 + 276, ctx.r7.u32);
	// stw r6,280(r25)
	PPC_STORE_U32(ctx.r25.u32 + 280, ctx.r6.u32);
	// lwz r10,268(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,272(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	// addi r3,r9,607
	ctx.r3.s64 = ctx.r9.s64 + 607;
	// rlwinm r9,r3,0,0,26
	ctx.r9.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFE0;
	// stb r27,264(r11)
	PPC_STORE_U8(ctx.r11.u32 + 264, ctx.r27.u8);
	// stw r9,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r9.u32);
	// lwzx r3,r10,r8
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// lwz r9,24(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r4,r9,0,0,29
	ctx.r4.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFC;
	// bl 0x8222ee68
	ctx.lr = 0x82136AD4;
	sub_8222EE68(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,12
	ctx.r7.s64 = 12;
	// lwz r6,180(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,176(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x82136AF0;
	sub_8222CC48(ctx, base);
	// addi r4,r1,368
	ctx.r4.s64 = ctx.r1.s64 + 368;
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// bl 0x82257a50
	ctx.lr = 0x82136AFC;
	sub_82257A50(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,4
	ctx.r6.s64 = 4;
	// rldicr r7,r7,36,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// addi r5,r1,240
	ctx.r5.s64 = ctx.r1.s64 + 240;
	// li r4,108
	ctx.r4.s64 = 108;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238048
	ctx.lr = 0x82136B18;
	sub_82238048(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// bl 0x82257a50
	ctx.lr = 0x82136B24;
	sub_82257A50(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,4
	ctx.r6.s64 = 4;
	// rldicr r7,r7,35,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 35) & 0xFFFFFFFFFFFFFFFF;
	// addi r5,r1,240
	ctx.r5.s64 = ctx.r1.s64 + 240;
	// li r4,112
	ctx.r4.s64 = 112;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238048
	ctx.lr = 0x82136B40;
	sub_82238048(ctx, base);
	// lfs f0,224(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 224);
	ctx.f0.f64 = double(temp.f32);
	// li r12,1
	ctx.r12.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// rldicr r12,r12,34,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 34) & 0xFFFFFFFFFFFFFFFF;
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f8,380(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 380);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,376(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 376);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f8,f0
	ctx.f6.f64 = static_cast<float>(ctx.f8.f64 - ctx.f0.f64);
	// lfs f10,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f10.f64 = double(temp.f32);
	// fadds f5,f7,f0
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f0.f64));
	// lfs f9,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f9.f64 = double(temp.f32);
	// stfs f6,3780(r31)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3780, temp.u32);
	// stfs f5,3776(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3776, temp.u32);
	// stfs f10,3784(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3784, temp.u32);
	// stfs f9,3788(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3788, temp.u32);
	// ld r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r7,r8,r12
	ctx.r7.u64 = ctx.r8.u64 | ctx.r12.u64;
	// std r7,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r7.u64);
	// bl 0x82113bc0
	ctx.lr = 0x82136B8C;
	sub_82113BC0(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x82136B98;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82136BA4;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82136BB0;
	sub_821112B0(ctx, base);
	// lis r6,-32182
	ctx.r6.s64 = -2109079552;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,-25544(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + -25544);
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r5,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r5.u32);
	// ld r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r10,r4,8
	ctx.r10.u64 = ctx.r4.u64 | 524288;
	// std r10,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r10.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82136BD8;
	sub_82238728(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238380
	ctx.lr = 0x82136BE4;
	sub_82238380(ctx, base);
	// li r6,24
	ctx.r6.s64 = 24;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,13
	ctx.r4.s64 = 13;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x82136BF8;
	sub_8222DFC8(ctx, base);
	// addi r1,r1,512
	ctx.r1.s64 = ctx.r1.s64 + 512;
	// lfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82136C04"))) PPC_WEAK_FUNC(sub_82136C04);
PPC_FUNC_IMPL(__imp__sub_82136C04) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82136C08"))) PPC_WEAK_FUNC(sub_82136C08);
PPC_FUNC_IMPL(__imp__sub_82136C08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e454
	ctx.lr = 0x82136C10;
	__restfpr_23(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r5,328(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 328);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// addi r27,r3,324
	ctx.r27.s64 = ctx.r3.s64 + 324;
	// li r24,0
	ctx.r24.s64 = 0;
	// li r23,-1
	ctx.r23.s64 = -1;
	// cmpwi cr6,r5,-1
	ctx.cr6.compare<int32_t>(ctx.r5.s32, -1, ctx.xer);
	// beq cr6,0x82136cfc
	if (ctx.cr6.eq) goto loc_82136CFC;
	// lwz r8,0(r27)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82136cf0
	if (ctx.cr6.eq) goto loc_82136CF0;
	// lwz r6,4(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// mtctr r5
	ctx.ctr.u64 = ctx.r5.u64;
	// lwz r7,0(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lwz r4,12(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
loc_82136C50:
	// lwz r11,8(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82136c8c
	if (!ctx.cr6.lt) goto loc_82136C8C;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r10,r10,4,0,27
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r9,r7
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r7.s32, ctx.xer);
	// bne cr6,0x82136c8c
	if (!ctx.cr6.eq) goto loc_82136C8C;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r10,r6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, ctx.xer);
	// beq cr6,0x82136ccc
	if (ctx.cr6.eq) goto loc_82136CCC;
loc_82136C8C:
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82136cc8
	if (ctx.cr6.eq) goto loc_82136CC8;
loc_82136CA0:
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r3,r7
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r7.s32, ctx.xer);
	// bne cr6,0x82136cb8
	if (!ctx.cr6.eq) goto loc_82136CB8;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplw cr6,r3,r6
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r6.u32, ctx.xer);
	// beq cr6,0x82136d74
	if (ctx.cr6.eq) goto loc_82136D74;
loc_82136CB8:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,80
	ctx.r11.s64 = ctx.r11.s64 + 80;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82136ca0
	if (ctx.cr6.lt) goto loc_82136CA0;
loc_82136CC8:
	// mr r11,r23
	ctx.r11.u64 = ctx.r23.u64;
loc_82136CCC:
	// stw r11,8(r8)
	PPC_STORE_U32(ctx.r8.u32 + 8, ctx.r11.u32);
	// cmplwi cr6,r4,8
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 8, ctx.xer);
	// bge cr6,0x82136cec
	if (!ctx.cr6.lt) goto loc_82136CEC;
	// lwz r11,16(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// twllei r4,0
	if (ctx.r4.u32 <= 0) __builtin_debugtrap();
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// divwu r9,r10,r4
	ctx.r9.u32 = ctx.r10.u32 / ctx.r4.u32;
	// stw r9,16(r8)
	PPC_STORE_U32(ctx.r8.u32 + 16, ctx.r9.u32);
loc_82136CEC:
	// bdnz 0x82136c50
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82136C50;
loc_82136CF0:
	// li r4,255
	ctx.r4.s64 = 255;
	// addi r3,r25,352
	ctx.r3.s64 = ctx.r25.s64 + 352;
	// bl 0x8233eaf0
	ctx.lr = 0x82136CFC;
	sub_8233EAF0(ctx, base);
loc_82136CFC:
	// lis r11,-32197
	ctx.r11.s64 = -2110062592;
	// lwz r3,-27096(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -27096);
	// bl 0x82388734
	ctx.lr = 0x82136D08;
	__imp__KeTlsGetValue(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82136d14
	if (!ctx.cr6.eq) goto loc_82136D14;
	// bl 0x821b3000
	ctx.lr = 0x82136D14;
	sub_821B3000(ctx, base);
loc_82136D14:
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// addi r28,r3,20
	ctx.r28.s64 = ctx.r3.s64 + 20;
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lis r26,-13569
	ctx.r26.s64 = -889257984;
	// addi r9,r11,7168
	ctx.r9.s64 = ctx.r11.s64 + 7168;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82136d3c
	if (!ctx.cr6.gt) goto loc_82136D3C;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,4492
	ctx.r10.s64 = ctx.r11.s64 + 4492;
	// stw r10,-13570(r26)
	PPC_STORE_U32(ctx.r26.u32 + -13570, ctx.r10.u32);
loc_82136D3C:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// addi r9,r11,7168
	ctx.r9.s64 = ctx.r11.s64 + 7168;
	// add r29,r11,r10
	ctx.r29.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r9,4(r28)
	PPC_STORE_U32(ctx.r28.u32 + 4, ctx.r9.u32);
	// lwz r8,4(r27)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// cmpwi cr6,r8,-1
	ctx.cr6.compare<int32_t>(ctx.r8.s32, -1, ctx.xer);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bne cr6,0x82136d7c
	if (!ctx.cr6.eq) goto loc_82136D7C;
	// bl 0x821372b0
	ctx.lr = 0x82136D6C;
	sub_821372B0(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x82136da8
	goto loc_82136DA8;
loc_82136D74:
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// b 0x82136ccc
	goto loc_82136CCC;
loc_82136D7C:
	// bl 0x82137430
	ctx.lr = 0x82136D80;
	sub_82137430(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,64
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 64, ctx.xer);
	// bge cr6,0x82136da8
	if (!ctx.cr6.lt) goto loc_82136DA8;
	// subfic r7,r3,64
	ctx.xer.ca = ctx.r3.u32 <= 64;
	ctx.r7.s64 = 64 - ctx.r3.s64;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82136ed8
	ctx.lr = 0x82136DA4;
	sub_82136ED8(ctx, base);
	// add r31,r3,r31
	ctx.r31.u64 = ctx.r3.u64 + ctx.r31.u64;
loc_82136DA8:
	// lwz r11,12(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// bgt cr6,0x82136dc0
	if (ctx.cr6.gt) goto loc_82136DC0;
	// addi r10,r31,8
	ctx.r10.s64 = ctx.r31.s64 + 8;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82136e10
	if (!ctx.cr6.lt) goto loc_82136E10;
loc_82136DC0:
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r10,r31,7
	ctx.r10.s64 = ctx.r31.s64 + 7;
	// rlwinm r30,r10,0,0,29
	ctx.r30.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82136de0
	if (ctx.cr6.eq) goto loc_82136DE0;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82136DE0;
	sub_82080000(ctx, base);
loc_82136DE0:
	// lis r11,585
	ctx.r11.s64 = 38338560;
	// mulli r3,r30,112
	ctx.r3.s64 = ctx.r30.s64 * 112;
	// ori r10,r11,9362
	ctx.r10.u64 = ctx.r11.u64 | 9362;
	// cmplw cr6,r30,r10
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82136df8
	if (!ctx.cr6.gt) goto loc_82136DF8;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
loc_82136DF8:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x82136E08;
	sub_82082030(ctx, base);
	// stw r30,12(r27)
	PPC_STORE_U32(ctx.r27.u32 + 12, ctx.r30.u32);
	// stw r3,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r3.u32);
loc_82136E10:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82136e70
	if (ctx.cr6.eq) goto loc_82136E70;
	// mulli r5,r31,112
	ctx.r5.s64 = ctx.r31.s64 * 112;
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x82136E28;
	sub_8233E4E0(ctx, base);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82136e70
	if (ctx.cr6.eq) goto loc_82136E70;
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
loc_82136E38:
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r9,r10,12
	ctx.r9.s64 = ctx.r10.s64 + 12;
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r9.u32);
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// add r8,r11,r10
	ctx.r8.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r24,16(r8)
	PPC_STORE_U32(ctx.r8.u32 + 16, ctx.r24.u32);
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// add r7,r11,r10
	ctx.r7.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 + 112;
	// stw r24,20(r7)
	PPC_STORE_U32(ctx.r7.u32 + 20, ctx.r24.u32);
	// bdnz 0x82136e38
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82136E38;
loc_82136E70:
	// lwz r11,4(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// stw r11,8(r27)
	PPC_STORE_U32(ctx.r27.u32 + 8, ctx.r11.u32);
	// bne cr6,0x82136e84
	if (!ctx.cr6.eq) goto loc_82136E84;
	// stw r24,8(r27)
	PPC_STORE_U32(ctx.r27.u32 + 8, ctx.r24.u32);
loc_82136E84:
	// stw r31,4(r27)
	PPC_STORE_U32(ctx.r27.u32 + 4, ctx.r31.u32);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82136ed0
	if (ctx.cr6.eq) goto loc_82136ED0;
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// cmplwi cr6,r10,7168
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 7168, ctx.xer);
	// addi r9,r11,4520
	ctx.r9.s64 = ctx.r11.s64 + 4520;
	// bge cr6,0x82136ea8
	if (!ctx.cr6.lt) goto loc_82136EA8;
	// stw r9,-13570(r26)
	PPC_STORE_U32(ctx.r26.u32 + -13570, ctx.r9.u32);
loc_82136EA8:
	// lwz r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-7168
	ctx.r11.s64 = ctx.r11.s64 + -7168;
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82136ec4
	if (ctx.cr6.eq) goto loc_82136EC4;
	// stw r9,-13570(r26)
	PPC_STORE_U32(ctx.r26.u32 + -13570, ctx.r9.u32);
loc_82136EC4:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// addi r11,r11,-7168
	ctx.r11.s64 = ctx.r11.s64 + -7168;
	// stw r11,4(r28)
	PPC_STORE_U32(ctx.r28.u32 + 4, ctx.r11.u32);
loc_82136ED0:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82136ED8"))) PPC_WEAK_FUNC(sub_82136ED8);
PPC_FUNC_IMPL(__imp__sub_82136ED8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x82136EE0;
	__restfpr_14(ctx, base);
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, ctx.f31.u64);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r21,r3
	ctx.r21.u64 = ctx.r3.u64;
	// stw r7,372(r1)
	PPC_STORE_U32(ctx.r1.u32 + 372, ctx.r7.u32);
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r16,r4
	ctx.r16.u64 = ctx.r4.u64;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// mr r15,r6
	ctx.r15.u64 = ctx.r6.u64;
	// bl 0x8213a6f8
	ctx.lr = 0x82136F04;
	sub_8213A6F8(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lis r11,-32197
	ctx.r11.s64 = -2110062592;
	// addi r27,r21,352
	ctx.r27.s64 = ctx.r21.s64 + 352;
	// lwz r3,-27096(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -27096);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// lwz r17,12(r31)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r28,324(r21)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r21.u32 + 324);
	// lwz r29,328(r21)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r21.u32 + 328);
	// bl 0x82388734
	ctx.lr = 0x82136F28;
	__imp__KeTlsGetValue(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82136f34
	if (!ctx.cr6.eq) goto loc_82136F34;
	// bl 0x821b3000
	ctx.lr = 0x82136F34;
	sub_821B3000(ctx, base);
loc_82136F34:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// addi r8,r17,15
	ctx.r8.s64 = ctx.r17.s64 + 15;
	// addi r30,r11,4492
	ctx.r30.s64 = ctx.r11.s64 + 4492;
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r10,r8,0,0,27
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFF0;
	// addi r26,r3,20
	ctx.r26.s64 = ctx.r3.s64 + 20;
	// add r7,r10,r11
	ctx.r7.u64 = ctx.r10.u64 + ctx.r11.u64;
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// lis r24,-13569
	ctx.r24.s64 = -889257984;
	// cmplw cr6,r7,r9
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x82136f68
	if (!ctx.cr6.gt) goto loc_82136F68;
	// stw r30,-13570(r24)
	PPC_STORE_U32(ctx.r24.u32 + -13570, ctx.r30.u32);
loc_82136F68:
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// mr r5,r17
	ctx.r5.u64 = ctx.r17.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// add r25,r11,r10
	ctx.r25.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r9,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r9.u32);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r25.u32);
	// bl 0x8233eaf0
	ctx.lr = 0x82136F90;
	sub_8233EAF0(ctx, base);
	// lwz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r10,4(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r7,0(r26)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r6,r11,15
	ctx.r6.s64 = ctx.r11.s64 + 15;
	// rlwinm r5,r6,0,0,27
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFF0;
	// add r4,r5,r10
	ctx.r4.u64 = ctx.r5.u64 + ctx.r10.u64;
	// cmplw cr6,r4,r7
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r7.u32, ctx.xer);
	// ble cr6,0x82136fb8
	if (!ctx.cr6.gt) goto loc_82136FB8;
	// stw r30,-13570(r24)
	PPC_STORE_U32(ctx.r24.u32 + -13570, ctx.r30.u32);
loc_82136FB8:
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// add r7,r5,r11
	ctx.r7.u64 = ctx.r5.u64 + ctx.r11.u64;
	// add r8,r11,r10
	ctx.r8.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r7,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r7.u32);
	// beq cr6,0x82137000
	if (ctx.cr6.eq) goto loc_82137000;
	// addi r10,r28,8
	ctx.r10.s64 = ctx.r28.s64 + 8;
	// mtctr r29
	ctx.ctr.u64 = ctx.r29.u64;
loc_82136FE0:
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x82136ff4
	if (ctx.cr6.eq) goto loc_82136FF4;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r11,r8
	PPC_STORE_U32(ctx.r11.u32 + ctx.r8.u32, ctx.r9.u32);
loc_82136FF4:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,112
	ctx.r10.s64 = ctx.r10.s64 + 112;
	// bdnz 0x82136fe0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82136FE0;
loc_82137000:
	// li r6,-1
	ctx.r6.s64 = -1;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82137050
	if (ctx.cr6.eq) goto loc_82137050;
	// addi r9,r28,8
	ctx.r9.s64 = ctx.r28.s64 + 8;
	// mtctr r29
	ctx.ctr.u64 = ctx.r29.u64;
	// li r7,1
	ctx.r7.s64 = 1;
loc_82137018:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
	// cmpwi cr6,r10,-1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, -1, ctx.xer);
	// beq cr6,0x82137030
	if (ctx.cr6.eq) goto loc_82137030;
	// rlwinm r11,r10,2,0,29
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r8
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
loc_82137030:
	// cmplw cr6,r11,r17
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r17.u32, ctx.xer);
	// bge cr6,0x82137048
	if (!ctx.cr6.lt) goto loc_82137048;
	// lbzx r10,r11,r27
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r27.u32);
	// cmplwi cr6,r10,255
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 255, ctx.xer);
	// beq cr6,0x82137048
	if (ctx.cr6.eq) goto loc_82137048;
	// stbx r7,r25,r11
	PPC_STORE_U8(ctx.r25.u32 + ctx.r11.u32, ctx.r7.u8);
loc_82137048:
	// addi r9,r9,112
	ctx.r9.s64 = ctx.r9.s64 + 112;
	// bdnz 0x82137018
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82137018;
loc_82137050:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// addi r14,r11,4520
	ctx.r14.s64 = ctx.r11.s64 + 4520;
	// beq cr6,0x82137098
	if (ctx.cr6.eq) goto loc_82137098;
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82137070
	if (!ctx.cr6.gt) goto loc_82137070;
	// stw r14,-13570(r24)
	PPC_STORE_U32(ctx.r24.u32 + -13570, ctx.r14.u32);
loc_82137070:
	// lwz r11,8(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// lwz r10,4(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// subf r11,r5,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r5.s64;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x8213708c
	if (ctx.cr6.eq) goto loc_8213708C;
	// stw r14,-13570(r24)
	PPC_STORE_U32(ctx.r24.u32 + -13570, ctx.r14.u32);
loc_8213708C:
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// subf r10,r5,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r5.s64;
	// stw r10,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r10.u32);
loc_82137098:
	// lwz r19,300(r21)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r21.u32 + 300);
	// li r27,0
	ctx.r27.s64 = 0;
	// lwz r23,312(r21)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r21.u32 + 312);
	// addi r18,r21,84
	ctx.r18.s64 = ctx.r21.s64 + 84;
	// lwz r22,348(r21)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r21.u32 + 348);
	// mr r24,r6
	ctx.r24.u64 = ctx.r6.u64;
	// cmplwi cr6,r17,16
	ctx.cr6.compare<uint32_t>(ctx.r17.u32, 16, ctx.xer);
	// mr r20,r17
	ctx.r20.u64 = ctx.r17.u64;
	// blt cr6,0x821370c0
	if (ctx.cr6.lt) goto loc_821370C0;
	// li r20,16
	ctx.r20.s64 = 16;
loc_821370C0:
	// li r25,0
	ctx.r25.s64 = 0;
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x821372a0
	if (ctx.cr6.eq) goto loc_821372A0;
	// mulli r11,r15,112
	ctx.r11.s64 = ctx.r15.s64 * 112;
	// add r11,r11,r16
	ctx.r11.u64 = ctx.r11.u64 + ctx.r16.u64;
	// addi r30,r11,4
	ctx.r30.s64 = ctx.r11.s64 + 4;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// lfs f31,256(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 256);
	ctx.f31.f64 = double(temp.f32);
loc_821370E4:
	// add r11,r25,r22
	ctx.r11.u64 = ctx.r25.u64 + ctx.r22.u64;
	// lwz r16,80(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// twllei r17,0
	if (ctx.r17.u32 <= 0) __builtin_debugtrap();
	// divwu r10,r11,r17
	ctx.r10.u32 = ctx.r11.u32 / ctx.r17.u32;
	// mullw r9,r10,r17
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r17.s32);
	// subf r29,r9,r11
	ctx.r29.s64 = ctx.r11.s64 - ctx.r9.s64;
	// lbzx r8,r16,r29
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r16.u32 + ctx.r29.u32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82137228
	if (!ctx.cr6.eq) goto loc_82137228;
	// rlwinm r11,r29,2,0,29
	ctx.r11.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// clrlwi r9,r23,31
	ctx.r9.u64 = ctx.r23.u32 & 0x1;
	// add r8,r29,r11
	ctx.r8.u64 = ctx.r29.u64 + ctx.r11.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// add r31,r11,r10
	ctx.r31.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lhz r11,74(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 74);
	// beq cr6,0x82137140
	if (ctx.cr6.eq) goto loc_82137140;
	// clrlwi r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82137154
	if (!ctx.cr6.eq) goto loc_82137154;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82137164
	goto loc_82137164;
loc_82137140:
	// rlwinm r10,r11,0,28,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xE;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82137154
	if (!ctx.cr6.eq) goto loc_82137154;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82137164
	goto loc_82137164;
loc_82137154:
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// and r10,r11,r19
	ctx.r10.u64 = ctx.r11.u64 & ctx.r19.u64;
	// addic r9,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r9.s64 = ctx.r10.s64 + -1;
	// subfe r11,r9,r10
	temp.u8 = (~ctx.r9.u32 + ctx.r10.u32 < ~ctx.r9.u32) | (~ctx.r9.u32 + ctx.r10.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r9.u64 + ctx.r10.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
loc_82137164:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137228
	if (ctx.cr6.eq) goto loc_82137228;
	// mr r5,r18
	ctx.r5.u64 = ctx.r18.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8213a800
	ctx.lr = 0x82137180;
	sub_8213A800(ctx, base);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,3
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 3, ctx.xer);
	// blt cr6,0x82137228
	if (ctx.cr6.lt) goto loc_82137228;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x821377a0
	ctx.lr = 0x8213719C;
	sub_821377A0(ctx, base);
	// fcmpu cr6,f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f1.f64, ctx.f31.f64);
	// blt cr6,0x82137228
	if (ctx.cr6.lt) goto loc_82137228;
	// lwz r11,312(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 312);
	// clrlwi r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x821371d0
	if (!ctx.cr6.eq) goto loc_821371D0;
	// addi r4,r31,8
	ctx.r4.s64 = ctx.r31.s64 + 8;
	// lhz r5,72(r31)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r31.u32 + 72);
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x82137618
	ctx.lr = 0x821371C4;
	sub_82137618(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137228
	if (ctx.cr6.eq) goto loc_82137228;
loc_821371D0:
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// addi r5,r31,8
	ctx.r5.s64 = ctx.r31.s64 + 8;
	// addi r4,r30,20
	ctx.r4.s64 = ctx.r30.s64 + 20;
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x821378c0
	ctx.lr = 0x821371E8;
	sub_821378C0(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137228
	if (ctx.cr6.eq) goto loc_82137228;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r9,372(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// mr r24,r29
	ctx.r24.u64 = ctx.r29.u64;
	// cmplw cr6,r27,r9
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r9.u32, ctx.xer);
	// stw r11,-4(r30)
	PPC_STORE_U32(ctx.r30.u32 + -4, ctx.r11.u32);
	// lwz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r8,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r8.u32);
	// stw r29,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r29.u32);
	// stw r10,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r10.u32);
	// addi r30,r30,112
	ctx.r30.s64 = ctx.r30.s64 + 112;
	// bge cr6,0x82137234
	if (!ctx.cr6.lt) goto loc_82137234;
loc_82137228:
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// cmplw cr6,r25,r20
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r20.u32, ctx.xer);
	// blt cr6,0x821370e4
	if (ctx.cr6.lt) goto loc_821370E4;
loc_82137234:
	// cmpwi cr6,r24,-1
	ctx.cr6.compare<int32_t>(ctx.r24.s32, -1, ctx.xer);
	// beq cr6,0x821372a4
	if (ctx.cr6.eq) goto loc_821372A4;
	// addi r11,r24,1
	ctx.r11.s64 = ctx.r24.s64 + 1;
loc_82137240:
	// stw r11,348(r21)
	PPC_STORE_U32(ctx.r21.u32 + 348, ctx.r11.u32);
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// beq cr6,0x82137290
	if (ctx.cr6.eq) goto loc_82137290;
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplw cr6,r9,r11
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82137264
	if (!ctx.cr6.gt) goto loc_82137264;
	// lis r11,-13569
	ctx.r11.s64 = -889257984;
	// stw r14,-13570(r11)
	PPC_STORE_U32(ctx.r11.u32 + -13570, ctx.r14.u32);
loc_82137264:
	// lwz r11,8(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// lwz r10,4(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// subf r11,r9,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r9.s64;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r10,r16
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r16.u32, ctx.xer);
	// beq cr6,0x82137284
	if (ctx.cr6.eq) goto loc_82137284;
	// lis r11,-13569
	ctx.r11.s64 = -889257984;
	// stw r14,-13570(r11)
	PPC_STORE_U32(ctx.r11.u32 + -13570, ctx.r14.u32);
loc_82137284:
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// subf r10,r9,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r9.s64;
	// stw r10,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r10.u32);
loc_82137290:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
loc_821372A0:
	// lwz r16,80(r1)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_821372A4:
	// lwz r11,348(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 348);
	// add r11,r11,r20
	ctx.r11.u64 = ctx.r11.u64 + ctx.r20.u64;
	// b 0x82137240
	goto loc_82137240;
}

__attribute__((alias("__imp__sub_821372B0"))) PPC_WEAK_FUNC(sub_821372B0);
PPC_FUNC_IMPL(__imp__sub_821372B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e444
	ctx.lr = 0x821372B8;
	__restfpr_19(ctx, base);
	// stfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, ctx.f31.u64);
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// addi r20,r28,84
	ctx.r20.s64 = ctx.r28.s64 + 84;
	// lwz r29,312(r28)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r28.u32 + 312);
	// lwz r21,300(r28)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r28.u32 + 300);
	// bl 0x8213a6f8
	ctx.lr = 0x821372E0;
	sub_8213A6F8(ctx, base);
	// li r22,0
	ctx.r22.s64 = 0;
	// mr r25,r22
	ctx.r25.u64 = ctx.r22.u64;
	// mr r24,r22
	ctx.r24.u64 = ctx.r22.u64;
	// mr r26,r22
	ctx.r26.u64 = ctx.r22.u64;
	// lwz r23,12(r31)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// lwz r31,0(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82137418
	if (ctx.cr6.eq) goto loc_82137418;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// clrlwi r19,r29,31
	ctx.r19.u64 = ctx.r29.u32 & 0x1;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// lfs f31,256(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 256);
	ctx.f31.f64 = double(temp.f32);
loc_82137314:
	// lhz r11,74(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 74);
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x82137334
	if (ctx.cr6.eq) goto loc_82137334;
	// clrlwi r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82137348
	if (!ctx.cr6.eq) goto loc_82137348;
	// mr r11,r22
	ctx.r11.u64 = ctx.r22.u64;
	// b 0x82137358
	goto loc_82137358;
loc_82137334:
	// rlwinm r10,r11,0,28,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xE;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82137348
	if (!ctx.cr6.eq) goto loc_82137348;
	// mr r11,r22
	ctx.r11.u64 = ctx.r22.u64;
	// b 0x82137358
	goto loc_82137358;
loc_82137348:
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// and r10,r11,r21
	ctx.r10.u64 = ctx.r11.u64 & ctx.r21.u64;
	// addic r9,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r9.s64 = ctx.r10.s64 + -1;
	// subfe r11,r9,r10
	temp.u8 = (~ctx.r9.u32 + ctx.r10.u32 < ~ctx.r9.u32) | (~ctx.r9.u32 + ctx.r10.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r9.u64 + ctx.r10.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
loc_82137358:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137408
	if (ctx.cr6.eq) goto loc_82137408;
	// addi r27,r31,8
	ctx.r27.s64 = ctx.r31.s64 + 8;
	// lhz r5,72(r31)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r31.u32 + 72);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// bl 0x82137618
	ctx.lr = 0x82137378;
	sub_82137618(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137408
	if (ctx.cr6.eq) goto loc_82137408;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8213a800
	ctx.lr = 0x82137394;
	sub_8213A800(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,3
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 3, ctx.xer);
	// blt cr6,0x82137408
	if (ctx.cr6.lt) goto loc_82137408;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x821377a0
	ctx.lr = 0x821373B0;
	sub_821377A0(ctx, base);
	// fcmpu cr6,f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f1.f64, ctx.f31.f64);
	// blt cr6,0x82137408
	if (ctx.cr6.lt) goto loc_82137408;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// addi r4,r30,20
	ctx.r4.s64 = ctx.r30.s64 + 20;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x821378c0
	ctx.lr = 0x821373D0;
	sub_821378C0(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137408
	if (ctx.cr6.eq) goto loc_82137408;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// mr r24,r26
	ctx.r24.u64 = ctx.r26.u64;
	// cmplwi cr6,r25,64
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 64, ctx.xer);
	// stw r11,-4(r30)
	PPC_STORE_U32(ctx.r30.u32 + -4, ctx.r11.u32);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r10.u32);
	// stw r26,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r26.u32);
	// stw r22,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r22.u32);
	// addi r30,r30,112
	ctx.r30.s64 = ctx.r30.s64 + 112;
	// bge cr6,0x82137418
	if (!ctx.cr6.lt) goto loc_82137418;
loc_82137408:
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// addi r31,r31,80
	ctx.r31.s64 = ctx.r31.s64 + 80;
	// cmplw cr6,r26,r23
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r23.u32, ctx.xer);
	// blt cr6,0x82137314
	if (ctx.cr6.lt) goto loc_82137314;
loc_82137418:
	// addi r11,r24,1
	ctx.r11.s64 = ctx.r24.s64 + 1;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// stw r11,348(r28)
	PPC_STORE_U32(ctx.r28.u32 + 348, ctx.r11.u32);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// b 0x8233e494
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82137430"))) PPC_WEAK_FUNC(sub_82137430);
PPC_FUNC_IMPL(__imp__sub_82137430) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e438
	ctx.lr = 0x82137438;
	__restfpr_16(ctx, base);
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// bl 0x8213a6f8
	ctx.lr = 0x82137450;
	sub_8213A6F8(ctx, base);
	// lwz r11,340(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 340);
	// li r25,0
	ctx.r25.s64 = 0;
	// lwz r10,344(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 344);
	// mr r24,r25
	ctx.r24.u64 = ctx.r25.u64;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// rlwinm r11,r11,27,5,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// cmplwi cr6,r11,8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8, ctx.xer);
	// mr r16,r11
	ctx.r16.u64 = ctx.r11.u64;
	// lwz r20,0(r30)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r21,328(r27)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r27.u32 + 328);
	// lwz r23,324(r27)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r27.u32 + 324);
	// bgt cr6,0x82137484
	if (ctx.cr6.gt) goto loc_82137484;
	// li r16,8
	ctx.r16.s64 = 8;
loc_82137484:
	// lwz r22,312(r27)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r27.u32 + 312);
	// mr r18,r25
	ctx.r18.u64 = ctx.r25.u64;
	// lwz r17,300(r27)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r27.u32 + 300);
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x8213760c
	if (ctx.cr6.eq) goto loc_8213760C;
	// addi r19,r23,20
	ctx.r19.s64 = ctx.r23.s64 + 20;
	// addi r26,r31,4
	ctx.r26.s64 = ctx.r31.s64 + 4;
loc_821374A0:
	// mr r28,r25
	ctx.r28.u64 = ctx.r25.u64;
	// mtctr r21
	ctx.ctr.u64 = ctx.r21.u64;
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r11,r19
	ctx.r11.u64 = ctx.r19.u64;
loc_821374B4:
	// lwz r10,-12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -12);
	// cmpwi cr6,r10,-1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, -1, ctx.xer);
	// beq cr6,0x821374dc
	if (ctx.cr6.eq) goto loc_821374DC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r8,-4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x821374dc
	if (!ctx.cr6.gt) goto loc_821374DC;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
loc_821374DC:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,112
	ctx.r11.s64 = ctx.r11.s64 + 112;
	// bdnz 0x821374b4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_821374B4;
	// cmplw cr6,r9,r16
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r16.u32, ctx.xer);
	// blt cr6,0x8213760c
	if (ctx.cr6.lt) goto loc_8213760C;
	// mulli r11,r28,112
	ctx.r11.s64 = ctx.r28.s64 * 112;
	// add r31,r11,r23
	ctx.r31.u64 = ctx.r11.u64 + ctx.r23.u64;
	// clrlwi r11,r22,31
	ctx.r11.u64 = ctx.r22.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r25,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r25.u32);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r25,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r25.u32);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r10,4,0,27
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// add r30,r11,r20
	ctx.r30.u64 = ctx.r11.u64 + ctx.r20.u64;
	// lhz r11,74(r30)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r30.u32 + 74);
	// beq cr6,0x82137538
	if (ctx.cr6.eq) goto loc_82137538;
	// clrlwi r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8213754c
	if (!ctx.cr6.eq) goto loc_8213754C;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// b 0x8213755c
	goto loc_8213755C;
loc_82137538:
	// rlwinm r10,r11,0,28,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xE;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8213754c
	if (!ctx.cr6.eq) goto loc_8213754C;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// b 0x8213755c
	goto loc_8213755C;
loc_8213754C:
	// lwz r11,76(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 76);
	// and r10,r11,r17
	ctx.r10.u64 = ctx.r11.u64 & ctx.r17.u64;
	// addic r9,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r9.s64 = ctx.r10.s64 + -1;
	// subfe r11,r9,r10
	temp.u8 = (~ctx.r9.u32 + ctx.r10.u32 < ~ctx.r9.u32) | (~ctx.r9.u32 + ctx.r10.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r9.u64 + ctx.r10.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
loc_8213755C:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137600
	if (ctx.cr6.eq) goto loc_82137600;
	// addi r5,r27,84
	ctx.r5.s64 = ctx.r27.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8213a800
	ctx.lr = 0x82137578;
	sub_8213A800(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,3
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 3, ctx.xer);
	// blt cr6,0x82137600
	if (ctx.cr6.lt) goto loc_82137600;
	// addi r4,r30,8
	ctx.r4.s64 = ctx.r30.s64 + 8;
	// lhz r5,72(r30)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r30.u32 + 72);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82137618
	ctx.lr = 0x82137594;
	sub_82137618(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137600
	if (ctx.cr6.eq) goto loc_82137600;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r4,r26,20
	ctx.r4.s64 = ctx.r26.s64 + 20;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x821378c0
	ctx.lr = 0x821375B8;
	sub_821378C0(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137600
	if (ctx.cr6.eq) goto loc_82137600;
	// add r11,r28,r27
	ctx.r11.u64 = ctx.r28.u64 + ctx.r27.u64;
	// mr r10,r24
	ctx.r10.u64 = ctx.r24.u64;
	// addi r24,r24,1
	ctx.r24.s64 = ctx.r24.s64 + 1;
	// cmplwi cr6,r24,62
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 62, ctx.xer);
	// stb r10,352(r11)
	PPC_STORE_U8(ctx.r11.u32 + 352, ctx.r10.u8);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r9,-4(r26)
	PPC_STORE_U32(ctx.r26.u32 + -4, ctx.r9.u32);
	// lwz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r8,0(r26)
	PPC_STORE_U32(ctx.r26.u32 + 0, ctx.r8.u32);
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r7,4(r26)
	PPC_STORE_U32(ctx.r26.u32 + 4, ctx.r7.u32);
	// lwz r6,12(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r6,8(r26)
	PPC_STORE_U32(ctx.r26.u32 + 8, ctx.r6.u32);
	// addi r26,r26,112
	ctx.r26.s64 = ctx.r26.s64 + 112;
	// bge cr6,0x8213760c
	if (!ctx.cr6.lt) goto loc_8213760C;
loc_82137600:
	// addi r18,r18,1
	ctx.r18.s64 = ctx.r18.s64 + 1;
	// cmplw cr6,r18,r21
	ctx.cr6.compare<uint32_t>(ctx.r18.u32, ctx.r21.u32, ctx.xer);
	// blt cr6,0x821374a0
	if (ctx.cr6.lt) goto loc_821374A0;
loc_8213760C:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// b 0x8233e488
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82137618"))) PPC_WEAK_FUNC(sub_82137618);
PPC_FUNC_IMPL(__imp__sub_82137618) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lwz r7,64(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 64);
	// addi r9,r3,84
	ctx.r9.s64 = ctx.r3.s64 + 84;
	// li r8,1
	ctx.r8.s64 = 1;
	// cmplwi cr6,r7,1
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 1, ctx.xer);
	// ble cr6,0x8213778c
	if (!ctx.cr6.gt) goto loc_8213778C;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// lfs f10,48(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	ctx.f10.f64 = double(temp.f32);
loc_82137638:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpwi cr6,r5,4
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 4, ctx.xer);
	// blt cr6,0x821376fc
	if (ctx.cr6.lt) goto loc_821376FC;
	// lfs f0,8(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r4,16
	ctx.r10.s64 = ctx.r4.s64 + 16;
	// lfs f13,4(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
loc_82137658:
	// lfs f9,-12(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -12);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f13,f9
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f7,-16(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -16);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,-8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f5,f12,f7,f8
	ctx.f5.f64 = double(std::fma(float(ctx.f12.f64), float(ctx.f7.f64), float(ctx.f8.f64)));
	// fmadds f4,f0,f6,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f0.f64), float(ctx.f6.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f11
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// fcmpu cr6,f3,f10
	ctx.cr6.compare(ctx.f3.f64, ctx.f10.f64);
	// blt cr6,0x82137774
	if (ctx.cr6.lt) goto loc_82137774;
	// lfs f9,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f13,f9
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f7,-4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f5,f12,f7,f8
	ctx.f5.f64 = double(std::fma(float(ctx.f12.f64), float(ctx.f7.f64), float(ctx.f8.f64)));
	// fmadds f4,f0,f6,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f0.f64), float(ctx.f6.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f11
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// fcmpu cr6,f3,f10
	ctx.cr6.compare(ctx.f3.f64, ctx.f10.f64);
	// blt cr6,0x82137760
	if (ctx.cr6.lt) goto loc_82137760;
	// lfs f9,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f13,f9
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f7,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,16(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f5,f12,f7,f8
	ctx.f5.f64 = double(std::fma(float(ctx.f12.f64), float(ctx.f7.f64), float(ctx.f8.f64)));
	// fmadds f4,f0,f6,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f0.f64), float(ctx.f6.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f11
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// fcmpu cr6,f3,f10
	ctx.cr6.compare(ctx.f3.f64, ctx.f10.f64);
	// blt cr6,0x82137768
	if (ctx.cr6.lt) goto loc_82137768;
	// lfs f9,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f12,f9
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// lfs f7,28(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,24(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f5,f0,f7,f8
	ctx.f5.f64 = double(std::fma(float(ctx.f0.f64), float(ctx.f7.f64), float(ctx.f8.f64)));
	// fmadds f4,f13,f6,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f13.f64), float(ctx.f6.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f11
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// fcmpu cr6,f3,f10
	ctx.cr6.compare(ctx.f3.f64, ctx.f10.f64);
	// blt cr6,0x82137770
	if (ctx.cr6.lt) goto loc_82137770;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r6,r5,-3
	ctx.r6.s64 = ctx.r5.s64 + -3;
	// addi r10,r10,48
	ctx.r10.s64 = ctx.r10.s64 + 48;
	// cmplw cr6,r11,r6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x82137658
	if (ctx.cr6.lt) goto loc_82137658;
loc_821376FC:
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// bge cr6,0x82137778
	if (!ctx.cr6.lt) goto loc_82137778;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f0,8(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lfs f12,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_82137728:
	// lfs f9,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f13,f9
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f7,-4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f5,f12,f7,f8
	ctx.f5.f64 = double(std::fma(float(ctx.f12.f64), float(ctx.f7.f64), float(ctx.f8.f64)));
	// fmadds f4,f0,f6,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f0.f64), float(ctx.f6.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f11
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f11.f64));
	// fcmpu cr6,f3,f10
	ctx.cr6.compare(ctx.f3.f64, ctx.f10.f64);
	// blt cr6,0x82137774
	if (ctx.cr6.lt) goto loc_82137774;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// blt cr6,0x82137728
	if (ctx.cr6.lt) goto loc_82137728;
	// b 0x82137774
	goto loc_82137774;
loc_82137760:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x82137774
	goto loc_82137774;
loc_82137768:
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// b 0x82137774
	goto loc_82137774;
loc_82137770:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
loc_82137774:
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
loc_82137778:
	// beq cr6,0x82137794
	if (ctx.cr6.eq) goto loc_82137794;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,16
	ctx.r9.s64 = ctx.r9.s64 + 16;
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// blt cr6,0x82137638
	if (ctx.cr6.lt) goto loc_82137638;
loc_8213778C:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_82137794:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213779C"))) PPC_WEAK_FUNC(sub_8213779C);
PPC_FUNC_IMPL(__imp__sub_8213779C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821377A0"))) PPC_WEAK_FUNC(sub_821377A0);
PPC_FUNC_IMPL(__imp__sub_821377A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x821377A8;
	__restfpr_27(ctx, base);
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x8233fa30
	ctx.lr = 0x821377B0;
	sub_8233FA30(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// addi r29,r11,31376
	ctx.r29.s64 = ctx.r11.s64 + 31376;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// lfs f0,92(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,408(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 408);
	ctx.f13.f64 = double(temp.f32);
	// fmr f27,f0
	ctx.f27.f64 = ctx.f0.f64;
	// fmr f26,f13
	ctx.f26.f64 = ctx.f13.f64;
	// fmr f29,f0
	ctx.f29.f64 = ctx.f0.f64;
	// fmr f28,f13
	ctx.f28.f64 = ctx.f13.f64;
	// beq cr6,0x82137888
	if (ctx.cr6.eq) goto loc_82137888;
	// lfs f31,36(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lfs f30,32(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 32);
	ctx.f30.f64 = double(temp.f32);
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
loc_821377F4:
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82257540
	ctx.lr = 0x82137804;
	sub_82257540(ctx, base);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f30
	ctx.cr6.compare(ctx.f0.f64, ctx.f30.f64);
	// bge cr6,0x82137818
	if (!ctx.cr6.lt) goto loc_82137818;
	// fmr f13,f30
	ctx.f13.f64 = ctx.f30.f64;
	// b 0x8213782c
	goto loc_8213782C;
loc_82137818:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// ble cr6,0x82137828
	if (!ctx.cr6.gt) goto loc_82137828;
	// fmr f13,f31
	ctx.f13.f64 = ctx.f31.f64;
	// b 0x8213782c
	goto loc_8213782C;
loc_82137828:
	// fmr f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f0.f64;
loc_8213782C:
	// lfs f0,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f30
	ctx.cr6.compare(ctx.f0.f64, ctx.f30.f64);
	// bge cr6,0x82137840
	if (!ctx.cr6.lt) goto loc_82137840;
	// fmr f0,f30
	ctx.f0.f64 = ctx.f30.f64;
	// b 0x8213784c
	goto loc_8213784C;
loc_82137840:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// ble cr6,0x8213784c
	if (!ctx.cr6.gt) goto loc_8213784C;
	// fmr f0,f31
	ctx.f0.f64 = ctx.f31.f64;
loc_8213784C:
	// fcmpu cr6,f13,f26
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f13.f64, ctx.f26.f64);
	// ble cr6,0x82137858
	if (!ctx.cr6.gt) goto loc_82137858;
	// fmr f26,f13
	ctx.f26.f64 = ctx.f13.f64;
loc_82137858:
	// fcmpu cr6,f13,f27
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f13.f64, ctx.f27.f64);
	// bge cr6,0x82137864
	if (!ctx.cr6.lt) goto loc_82137864;
	// fmr f27,f13
	ctx.f27.f64 = ctx.f13.f64;
loc_82137864:
	// fcmpu cr6,f0,f28
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f28.f64);
	// ble cr6,0x82137870
	if (!ctx.cr6.gt) goto loc_82137870;
	// fmr f28,f0
	ctx.f28.f64 = ctx.f0.f64;
loc_82137870:
	// fcmpu cr6,f0,f29
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f0.f64, ctx.f29.f64);
	// bge cr6,0x8213787c
	if (!ctx.cr6.lt) goto loc_8213787C;
	// fmr f29,f0
	ctx.f29.f64 = ctx.f0.f64;
loc_8213787C:
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// addi r31,r31,12
	ctx.r31.s64 = ctx.r31.s64 + 12;
	// bne 0x821377f4
	if (!ctx.cr0.eq) goto loc_821377F4;
loc_82137888:
	// fsubs f13,f28,f29
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = static_cast<float>(ctx.f28.f64 - ctx.f29.f64);
	// lfs f0,148(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 148);
	ctx.f0.f64 = double(temp.f32);
	// fsubs f12,f26,f27
	ctx.f12.f64 = static_cast<float>(ctx.f26.f64 - ctx.f27.f64);
	// cmplwi cr6,r28,3
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 3, ctx.xer);
	// fmuls f11,f13,f12
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmuls f1,f11,f0
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f0.f64));
	// bne cr6,0x821378ac
	if (!ctx.cr6.eq) goto loc_821378AC;
	// lfs f0,516(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 516);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
loc_821378AC:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x8233fa7c
	ctx.lr = 0x821378B8;
	__savefpr_26(ctx, base);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821378BC"))) PPC_WEAK_FUNC(sub_821378BC);
PPC_FUNC_IMPL(__imp__sub_821378BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821378C0"))) PPC_WEAK_FUNC(sub_821378C0);
PPC_FUNC_IMPL(__imp__sub_821378C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e444
	ctx.lr = 0x821378C8;
	__restfpr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x8233fa38
	ctx.lr = 0x821378D0;
	sub_8233FA38(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lhz r8,66(r5)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r5.u32 + 66);
	// mr r21,r4
	ctx.r21.u64 = ctx.r4.u64;
	// mr r24,r7
	ctx.r24.u64 = ctx.r7.u64;
	// mr r25,r6
	ctx.r25.u64 = ctx.r6.u64;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// addi r10,r4,4
	ctx.r10.s64 = ctx.r4.s64 + 4;
	// sth r8,84(r4)
	PPC_STORE_U16(ctx.r4.u32 + 84, ctx.r8.u16);
	// addi r19,r3,68
	ctx.r19.s64 = ctx.r3.s64 + 68;
	// lwz r7,48(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	// addi r27,r3,260
	ctx.r27.s64 = ctx.r3.s64 + 260;
	// stw r7,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r7.u32);
	// lis r9,-32250
	ctx.r9.s64 = -2113536000;
	// lwz r6,52(r5)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r5.u32 + 52);
	// addi r9,r9,31376
	ctx.r9.s64 = ctx.r9.s64 + 31376;
	// stw r6,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r6.u32);
	// addi r11,r5,48
	ctx.r11.s64 = ctx.r5.s64 + 48;
	// lwz r4,56(r5)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r5.u32 + 56);
	// lfs f31,48(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// stw r4,12(r21)
	PPC_STORE_U32(ctx.r21.u32 + 12, ctx.r4.u32);
	// li r22,1
	ctx.r22.s64 = 1;
	// lwz r3,60(r5)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + 60);
	// fmr f29,f31
	ctx.f29.f64 = ctx.f31.f64;
	// stw r3,16(r21)
	PPC_STORE_U32(ctx.r21.u32 + 16, ctx.r3.u32);
	// lfs f0,44(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 44);
	ctx.f0.f64 = double(temp.f32);
	// fmr f30,f31
	ctx.f30.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// fmr f28,f31
	ctx.f28.f64 = ctx.f31.f64;
	// addi r8,r11,4
	ctx.r8.s64 = ctx.r11.s64 + 4;
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// addi r7,r11,8
	ctx.r7.s64 = ctx.r11.s64 + 8;
	// bne cr6,0x821379b8
	if (!ctx.cr6.eq) goto loc_821379B8;
	// lwz r6,292(r26)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r26.u32 + 292);
	// lfs f12,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r5,284(r26)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r26.u32 + 284);
	// lfs f10,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lwz r4,288(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 288);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,52(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 52);
	ctx.f0.f64 = double(temp.f32);
	// stw r6,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r6.u32);
	// lfs f29,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f29.f64 = double(temp.f32);
	// stw r5,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r5.u32);
	// lfs f28,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f28.f64 = double(temp.f32);
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// lfs f30,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f11,f12,f30
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// fmadds f9,f10,f29,f11
	ctx.f9.f64 = double(std::fma(float(ctx.f10.f64), float(ctx.f29.f64), float(ctx.f11.f64)));
	// fmadds f8,f13,f28,f9
	ctx.f8.f64 = double(std::fma(float(ctx.f13.f64), float(ctx.f28.f64), float(ctx.f9.f64)));
	// fabs f7,f8
	ctx.f7.u64 = ctx.f8.u64 & 0x7FFFFFFFFFFFFFFF;
	// fcmpu cr6,f7,f0
	ctx.cr6.compare(ctx.f7.f64, ctx.f0.f64);
	// bge cr6,0x821379b0
	if (!ctx.cr6.lt) goto loc_821379B0;
loc_8213799C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x8233fa84
	ctx.lr = 0x821379AC;
	__savefpr_28(ctx, base);
	// b 0x8233e494
	__restgprlr_19(ctx, base);
	return;
loc_821379B0:
	// li r6,1
	ctx.r6.s64 = 1;
	// b 0x82137a04
	goto loc_82137A04;
loc_821379B8:
	// lfs f0,4(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f0,f13
	ctx.f12.f64 = static_cast<float>(ctx.f0.f64 - ctx.f13.f64);
	// lfs f11,8(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,8(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f8,f11,f10
	ctx.f8.f64 = static_cast<float>(ctx.f11.f64 - ctx.f10.f64);
	// lfs f7,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f5,f7,f6
	ctx.f5.f64 = static_cast<float>(ctx.f7.f64 - ctx.f6.f64);
	// lfs f4,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f0,52(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 52);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f2,f9,f12
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// fmadds f1,f3,f8,f2
	ctx.f1.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f8.f64), float(ctx.f2.f64)));
	// fmadds f13,f4,f5,f1
	ctx.f13.f64 = double(std::fma(float(ctx.f4.f64), float(ctx.f5.f64), float(ctx.f1.f64)));
	// fabs f12,f13
	ctx.f12.u64 = ctx.f13.u64 & 0x7FFFFFFFFFFFFFFF;
	// fcmpu cr6,f12,f0
	ctx.cr6.compare(ctx.f12.f64, ctx.f0.f64);
	// blt cr6,0x8213799c
	if (ctx.cr6.lt) goto loc_8213799C;
loc_82137A04:
	// lfs f0,4(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f11,8(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,0(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// li r11,1
	ctx.r11.s64 = 1;
	// fmadds f6,f11,f10,f12
	ctx.f6.f64 = double(std::fma(float(ctx.f11.f64), float(ctx.f10.f64), float(ctx.f12.f64)));
	// fmadds f5,f9,f8,f6
	ctx.f5.f64 = double(std::fma(float(ctx.f9.f64), float(ctx.f8.f64), float(ctx.f6.f64)));
	// fadds f4,f5,f7
	ctx.f4.f64 = double(float(ctx.f5.f64 + ctx.f7.f64));
	// fcmpu cr6,f4,f31
	ctx.cr6.compare(ctx.f4.f64, ctx.f31.f64);
	// blt cr6,0x82137a40
	if (ctx.cr6.lt) goto loc_82137A40;
	// li r11,0
	ctx.r11.s64 = 0;
loc_82137A40:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// mr r20,r11
	ctx.r20.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137a80
	if (ctx.cr6.eq) goto loc_82137A80;
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fneg f12,f0
	ctx.f12.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// lfs f11,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fneg f10,f13
	ctx.f10.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// lfs f9,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// fneg f8,f11
	ctx.f8.u64 = ctx.f11.u64 ^ 0x8000000000000000;
	// fneg f7,f9
	ctx.f7.u64 = ctx.f9.u64 ^ 0x8000000000000000;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// stfs f10,4(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// stfs f8,8(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// stfs f7,12(r10)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
loc_82137A80:
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82137c00
	if (ctx.cr6.eq) goto loc_82137C00;
	// clrlwi r23,r6,24
	ctx.r23.u64 = ctx.r6.u32 & 0xFF;
	// mr r31,r25
	ctx.r31.u64 = ctx.r25.u64;
	// addi r30,r10,16
	ctx.r30.s64 = ctx.r10.s64 + 16;
loc_82137A98:
	// addi r28,r11,1
	ctx.r28.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// divwu r11,r28,r24
	ctx.r11.u32 = ctx.r28.u32 / ctx.r24.u32;
	// twllei r24,0
	if (ctx.r24.u32 <= 0) __builtin_debugtrap();
	// mullw r10,r11,r24
	ctx.r10.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r24.s32);
	// subf r11,r10,r28
	ctx.r11.s64 = ctx.r28.s64 - ctx.r10.s64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r29,r11,r25
	ctx.r29.u64 = ctx.r11.u64 + ctx.r25.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// beq cr6,0x82137af8
	if (ctx.cr6.eq) goto loc_82137AF8;
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lfs f13,4(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f0,f28
	ctx.f12.f64 = static_cast<float>(ctx.f0.f64 - ctx.f28.f64);
	// lfs f11,8(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f10,f13,f30
	ctx.f10.f64 = static_cast<float>(ctx.f13.f64 - ctx.f30.f64);
	// fsubs f9,f11,f29
	ctx.f9.f64 = static_cast<float>(ctx.f11.f64 - ctx.f29.f64);
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f9,88(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// b 0x82137afc
	goto loc_82137AFC;
loc_82137AF8:
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
loc_82137AFC:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x82137c48
	ctx.lr = 0x82137B04;
	sub_82137C48(ctx, base);
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x82137b3c
	if (ctx.cr6.eq) goto loc_82137B3C;
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fneg f13,f0
	ctx.f13.u64 = ctx.f0.u64 ^ 0x8000000000000000;
	// lfs f11,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fneg f10,f12
	ctx.f10.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// fneg f9,f11
	ctx.f9.u64 = ctx.f11.u64 ^ 0x8000000000000000;
	// stfs f13,4(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r30.u32 + 4, temp.u32);
	// stfs f10,0(r30)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r30.u32 + 0, temp.u32);
	// stfs f9,8(r30)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r30.u32 + 8, temp.u32);
	// lfs f8,12(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	ctx.f8.f64 = double(temp.f32);
	// fneg f7,f8
	ctx.f7.u64 = ctx.f8.u64 ^ 0x8000000000000000;
	// stfs f7,12(r30)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r30.u32 + 12, temp.u32);
loc_82137B3C:
	// lwz r11,312(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 312);
	// rlwinm r10,r11,0,30,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82137be8
	if (!ctx.cr6.eq) goto loc_82137BE8;
	// lfs f10,8(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// li r10,2
	ctx.r10.s64 = 2;
	// lfs f9,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// addi r11,r19,36
	ctx.r11.s64 = ctx.r19.s64 + 36;
	// lfs f8,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
loc_82137B60:
	// lfs f0,4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f11,f10,f0
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// lfs f13,-4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f7,f8,f13,f11
	ctx.f7.f64 = double(std::fma(float(ctx.f8.f64), float(ctx.f13.f64), float(ctx.f11.f64)));
	// fmadds f6,f9,f12,f7
	ctx.f6.f64 = double(std::fma(float(ctx.f9.f64), float(ctx.f12.f64), float(ctx.f7.f64)));
	// fcmpu cr6,f6,f31
	ctx.cr6.compare(ctx.f6.f64, ctx.f31.f64);
	// blt cr6,0x82137bcc
	if (ctx.cr6.lt) goto loc_82137BCC;
	// lfs f11,4(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f7,f11,f12
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f6,8(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfs f11,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f4,f6,f0,f7
	ctx.f4.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f0.f64), float(ctx.f7.f64)));
	// fmadds f3,f5,f13,f4
	ctx.f3.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f13.f64), float(ctx.f4.f64)));
	// fadds f2,f3,f11
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f11.f64));
	// fcmpu cr6,f2,f31
	ctx.cr6.compare(ctx.f2.f64, ctx.f31.f64);
	// ble cr6,0x82137bcc
	if (!ctx.cr6.gt) goto loc_82137BCC;
	// lfs f7,4(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f7,f12
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// lfs f5,8(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,0(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmadds f3,f5,f0,f6
	ctx.f3.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f0.f64), float(ctx.f6.f64)));
	// fmadds f2,f4,f13,f3
	ctx.f2.f64 = double(std::fma(float(ctx.f4.f64), float(ctx.f13.f64), float(ctx.f3.f64)));
	// fadds f1,f2,f11
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f11.f64));
	// fcmpu cr6,f1,f31
	ctx.cr6.compare(ctx.f1.f64, ctx.f31.f64);
	// bgt cr6,0x82137be0
	if (ctx.cr6.gt) goto loc_82137BE0;
loc_82137BCC:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// cmplwi cr6,r10,6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 6, ctx.xer);
	// blt cr6,0x82137b60
	if (ctx.cr6.lt) goto loc_82137B60;
	// b 0x82137be8
	goto loc_82137BE8;
loc_82137BE0:
	// cmplwi cr6,r10,6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 6, ctx.xer);
	// blt cr6,0x82137bf0
	if (ctx.cr6.lt) goto loc_82137BF0;
loc_82137BE8:
	// addi r30,r30,16
	ctx.r30.s64 = ctx.r30.s64 + 16;
	// addi r22,r22,1
	ctx.r22.s64 = ctx.r22.s64 + 1;
loc_82137BF0:
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// addi r31,r31,12
	ctx.r31.s64 = ctx.r31.s64 + 12;
	// cmplw cr6,r28,r24
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r24.u32, ctx.xer);
	// blt cr6,0x82137a98
	if (ctx.cr6.lt) goto loc_82137A98;
loc_82137C00:
	// stw r22,0(r21)
	PPC_STORE_U32(ctx.r21.u32 + 0, ctx.r22.u32);
	// cmplwi cr6,r22,5
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 5, ctx.xer);
	// bge cr6,0x82137c30
	if (!ctx.cr6.lt) goto loc_82137C30;
	// subfic r10,r22,5
	ctx.xer.ca = ctx.r22.u32 <= 5;
	ctx.r10.s64 = 5 - ctx.r22.s64;
	// rlwinm r11,r22,4,0,27
	ctx.r11.u64 = rotl64(ctx.r22.u32 | (ctx.r22.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r21
	ctx.r11.u64 = ctx.r11.u64 + ctx.r21.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82137C1C:
	// stfs f31,4(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 4, temp.u32);
	// stfs f31,8(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 8, temp.u32);
	// stfs f31,12(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 12, temp.u32);
	// stfsu f31,16(r11)
	temp.f32 = float(ctx.f31.f64);
	ea = 16 + ctx.r11.u32;
	PPC_STORE_U32(ea, temp.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x82137c1c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82137C1C;
loc_82137C30:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x8233fa84
	ctx.lr = 0x82137C40;
	__savefpr_28(ctx, base);
	// b 0x8233e494
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82137C44"))) PPC_WEAK_FUNC(sub_82137C44);
PPC_FUNC_IMPL(__imp__sub_82137C44) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82137C48"))) PPC_WEAK_FUNC(sub_82137C48);
PPC_FUNC_IMPL(__imp__sub_82137C48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f13,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f10,f13,f12
	ctx.f10.f64 = static_cast<float>(ctx.f13.f64 - ctx.f12.f64);
	// fsubs f9,f0,f11
	ctx.f9.f64 = static_cast<float>(ctx.f0.f64 - ctx.f11.f64);
	// lfs f8,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,4(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fsubs f5,f0,f7
	ctx.f5.f64 = static_cast<float>(ctx.f0.f64 - ctx.f7.f64);
	// lfs f4,8(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f3,f8,f6
	ctx.f3.f64 = static_cast<float>(ctx.f8.f64 - ctx.f6.f64);
	// fsubs f2,f13,f4
	ctx.f2.f64 = static_cast<float>(ctx.f13.f64 - ctx.f4.f64);
	// lfs f1,4(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f13,f8,f1
	ctx.f13.f64 = static_cast<float>(ctx.f8.f64 - ctx.f1.f64);
	// lfs f0,36(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f12,f9,f10
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f10.f64));
	// fmuls f11,f2,f3
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// fmuls f8,f13,f5
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f5.f64));
	// fmsubs f7,f2,f5,f12
	ctx.f7.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f5.f64), -float(ctx.f12.f64)));
	// stfs f7,-12(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -12, temp.u32);
	// lwz r9,-12(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -12);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// fmsubs f6,f13,f10,f11
	ctx.f6.f64 = double(std::fma(float(ctx.f13.f64), float(ctx.f10.f64), -float(ctx.f11.f64)));
	// stfs f6,-16(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -16, temp.u32);
	// lwz r8,-16(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// fmsubs f5,f9,f3,f8
	ctx.f5.f64 = double(std::fma(float(ctx.f9.f64), float(ctx.f3.f64), -float(ctx.f8.f64)));
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// stfs f5,-8(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + -8, temp.u32);
	// lfs f4,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f4.f64 = double(temp.f32);
	// lwz r7,-8(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// stw r7,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r7.u32);
	// fmuls f3,f4,f4
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f4.f64));
	// lfs f2,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f1,f2,f2,f3
	ctx.f1.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f2.f64), float(ctx.f3.f64)));
	// lfs f13,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmr f12,f2
	ctx.f12.f64 = ctx.f2.f64;
	// fmadds f11,f13,f13,f1
	ctx.f11.f64 = double(std::fma(float(ctx.f13.f64), float(ctx.f13.f64), float(ctx.f1.f64)));
	// fsqrts f10,f11
	ctx.f10.f64 = double(simd::sqrt_f32(float(ctx.f11.f64)));
	// fdivs f9,f0,f10
	ctx.f9.f64 = double(float(ctx.f0.f64 / ctx.f10.f64));
	// fmuls f8,f2,f9
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f9.f64));
	// stfs f8,0(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f7,f4,f9
	ctx.f7.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// stfs f7,4(r3)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// fmuls f6,f13,f9
	ctx.f6.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// stfs f6,8(r3)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// lfs f5,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f3,f7
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f7.f64));
	// fmadds f1,f5,f8,f2
	ctx.f1.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f8.f64), float(ctx.f2.f64)));
	// fnmadds f0,f6,f4,f1
	ctx.f0.f64 = -double(std::fma(float(ctx.f6.f64), float(ctx.f4.f64), float(ctx.f1.f64)));
	// stfs f0,12(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82137D28"))) PPC_WEAK_FUNC(sub_82137D28);
PPC_FUNC_IMPL(__imp__sub_82137D28) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137d54
	if (ctx.cr6.eq) goto loc_82137D54;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82137D54;
	sub_82080000(ctx, base);
loc_82137D54:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137d6c
	if (ctx.cr6.eq) goto loc_82137D6C;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82137D6C;
	sub_82080000(ctx, base);
loc_82137D6C:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137d84
	if (ctx.cr6.eq) goto loc_82137D84;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82137D84;
	sub_82080000(ctx, base);
loc_82137D84:
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137d9c
	if (ctx.cr6.eq) goto loc_82137D9C;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82137D9C;
	sub_82080000(ctx, base);
loc_82137D9C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82137DB0"))) PPC_WEAK_FUNC(sub_82137DB0);
PPC_FUNC_IMPL(__imp__sub_82137DB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82137DB8;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,2340
	ctx.r10.s64 = 153354240;
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// lwz r11,44(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 44);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// ori r30,r10,37449
	ctx.r30.u64 = ctx.r10.u64 | 37449;
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r11.u32);
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r28,-1
	ctx.r28.s64 = -1;
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// mulli r3,r11,28
	ctx.r3.s64 = ctx.r11.s64 * 28;
	// ble cr6,0x82137dec
	if (!ctx.cr6.gt) goto loc_82137DEC;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
loc_82137DEC:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x82137DFC;
	sub_82082030(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// lwz r11,60(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 60);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r11.u32);
	// beq cr6,0x82137e34
	if (ctx.cr6.eq) goto loc_82137E34;
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// mulli r3,r11,28
	ctx.r3.s64 = ctx.r11.s64 * 28;
	// ble cr6,0x82137e20
	if (!ctx.cr6.gt) goto loc_82137E20;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
loc_82137E20:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x82137E30;
	sub_82082030(ctx, base);
	// stw r3,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r3.u32);
loc_82137E34:
	// lwz r11,44(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 44);
	// lwz r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r9,40(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 40);
	// beq cr6,0x82137e80
	if (ctx.cr6.eq) goto loc_82137E80;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
loc_82137E50:
	// li r7,6
	ctx.r7.s64 = 6;
	// addi r11,r9,-4
	ctx.r11.s64 = ctx.r9.s64 + -4;
	// addi r10,r8,-4
	ctx.r10.s64 = ctx.r8.s64 + -4;
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
loc_82137E60:
	// lwzu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	ctx.r7.u64 = PPC_LOAD_U32(ea);
	ctx.r11.u32 = ea;
	// stwu r7,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x82137e60
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82137E60;
	// stw r9,24(r8)
	PPC_STORE_U32(ctx.r8.u32 + 24, ctx.r9.u32);
	// addic. r6,r6,-1
	ctx.xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r6.s32, 0, ctx.xer);
	// addi r8,r8,28
	ctx.r8.s64 = ctx.r8.s64 + 28;
	// addi r9,r9,76
	ctx.r9.s64 = ctx.r9.s64 + 76;
	// bne 0x82137e50
	if (!ctx.cr0.eq) goto loc_82137E50;
loc_82137E80:
	// lwz r11,60(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 60);
	// lwz r9,56(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137ec4
	if (ctx.cr6.eq) goto loc_82137EC4;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
loc_82137E94:
	// li r8,6
	ctx.r8.s64 = 6;
	// addi r11,r9,60
	ctx.r11.s64 = ctx.r9.s64 + 60;
	// addi r10,r5,-4
	ctx.r10.s64 = ctx.r5.s64 + -4;
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_82137EA4:
	// lwzu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	ctx.r8.u64 = PPC_LOAD_U32(ea);
	ctx.r11.u32 = ea;
	// stwu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x82137ea4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82137EA4;
	// stw r9,24(r5)
	PPC_STORE_U32(ctx.r5.u32 + 24, ctx.r9.u32);
	// addic. r7,r7,-1
	ctx.xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// addi r5,r5,28
	ctx.r5.s64 = ctx.r5.s64 + 28;
	// addi r9,r9,140
	ctx.r9.s64 = ctx.r9.s64 + 140;
	// bne 0x82137e94
	if (!ctx.cr0.eq) goto loc_82137E94;
loc_82137EC4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82137ECC"))) PPC_WEAK_FUNC(sub_82137ECC);
PPC_FUNC_IMPL(__imp__sub_82137ECC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82137ED0"))) PPC_WEAK_FUNC(sub_82137ED0);
PPC_FUNC_IMPL(__imp__sub_82137ED0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82137f30
	ctx.lr = 0x82137EF0;
	sub_82137F30(ctx, base);
	// clrlwi r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137f10
	if (ctx.cr6.eq) goto loc_82137F10;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82137f10
	if (ctx.cr6.eq) goto loc_82137F10;
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82137F10;
	sub_82080000(ctx, base);
loc_82137F10:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82137F2C"))) PPC_WEAK_FUNC(sub_82137F2C);
PPC_FUNC_IMPL(__imp__sub_82137F2C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82137F30"))) PPC_WEAK_FUNC(sub_82137F30);
PPC_FUNC_IMPL(__imp__sub_82137F30) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r9,r10,-29576
	ctx.r9.s64 = ctx.r10.s64 + -29576;
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137f70
	if (ctx.cr6.eq) goto loc_82137F70;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82137F70;
	sub_82080000(ctx, base);
loc_82137F70:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82137f88
	if (ctx.cr6.eq) goto loc_82137F88;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82137F88;
	sub_82080000(ctx, base);
loc_82137F88:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82137fa0
	if (ctx.cr6.eq) goto loc_82137FA0;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82137FA0;
	sub_82246E18(ctx, base);
loc_82137FA0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82137FB4"))) PPC_WEAK_FUNC(sub_82137FB4);
PPC_FUNC_IMPL(__imp__sub_82137FB4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82137FB8"))) PPC_WEAK_FUNC(sub_82137FB8);
PPC_FUNC_IMPL(__imp__sub_82137FB8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,28(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// lwz r10,32(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82138020
	if (!ctx.cr6.eq) goto loc_82138020;
	// lwz r31,28(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// lwz r11,28(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// rlwinm r10,r11,29,3,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// cmplwi cr6,r10,64
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 64, ctx.xer);
	// bge cr6,0x82137ff0
	if (!ctx.cr6.lt) goto loc_82137FF0;
	// li r10,64
	ctx.r10.s64 = 64;
loc_82137FF0:
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,28(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82138008;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82138020:
	// lwz r11,36(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// lwz r10,32(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82138048
	if (!ctx.cr6.eq) goto loc_82138048;
	// lwz r3,32(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82138048:
	// lwz r9,36(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r8,40(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// lwz r7,44(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// beq cr6,0x82138084
	if (ctx.cr6.eq) goto loc_82138084;
loc_82138068:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x8213809c
	if (ctx.cr6.eq) goto loc_8213809C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82138068
	if (ctx.cr6.lt) goto loc_82138068;
loc_82138084:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_8213809C:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821380B4"))) PPC_WEAK_FUNC(sub_821380B4);
PPC_FUNC_IMPL(__imp__sub_821380B4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821380B8"))) PPC_WEAK_FUNC(sub_821380B8);
PPC_FUNC_IMPL(__imp__sub_821380B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x821380C0;
	__restfpr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,28(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r24,r4
	ctx.r24.u64 = ctx.r4.u64;
	// cmplw cr6,r4,r11
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x821380e4
	if (!ctx.cr6.eq) goto loc_821380E4;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
loc_821380E4:
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// bne cr6,0x82138128
	if (!ctx.cr6.eq) goto loc_82138128;
	// li r27,0
	ctx.r27.s64 = 0;
	// stw r27,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r27.u32);
	// stw r27,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r27.u32);
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138118
	if (ctx.cr6.eq) goto loc_82138118;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138118;
	sub_82080000(ctx, base);
loc_82138118:
	// stw r27,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r27.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
loc_82138128:
	// lwz r11,40(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// add r28,r11,r10
	ctx.r28.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mullw r11,r28,r24
	ctx.r11.s64 = int64_t(ctx.r28.s32) * int64_t(ctx.r24.s32);
	// addi r11,r11,15
	ctx.r11.s64 = ctx.r11.s64 + 15;
	// rlwinm r30,r11,0,0,27
	ctx.r30.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82082030
	ctx.lr = 0x82138154;
	sub_82082030(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// bl 0x8233eaf0
	ctx.lr = 0x82138164;
	sub_8233EAF0(ctx, base);
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// lwz r9,36(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x821381b4
	if (!ctx.cr6.eq) goto loc_821381B4;
	// lwz r30,36(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mullw r5,r30,r28
	ctx.r5.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r28.s32);
	// bl 0x8233e4e0
	ctx.lr = 0x82138188;
	sub_8233E4E0(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x8213821c
	if (ctx.cr6.eq) goto loc_8213821C;
	// mtctr r30
	ctx.ctr.u64 = ctx.r30.u64;
loc_82138198:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821381a8
	if (ctx.cr6.eq) goto loc_821381A8;
	// stw r11,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r11.u32);
loc_821381A8:
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// bdnz 0x82138198
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82138198;
	// b 0x8213821c
	goto loc_8213821C;
loc_821381B4:
	// lwz r29,24(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// li r27,0
	ctx.r27.s64 = 0;
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// mr r30,r25
	ctx.r30.u64 = ctx.r25.u64;
	// mr r26,r27
	ctx.r26.u64 = ctx.r27.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138218
	if (ctx.cr6.eq) goto loc_82138218;
loc_821381D0:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138204
	if (ctx.cr6.eq) goto loc_82138204;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x821381EC;
	sub_8233E4E0(ctx, base);
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// stw r30,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r30.u32);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r30,r30,r28
	ctx.r30.u64 = ctx.r30.u64 + ctx.r28.u64;
	// stw r27,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r27.u32);
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
loc_82138204:
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// addi r26,r26,1
	ctx.r26.s64 = ctx.r26.s64 + 1;
	// add r29,r29,r28
	ctx.r29.u64 = ctx.r29.u64 + ctx.r28.u64;
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x821381d0
	if (ctx.cr6.lt) goto loc_821381D0;
loc_82138218:
	// stw r27,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r27.u32);
loc_8213821C:
	// stw r24,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r24.u32);
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138240
	if (ctx.cr6.eq) goto loc_82138240;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138240;
	sub_82080000(ctx, base);
loc_82138240:
	// stw r25,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r25.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82138250"))) PPC_WEAK_FUNC(sub_82138250);
PPC_FUNC_IMPL(__imp__sub_82138250) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e44c
	ctx.lr = 0x82138258;
	__restfpr_21(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r4,3
	ctx.r11.s64 = ctx.r4.s64 + 3;
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// rlwinm r26,r11,0,0,29
	ctx.r26.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// cmplw cr6,r26,r10
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82138280
	if (!ctx.cr6.eq) goto loc_82138280;
loc_82138274:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
loc_82138280:
	// lwz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82138274
	if (ctx.cr6.lt) goto loc_82138274;
	// lwz r11,44(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 44);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// li r5,-1
	ctx.r5.s64 = -1;
	// add r25,r11,r26
	ctx.r25.u64 = ctx.r11.u64 + ctx.r26.u64;
	// li r4,16
	ctx.r4.s64 = 16;
	// mullw r11,r10,r25
	ctx.r11.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r25.s32);
	// addi r9,r11,15
	ctx.r9.s64 = ctx.r11.s64 + 15;
	// rlwinm r31,r9,0,0,27
	ctx.r31.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFF0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82082030
	ctx.lr = 0x821382B8;
	sub_82082030(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// bl 0x8233eaf0
	ctx.lr = 0x821382C8;
	sub_8233EAF0(ctx, base);
	// lwz r9,36(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// lwz r10,40(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// mr r31,r22
	ctx.r31.u64 = ctx.r22.u64;
	// mr r27,r26
	ctx.r27.u64 = ctx.r26.u64;
	// lwz r28,24(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// lwz r29,44(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 44);
	// lwz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// add r23,r10,r29
	ctx.r23.u64 = ctx.r10.u64 + ctx.r29.u64;
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x821382f4
	if (ctx.cr6.lt) goto loc_821382F4;
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
loc_821382F4:
	// li r21,0
	ctx.r21.s64 = 0;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82138390
	if (ctx.cr6.eq) goto loc_82138390;
	// mr r24,r9
	ctx.r24.u64 = ctx.r9.u64;
loc_82138304:
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x82138314;
	sub_8233E4E0(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138324
	if (ctx.cr6.eq) goto loc_82138324;
	// stw r31,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r31.u32);
loc_82138324:
	// add r9,r29,r31
	ctx.r9.u64 = ctx.r29.u64 + ctx.r31.u64;
	// mr r11,r21
	ctx.r11.u64 = ctx.r21.u64;
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82138358
	if (ctx.cr6.eq) goto loc_82138358;
	// subf r11,r9,r29
	ctx.r11.s64 = ctx.r29.s64 - ctx.r9.s64;
	// mtctr r27
	ctx.ctr.u64 = ctx.r27.u64;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// add r8,r11,r28
	ctx.r8.u64 = ctx.r11.u64 + ctx.r28.u64;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
loc_82138348:
	// lbzx r7,r8,r10
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r10.u32);
	// stb r7,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r7.u8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// bdnz 0x82138348
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82138348;
loc_82138358:
	// cmplw cr6,r11,r26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r26.u32, ctx.xer);
	// bge cr6,0x82138380
	if (!ctx.cr6.lt) goto loc_82138380;
	// add r10,r11,r9
	ctx.r10.u64 = ctx.r11.u64 + ctx.r9.u64;
	// subf. r11,r11,r26
	ctx.r11.s64 = ctx.r26.s64 - ctx.r11.s64;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// li r9,255
	ctx.r9.s64 = 255;
	// beq 0x82138380
	if (ctx.cr0.eq) goto loc_82138380;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
loc_82138378:
	// stbu r9,1(r10)
	ea = 1 + ctx.r10.u32;
	PPC_STORE_U8(ea, ctx.r9.u8);
	ctx.r10.u32 = ea;
	// bdnz 0x82138378
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82138378;
loc_82138380:
	// addic. r24,r24,-1
	ctx.xer.ca = ctx.r24.u32 > 0;
	ctx.r24.s64 = ctx.r24.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// add r31,r31,r25
	ctx.r31.u64 = ctx.r31.u64 + ctx.r25.u64;
	// add r28,r28,r23
	ctx.r28.u64 = ctx.r28.u64 + ctx.r23.u64;
	// bne 0x82138304
	if (!ctx.cr0.eq) goto loc_82138304;
loc_82138390:
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// lwz r10,36(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x821383b4
	if (!ctx.cr6.lt) goto loc_821383B4;
	// subf r10,r10,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r10.s64;
	// subf r11,r25,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r25.s64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_821383AC:
	// stwux r21,r11,r25
	ea = ctx.r11.u32 + ctx.r25.u32;
	PPC_STORE_U32(ea, ctx.r21.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x821383ac
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_821383AC;
loc_821383B4:
	// stw r26,40(r30)
	PPC_STORE_U32(ctx.r30.u32 + 40, ctx.r26.u32);
	// lwz r11,24(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821383d8
	if (ctx.cr6.eq) goto loc_821383D8;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821383D8;
	sub_82080000(ctx, base);
loc_821383D8:
	// stw r22,24(r30)
	PPC_STORE_U32(ctx.r30.u32 + 24, ctx.r22.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821383E8"))) PPC_WEAK_FUNC(sub_821383E8);
PPC_FUNC_IMPL(__imp__sub_821383E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e440
	ctx.lr = 0x821383F0;
	__restfpr_18(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// addi r29,r3,260
	ctx.r29.s64 = ctx.r3.s64 + 260;
	// stw r30,256(r3)
	PPC_STORE_U32(ctx.r3.u32 + 256, ctx.r30.u32);
	// li r4,4000
	ctx.r4.s64 = 4000;
	// stw r30,260(r3)
	PPC_STORE_U32(ctx.r3.u32 + 260, ctx.r30.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r30,264(r31)
	PPC_STORE_U32(ctx.r31.u32 + 264, ctx.r30.u32);
	// stw r30,268(r31)
	PPC_STORE_U32(ctx.r31.u32 + 268, ctx.r30.u32);
	// stw r30,272(r31)
	PPC_STORE_U32(ctx.r31.u32 + 272, ctx.r30.u32);
	// stw r30,276(r31)
	PPC_STORE_U32(ctx.r31.u32 + 276, ctx.r30.u32);
	// bl 0x82305000
	ctx.lr = 0x82138424;
	sub_82305000(ctx, base);
	// li r10,64
	ctx.r10.s64 = 64;
	// li r9,64
	ctx.r9.s64 = 64;
	// stw r30,796(r31)
	PPC_STORE_U32(ctx.r31.u32 + 796, ctx.r30.u32);
	// addi r11,r29,12
	ctx.r11.s64 = ctx.r29.s64 + 12;
	// stw r9,792(r31)
	PPC_STORE_U32(ctx.r31.u32 + 792, ctx.r9.u32);
	// li r29,1
	ctx.r29.s64 = 1;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82138440:
	// stw r30,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r30.u32);
	// stwu r29,8(r11)
	ea = 8 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r29.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x82138440
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82138440;
	// stw r30,800(r31)
	PPC_STORE_U32(ctx.r31.u32 + 800, ctx.r30.u32);
	// addi r28,r31,800
	ctx.r28.s64 = ctx.r31.s64 + 800;
	// stw r30,804(r31)
	PPC_STORE_U32(ctx.r31.u32 + 804, ctx.r30.u32);
	// li r4,4000
	ctx.r4.s64 = 4000;
	// stw r30,808(r31)
	PPC_STORE_U32(ctx.r31.u32 + 808, ctx.r30.u32);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r30,812(r31)
	PPC_STORE_U32(ctx.r31.u32 + 812, ctx.r30.u32);
	// stw r30,816(r31)
	PPC_STORE_U32(ctx.r31.u32 + 816, ctx.r30.u32);
	// bl 0x82305000
	ctx.lr = 0x82138470;
	sub_82305000(ctx, base);
	// li r10,1024
	ctx.r10.s64 = 1024;
	// addi r11,r28,12
	ctx.r11.s64 = ctx.r28.s64 + 12;
	// stw r30,9016(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9016, ctx.r30.u32);
	// stw r10,9012(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9012, ctx.r10.u32);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82138484:
	// stw r30,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r30.u32);
	// stwu r29,8(r11)
	ea = 8 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r29.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x82138484
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82138484;
	// addi r28,r31,9020
	ctx.r28.s64 = ctx.r31.s64 + 9020;
	// li r4,36
	ctx.r4.s64 = 36;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8213c8a8
	ctx.lr = 0x821384A0;
	sub_8213C8A8(ctx, base);
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// addi r27,r31,9100
	ctx.r27.s64 = ctx.r31.s64 + 9100;
	// addi r10,r11,-29556
	ctx.r10.s64 = ctx.r11.s64 + -29556;
	// li r4,44
	ctx.r4.s64 = 44;
	// stw r10,9020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9020, ctx.r10.u32);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8213c8a8
	ctx.lr = 0x821384BC;
	sub_8213C8A8(ctx, base);
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r26,r31,9180
	ctx.r26.s64 = ctx.r31.s64 + 9180;
	// addi r8,r9,-29528
	ctx.r8.s64 = ctx.r9.s64 + -29528;
	// li r4,44
	ctx.r4.s64 = 44;
	// stw r8,9100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9100, ctx.r8.u32);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x8213c8a8
	ctx.lr = 0x821384D8;
	sub_8213C8A8(ctx, base);
	// lis r7,-32249
	ctx.r7.s64 = -2113470464;
	// addi r25,r31,9260
	ctx.r25.s64 = ctx.r31.s64 + 9260;
	// addi r6,r7,-29500
	ctx.r6.s64 = ctx.r7.s64 + -29500;
	// li r4,36
	ctx.r4.s64 = 36;
	// stw r6,9180(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9180, ctx.r6.u32);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x8213c8a8
	ctx.lr = 0x821384F4;
	sub_8213C8A8(ctx, base);
	// lis r5,-32249
	ctx.r5.s64 = -2113470464;
	// addi r24,r31,9340
	ctx.r24.s64 = ctx.r31.s64 + 9340;
	// addi r3,r5,-29472
	ctx.r3.s64 = ctx.r5.s64 + -29472;
	// li r4,36
	ctx.r4.s64 = 36;
	// stw r3,9260(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9260, ctx.r3.u32);
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x8213c8a8
	ctx.lr = 0x82138510;
	sub_8213C8A8(ctx, base);
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// addi r23,r31,9420
	ctx.r23.s64 = ctx.r31.s64 + 9420;
	// addi r10,r11,-29472
	ctx.r10.s64 = ctx.r11.s64 + -29472;
	// li r4,44
	ctx.r4.s64 = 44;
	// stw r10,9340(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9340, ctx.r10.u32);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x8213c8a8
	ctx.lr = 0x8213852C;
	sub_8213C8A8(ctx, base);
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r22,r31,9500
	ctx.r22.s64 = ctx.r31.s64 + 9500;
	// addi r8,r9,-29444
	ctx.r8.s64 = ctx.r9.s64 + -29444;
	// li r4,44
	ctx.r4.s64 = 44;
	// stw r8,9420(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9420, ctx.r8.u32);
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x8213c8a8
	ctx.lr = 0x82138548;
	sub_8213C8A8(ctx, base);
	// lis r7,-32249
	ctx.r7.s64 = -2113470464;
	// addi r21,r31,9580
	ctx.r21.s64 = ctx.r31.s64 + 9580;
	// addi r6,r7,-29444
	ctx.r6.s64 = ctx.r7.s64 + -29444;
	// li r4,36
	ctx.r4.s64 = 36;
	// stw r6,9500(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9500, ctx.r6.u32);
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x8213c8a8
	ctx.lr = 0x82138564;
	sub_8213C8A8(ctx, base);
	// lis r5,-32249
	ctx.r5.s64 = -2113470464;
	// addi r20,r31,9660
	ctx.r20.s64 = ctx.r31.s64 + 9660;
	// addi r3,r5,-29472
	ctx.r3.s64 = ctx.r5.s64 + -29472;
	// li r4,36
	ctx.r4.s64 = 36;
	// stw r3,9580(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9580, ctx.r3.u32);
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x8213c8a8
	ctx.lr = 0x82138580;
	sub_8213C8A8(ctx, base);
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// addi r19,r31,9740
	ctx.r19.s64 = ctx.r31.s64 + 9740;
	// addi r18,r11,-29416
	ctx.r18.s64 = ctx.r11.s64 + -29416;
	// li r4,36
	ctx.r4.s64 = 36;
	// stw r18,9660(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9660, ctx.r18.u32);
	// mr r3,r19
	ctx.r3.u64 = ctx.r19.u64;
	// bl 0x8213c8a8
	ctx.lr = 0x8213859C;
	sub_8213C8A8(ctx, base);
	// stw r18,9740(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9740, ctx.r18.u32);
	// stw r30,9860(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9860, ctx.r30.u32);
	// addi r3,r31,9860
	ctx.r3.s64 = ctx.r31.s64 + 9860;
	// stw r30,9864(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9864, ctx.r30.u32);
	// li r4,32
	ctx.r4.s64 = 32;
	// stw r30,9868(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9868, ctx.r30.u32);
	// stw r30,9872(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9872, ctx.r30.u32);
	// bl 0x8213a610
	ctx.lr = 0x821385BC;
	sub_8213A610(ctx, base);
	// stw r28,9820(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9820, ctx.r28.u32);
	// stw r30,9876(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9876, ctx.r30.u32);
	// li r5,256
	ctx.r5.s64 = 256;
	// stw r30,9880(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9880, ctx.r30.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r30,10012(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10012, ctx.r30.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stb r29,9088(r31)
	PPC_STORE_U8(ctx.r31.u32 + 9088, ctx.r29.u8);
	// stb r29,9248(r31)
	PPC_STORE_U8(ctx.r31.u32 + 9248, ctx.r29.u8);
	// stw r26,9824(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9824, ctx.r26.u32);
	// stb r30,9328(r31)
	PPC_STORE_U8(ctx.r31.u32 + 9328, ctx.r30.u8);
	// stw r25,9828(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9828, ctx.r25.u32);
	// stb r30,9408(r31)
	PPC_STORE_U8(ctx.r31.u32 + 9408, ctx.r30.u8);
	// stw r24,9832(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9832, ctx.r24.u32);
	// stb r30,9488(r31)
	PPC_STORE_U8(ctx.r31.u32 + 9488, ctx.r30.u8);
	// stw r23,9836(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9836, ctx.r23.u32);
	// stb r29,9168(r31)
	PPC_STORE_U8(ctx.r31.u32 + 9168, ctx.r29.u8);
	// stw r27,9840(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9840, ctx.r27.u32);
	// stb r30,9648(r31)
	PPC_STORE_U8(ctx.r31.u32 + 9648, ctx.r30.u8);
	// stw r21,9844(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9844, ctx.r21.u32);
	// stb r29,9728(r31)
	PPC_STORE_U8(ctx.r31.u32 + 9728, ctx.r29.u8);
	// stw r20,9848(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9848, ctx.r20.u32);
	// stb r29,9808(r31)
	PPC_STORE_U8(ctx.r31.u32 + 9808, ctx.r29.u8);
	// stw r19,9852(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9852, ctx.r19.u32);
	// stb r30,9568(r31)
	PPC_STORE_U8(ctx.r31.u32 + 9568, ctx.r30.u8);
	// stw r22,9856(r31)
	PPC_STORE_U32(ctx.r31.u32 + 9856, ctx.r22.u32);
	// bl 0x8233eaf0
	ctx.lr = 0x82138628;
	sub_8233EAF0(ctx, base);
	// li r5,128
	ctx.r5.s64 = 128;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,9884
	ctx.r3.s64 = ctx.r31.s64 + 9884;
	// bl 0x8233eaf0
	ctx.lr = 0x82138638;
	sub_8233EAF0(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82081c00
	ctx.lr = 0x82138640;
	sub_82081C00(ctx, base);
	// lis r9,-32176
	ctx.r9.s64 = -2108686336;
	// li r11,128
	ctx.r11.s64 = 128;
	// addi r29,r9,5528
	ctx.r29.s64 = ctx.r9.s64 + 5528;
	// li r10,64
	ctx.r10.s64 = 64;
	// li r3,128
	ctx.r3.s64 = 128;
	// stw r11,5528(r9)
	PPC_STORE_U32(ctx.r9.u32 + 5528, ctx.r11.u32);
	// stw r10,4(r29)
	PPC_STORE_U32(ctx.r29.u32 + 4, ctx.r10.u32);
	// bl 0x82139b18
	ctx.lr = 0x82138660;
	sub_82139B18(ctx, base);
	// lbz r8,44(r29)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r29.u32 + 44);
	// stw r30,48(r29)
	PPC_STORE_U32(ctx.r29.u32 + 48, ctx.r30.u32);
	// lis r7,-32197
	ctx.r7.s64 = -2110062592;
	// ori r11,r8,128
	ctx.r11.u64 = ctx.r8.u64 | 128;
	// stb r11,44(r29)
	PPC_STORE_U8(ctx.r29.u32 + 44, ctx.r11.u8);
	// lwz r3,-27096(r7)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + -27096);
	// bl 0x82388734
	ctx.lr = 0x8213867C;
	__imp__KeTlsGetValue(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82138688
	if (!ctx.cr6.eq) goto loc_82138688;
	// bl 0x821b3000
	ctx.lr = 0x82138688;
	sub_821B3000(ctx, base);
loc_82138688:
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821386a4
	if (ctx.cr6.eq) goto loc_821386A4;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_821386A4:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8233e490
	__restgprlr_18(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821386AC"))) PPC_WEAK_FUNC(sub_821386AC);
PPC_FUNC_IMPL(__imp__sub_821386AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821386B0"))) PPC_WEAK_FUNC(sub_821386B0);
PPC_FUNC_IMPL(__imp__sub_821386B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x8213c948
	ctx.lr = 0x821386D0;
	sub_8213C948(ctx, base);
	// clrlwi r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821386f0
	if (ctx.cr6.eq) goto loc_821386F0;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x821386f0
	if (ctx.cr6.eq) goto loc_821386F0;
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821386F0;
	sub_82080000(ctx, base);
loc_821386F0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213870C"))) PPC_WEAK_FUNC(sub_8213870C);
PPC_FUNC_IMPL(__imp__sub_8213870C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82138710"))) PPC_WEAK_FUNC(sub_82138710);
PPC_FUNC_IMPL(__imp__sub_82138710) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82138718;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r29,64
	ctx.r29.s64 = 64;
loc_82138728:
	// lwz r31,0(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82138758
	if (ctx.cr6.eq) goto loc_82138758;
	// lwz r11,324(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 324);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213874c
	if (ctx.cr6.eq) goto loc_8213874C;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213874C;
	sub_82080000(ctx, base);
loc_8213874C:
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138758;
	sub_82080000(ctx, base);
loc_82138758:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// bne 0x82138728
	if (!ctx.cr0.eq) goto loc_82138728;
	// lwz r11,10012(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 10012);
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x821387ac
	if (!ctx.cr6.gt) goto loc_821387AC;
	// addi r30,r28,9884
	ctx.r30.s64 = ctx.r28.s64 + 9884;
loc_82138778:
	// lwz r31,0(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82138798
	if (ctx.cr6.eq) goto loc_82138798;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82137d28
	ctx.lr = 0x8213878C;
	sub_82137D28(ctx, base);
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138798;
	sub_82080000(ctx, base);
loc_82138798:
	// lwz r11,10012(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 10012);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82138778
	if (ctx.cr6.lt) goto loc_82138778;
loc_821387AC:
	// lwz r11,9860(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9860);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821387c4
	if (ctx.cr6.eq) goto loc_821387C4;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821387C4;
	sub_82080000(ctx, base);
loc_821387C4:
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r30,r11,-29364
	ctx.r30.s64 = ctx.r11.s64 + -29364;
	// stw r10,9864(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9864, ctx.r10.u32);
	// addi r31,r28,9740
	ctx.r31.s64 = ctx.r28.s64 + 9740;
	// lwz r3,9812(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9812);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r30,9740(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9740, ctx.r30.u32);
	// beq cr6,0x82138824
	if (ctx.cr6.eq) goto loc_82138824;
	// lwz r10,-4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82138810
	if (ctx.cr6.eq) goto loc_82138810;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8213880C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82138824
	goto loc_82138824;
loc_82138810:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138824
	if (ctx.cr6.eq) goto loc_82138824;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138824;
	sub_82080000(ctx, base);
loc_82138824:
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// addi r29,r11,-29576
	ctx.r29.s64 = ctx.r11.s64 + -29576;
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138850
	if (ctx.cr6.eq) goto loc_82138850;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138850;
	sub_82080000(ctx, base);
loc_82138850:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138868
	if (ctx.cr6.eq) goto loc_82138868;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138868;
	sub_82080000(ctx, base);
loc_82138868:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82138880
	if (ctx.cr6.eq) goto loc_82138880;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82138880;
	sub_82246E18(ctx, base);
loc_82138880:
	// lwz r3,9732(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9732);
	// addi r31,r28,9660
	ctx.r31.s64 = ctx.r28.s64 + 9660;
	// stw r30,9660(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9660, ctx.r30.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821388d0
	if (ctx.cr6.eq) goto loc_821388D0;
	// lwz r10,-4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x821388bc
	if (ctx.cr6.eq) goto loc_821388BC;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x821388B8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x821388d0
	goto loc_821388D0;
loc_821388BC:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821388d0
	if (ctx.cr6.eq) goto loc_821388D0;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821388D0;
	sub_82080000(ctx, base);
loc_821388D0:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821388f4
	if (ctx.cr6.eq) goto loc_821388F4;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821388F4;
	sub_82080000(ctx, base);
loc_821388F4:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213890c
	if (ctx.cr6.eq) goto loc_8213890C;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213890C;
	sub_82080000(ctx, base);
loc_8213890C:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82138924
	if (ctx.cr6.eq) goto loc_82138924;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82138924;
	sub_82246E18(ctx, base);
loc_82138924:
	// lwz r3,9652(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9652);
	// addi r31,r28,9580
	ctx.r31.s64 = ctx.r28.s64 + 9580;
	// stw r30,9580(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9580, ctx.r30.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82138974
	if (ctx.cr6.eq) goto loc_82138974;
	// lwz r10,-4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82138960
	if (ctx.cr6.eq) goto loc_82138960;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8213895C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82138974
	goto loc_82138974;
loc_82138960:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138974
	if (ctx.cr6.eq) goto loc_82138974;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138974;
	sub_82080000(ctx, base);
loc_82138974:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138998
	if (ctx.cr6.eq) goto loc_82138998;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138998;
	sub_82080000(ctx, base);
loc_82138998:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821389b0
	if (ctx.cr6.eq) goto loc_821389B0;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821389B0;
	sub_82080000(ctx, base);
loc_821389B0:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821389c8
	if (ctx.cr6.eq) goto loc_821389C8;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x821389C8;
	sub_82246E18(ctx, base);
loc_821389C8:
	// lwz r3,9572(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9572);
	// addi r31,r28,9500
	ctx.r31.s64 = ctx.r28.s64 + 9500;
	// stw r30,9500(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9500, ctx.r30.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82138a18
	if (ctx.cr6.eq) goto loc_82138A18;
	// lwz r10,-4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82138a04
	if (ctx.cr6.eq) goto loc_82138A04;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82138A00;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82138a18
	goto loc_82138A18;
loc_82138A04:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138a18
	if (ctx.cr6.eq) goto loc_82138A18;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138A18;
	sub_82080000(ctx, base);
loc_82138A18:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138a3c
	if (ctx.cr6.eq) goto loc_82138A3C;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138A3C;
	sub_82080000(ctx, base);
loc_82138A3C:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138a54
	if (ctx.cr6.eq) goto loc_82138A54;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138A54;
	sub_82080000(ctx, base);
loc_82138A54:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82138a6c
	if (ctx.cr6.eq) goto loc_82138A6C;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82138A6C;
	sub_82246E18(ctx, base);
loc_82138A6C:
	// lwz r3,9492(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9492);
	// addi r31,r28,9420
	ctx.r31.s64 = ctx.r28.s64 + 9420;
	// stw r30,9420(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9420, ctx.r30.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82138abc
	if (ctx.cr6.eq) goto loc_82138ABC;
	// lwz r10,-4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82138aa8
	if (ctx.cr6.eq) goto loc_82138AA8;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82138AA4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82138abc
	goto loc_82138ABC;
loc_82138AA8:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138abc
	if (ctx.cr6.eq) goto loc_82138ABC;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138ABC;
	sub_82080000(ctx, base);
loc_82138ABC:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138ae0
	if (ctx.cr6.eq) goto loc_82138AE0;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138AE0;
	sub_82080000(ctx, base);
loc_82138AE0:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138af8
	if (ctx.cr6.eq) goto loc_82138AF8;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138AF8;
	sub_82080000(ctx, base);
loc_82138AF8:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82138b10
	if (ctx.cr6.eq) goto loc_82138B10;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82138B10;
	sub_82246E18(ctx, base);
loc_82138B10:
	// lwz r3,9412(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9412);
	// addi r31,r28,9340
	ctx.r31.s64 = ctx.r28.s64 + 9340;
	// stw r30,9340(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9340, ctx.r30.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82138b60
	if (ctx.cr6.eq) goto loc_82138B60;
	// lwz r10,-4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82138b4c
	if (ctx.cr6.eq) goto loc_82138B4C;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82138B48;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82138b60
	goto loc_82138B60;
loc_82138B4C:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138b60
	if (ctx.cr6.eq) goto loc_82138B60;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138B60;
	sub_82080000(ctx, base);
loc_82138B60:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138b84
	if (ctx.cr6.eq) goto loc_82138B84;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138B84;
	sub_82080000(ctx, base);
loc_82138B84:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138b9c
	if (ctx.cr6.eq) goto loc_82138B9C;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138B9C;
	sub_82080000(ctx, base);
loc_82138B9C:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82138bb4
	if (ctx.cr6.eq) goto loc_82138BB4;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82138BB4;
	sub_82246E18(ctx, base);
loc_82138BB4:
	// lwz r3,9332(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9332);
	// addi r31,r28,9260
	ctx.r31.s64 = ctx.r28.s64 + 9260;
	// stw r30,9260(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9260, ctx.r30.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82138c04
	if (ctx.cr6.eq) goto loc_82138C04;
	// lwz r10,-4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82138bf0
	if (ctx.cr6.eq) goto loc_82138BF0;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82138BEC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82138c04
	goto loc_82138C04;
loc_82138BF0:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138c04
	if (ctx.cr6.eq) goto loc_82138C04;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138C04;
	sub_82080000(ctx, base);
loc_82138C04:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138c28
	if (ctx.cr6.eq) goto loc_82138C28;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138C28;
	sub_82080000(ctx, base);
loc_82138C28:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138c40
	if (ctx.cr6.eq) goto loc_82138C40;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138C40;
	sub_82080000(ctx, base);
loc_82138C40:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82138c58
	if (ctx.cr6.eq) goto loc_82138C58;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82138C58;
	sub_82246E18(ctx, base);
loc_82138C58:
	// lwz r3,9252(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9252);
	// addi r31,r28,9180
	ctx.r31.s64 = ctx.r28.s64 + 9180;
	// stw r30,9180(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9180, ctx.r30.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82138ca8
	if (ctx.cr6.eq) goto loc_82138CA8;
	// lwz r10,-4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82138c94
	if (ctx.cr6.eq) goto loc_82138C94;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82138C90;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82138ca8
	goto loc_82138CA8;
loc_82138C94:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138ca8
	if (ctx.cr6.eq) goto loc_82138CA8;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138CA8;
	sub_82080000(ctx, base);
loc_82138CA8:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138ccc
	if (ctx.cr6.eq) goto loc_82138CCC;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138CCC;
	sub_82080000(ctx, base);
loc_82138CCC:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138ce4
	if (ctx.cr6.eq) goto loc_82138CE4;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138CE4;
	sub_82080000(ctx, base);
loc_82138CE4:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82138cfc
	if (ctx.cr6.eq) goto loc_82138CFC;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82138CFC;
	sub_82246E18(ctx, base);
loc_82138CFC:
	// lwz r3,9172(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9172);
	// addi r31,r28,9100
	ctx.r31.s64 = ctx.r28.s64 + 9100;
	// stw r30,9100(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9100, ctx.r30.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82138d4c
	if (ctx.cr6.eq) goto loc_82138D4C;
	// lwz r10,-4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82138d38
	if (ctx.cr6.eq) goto loc_82138D38;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82138D34;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82138d4c
	goto loc_82138D4C;
loc_82138D38:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138d4c
	if (ctx.cr6.eq) goto loc_82138D4C;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138D4C;
	sub_82080000(ctx, base);
loc_82138D4C:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138d70
	if (ctx.cr6.eq) goto loc_82138D70;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138D70;
	sub_82080000(ctx, base);
loc_82138D70:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138d88
	if (ctx.cr6.eq) goto loc_82138D88;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138D88;
	sub_82080000(ctx, base);
loc_82138D88:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82138da0
	if (ctx.cr6.eq) goto loc_82138DA0;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82138DA0;
	sub_82246E18(ctx, base);
loc_82138DA0:
	// lwz r3,9092(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9092);
	// addi r31,r28,9020
	ctx.r31.s64 = ctx.r28.s64 + 9020;
	// stw r30,9020(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9020, ctx.r30.u32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82138df0
	if (ctx.cr6.eq) goto loc_82138DF0;
	// lwz r10,-4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x82138ddc
	if (ctx.cr6.eq) goto loc_82138DDC;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82138DD8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x82138df0
	goto loc_82138DF0;
loc_82138DDC:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138df0
	if (ctx.cr6.eq) goto loc_82138DF0;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138DF0;
	sub_82080000(ctx, base);
loc_82138DF0:
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138e14
	if (ctx.cr6.eq) goto loc_82138E14;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138E14;
	sub_82080000(ctx, base);
loc_82138E14:
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82138e2c
	if (ctx.cr6.eq) goto loc_82138E2C;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82138E2C;
	sub_82080000(ctx, base);
loc_82138E2C:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82138e44
	if (ctx.cr6.eq) goto loc_82138E44;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82138E44;
	sub_82246E18(ctx, base);
loc_82138E44:
	// lwz r10,808(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 808);
	// addi r11,r28,800
	ctx.r11.s64 = ctx.r28.s64 + 800;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82138e5c
	if (ctx.cr6.eq) goto loc_82138E5C;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82138E5C;
	sub_82246E18(ctx, base);
loc_82138E5C:
	// lwz r10,268(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 268);
	// addi r11,r28,260
	ctx.r11.s64 = ctx.r28.s64 + 260;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82138e74
	if (ctx.cr6.eq) goto loc_82138E74;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82138E74;
	sub_82246E18(ctx, base);
loc_82138E74:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82138E7C"))) PPC_WEAK_FUNC(sub_82138E7C);
PPC_FUNC_IMPL(__imp__sub_82138E7C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82138E80"))) PPC_WEAK_FUNC(sub_82138E80);
PPC_FUNC_IMPL(__imp__sub_82138E80) {
	PPC_FUNC_PROLOGUE();
	// lwz r9,10012(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10012);
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82138eb4
	if (ctx.cr6.eq) goto loc_82138EB4;
	// addi r10,r3,9884
	ctx.r10.s64 = ctx.r3.s64 + 9884;
loc_82138E94:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r7,0(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82138eb4
	if (ctx.cr6.eq) goto loc_82138EB4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82138e94
	if (ctx.cr6.lt) goto loc_82138E94;
loc_82138EB4:
	// addi r10,r11,2471
	ctx.r10.s64 = ctx.r11.s64 + 2471;
	// rlwinm r11,r4,16,16,31
	ctx.r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 16) & 0xFFFF;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r3,260
	ctx.r10.s64 = ctx.r3.s64 + 260;
	// cmplwi cr6,r11,64
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 64, ctx.xer);
	// lwzx r8,r9,r3
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// blt cr6,0x82138ed8
	if (ctx.cr6.lt) goto loc_82138ED8;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82138f04
	goto loc_82138F04;
loc_82138ED8:
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// clrlwi r7,r4,16
	ctx.r7.u64 = ctx.r4.u32 & 0xFFFF;
	// add r5,r9,r10
	ctx.r5.u64 = ctx.r9.u64 + ctx.r10.u64;
	// lwz r4,20(r5)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r5.u32 + 20);
	// cmplw cr6,r4,r7
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82138ef8
	if (ctx.cr6.eq) goto loc_82138EF8;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82138f04
	goto loc_82138F04;
loc_82138EF8:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r11,r9,r10
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
loc_82138F04:
	// lwz r11,316(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 316);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82138f20
	if (ctx.cr6.eq) goto loc_82138F20;
	// lwz r10,20(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// rlwinm r9,r11,4,0,27
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// lwzx r7,r9,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// stw r7,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r7.u32);
loc_82138F20:
	// lwz r10,20(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82138F34"))) PPC_WEAK_FUNC(sub_82138F34);
PPC_FUNC_IMPL(__imp__sub_82138F34) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82138F38"))) PPC_WEAK_FUNC(sub_82138F38);
PPC_FUNC_IMPL(__imp__sub_82138F38) {
	PPC_FUNC_PROLOGUE();
	// lwz r9,10012(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10012);
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82138f6c
	if (ctx.cr6.eq) goto loc_82138F6C;
	// addi r10,r3,9884
	ctx.r10.s64 = ctx.r3.s64 + 9884;
loc_82138F4C:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r7,0(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x82138f6c
	if (ctx.cr6.eq) goto loc_82138F6C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82138f4c
	if (ctx.cr6.lt) goto loc_82138F4C;
loc_82138F6C:
	// addi r10,r11,2471
	ctx.r10.s64 = ctx.r11.s64 + 2471;
	// rlwinm r11,r4,16,16,31
	ctx.r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 16) & 0xFFFF;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r3,260
	ctx.r10.s64 = ctx.r3.s64 + 260;
	// cmplwi cr6,r11,64
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 64, ctx.xer);
	// lwzx r8,r9,r3
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// blt cr6,0x82138f90
	if (ctx.cr6.lt) goto loc_82138F90;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82138fbc
	goto loc_82138FBC;
loc_82138F90:
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// clrlwi r7,r4,16
	ctx.r7.u64 = ctx.r4.u32 & 0xFFFF;
	// add r5,r9,r10
	ctx.r5.u64 = ctx.r9.u64 + ctx.r10.u64;
	// lwz r4,20(r5)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r5.u32 + 20);
	// cmplw cr6,r4,r7
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x82138fb0
	if (ctx.cr6.eq) goto loc_82138FB0;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82138fbc
	goto loc_82138FBC;
loc_82138FB0:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r11,r9,r10
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
loc_82138FBC:
	// lwz r11,316(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 316);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82138fdc
	if (ctx.cr6.eq) goto loc_82138FDC;
	// lwz r9,20(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// rlwinm r10,r11,4,0,27
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// stw r9,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r9.u32);
loc_82138FDC:
	// lwz r10,20(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 20);
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r3,12(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82138FF0"))) PPC_WEAK_FUNC(sub_82138FF0);
PPC_FUNC_IMPL(__imp__sub_82138FF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x82138FF8;
	__restfpr_29(ctx, base);
	// stfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// fmr f31,f1
	ctx.f31.f64 = ctx.f1.f64;
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82081c00
	ctx.lr = 0x82139014;
	sub_82081C00(ctx, base);
	// bl 0x82139908
	ctx.lr = 0x82139018;
	sub_82139908(ctx, base);
	// lis r11,-32197
	ctx.r11.s64 = -2110062592;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,-27096(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -27096);
	// bl 0x82388734
	ctx.lr = 0x82139028;
	__imp__KeTlsGetValue(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82139034
	if (!ctx.cr6.eq) goto loc_82139034;
	// bl 0x821b3000
	ctx.lr = 0x82139034;
	sub_821B3000(ctx, base);
loc_82139034:
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82139048
	if (ctx.cr6.eq) goto loc_82139048;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r11.u32);
loc_82139048:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82139078
	if (ctx.cr6.eq) goto loc_82139078;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// li r10,15
	ctx.r10.s64 = 15;
	// addi r9,r11,-29560
	ctx.r9.s64 = ctx.r11.s64 + -29560;
	// li r8,-1
	ctx.r8.s64 = -1;
	// stw r10,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r10.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// stw r8,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r8.u32);
	// stw r7,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r7.u32);
	// b 0x8213907c
	goto loc_8213907C;
loc_82139078:
	// li r31,0
	ctx.r31.s64 = 0;
loc_8213907C:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r29,9580
	ctx.r3.s64 = ctx.r29.s64 + 9580;
	// bl 0x8213a0d0
	ctx.lr = 0x82139088;
	sub_8213A0D0(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r9,4(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// stfs f31,92(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// stw r8,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r8.u32);
	// beq cr6,0x821390f4
	if (ctx.cr6.eq) goto loc_821390F4;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lis r9,-32250
	ctx.r9.s64 = -2113536000;
	// addi r8,r11,20
	ctx.r8.s64 = ctx.r11.s64 + 20;
	// addi r7,r9,31376
	ctx.r7.s64 = ctx.r9.s64 + 31376;
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r5,4(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r4,8(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r3,12(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lfs f0,92(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// stw r6,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r6.u32);
	// stw r5,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r5.u32);
	// stw r4,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r4.u32);
	// stw r3,32(r11)
	PPC_STORE_U32(ctx.r11.u32 + 32, ctx.r3.u32);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stfs f0,16(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 16, temp.u32);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stfs f0,12(r10)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
loc_821390F4:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r29,800
	ctx.r3.s64 = ctx.r29.s64 + 800;
	// bl 0x8217dcb0
	ctx.lr = 0x82139100;
	sub_8217DCB0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213910C"))) PPC_WEAK_FUNC(sub_8213910C);
PPC_FUNC_IMPL(__imp__sub_8213910C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82139110"))) PPC_WEAK_FUNC(sub_82139110);
PPC_FUNC_IMPL(__imp__sub_82139110) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// clrlwi r10,r4,31
	ctx.r10.u64 = ctx.r4.u32 & 0x1;
	// addi r9,r11,-31304
	ctx.r9.s64 = ctx.r11.s64 + -31304;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// beq cr6,0x82139144
	if (ctx.cr6.eq) goto loc_82139144;
	// bl 0x821397f0
	ctx.lr = 0x82139140;
	sub_821397F0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82139144:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82139158"))) PPC_WEAK_FUNC(sub_82139158);
PPC_FUNC_IMPL(__imp__sub_82139158) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82139160;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r30,r4,16,16,31
	ctx.r30.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 16) & 0xFFFF;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// addi r31,r3,800
	ctx.r31.s64 = ctx.r3.s64 + 800;
	// cmplwi cr6,r30,1024
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 1024, ctx.xer);
	// blt cr6,0x82139180
	if (ctx.cr6.lt) goto loc_82139180;
	// li r28,0
	ctx.r28.s64 = 0;
	// b 0x821391ac
	goto loc_821391AC;
loc_82139180:
	// rlwinm r11,r30,3,0,28
	ctx.r11.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 3) & 0xFFFFFFF8;
	// clrlwi r10,r29,16
	ctx.r10.u64 = ctx.r29.u32 & 0xFFFF;
	// add r9,r11,r31
	ctx.r9.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lwz r8,20(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmplw cr6,r8,r10
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x821391a0
	if (ctx.cr6.eq) goto loc_821391A0;
	// li r28,0
	ctx.r28.s64 = 0;
	// b 0x821391ac
	goto loc_821391AC;
loc_821391A0:
	// addi r11,r30,3
	ctx.r11.s64 = ctx.r30.s64 + 3;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r28,r10,r31
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r31.u32);
loc_821391AC:
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// addi r3,r3,9580
	ctx.r3.s64 = ctx.r3.s64 + 9580;
	// bl 0x82139fe8
	ctx.lr = 0x821391B8;
	sub_82139FE8(ctx, base);
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x823052d8
	ctx.lr = 0x821391C4;
	sub_823052D8(ctx, base);
	// rlwinm r11,r30,3,0,28
	ctx.r11.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 3) & 0xFFFFFFF8;
	// clrlwi r9,r29,16
	ctx.r9.u64 = ctx.r29.u32 & 0xFFFF;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82139214
	if (!ctx.cr6.eq) goto loc_82139214;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lis r9,1
	ctx.r9.s64 = 65536;
	// stw r10,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r10.u32);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x821391f8
	if (!ctx.cr6.eq) goto loc_821391F8;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r10,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r10.u32);
loc_821391F8:
	// addi r11,r30,3
	ctx.r11.s64 = ctx.r30.s64 + 3;
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// stwx r10,r9,r31
	PPC_STORE_U32(ctx.r9.u32 + ctx.r31.u32, ctx.r10.u32);
	// lwz r11,8212(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8212);
	// addi r8,r11,1
	ctx.r8.s64 = ctx.r11.s64 + 1;
	// stw r8,8212(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8212, ctx.r8.u32);
loc_82139214:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x823051a8
	ctx.lr = 0x8213921C;
	sub_823051A8(ctx, base);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x8213923c
	if (ctx.cr6.eq) goto loc_8213923C;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8213923C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_8213923C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82139244"))) PPC_WEAK_FUNC(sub_82139244);
PPC_FUNC_IMPL(__imp__sub_82139244) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82139248"))) PPC_WEAK_FUNC(sub_82139248);
PPC_FUNC_IMPL(__imp__sub_82139248) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e44c
	ctx.lr = 0x82139250;
	__restfpr_21(ctx, base);
	// stwu r1,-432(r1)
	ea = -432 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r22,256(r3)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r3.u32 + 256);
	// li r21,0
	ctx.r21.s64 = 0;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r8,r21
	ctx.r8.u64 = ctx.r21.u64;
	// mr r10,r21
	ctx.r10.u64 = ctx.r21.u64;
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x821392a4
	if (ctx.cr6.eq) goto loc_821392A4;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// mtctr r22
	ctx.ctr.u64 = ctx.r22.u64;
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// subf r9,r9,r3
	ctx.r9.s64 = ctx.r3.s64 - ctx.r9.s64;
loc_82139280:
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82139294
	if (ctx.cr6.eq) goto loc_82139294;
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// b 0x82139298
	goto loc_82139298;
loc_82139294:
	// li r8,1
	ctx.r8.s64 = 1;
loc_82139298:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x82139280
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82139280;
loc_821392A4:
	// clrlwi r11,r8,24
	ctx.r11.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82139330
	if (ctx.cr6.eq) goto loc_82139330;
	// mr r11,r21
	ctx.r11.u64 = ctx.r21.u64;
	// mr r8,r22
	ctx.r8.u64 = ctx.r22.u64;
	// cmplwi cr6,r22,64
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 64, ctx.xer);
	// bge cr6,0x82139330
	if (!ctx.cr6.lt) goto loc_82139330;
	// rlwinm r10,r22,2,0,29
	ctx.r10.u64 = rotl64(ctx.r22.u32 | (ctx.r22.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r10,r27
	ctx.r9.u64 = ctx.r10.u64 + ctx.r27.u64;
loc_821392C8:
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82139320
	if (ctx.cr6.eq) goto loc_82139320;
	// cmplwi cr6,r11,64
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 64, ctx.xer);
	// bge cr6,0x82139320
	if (!ctx.cr6.lt) goto loc_82139320;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r27
	ctx.r10.u64 = ctx.r10.u64 + ctx.r27.u64;
loc_821392E4:
	// lwz r6,0(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x82139304
	if (ctx.cr6.eq) goto loc_82139304;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,64
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 64, ctx.xer);
	// blt cr6,0x821392e4
	if (ctx.cr6.lt) goto loc_821392E4;
	// b 0x82139320
	goto loc_82139320;
loc_82139304:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stwx r7,r10,r27
	PPC_STORE_U32(ctx.r10.u32 + ctx.r27.u32, ctx.r7.u32);
	// stw r21,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r21.u32);
	// lwzx r5,r10,r27
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r27.u32);
	// stwx r8,r10,r6
	PPC_STORE_U32(ctx.r10.u32 + ctx.r6.u32, ctx.r8.u32);
	// stw r11,316(r5)
	PPC_STORE_U32(ctx.r5.u32 + 316, ctx.r11.u32);
loc_82139320:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplwi cr6,r8,64
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 64, ctx.xer);
	// blt cr6,0x821392c8
	if (ctx.cr6.lt) goto loc_821392C8;
loc_82139330:
	// mr r29,r21
	ctx.r29.u64 = ctx.r21.u64;
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82139380
	if (ctx.cr6.eq) goto loc_82139380;
	// addi r26,r27,9860
	ctx.r26.s64 = ctx.r27.s64 + 9860;
	// addi r28,r27,-4
	ctx.r28.s64 = ctx.r27.s64 + -4;
	// mr r30,r22
	ctx.r30.u64 = ctx.r22.u64;
loc_82139348:
	// lwzu r31,4(r28)
	ea = 4 + ctx.r28.u32;
	ctx.r31.u64 = PPC_LOAD_U32(ea);
	ctx.r28.u32 = ea;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82136c08
	ctx.lr = 0x82139358;
	sub_82136C08(ctx, base);
	// lwz r11,332(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 332);
	// lwz r9,328(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 328);
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r11,0,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// mulli r11,r9,88
	ctx.r11.s64 = ctx.r9.s64 * 88;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// add r11,r11,r29
	ctx.r11.u64 = ctx.r11.u64 + ctx.r29.u64;
	// addi r29,r11,244
	ctx.r29.s64 = ctx.r11.s64 + 244;
	// bne 0x82139348
	if (!ctx.cr0.eq) goto loc_82139348;
loc_82139380:
	// lis r11,-32197
	ctx.r11.s64 = -2110062592;
	// lwz r3,-27096(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -27096);
	// bl 0x82388734
	ctx.lr = 0x8213938C;
	__imp__KeTlsGetValue(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82139398
	if (!ctx.cr6.eq) goto loc_82139398;
	// bl 0x821b3000
	ctx.lr = 0x82139398;
	sub_821B3000(ctx, base);
loc_82139398:
	// addi r9,r29,15
	ctx.r9.s64 = ctx.r29.s64 + 15;
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r8,20(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// addi r10,r3,20
	ctx.r10.s64 = ctx.r3.s64 + 20;
	// rlwinm r7,r9,0,0,27
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFF0;
	// add r6,r11,r7
	ctx.r6.u64 = ctx.r11.u64 + ctx.r7.u64;
	// cmplw cr6,r6,r8
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, ctx.xer);
	// ble cr6,0x821393c8
	if (!ctx.cr6.gt) goto loc_821393C8;
	// lis r11,-13569
	ctx.r11.s64 = -889257984;
	// lis r9,-32250
	ctx.r9.s64 = -2113536000;
	// addi r8,r9,4492
	ctx.r8.s64 = ctx.r9.s64 + 4492;
	// stw r8,-13570(r11)
	PPC_STORE_U32(ctx.r11.u32 + -13570, ctx.r8.u32);
loc_821393C8:
	// lwz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// mulli r9,r22,244
	ctx.r9.s64 = ctx.r22.s64 * 244;
	// lwz r8,8(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// add r7,r11,r7
	ctx.r7.u64 = ctx.r11.u64 + ctx.r7.u64;
	// add r11,r8,r11
	ctx.r11.u64 = ctx.r8.u64 + ctx.r11.u64;
	// stw r7,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r7.u32);
	// mr r24,r21
	ctx.r24.u64 = ctx.r21.u64;
	// stw r29,9880(r27)
	PPC_STORE_U32(ctx.r27.u32 + 9880, ctx.r29.u32);
	// mr r26,r11
	ctx.r26.u64 = ctx.r11.u64;
	// stw r11,9876(r27)
	PPC_STORE_U32(ctx.r27.u32 + 9876, ctx.r11.u32);
	// add r29,r9,r11
	ctx.r29.u64 = ctx.r9.u64 + ctx.r11.u64;
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x82139544
	if (ctx.cr6.eq) goto loc_82139544;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r30,r11,196
	ctx.r30.s64 = ctx.r11.s64 + 196;
	// addi r25,r1,80
	ctx.r25.s64 = ctx.r1.s64 + 80;
	// subf r23,r10,r27
	ctx.r23.s64 = ctx.r27.s64 - ctx.r10.s64;
loc_8213940C:
	// lwzx r31,r25,r23
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r25.u32 + ctx.r23.u32);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// addi r4,r31,68
	ctx.r4.s64 = ctx.r31.s64 + 68;
	// stw r21,340(r31)
	PPC_STORE_U32(ctx.r31.u32 + 340, ctx.r21.u32);
	// stw r21,344(r31)
	PPC_STORE_U32(ctx.r31.u32 + 344, ctx.r21.u32);
	// lwz r11,64(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// rlwinm r5,r11,4,0,27
	ctx.r5.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x8233e4e0
	ctx.lr = 0x8213942C;
	sub_8233E4E0(ctx, base);
	// lwz r9,64(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// subf r10,r26,r29
	ctx.r10.s64 = ctx.r29.s64 - ctx.r26.s64;
	// addi r28,r31,324
	ctx.r28.s64 = ctx.r31.s64 + 324;
	// stw r9,-4(r30)
	PPC_STORE_U32(ctx.r30.u32 + -4, ctx.r9.u32);
	// lwz r8,272(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 272);
	// stw r8,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r8.u32);
	// lwz r7,276(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 276);
	// stw r7,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r7.u32);
	// lwz r6,280(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 280);
	// stw r6,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r6.u32);
	// lwz r5,284(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 284);
	// stw r5,12(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12, ctx.r5.u32);
	// lwz r4,288(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 288);
	// stw r4,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r4.u32);
	// lwz r3,292(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// stw r3,20(r30)
	PPC_STORE_U32(ctx.r30.u32 + 20, ctx.r3.u32);
	// lfs f0,296(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 296);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,24(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 24, temp.u32);
	// lbz r11,307(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 307);
	// lbz r9,303(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 303);
	// lwz r8,308(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 308);
	// rlwinm r7,r8,8,0,23
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFFFF00;
	// or r6,r7,r11
	ctx.r6.u64 = ctx.r7.u64 | ctx.r11.u64;
	// rlwinm r5,r6,8,0,23
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 8) & 0xFFFFFF00;
	// or r4,r5,r9
	ctx.r4.u64 = ctx.r5.u64 | ctx.r9.u64;
	// stw r4,28(r30)
	PPC_STORE_U32(ctx.r30.u32 + 28, ctx.r4.u32);
	// lwz r3,312(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 312);
	// stw r3,44(r30)
	PPC_STORE_U32(ctx.r30.u32 + 44, ctx.r3.u32);
	// lwz r11,328(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 328);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r10,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r10.u32);
	// stb r11,33(r30)
	PPC_STORE_U8(ctx.r30.u32 + 33, ctx.r11.u8);
	// lwz r10,324(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 324);
	// beq cr6,0x821394dc
	if (ctx.cr6.eq) goto loc_821394DC;
	// addi r27,r10,24
	ctx.r27.s64 = ctx.r10.s64 + 24;
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
loc_821394BC:
	// li r5,88
	ctx.r5.s64 = 88;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x821394CC;
	sub_8233E4E0(ctx, base);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// addi r27,r27,112
	ctx.r27.s64 = ctx.r27.s64 + 112;
	// addi r29,r29,88
	ctx.r29.s64 = ctx.r29.s64 + 88;
	// bne 0x821394bc
	if (!ctx.cr0.eq) goto loc_821394BC;
loc_821394DC:
	// lwz r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// subf r10,r26,r29
	ctx.r10.s64 = ctx.r29.s64 - ctx.r26.s64;
	// lwz r9,0(r25)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// stw r10,40(r30)
	PPC_STORE_U32(ctx.r30.u32 + 40, ctx.r10.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stb r24,35(r30)
	PPC_STORE_U8(ctx.r30.u32 + 35, ctx.r24.u8);
	// stb r11,32(r30)
	PPC_STORE_U8(ctx.r30.u32 + 32, ctx.r11.u8);
	// stb r9,34(r30)
	PPC_STORE_U8(ctx.r30.u32 + 34, ctx.r9.u8);
	// beq cr6,0x8213952c
	if (ctx.cr6.eq) goto loc_8213952C;
	// subf r9,r29,r28
	ctx.r9.s64 = ctx.r28.s64 - ctx.r29.s64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// addi r9,r9,28
	ctx.r9.s64 = ctx.r9.s64 + 28;
loc_82139510:
	// lbzx r8,r9,r10
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// stb r8,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r8.u8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// bdnz 0x82139510
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82139510;
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// rlwinm r11,r11,0,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
loc_8213952C:
	// addi r24,r24,1
	ctx.r24.s64 = ctx.r24.s64 + 1;
	// addi r26,r26,244
	ctx.r26.s64 = ctx.r26.s64 + 244;
	// addi r30,r30,244
	ctx.r30.s64 = ctx.r30.s64 + 244;
	// addi r25,r25,4
	ctx.r25.s64 = ctx.r25.s64 + 4;
	// cmplw cr6,r24,r22
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r22.u32, ctx.xer);
	// blt cr6,0x8213940c
	if (ctx.cr6.lt) goto loc_8213940C;
loc_82139544:
	// addi r1,r1,432
	ctx.r1.s64 = ctx.r1.s64 + 432;
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213954C"))) PPC_WEAK_FUNC(sub_8213954C);
PPC_FUNC_IMPL(__imp__sub_8213954C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82139550"))) PPC_WEAK_FUNC(sub_82139550);
PPC_FUNC_IMPL(__imp__sub_82139550) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82139558;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r27,0
	ctx.r27.s64 = 0;
	// addi r11,r3,8
	ctx.r11.s64 = ctx.r3.s64 + 8;
loc_82139568:
	// lwz r10,-8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821395c0
	if (ctx.cr6.eq) goto loc_821395C0;
	// lwz r10,-4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821395ac
	if (ctx.cr6.eq) goto loc_821395AC;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821395b4
	if (ctx.cr6.eq) goto loc_821395B4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821395bc
	if (ctx.cr6.eq) goto loc_821395BC;
	// addi r27,r27,4
	ctx.r27.s64 = ctx.r27.s64 + 4;
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// cmplwi cr6,r27,64
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 64, ctx.xer);
	// blt cr6,0x82139568
	if (ctx.cr6.lt) goto loc_82139568;
	// b 0x821395c0
	goto loc_821395C0;
loc_821395AC:
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// b 0x821395c0
	goto loc_821395C0;
loc_821395B4:
	// addi r27,r27,2
	ctx.r27.s64 = ctx.r27.s64 + 2;
	// b 0x821395c0
	goto loc_821395C0;
loc_821395BC:
	// addi r27,r27,3
	ctx.r27.s64 = ctx.r27.s64 + 3;
loc_821395C0:
	// lwz r11,256(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 256);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// li r4,16
	ctx.r4.s64 = 16;
	// stw r11,256(r31)
	PPC_STORE_U32(ctx.r31.u32 + 256, ctx.r11.u32);
	// li r3,416
	ctx.r3.s64 = 416;
	// bl 0x82082030
	ctx.lr = 0x821395E0;
	sub_82082030(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// li r4,0
	ctx.r4.s64 = 0;
	// beq cr6,0x8213961c
	if (ctx.cr6.eq) goto loc_8213961C;
	// li r29,-1
	ctx.r29.s64 = -1;
	// li r5,316
	ctx.r5.s64 = 316;
	// stw r29,316(r3)
	PPC_STORE_U32(ctx.r3.u32 + 316, ctx.r29.u32);
	// stw r29,320(r3)
	PPC_STORE_U32(ctx.r3.u32 + 320, ctx.r29.u32);
	// bl 0x8233eaf0
	ctx.lr = 0x82139604;
	sub_8233EAF0(ctx, base);
	// li r5,92
	ctx.r5.s64 = 92;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r30,324
	ctx.r3.s64 = ctx.r30.s64 + 324;
	// bl 0x8233eaf0
	ctx.lr = 0x82139614;
	sub_8233EAF0(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// stw r29,328(r30)
	PPC_STORE_U32(ctx.r30.u32 + 328, ctx.r29.u32);
loc_8213961C:
	// rlwinm r29,r27,2,0,29
	ctx.r29.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r3,r31,260
	ctx.r3.s64 = ctx.r31.s64 + 260;
	// stwx r4,r29,r31
	PPC_STORE_U32(ctx.r29.u32 + ctx.r31.u32, ctx.r4.u32);
	// bl 0x82139a08
	ctx.lr = 0x8213962C;
	sub_82139A08(ctx, base);
	// lwzx r11,r29,r31
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r31.u32);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// li r30,9
	ctx.r30.s64 = 9;
	// addi r28,r31,9860
	ctx.r28.s64 = ctx.r31.s64 + 9860;
	// stw r3,320(r11)
	PPC_STORE_U32(ctx.r11.u32 + 320, ctx.r3.u32);
	// lwzx r10,r29,r31
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r31.u32);
	// stw r27,316(r10)
	PPC_STORE_U32(ctx.r10.u32 + 316, ctx.r27.u32);
loc_82139648:
	// lwzu r3,-4(r28)
	ea = -4 + ctx.r28.u32;
	ctx.r3.u64 = PPC_LOAD_U32(ea);
	ctx.r28.u32 = ea;
	// lwz r4,256(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 256);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82139660;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bge 0x82139648
	if (!ctx.cr0.lt) goto loc_82139648;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82139674"))) PPC_WEAK_FUNC(sub_82139674);
PPC_FUNC_IMPL(__imp__sub_82139674) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82139678"))) PPC_WEAK_FUNC(sub_82139678);
PPC_FUNC_IMPL(__imp__sub_82139678) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82139680;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r30,r4,16,16,31
	ctx.r30.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 16) & 0xFFFF;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r26,0
	ctx.r26.s64 = 0;
	// addi r31,r3,260
	ctx.r31.s64 = ctx.r3.s64 + 260;
	// cmplwi cr6,r30,64
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 64, ctx.xer);
	// blt cr6,0x821396a8
	if (ctx.cr6.lt) goto loc_821396A8;
	// mr r28,r26
	ctx.r28.u64 = ctx.r26.u64;
	// b 0x821396d4
	goto loc_821396D4;
loc_821396A8:
	// rlwinm r11,r30,3,0,28
	ctx.r11.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 3) & 0xFFFFFFF8;
	// clrlwi r10,r29,16
	ctx.r10.u64 = ctx.r29.u32 & 0xFFFF;
	// add r9,r11,r31
	ctx.r9.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lwz r8,20(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmplw cr6,r8,r10
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x821396c8
	if (ctx.cr6.eq) goto loc_821396C8;
	// mr r28,r26
	ctx.r28.u64 = ctx.r26.u64;
	// b 0x821396d4
	goto loc_821396D4;
loc_821396C8:
	// addi r11,r30,3
	ctx.r11.s64 = ctx.r30.s64 + 3;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r28,r10,r31
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r31.u32);
loc_821396D4:
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x823052d8
	ctx.lr = 0x821396E0;
	sub_823052D8(ctx, base);
	// rlwinm r11,r30,3,0,28
	ctx.r11.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 3) & 0xFFFFFFF8;
	// clrlwi r9,r29,16
	ctx.r9.u64 = ctx.r29.u32 & 0xFFFF;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x8213972c
	if (!ctx.cr6.eq) goto loc_8213972C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lis r9,1
	ctx.r9.s64 = 65536;
	// stw r10,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r10.u32);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82139714
	if (!ctx.cr6.eq) goto loc_82139714;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r10,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r10.u32);
loc_82139714:
	// addi r11,r30,3
	ctx.r11.s64 = ctx.r30.s64 + 3;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// stwx r26,r10,r31
	PPC_STORE_U32(ctx.r10.u32 + ctx.r31.u32, ctx.r26.u32);
	// lwz r11,532(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 532);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// stw r9,532(r31)
	PPC_STORE_U32(ctx.r31.u32 + 532, ctx.r9.u32);
loc_8213972C:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x823051a8
	ctx.lr = 0x82139734;
	sub_823051A8(ctx, base);
	// lwz r11,324(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 324);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r31,316(r28)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r28.u32 + 316);
	// beq cr6,0x82139750
	if (ctx.cr6.eq) goto loc_82139750;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82139750;
	sub_82080000(ctx, base);
loc_82139750:
	// addi r4,r28,-16
	ctx.r4.s64 = ctx.r28.s64 + -16;
	// lwz r3,-8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213975C;
	sub_82080000(ctx, base);
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r26,r11,r27
	PPC_STORE_U32(ctx.r11.u32 + ctx.r27.u32, ctx.r26.u32);
	// lwz r11,256(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 256);
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// stw r10,256(r27)
	PPC_STORE_U32(ctx.r27.u32 + 256, ctx.r10.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82139778"))) PPC_WEAK_FUNC(sub_82139778);
PPC_FUNC_IMPL(__imp__sub_82139778) {
	PPC_FUNC_PROLOGUE();
	// rlwinm r11,r4,16,16,31
	ctx.r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 16) & 0xFFFF;
	// addi r10,r3,260
	ctx.r10.s64 = ctx.r3.s64 + 260;
	// cmplwi cr6,r11,64
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 64, ctx.xer);
	// blt cr6,0x82139790
	if (ctx.cr6.lt) goto loc_82139790;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x821397bc
	goto loc_821397BC;
loc_82139790:
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// clrlwi r8,r4,16
	ctx.r8.u64 = ctx.r4.u32 & 0xFFFF;
	// add r7,r9,r10
	ctx.r7.u64 = ctx.r9.u64 + ctx.r10.u64;
	// lwz r6,20(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// cmplw cr6,r6,r8
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x821397b0
	if (ctx.cr6.eq) goto loc_821397B0;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x821397bc
	goto loc_821397BC;
loc_821397B0:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r11,r9,r10
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
loc_821397BC:
	// lwz r11,316(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 316);
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x821397dc
	if (ctx.cr6.eq) goto loc_821397DC;
	// lwz r10,9796(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 9796);
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r9,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r9.u32);
loc_821397DC:
	// lwz r10,9796(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 9796);
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r3,r10,r9
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821397EC"))) PPC_WEAK_FUNC(sub_821397EC);
PPC_FUNC_IMPL(__imp__sub_821397EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821397F0"))) PPC_WEAK_FUNC(sub_821397F0);
PPC_FUNC_IMPL(__imp__sub_821397F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821398ec
	if (ctx.cr6.eq) goto loc_821398EC;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r31,r11,5528
	ctx.r31.s64 = ctx.r11.s64 + 5528;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823052d8
	ctx.lr = 0x82139824;
	sub_823052D8(ctx, base);
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r10.u32);
	// stw r30,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r30.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r9,r10,-1
	ctx.r9.s64 = ctx.r10.s64 + -1;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r7,r10,-1
	ctx.r7.s64 = ctx.r10.s64 + -1;
	// stw r7,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r7.u32);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// bne cr6,0x821398e0
	if (!ctx.cr6.eq) goto loc_821398E0;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x821398e0
	if (ctx.cr6.eq) goto loc_821398E0;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r8,52(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// subf r6,r9,r8
	ctx.r6.s64 = ctx.r8.s64 - ctx.r9.s64;
	// cmpw cr6,r7,r6
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r6.s32, ctx.xer);
	// bge cr6,0x821398e0
	if (!ctx.cr6.lt) goto loc_821398E0;
	// subf r8,r9,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r9.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// stw r8,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r8.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821398b8
	if (ctx.cr6.eq) goto loc_821398B8;
loc_82139890:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x821398b0
	if (ctx.cr6.eq) goto loc_821398B0;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82139890
	if (!ctx.cr6.eq) goto loc_82139890;
	// b 0x821398b8
	goto loc_821398B8;
loc_821398B0:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
loc_821398B8:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x821398d0
	if (!ctx.cr6.eq) goto loc_821398D0;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r9,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r9.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
loc_821398D0:
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821398DC;
	sub_82080000(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
loc_821398E0:
	// stw r10,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r10.u32);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x821398EC;
	sub_823051A8(ctx, base);
loc_821398EC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82139904"))) PPC_WEAK_FUNC(sub_82139904);
PPC_FUNC_IMPL(__imp__sub_82139904) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82139908"))) PPC_WEAK_FUNC(sub_82139908);
PPC_FUNC_IMPL(__imp__sub_82139908) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r31,r11,5528
	ctx.r31.s64 = ctx.r11.s64 + 5528;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823052d8
	ctx.lr = 0x82139930;
	sub_823052D8(ctx, base);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82139954
	if (ctx.cr6.eq) goto loc_82139954;
loc_8213993C:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82139984
	if (!ctx.cr6.eq) goto loc_82139984;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8213993c
	if (!ctx.cr6.eq) goto loc_8213993C;
loc_82139954:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821399ac
	if (!ctx.cr6.eq) goto loc_821399AC;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82139b18
	ctx.lr = 0x82139968;
	sub_82139B18(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821399ac
	if (!ctx.cr6.eq) goto loc_821399AC;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x8213997C;
	sub_823051A8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x821399f0
	goto loc_821399F0;
loc_82139984:
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// lwz r30,4(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x821399e0
	goto loc_821399E0;
loc_821399AC:
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// addi r10,r11,16
	ctx.r10.s64 = ctx.r11.s64 + 16;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// addi r11,r10,16
	ctx.r11.s64 = ctx.r10.s64 + 16;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stw r8,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r8.u32);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
loc_821399E0:
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x821399EC;
	sub_823051A8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_821399F0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82139A08"))) PPC_WEAK_FUNC(sub_82139A08);
PPC_FUNC_IMPL(__imp__sub_82139A08) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x823052d8
	ctx.lr = 0x82139A2C;
	sub_823052D8(ctx, base);
	// lwz r11,532(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 532);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82139a58
	if (!ctx.cr6.eq) goto loc_82139A58;
	// lis r11,-13569
	ctx.r11.s64 = -889257984;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r9,r10,-31096
	ctx.r9.s64 = ctx.r10.s64 + -31096;
	// stw r9,-13570(r11)
	PPC_STORE_U32(ctx.r11.u32 + -13570, ctx.r9.u32);
	// bl 0x823051a8
	ctx.lr = 0x82139A50;
	sub_823051A8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82139b00
	goto loc_82139B00;
loc_82139A58:
	// lwz r9,536(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 536);
	// mr r11,r9
	ctx.r11.u64 = ctx.r9.u64;
	// cmplwi cr6,r9,64
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 64, ctx.xer);
	// bge cr6,0x82139a90
	if (!ctx.cr6.lt) goto loc_82139A90;
	// addi r10,r9,3
	ctx.r10.s64 = ctx.r9.s64 + 3;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
loc_82139A74:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82139a90
	if (ctx.cr6.eq) goto loc_82139A90;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// cmplwi cr6,r11,64
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 64, ctx.xer);
	// blt cr6,0x82139a74
	if (ctx.cr6.lt) goto loc_82139A74;
loc_82139A90:
	// cmplwi cr6,r11,64
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 64, ctx.xer);
	// bne cr6,0x82139ac8
	if (!ctx.cr6.eq) goto loc_82139AC8;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82139ac8
	if (ctx.cr6.eq) goto loc_82139AC8;
	// addi r10,r31,24
	ctx.r10.s64 = ctx.r31.s64 + 24;
loc_82139AA8:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82139ac8
	if (ctx.cr6.eq) goto loc_82139AC8;
	// lwz r9,536(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 536);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82139aa8
	if (ctx.cr6.lt) goto loc_82139AA8;
loc_82139AC8:
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r8,r9,3,0,28
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r7,r10,r31
	ctx.r7.u64 = ctx.r10.u64 + ctx.r31.u64;
	// rlwinm r6,r11,16,0,15
	ctx.r6.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 16) & 0xFFFF0000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stwx r30,r8,r31
	PPC_STORE_U32(ctx.r8.u32 + ctx.r31.u32, ctx.r30.u32);
	// lwz r11,532(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 532);
	// addi r5,r11,-1
	ctx.r5.s64 = ctx.r11.s64 + -1;
	// lwz r4,20(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	// stw r5,532(r31)
	PPC_STORE_U32(ctx.r31.u32 + 532, ctx.r5.u32);
	// or r31,r4,r6
	ctx.r31.u64 = ctx.r4.u64 | ctx.r6.u64;
	// bl 0x823051a8
	ctx.lr = 0x82139AFC;
	sub_823051A8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_82139B00:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82139B18"))) PPC_WEAK_FUNC(sub_82139B18);
PPC_FUNC_IMPL(__imp__sub_82139B18) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r3,1
	ctx.r11.s64 = ctx.r3.s64 + 1;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// rlwinm r3,r11,5,0,26
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// bl 0x82082030
	ctx.lr = 0x82139B44;
	sub_82082030(ctx, base);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r11,r11,5528
	ctx.r11.s64 = ctx.r11.s64 + 5528;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82139b60
	if (ctx.cr6.eq) goto loc_82139B60;
	// stw r3,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r3.u32);
	// b 0x82139b64
	goto loc_82139B64;
loc_82139B60:
	// stw r3,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r3.u32);
loc_82139B64:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// addi r9,r3,32
	ctx.r9.s64 = ctx.r3.s64 + 32;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// stw r3,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r3.u32);
	// stw r3,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r3.u32);
	// stw r31,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r31.u32);
	// beq cr6,0x82139ba4
	if (ctx.cr6.eq) goto loc_82139BA4;
	// addi r10,r9,-16
	ctx.r10.s64 = ctx.r9.s64 + -16;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
loc_82139B9C:
	// stwu r3,32(r10)
	ea = 32 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x82139b9c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82139B9C;
loc_82139BA4:
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// stw r10,52(r11)
	PPC_STORE_U32(ctx.r11.u32 + 52, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82139BC4"))) PPC_WEAK_FUNC(sub_82139BC4);
PPC_FUNC_IMPL(__imp__sub_82139BC4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82139BC8"))) PPC_WEAK_FUNC(sub_82139BC8);
PPC_FUNC_IMPL(__imp__sub_82139BC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82139BD0;
	__restfpr_27(ctx, base);
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x8233fa04
	ctx.lr = 0x82139BD8;
	sub_8233FA04(ctx, base);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,68(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 68);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82139e74
	if (ctx.cr6.eq) goto loc_82139E74;
	// lwz r29,24(r3)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r11,36(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// lwz r9,40(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// lwz r10,44(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// add r27,r9,r10
	ctx.r27.u64 = ctx.r9.u64 + ctx.r10.u64;
	// beq cr6,0x82139e74
	if (ctx.cr6.eq) goto loc_82139E74;
	// mr r28,r11
	ctx.r28.u64 = ctx.r11.u64;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// lfs f28,92(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 92);
	ctx.f28.f64 = double(temp.f32);
	// lfs f30,56(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,36(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f29.f64 = double(temp.f32);
loc_82139C1C:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82139e68
	if (ctx.cr6.eq) goto loc_82139E68;
	// addi r31,r11,-284
	ctx.r31.s64 = ctx.r11.s64 + -284;
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// rlwinm r10,r11,0,27,27
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82139ca8
	if (ctx.cr6.eq) goto loc_82139CA8;
	// lwz r9,80(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// lfs f0,324(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 324);
	ctx.f0.f64 = double(temp.f32);
	// lwz r8,84(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lwz r7,88(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// addi r10,r31,284
	ctx.r10.s64 = ctx.r31.s64 + 284;
	// lwz r11,296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 296);
	// stw r9,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r9.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r8,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r8.u32);
	// stw r7,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r7.u32);
	// beq cr6,0x82139e68
	if (ctx.cr6.eq) goto loc_82139E68;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// addi r8,r11,20
	ctx.r8.s64 = ctx.r11.s64 + 20;
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r6,4(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lwz r5,8(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r4,12(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// stw r7,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r7.u32);
	// stw r6,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r6.u32);
	// stw r5,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r5.u32);
	// stw r4,32(r11)
	PPC_STORE_U32(ctx.r11.u32 + 32, ctx.r4.u32);
	// lwz r3,12(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stfs f28,16(r3)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r3.u32 + 16, temp.u32);
	// lwz r11,12(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stfs f28,12(r11)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + 12, temp.u32);
	// b 0x82139e68
	goto loc_82139E68;
loc_82139CA8:
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82139e68
	if (ctx.cr6.eq) goto loc_82139E68;
	// rlwinm r11,r11,0,20,20
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x800;
	// lfs f31,324(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 324);
	ctx.f31.f64 = double(temp.f32);
	// addi r30,r31,32
	ctx.r30.s64 = ctx.r31.s64 + 32;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82139cd8
	if (ctx.cr6.eq) goto loc_82139CD8;
	// lfs f0,404(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 404);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f31,f0
	ctx.cr6.compare(ctx.f31.f64, ctx.f0.f64);
	// bgt cr6,0x82139cd8
	if (ctx.cr6.gt) goto loc_82139CD8;
	// fmr f31,f0
	ctx.f31.f64 = ctx.f0.f64;
loc_82139CD8:
	// lfs f0,348(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 348);
	ctx.f0.f64 = double(temp.f32);
	// lfs f1,344(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 344);
	ctx.f1.f64 = double(temp.f32);
	// fdivs f27,f31,f0
	ctx.f27.f64 = double(float(ctx.f31.f64 / ctx.f0.f64));
	// bl 0x8233c870
	ctx.lr = 0x82139CE8;
	sub_8233C870(ctx, base);
	// frsp f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64));
	// lfs f12,32(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f27,f27
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f27.f64));
	// lfs f5,36(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f9,f12,f31
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// lfs f10,40(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f3,f5,f31
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// fmuls f8,f10,f31
	ctx.f8.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// lfs f7,48(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	ctx.f7.f64 = double(temp.f32);
	// lfs f4,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// addi r3,r31,284
	ctx.r3.s64 = ctx.r31.s64 + 284;
	// lfs f1,52(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	ctx.f1.f64 = double(temp.f32);
	// lfs f6,56(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	ctx.f6.f64 = double(temp.f32);
	// fmr f12,f1
	ctx.f12.f64 = ctx.f1.f64;
	// lfs f2,8(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// fmr f10,f6
	ctx.f10.f64 = ctx.f6.f64;
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f13,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f27.f64));
	// fadds f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 + ctx.f9.f64));
	// fadds f5,f1,f3
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fadds f8,f6,f8
	ctx.f8.f64 = double(float(ctx.f6.f64 + ctx.f8.f64));
	// fmuls f4,f4,f13
	ctx.f4.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// fmuls f3,f2,f13
	ctx.f3.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// fmuls f2,f0,f13
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fmuls f0,f13,f30
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// fadds f13,f4,f9
	ctx.f13.f64 = double(float(ctx.f4.f64 + ctx.f9.f64));
	// fsubs f9,f9,f4
	ctx.f9.f64 = static_cast<float>(ctx.f9.f64 - ctx.f4.f64);
	// fsubs f4,f8,f3
	ctx.f4.f64 = static_cast<float>(ctx.f8.f64 - ctx.f3.f64);
	// fadds f31,f2,f5
	ctx.f31.f64 = double(float(ctx.f2.f64 + ctx.f5.f64));
	// fsubs f2,f5,f2
	ctx.f2.f64 = static_cast<float>(ctx.f5.f64 - ctx.f2.f64);
	// fadds f8,f3,f8
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f8.f64));
	// fmuls f5,f0,f0
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f0.f64));
	// fsubs f3,f13,f7
	ctx.f3.f64 = static_cast<float>(ctx.f13.f64 - ctx.f7.f64);
	// fsubs f27,f13,f9
	ctx.f27.f64 = static_cast<float>(ctx.f13.f64 - ctx.f9.f64);
	// fsubs f26,f4,f6
	ctx.f26.f64 = static_cast<float>(ctx.f4.f64 - ctx.f6.f64);
	// fsubs f25,f9,f7
	ctx.f25.f64 = static_cast<float>(ctx.f9.f64 - ctx.f7.f64);
	// fsubs f22,f2,f1
	ctx.f22.f64 = static_cast<float>(ctx.f2.f64 - ctx.f1.f64);
	// fsubs f1,f31,f1
	ctx.f1.f64 = static_cast<float>(ctx.f31.f64 - ctx.f1.f64);
	// fsubs f24,f31,f2
	ctx.f24.f64 = static_cast<float>(ctx.f31.f64 - ctx.f2.f64);
	// fsubs f23,f8,f4
	ctx.f23.f64 = static_cast<float>(ctx.f8.f64 - ctx.f4.f64);
	// fadds f2,f2,f31
	ctx.f2.f64 = double(float(ctx.f2.f64 + ctx.f31.f64));
	// fsubs f6,f8,f6
	ctx.f6.f64 = static_cast<float>(ctx.f8.f64 - ctx.f6.f64);
	// fadds f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// fneg f9,f3
	ctx.f9.u64 = ctx.f3.u64 ^ 0x8000000000000000;
	// fmuls f31,f26,f27
	ctx.f31.f64 = double(float(ctx.f26.f64 * ctx.f27.f64));
	// fneg f21,f26
	ctx.f21.u64 = ctx.f26.u64 ^ 0x8000000000000000;
	// fneg f17,f22
	ctx.f17.u64 = ctx.f22.u64 ^ 0x8000000000000000;
	// fneg f16,f1
	ctx.f16.u64 = ctx.f1.u64 ^ 0x8000000000000000;
	// fmuls f1,f1,f24
	ctx.f1.f64 = double(float(ctx.f1.f64 * ctx.f24.f64));
	// fmuls f18,f22,f23
	ctx.f18.f64 = double(float(ctx.f22.f64 * ctx.f23.f64));
	// fmuls f20,f24,f25
	ctx.f20.f64 = double(float(ctx.f24.f64 * ctx.f25.f64));
	// fneg f15,f6
	ctx.f15.u64 = ctx.f6.u64 ^ 0x8000000000000000;
	// fneg f19,f25
	ctx.f19.u64 = ctx.f25.u64 ^ 0x8000000000000000;
	// fmsubs f31,f23,f25,f31
	ctx.f31.f64 = double(std::fma(float(ctx.f23.f64), float(ctx.f25.f64), -float(ctx.f31.f64)));
	// fmadds f6,f6,f23,f1
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f23.f64), float(ctx.f1.f64)));
	// fmsubs f26,f26,f24,f18
	ctx.f26.f64 = double(std::fma(float(ctx.f26.f64), float(ctx.f24.f64), -float(ctx.f18.f64)));
	// fmuls f24,f16,f17
	ctx.f24.f64 = double(float(ctx.f16.f64 * ctx.f17.f64));
	// fmsubs f25,f22,f27,f20
	ctx.f25.f64 = double(std::fma(float(ctx.f22.f64), float(ctx.f27.f64), -float(ctx.f20.f64)));
	// fmuls f1,f31,f31
	ctx.f1.f64 = double(float(ctx.f31.f64 * ctx.f31.f64));
	// fmadds f6,f3,f27,f6
	ctx.f6.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f27.f64), float(ctx.f6.f64)));
	// fmadds f31,f15,f21,f24
	ctx.f31.f64 = double(std::fma(float(ctx.f15.f64), float(ctx.f21.f64), float(ctx.f24.f64)));
	// fmadds f3,f25,f25,f1
	ctx.f3.f64 = double(std::fma(float(ctx.f25.f64), float(ctx.f25.f64), float(ctx.f1.f64)));
	// fmadds f1,f9,f19,f31
	ctx.f1.f64 = double(std::fma(float(ctx.f9.f64), float(ctx.f19.f64), float(ctx.f31.f64)));
	// fmadds f9,f26,f26,f3
	ctx.f9.f64 = double(std::fma(float(ctx.f26.f64), float(ctx.f26.f64), float(ctx.f3.f64)));
	// fmuls f5,f1,f5
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f5.f64));
	// fsqrts f3,f9
	ctx.f3.f64 = double(simd::sqrt_f32(float(ctx.f9.f64)));
	// fmuls f1,f9,f30
	ctx.f1.f64 = double(float(ctx.f9.f64 * ctx.f30.f64));
	// fmuls f9,f3,f30
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f30.f64));
	// fdivs f3,f29,f1
	ctx.f3.f64 = double(float(ctx.f29.f64 / ctx.f1.f64));
	// fdivs f1,f11,f9
	ctx.f1.f64 = double(float(ctx.f11.f64 / ctx.f9.f64));
	// fmuls f9,f5,f3
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f3.f64));
	// fmuls f6,f6,f3
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f3.f64));
	// fmuls f5,f1,f0
	ctx.f5.f64 = double(float(ctx.f1.f64 * ctx.f0.f64));
	// stfs f5,124(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fmuls f3,f7,f9
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// fmuls f1,f6,f11
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f11.f64));
	// fmuls f0,f12,f9
	ctx.f0.f64 = double(float(ctx.f12.f64 * ctx.f9.f64));
	// fmuls f11,f10,f9
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// fmuls f10,f2,f1
	ctx.f10.f64 = double(float(ctx.f2.f64 * ctx.f1.f64));
	// fadds f12,f4,f8
	ctx.f12.f64 = double(float(ctx.f4.f64 + ctx.f8.f64));
	// fmuls f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fadds f7,f10,f0
	ctx.f7.f64 = double(float(ctx.f10.f64 + ctx.f0.f64));
	// stfs f7,84(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// fmuls f8,f12,f1
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// fadds f9,f13,f3
	ctx.f9.f64 = double(float(ctx.f13.f64 + ctx.f3.f64));
	// stfs f9,80(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r11.u32);
	// fadds f6,f8,f11
	ctx.f6.f64 = double(float(ctx.f8.f64 + ctx.f11.f64));
	// stfs f6,88(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stw r10,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r10.u32);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stw r9,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r9.u32);
	// bl 0x820c2ab0
	ctx.lr = 0x82139E68;
	sub_820C2AB0(ctx, base);
loc_82139E68:
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// add r29,r27,r29
	ctx.r29.u64 = ctx.r27.u64 + ctx.r29.u64;
	// bne 0x82139c1c
	if (!ctx.cr0.eq) goto loc_82139C1C;
loc_82139E74:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// addi r12,r1,-48
	ctx.r12.s64 = ctx.r1.s64 + -48;
	// bl 0x8233fa50
	ctx.lr = 0x82139E80;
	__savefpr_15(ctx, base);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82139E84"))) PPC_WEAK_FUNC(sub_82139E84);
PPC_FUNC_IMPL(__imp__sub_82139E84) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82139E88"))) PPC_WEAK_FUNC(sub_82139E88);
PPC_FUNC_IMPL(__imp__sub_82139E88) {
	PPC_FUNC_PROLOGUE();
	// lbz r11,68(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 68);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// lwz r9,40(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82139EA4"))) PPC_WEAK_FUNC(sub_82139EA4);
PPC_FUNC_IMPL(__imp__sub_82139EA4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82139EA8"))) PPC_WEAK_FUNC(sub_82139EA8);
PPC_FUNC_IMPL(__imp__sub_82139EA8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x82139EB0;
	__restfpr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,68(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 68);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82139f10
	if (ctx.cr6.eq) goto loc_82139F10;
	// lwz r31,24(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r11,36(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// lwz r9,44(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// add r29,r10,r9
	ctx.r29.u64 = ctx.r10.u64 + ctx.r9.u64;
	// beq cr6,0x82139f10
	if (ctx.cr6.eq) goto loc_82139F10;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
loc_82139EE0:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82139f04
	if (ctx.cr6.eq) goto loc_82139F04;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// addi r3,r11,-284
	ctx.r3.s64 = ctx.r11.s64 + -284;
	// rlwinm r9,r10,0,19,19
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x1000;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82139f04
	if (ctx.cr6.eq) goto loc_82139F04;
	// bl 0x820ebe28
	ctx.lr = 0x82139F04;
	sub_820EBE28(ctx, base);
loc_82139F04:
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// add r31,r29,r31
	ctx.r31.u64 = ctx.r29.u64 + ctx.r31.u64;
	// bne 0x82139ee0
	if (!ctx.cr0.eq) goto loc_82139EE0;
loc_82139F10:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82139F18"))) PPC_WEAK_FUNC(sub_82139F18);
PPC_FUNC_IMPL(__imp__sub_82139F18) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x82139F20;
	__restfpr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,68(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 68);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82139f74
	if (ctx.cr6.eq) goto loc_82139F74;
	// lwz r31,24(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r11,36(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// lwz r9,44(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// add r29,r10,r9
	ctx.r29.u64 = ctx.r10.u64 + ctx.r9.u64;
	// beq cr6,0x82139f74
	if (ctx.cr6.eq) goto loc_82139F74;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
loc_82139F50:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82139f68
	if (ctx.cr6.eq) goto loc_82139F68;
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r4,r11,20
	ctx.r4.s64 = ctx.r11.s64 + 20;
	// bl 0x820e6a90
	ctx.lr = 0x82139F68;
	sub_820E6A90(ctx, base);
loc_82139F68:
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// add r31,r29,r31
	ctx.r31.u64 = ctx.r29.u64 + ctx.r31.u64;
	// bne 0x82139f50
	if (!ctx.cr0.eq) goto loc_82139F50;
loc_82139F74:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82139F7C"))) PPC_WEAK_FUNC(sub_82139F7C);
PPC_FUNC_IMPL(__imp__sub_82139F7C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82139F80"))) PPC_WEAK_FUNC(sub_82139F80);
PPC_FUNC_IMPL(__imp__sub_82139F80) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x82139F88;
	__restfpr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,68(r3)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 68);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82139fe0
	if (ctx.cr6.eq) goto loc_82139FE0;
	// lwz r31,24(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r11,36(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// lwz r9,44(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// add r29,r10,r9
	ctx.r29.u64 = ctx.r10.u64 + ctx.r9.u64;
	// beq cr6,0x82139fe0
	if (ctx.cr6.eq) goto loc_82139FE0;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
loc_82139FB8:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82139fd4
	if (ctx.cr6.eq) goto loc_82139FD4;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// addi r3,r11,-284
	ctx.r3.s64 = ctx.r11.s64 + -284;
	// addi r4,r10,20
	ctx.r4.s64 = ctx.r10.s64 + 20;
	// bl 0x820e5c88
	ctx.lr = 0x82139FD4;
	sub_820E5C88(ctx, base);
loc_82139FD4:
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// add r31,r29,r31
	ctx.r31.u64 = ctx.r29.u64 + ctx.r31.u64;
	// bne 0x82139fb8
	if (!ctx.cr0.eq) goto loc_82139FB8;
loc_82139FE0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82139FE8"))) PPC_WEAK_FUNC(sub_82139FE8);
PPC_FUNC_IMPL(__imp__sub_82139FE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82139FF0;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r27,r3,4
	ctx.r27.s64 = ctx.r3.s64 + 4;
	// li r28,-1
	ctx.r28.s64 = -1;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x8213A010;
	sub_823052D8(ctx, base);
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x8213a0c0
	if (ctx.cr6.eq) goto loc_8213A0C0;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// li r30,0
	ctx.r30.s64 = 0;
	// lwz r9,44(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// addi r7,r11,1
	ctx.r7.s64 = ctx.r11.s64 + 1;
	// lwz r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mullw r9,r10,r11
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// stw r30,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r30.u32);
	// lwz r6,36(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r7,r6
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r6.u32, ctx.xer);
	// bne cr6,0x8213a078
	if (!ctx.cr6.eq) goto loc_8213A078;
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// blt 0x8213a070
	if (ctx.cr0.lt) goto loc_8213A070;
loc_8213A058:
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x8213a070
	if (!ctx.cr6.eq) goto loc_8213A070;
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// bge 0x8213a058
	if (!ctx.cr0.lt) goto loc_8213A058;
loc_8213A070:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
loc_8213A078:
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// addi r9,r11,64
	ctx.r9.s64 = ctx.r11.s64 + 64;
	// rlwinm r8,r10,31,1,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// bgt cr6,0x8213a0b8
	if (ctx.cr6.gt) goto loc_8213A0B8;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// addi r4,r11,64
	ctx.r4.s64 = ctx.r11.s64 + 64;
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// bctrl 
	ctx.lr = 0x8213A0B8;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_8213A0B8:
	// stw r28,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r28.u32);
	// stw r30,12(r29)
	PPC_STORE_U32(ctx.r29.u32 + 12, ctx.r30.u32);
loc_8213A0C0:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823051a8
	ctx.lr = 0x8213A0C8;
	sub_823051A8(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213A0D0"))) PPC_WEAK_FUNC(sub_8213A0D0);
PPC_FUNC_IMPL(__imp__sub_8213A0D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x8213A0D8;
	__restfpr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r29,r3,4
	ctx.r29.s64 = ctx.r3.s64 + 4;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x823052d8
	ctx.lr = 0x8213A0F4;
	sub_823052D8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82137fb8
	ctx.lr = 0x8213A0FC;
	sub_82137FB8(ctx, base);
	// lwz r11,40(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// lwz r8,44(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// lis r7,-32250
	ctx.r7.s64 = -2113536000;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lis r5,0
	ctx.r5.s64 = 0;
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// addi r6,r7,31376
	ctx.r6.s64 = ctx.r7.s64 + 31376;
	// mullw r11,r11,r3
	ctx.r11.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r3.s32);
	// lfs f0,92(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// ori r4,r5,65535
	ctx.r4.u64 = ctx.r5.u64 | 65535;
	// addi r9,r3,1
	ctx.r9.s64 = ctx.r3.s64 + 1;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// stw r30,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r30.u32);
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// stfs f0,16(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 16, temp.u32);
	// stfs f0,12(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 12, temp.u32);
	// stw r3,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r3.u32);
	// stw r4,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r4.u32);
	// lwz r8,36(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// ble cr6,0x8213a158
	if (!ctx.cr6.gt) goto loc_8213A158;
	// stw r9,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r9.u32);
loc_8213A158:
	// lwz r9,32(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r9.u32);
	// stw r10,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r10.u32);
	// stw r11,12(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12, ctx.r11.u32);
	// bl 0x823051a8
	ctx.lr = 0x8213A174;
	sub_823051A8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213A17C"))) PPC_WEAK_FUNC(sub_8213A17C);
PPC_FUNC_IMPL(__imp__sub_8213A17C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213A180"))) PPC_WEAK_FUNC(sub_8213A180);
PPC_FUNC_IMPL(__imp__sub_8213A180) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r11,r4,0,30,30
	ctx.r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x2;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213a204
	if (ctx.cr6.eq) goto loc_8213A204;
	// lwz r11,-4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r30,r3,-4
	ctx.r30.s64 = ctx.r3.s64 + -4;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addic. r10,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r10.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// blt 0x8213a1dc
	if (ctx.cr0.lt) goto loc_8213A1DC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r10,r10,-31400
	ctx.r10.s64 = ctx.r10.s64 + -31400;
loc_8213A1D4:
	// stwu r10,-40(r11)
	ea = -40 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x8213a1d4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213A1D4;
loc_8213A1DC:
	// clrlwi r11,r4,31
	ctx.r11.u64 = ctx.r4.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213a1fc
	if (ctx.cr6.eq) goto loc_8213A1FC;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x8213a1fc
	if (ctx.cr6.eq) goto loc_8213A1FC;
	// addi r4,r30,-16
	ctx.r4.s64 = ctx.r30.s64 + -16;
	// lwz r3,-8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213A1FC;
	sub_82080000(ctx, base);
loc_8213A1FC:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// b 0x8213a22c
	goto loc_8213A22C;
loc_8213A204:
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// clrlwi r10,r4,31
	ctx.r10.u64 = ctx.r4.u32 & 0x1;
	// addi r9,r11,-31400
	ctx.r9.s64 = ctx.r11.s64 + -31400;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// beq cr6,0x8213a228
	if (ctx.cr6.eq) goto loc_8213A228;
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213A228;
	sub_82080000(ctx, base);
loc_8213A228:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
loc_8213A22C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213A244"))) PPC_WEAK_FUNC(sub_8213A244);
PPC_FUNC_IMPL(__imp__sub_8213A244) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213A248"))) PPC_WEAK_FUNC(sub_8213A248);
PPC_FUNC_IMPL(__imp__sub_8213A248) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,1638
	ctx.r11.s64 = 107347968;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// ori r10,r11,26214
	ctx.r10.u64 = ctx.r11.u64 | 26214;
	// cmplw cr6,r4,r10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, ctx.xer);
	// bgt cr6,0x8213a288
	if (ctx.cr6.gt) goto loc_8213A288;
	// rlwinm r11,r4,2,0,29
	ctx.r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// li r10,-5
	ctx.r10.s64 = -5;
	// add r9,r4,r11
	ctx.r9.u64 = ctx.r4.u64 + ctx.r11.u64;
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// addi r3,r11,4
	ctx.r3.s64 = ctx.r11.s64 + 4;
	// ble cr6,0x8213a28c
	if (!ctx.cr6.gt) goto loc_8213A28C;
loc_8213A288:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_8213A28C:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x8213A29C;
	sub_82082030(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213a30c
	if (ctx.cr6.eq) goto loc_8213A30C;
	// stw r31,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r31.u32);
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// addic. r11,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r11.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt 0x8213a310
	if (ctx.cr0.lt) goto loc_8213A310;
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r11,r3,-40
	ctx.r11.s64 = ctx.r3.s64 + -40;
	// addi r9,r9,-29388
	ctx.r9.s64 = ctx.r9.s64 + -29388;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// li r10,0
	ctx.r10.s64 = 0;
loc_8213A2D0:
	// stw r10,44(r11)
	PPC_STORE_U32(ctx.r11.u32 + 44, ctx.r10.u32);
	// stw r10,48(r11)
	PPC_STORE_U32(ctx.r11.u32 + 48, ctx.r10.u32);
	// stw r10,52(r11)
	PPC_STORE_U32(ctx.r11.u32 + 52, ctx.r10.u32);
	// stw r10,56(r11)
	PPC_STORE_U32(ctx.r11.u32 + 56, ctx.r10.u32);
	// stw r10,60(r11)
	PPC_STORE_U32(ctx.r11.u32 + 60, ctx.r10.u32);
	// stw r10,64(r11)
	PPC_STORE_U32(ctx.r11.u32 + 64, ctx.r10.u32);
	// stw r10,68(r11)
	PPC_STORE_U32(ctx.r11.u32 + 68, ctx.r10.u32);
	// stw r10,72(r11)
	PPC_STORE_U32(ctx.r11.u32 + 72, ctx.r10.u32);
	// stwu r9,40(r11)
	ea = 40 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x8213a2d0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213A2D0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_8213A30C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8213A310:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213A324"))) PPC_WEAK_FUNC(sub_8213A324);
PPC_FUNC_IMPL(__imp__sub_8213A324) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213A328"))) PPC_WEAK_FUNC(sub_8213A328);
PPC_FUNC_IMPL(__imp__sub_8213A328) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,1638
	ctx.r11.s64 = 107347968;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// ori r10,r11,26214
	ctx.r10.u64 = ctx.r11.u64 | 26214;
	// cmplw cr6,r4,r10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, ctx.xer);
	// bgt cr6,0x8213a368
	if (ctx.cr6.gt) goto loc_8213A368;
	// rlwinm r11,r4,2,0,29
	ctx.r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// li r10,-5
	ctx.r10.s64 = -5;
	// add r9,r4,r11
	ctx.r9.u64 = ctx.r4.u64 + ctx.r11.u64;
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// addi r3,r11,4
	ctx.r3.s64 = ctx.r11.s64 + 4;
	// ble cr6,0x8213a36c
	if (!ctx.cr6.gt) goto loc_8213A36C;
loc_8213A368:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_8213A36C:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x8213A37C;
	sub_82082030(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213a3ec
	if (ctx.cr6.eq) goto loc_8213A3EC;
	// stw r31,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r31.u32);
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// addic. r11,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r11.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt 0x8213a3f0
	if (ctx.cr0.lt) goto loc_8213A3F0;
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r11,r3,-40
	ctx.r11.s64 = ctx.r3.s64 + -40;
	// addi r9,r9,-29380
	ctx.r9.s64 = ctx.r9.s64 + -29380;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// li r10,0
	ctx.r10.s64 = 0;
loc_8213A3B0:
	// stw r10,44(r11)
	PPC_STORE_U32(ctx.r11.u32 + 44, ctx.r10.u32);
	// stw r10,48(r11)
	PPC_STORE_U32(ctx.r11.u32 + 48, ctx.r10.u32);
	// stw r10,52(r11)
	PPC_STORE_U32(ctx.r11.u32 + 52, ctx.r10.u32);
	// stw r10,56(r11)
	PPC_STORE_U32(ctx.r11.u32 + 56, ctx.r10.u32);
	// stw r10,60(r11)
	PPC_STORE_U32(ctx.r11.u32 + 60, ctx.r10.u32);
	// stw r10,64(r11)
	PPC_STORE_U32(ctx.r11.u32 + 64, ctx.r10.u32);
	// stw r10,68(r11)
	PPC_STORE_U32(ctx.r11.u32 + 68, ctx.r10.u32);
	// stw r10,72(r11)
	PPC_STORE_U32(ctx.r11.u32 + 72, ctx.r10.u32);
	// stwu r9,40(r11)
	ea = 40 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x8213a3b0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213A3B0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_8213A3EC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8213A3F0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213A404"))) PPC_WEAK_FUNC(sub_8213A404);
PPC_FUNC_IMPL(__imp__sub_8213A404) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213A408"))) PPC_WEAK_FUNC(sub_8213A408);
PPC_FUNC_IMPL(__imp__sub_8213A408) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x8213A410;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r26,r7
	ctx.r26.u64 = ctx.r7.u64;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x8213a454
	if (!ctx.cr6.eq) goto loc_8213A454;
	// rlwinm r10,r11,30,2,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// cmplwi cr6,r10,8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 8, ctx.xer);
	// bgt cr6,0x8213a448
	if (ctx.cr6.gt) goto loc_8213A448;
	// li r10,8
	ctx.r10.s64 = 8;
loc_8213A448:
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8213a610
	ctx.lr = 0x8213A454;
	sub_8213A610(ctx, base);
loc_8213A454:
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// cmplw cr6,r11,r7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r7.u32, ctx.xer);
	// bge cr6,0x8213a4a4
	if (!ctx.cr6.lt) goto loc_8213A4A4;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x8213a4a0
	if (ctx.cr6.eq) goto loc_8213A4A0;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r11,0
	ctx.r11.s64 = 0;
	// add r8,r11,r9
	ctx.r8.u64 = ctx.r11.u64 + ctx.r9.u64;
loc_8213A480:
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmpwi cr6,r8,-1
	ctx.cr6.compare<int32_t>(ctx.r8.s32, -1, ctx.xer);
	// beq cr6,0x8213a4a0
	if (ctx.cr6.eq) goto loc_8213A4A0;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,80
	ctx.r11.s64 = ctx.r11.s64 + 80;
	// cmplw cr6,r10,r29
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r29.u32, ctx.xer);
	// add r8,r11,r9
	ctx.r8.u64 = ctx.r11.u64 + ctx.r9.u64;
	// blt cr6,0x8213a480
	if (ctx.cr6.lt) goto loc_8213A480;
loc_8213A4A0:
	// mr r29,r10
	ctx.r29.u64 = ctx.r10.u64;
loc_8213A4A4:
	// addi r11,r29,1
	ctx.r11.s64 = ctx.r29.s64 + 1;
	// cmplw cr6,r11,r7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r7.u32, ctx.xer);
	// ble cr6,0x8213a4b4
	if (!ctx.cr6.gt) goto loc_8213A4B4;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
loc_8213A4B4:
	// rlwinm r10,r29,2,0,29
	ctx.r10.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// add r10,r29,r10
	ctx.r10.u64 = ctx.r29.u64 + ctx.r10.u64;
	// li r5,68
	ctx.r5.s64 = 68;
	// rlwinm r30,r10,4,0,27
	ctx.r30.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// addi r3,r11,8
	ctx.r3.s64 = ctx.r11.s64 + 8;
	// bl 0x8233e4e0
	ctx.lr = 0x8213A4D8;
	sub_8233E4E0(ctx, base);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stwx r28,r30,r9
	PPC_STORE_U32(ctx.r30.u32 + ctx.r9.u32, ctx.r28.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// add r8,r30,r11
	ctx.r8.u64 = ctx.r30.u64 + ctx.r11.u64;
	// stw r26,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r26.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// add r7,r30,r11
	ctx.r7.u64 = ctx.r30.u64 + ctx.r11.u64;
	// stw r27,76(r7)
	PPC_STORE_U32(ctx.r7.u32 + 76, ctx.r27.u32);
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// addi r6,r11,1
	ctx.r6.s64 = ctx.r11.s64 + 1;
	// stw r6,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r6.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213A510"))) PPC_WEAK_FUNC(sub_8213A510);
PPC_FUNC_IMPL(__imp__sub_8213A510) {
	PPC_FUNC_PROLOGUE();
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// lwz r7,0(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r3,0
	ctx.r3.s64 = 0;
	// cmpwi cr6,r5,-1
	ctx.cr6.compare<int32_t>(ctx.r5.s32, -1, ctx.xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,8(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// beq cr6,0x8213a588
	if (ctx.cr6.eq) goto loc_8213A588;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x8213a5c0
	if (!ctx.cr6.gt) goto loc_8213A5C0;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
loc_8213A538:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r9,r4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r4.s32, ctx.xer);
	// bne cr6,0x8213a550
	if (!ctx.cr6.eq) goto loc_8213A550;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplw cr6,r9,r5
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x8213a568
	if (ctx.cr6.eq) goto loc_8213A568;
loc_8213A550:
	// lwz r9,8(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,80
	ctx.r11.s64 = ctx.r11.s64 + 80;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8213a538
	if (ctx.cr6.lt) goto loc_8213A538;
	// b 0x8213a5c0
	goto loc_8213A5C0;
loc_8213A568:
	// rlwinm r11,r10,2,0,29
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// li r9,-1
	ctx.r9.s64 = -1;
	// add r6,r10,r11
	ctx.r6.u64 = ctx.r10.u64 + ctx.r11.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// rlwinm r11,r6,4,0,27
	ctx.r11.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 4) & 0xFFFFFFF0;
	// add r5,r11,r7
	ctx.r5.u64 = ctx.r11.u64 + ctx.r7.u64;
	// stw r9,4(r5)
	PPC_STORE_U32(ctx.r5.u32 + 4, ctx.r9.u32);
	// b 0x8213a5c0
	goto loc_8213A5C0;
loc_8213A588:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x8213a5c0
	if (!ctx.cr6.gt) goto loc_8213A5C0;
	// mr r11,r7
	ctx.r11.u64 = ctx.r7.u64;
	// li r9,-1
	ctx.r9.s64 = -1;
loc_8213A598:
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmpw cr6,r6,r4
	ctx.cr6.compare<int32_t>(ctx.r6.s32, ctx.r4.s32, ctx.xer);
	// bne cr6,0x8213a5ac
	if (!ctx.cr6.eq) goto loc_8213A5AC;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
loc_8213A5AC:
	// lwz r6,8(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,80
	ctx.r11.s64 = ctx.r11.s64 + 80;
	// cmplw cr6,r10,r6
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, ctx.xer);
	// blt cr6,0x8213a598
	if (ctx.cr6.lt) goto loc_8213A598;
loc_8213A5C0:
	// lwz r11,8(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// blt 0x8213a5f8
	if (ctx.cr0.lt) goto loc_8213A5F8;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r10,r10,4,0,27
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// add r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 + ctx.r7.u64;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_8213A5E0:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,-1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, -1, ctx.xer);
	// bne cr6,0x8213a5f8
	if (!ctx.cr6.eq) goto loc_8213A5F8;
	// addic. r11,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r11.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// addi r10,r10,-80
	ctx.r10.s64 = ctx.r10.s64 + -80;
	// bge 0x8213a5e0
	if (!ctx.cr0.lt) goto loc_8213A5E0;
loc_8213A5F8:
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// subf r7,r3,r10
	ctx.r7.s64 = ctx.r10.s64 - ctx.r3.s64;
	// stw r9,8(r8)
	PPC_STORE_U32(ctx.r8.u32 + 8, ctx.r9.u32);
	// stw r7,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, ctx.r7.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213A610"))) PPC_WEAK_FUNC(sub_8213A610);
PPC_FUNC_IMPL(__imp__sub_8213A610) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8213A618;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x8213a6cc
	if (ctx.cr6.eq) goto loc_8213A6CC;
	// lis r11,819
	ctx.r11.s64 = 53673984;
	// li r28,-1
	ctx.r28.s64 = -1;
	// ori r10,r11,13107
	ctx.r10.u64 = ctx.r11.u64 | 13107;
	// cmplw cr6,r4,r10
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, ctx.xer);
	// bgt cr6,0x8213a654
	if (ctx.cr6.gt) goto loc_8213A654;
	// rlwinm r11,r4,2,0,29
	ctx.r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r4,r11
	ctx.r11.u64 = ctx.r4.u64 + ctx.r11.u64;
	// rlwinm r3,r11,4,0,27
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// b 0x8213a658
	goto loc_8213A658;
loc_8213A654:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
loc_8213A658:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x8213A668;
	sub_82082030(ctx, base);
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x8213a67c
	if (!ctx.cr6.lt) goto loc_8213A67C;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
loc_8213A67C:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213a69c
	if (ctx.cr6.eq) goto loc_8213A69C;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r5,r11,4,0,27
	ctx.r5.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x8233e4e0
	ctx.lr = 0x8213A69C;
	sub_8233E4E0(ctx, base);
loc_8213A69C:
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// bge cr6,0x8213a6cc
	if (!ctx.cr6.lt) goto loc_8213A6CC;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r9,r11,r31
	ctx.r9.s64 = ctx.r31.s64 - ctx.r11.s64;
	// add r8,r11,r10
	ctx.r8.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r8,4,0,27
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r30
	ctx.r11.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// addi r11,r11,-76
	ctx.r11.s64 = ctx.r11.s64 + -76;
loc_8213A6C4:
	// stwu r28,80(r11)
	ea = 80 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x8213a6c4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213A6C4;
loc_8213A6CC:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213a6e4
	if (ctx.cr6.eq) goto loc_8213A6E4;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213A6E4;
	sub_82080000(ctx, base);
loc_8213A6E4:
	// stw r30,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r30.u32);
	// stw r31,4(r29)
	PPC_STORE_U32(ctx.r29.u32 + 4, ctx.r31.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213A6F4"))) PPC_WEAK_FUNC(sub_8213A6F4);
PPC_FUNC_IMPL(__imp__sub_8213A6F4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213A6F8"))) PPC_WEAK_FUNC(sub_8213A6F8);
PPC_FUNC_IMPL(__imp__sub_8213A6F8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8213A700;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8213a7f8
	if (ctx.cr6.eq) goto loc_8213A7F8;
	// addic. r31,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r31.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// li r30,0
	ctx.r30.s64 = 0;
	// beq 0x8213a7f0
	if (ctx.cr0.eq) goto loc_8213A7F0;
	// li r27,-1
	ctx.r27.s64 = -1;
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
	// bge cr6,0x8213a768
	if (!ctx.cr6.lt) goto loc_8213A768;
loc_8213A730:
	// rlwinm r11,r30,2,0,29
	ctx.r11.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// add r11,r30,r11
	ctx.r11.u64 = ctx.r30.u64 + ctx.r11.u64;
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_8213A744:
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r9,-1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, -1, ctx.xer);
	// beq cr6,0x8213a764
	if (ctx.cr6.eq) goto loc_8213A764;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// addi r11,r11,80
	ctx.r11.s64 = ctx.r11.s64 + 80;
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// blt cr6,0x8213a744
	if (ctx.cr6.lt) goto loc_8213A744;
loc_8213A764:
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
loc_8213A768:
	// beq cr6,0x8213a7f0
	if (ctx.cr6.eq) goto loc_8213A7F0;
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
	// bge cr6,0x8213a7ac
	if (!ctx.cr6.lt) goto loc_8213A7AC;
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// add r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 + ctx.r11.u64;
	// rlwinm r11,r11,4,0,27
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_8213A788:
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r9,-1
	ctx.cr6.compare<int32_t>(ctx.r9.s32, -1, ctx.xer);
	// bne cr6,0x8213a7a8
	if (!ctx.cr6.eq) goto loc_8213A7A8;
	// addi r31,r31,-1
	ctx.r31.s64 = ctx.r31.s64 + -1;
	// addi r11,r11,-80
	ctx.r11.s64 = ctx.r11.s64 + -80;
	// cmplw cr6,r31,r30
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r30.u32, ctx.xer);
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bgt cr6,0x8213a788
	if (ctx.cr6.gt) goto loc_8213A788;
loc_8213A7A8:
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
loc_8213A7AC:
	// beq cr6,0x8213a7f0
	if (ctx.cr6.eq) goto loc_8213A7F0;
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// rlwinm r9,r31,2,0,29
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r30,r10
	ctx.r8.u64 = ctx.r30.u64 + ctx.r10.u64;
	// add r9,r31,r9
	ctx.r9.u64 = ctx.r31.u64 + ctx.r9.u64;
	// rlwinm r10,r8,4,0,27
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r29,r9,4,0,27
	ctx.r29.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + ctx.r11.u64;
	// add r4,r29,r11
	ctx.r4.u64 = ctx.r29.u64 + ctx.r11.u64;
	// li r5,80
	ctx.r5.s64 = 80;
	// bl 0x8233e4e0
	ctx.lr = 0x8213A7DC;
	sub_8233E4E0(ctx, base);
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// cmplw cr6,r30,r31
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r31.u32, ctx.xer);
	// add r7,r29,r11
	ctx.r7.u64 = ctx.r29.u64 + ctx.r11.u64;
	// stw r27,4(r7)
	PPC_STORE_U32(ctx.r7.u32 + 4, ctx.r27.u32);
	// blt cr6,0x8213a730
	if (ctx.cr6.lt) goto loc_8213A730;
loc_8213A7F0:
	// lwz r11,12(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	// stw r11,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r11.u32);
loc_8213A7F8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213A800"))) PPC_WEAK_FUNC(sub_8213A800);
PPC_FUNC_IMPL(__imp__sub_8213A800) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8213A808;
	__restfpr_28(ctx, base);
	// stfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f29.u64);
	// stfd f30,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lhz r7,72(r3)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r3.u32 + 72);
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// addi r30,r10,31376
	ctx.r30.s64 = ctx.r10.s64 + 31376;
	// addi r31,r3,8
	ctx.r31.s64 = ctx.r3.s64 + 8;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmpwi cr6,r7,4
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 4, ctx.xer);
	// lfs f0,324(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 324);
	ctx.f0.f64 = double(temp.f32);
	// blt cr6,0x8213a8f4
	if (ctx.cr6.lt) goto loc_8213A8F4;
	// addi r10,r1,-76
	ctx.r10.s64 = ctx.r1.s64 + -76;
	// lfs f13,8(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// addi r6,r7,-3
	ctx.r6.s64 = ctx.r7.s64 + -3;
	// addi r8,r10,-8
	ctx.r8.s64 = ctx.r10.s64 + -8;
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,12(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// addi r10,r31,-12
	ctx.r10.s64 = ctx.r31.s64 + -12;
loc_8213A858:
	// lfs f9,16(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lfs f8,28(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f9,f12
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f6,40(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f8,f12
	ctx.f5.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// lfs f4,56(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f6,f12
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// fmuls f2,f4,f13
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// lfs f8,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f8.f64 = double(temp.f32);
	// lfs f4,24(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	ctx.f4.f64 = double(temp.f32);
	// cmplw cr6,r9,r6
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, ctx.xer);
	// lfs f1,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// lfs f6,32(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f31,44(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 44);
	ctx.f31.f64 = double(temp.f32);
	// lfs f30,36(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,52(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 52);
	ctx.f29.f64 = double(temp.f32);
	// fmadds f8,f8,f11,f7
	ctx.f8.f64 = double(std::fma(float(ctx.f8.f64), float(ctx.f11.f64), float(ctx.f7.f64)));
	// lfsu f9,48(r10)
	ea = 48 + ctx.r10.u32;
	temp.u32 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	ctx.f9.f64 = double(temp.f32);
	// fmadds f7,f4,f11,f5
	ctx.f7.f64 = double(std::fma(float(ctx.f4.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fmadds f5,f30,f11,f3
	ctx.f5.f64 = double(std::fma(float(ctx.f30.f64), float(ctx.f11.f64), float(ctx.f3.f64)));
	// fmadds f4,f9,f11,f2
	ctx.f4.f64 = double(std::fma(float(ctx.f9.f64), float(ctx.f11.f64), float(ctx.f2.f64)));
	// fmadds f3,f1,f13,f8
	ctx.f3.f64 = double(std::fma(float(ctx.f1.f64), float(ctx.f13.f64), float(ctx.f8.f64)));
	// fmadds f2,f6,f13,f7
	ctx.f2.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f13.f64), float(ctx.f7.f64)));
	// fmadds f1,f31,f13,f5
	ctx.f1.f64 = double(std::fma(float(ctx.f31.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fmadds f9,f29,f12,f4
	ctx.f9.f64 = double(std::fma(float(ctx.f29.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fadds f8,f3,f10
	ctx.f8.f64 = double(float(ctx.f3.f64 + ctx.f10.f64));
	// fadds f7,f2,f10
	ctx.f7.f64 = double(float(ctx.f2.f64 + ctx.f10.f64));
	// fadds f6,f1,f10
	ctx.f6.f64 = double(float(ctx.f1.f64 + ctx.f10.f64));
	// fadds f5,f9,f10
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fadds f4,f8,f0
	ctx.f4.f64 = double(float(ctx.f8.f64 + ctx.f0.f64));
	// stfs f4,4(r8)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r8.u32 + 4, temp.u32);
	// fadds f3,f7,f0
	ctx.f3.f64 = double(float(ctx.f7.f64 + ctx.f0.f64));
	// stfs f3,8(r8)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r8.u32 + 8, temp.u32);
	// fadds f2,f6,f0
	ctx.f2.f64 = double(float(ctx.f6.f64 + ctx.f0.f64));
	// stfs f2,12(r8)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r8.u32 + 12, temp.u32);
	// fadds f1,f5,f0
	ctx.f1.f64 = double(float(ctx.f5.f64 + ctx.f0.f64));
	// stfsu f1,16(r8)
	temp.f32 = float(ctx.f1.f64);
	ea = 16 + ctx.r8.u32;
	PPC_STORE_U32(ea, temp.u32);
	ctx.r8.u32 = ea;
	// blt cr6,0x8213a858
	if (ctx.cr6.lt) goto loc_8213A858;
loc_8213A8F4:
	// cmplw cr6,r9,r7
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, ctx.xer);
	// bge cr6,0x8213a960
	if (!ctx.cr6.lt) goto loc_8213A960;
	// rlwinm r10,r9,1,0,30
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f12,8(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r9,r10
	ctx.r6.u64 = ctx.r9.u64 + ctx.r10.u64;
	// lfs f10,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,12(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// addi r10,r1,-80
	ctx.r10.s64 = ctx.r1.s64 + -80;
	// subf r5,r9,r7
	ctx.r5.s64 = ctx.r7.s64 - ctx.r9.s64;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
	// add r9,r6,r31
	ctx.r9.u64 = ctx.r6.u64 + ctx.r31.u64;
	// addi r8,r10,-4
	ctx.r8.s64 = ctx.r10.s64 + -4;
	// addi r10,r9,-12
	ctx.r10.s64 = ctx.r9.s64 + -12;
	// mtctr r5
	ctx.ctr.u64 = ctx.r5.u64;
loc_8213A938:
	// lfs f13,16(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f8,f13,f11
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f7,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// lfsu f13,12(r10)
	ea = 12 + ctx.r10.u32;
	temp.u32 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	ctx.f13.f64 = double(temp.f32);
	// fmadds f6,f13,f10,f8
	ctx.f6.f64 = double(std::fma(float(ctx.f13.f64), float(ctx.f10.f64), float(ctx.f8.f64)));
	// fmadds f5,f7,f12,f6
	ctx.f5.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f12.f64), float(ctx.f6.f64)));
	// fadds f4,f5,f9
	ctx.f4.f64 = double(float(ctx.f5.f64 + ctx.f9.f64));
	// fadds f3,f4,f0
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f0.f64));
	// stfsu f3,4(r8)
	temp.f32 = float(ctx.f3.f64);
	ea = 4 + ctx.r8.u32;
	PPC_STORE_U32(ea, temp.u32);
	ctx.r8.u32 = ea;
	// bdnz 0x8213a938
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213A938;
loc_8213A960:
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x8213ab38
	if (ctx.cr6.eq) goto loc_8213AB38;
	// lfs f12,48(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// addi r4,r1,-80
	ctx.r4.s64 = ctx.r1.s64 + -80;
	// addi r29,r7,-2
	ctx.r29.s64 = ctx.r7.s64 + -2;
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
loc_8213A984:
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	ctx.cr6.compare(ctx.f0.f64, ctx.f12.f64);
	// bge cr6,0x8213a9a8
	if (!ctx.cr6.lt) goto loc_8213A9A8;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// lwz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r8,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r8.u32);
	// lwz r9,8(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// b 0x8213ab18
	goto loc_8213AB18;
loc_8213A9A8:
	// add r9,r29,r6
	ctx.r9.u64 = ctx.r29.u64 + ctx.r6.u64;
	// addi r8,r1,-80
	ctx.r8.s64 = ctx.r1.s64 + -80;
	// divwu r30,r9,r7
	ctx.r30.u32 = ctx.r9.u32 / ctx.r7.u32;
	// twllei r7,0
	if (ctx.r7.u32 <= 0) __builtin_debugtrap();
	// mullw r30,r30,r7
	ctx.r30.s64 = int64_t(ctx.r30.s32) * int64_t(ctx.r7.s32);
	// subf r9,r30,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r30.s64;
	// rlwinm r30,r9,2,0,29
	ctx.r30.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f13,r30,r8
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r8.u32);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f12
	ctx.cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// bgt cr6,0x8213aa68
	if (ctx.cr6.gt) goto loc_8213AA68;
	// rlwinm r8,r9,1,0,30
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// fsubs f13,f0,f13
	ctx.f13.f64 = static_cast<float>(ctx.f0.f64 - ctx.f13.f64);
	// lfs f9,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// lfs f11,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r9,r31
	ctx.r8.u64 = ctx.r9.u64 + ctx.r31.u64;
	// lwzx r9,r9,r31
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r31.u32);
	// fdivs f8,f0,f13
	ctx.f8.f64 = double(float(ctx.f0.f64 / ctx.f13.f64));
	// lwz r30,8(r8)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwz r8,4(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// stw r9,-112(r1)
	PPC_STORE_U32(ctx.r1.u32 + -112, ctx.r9.u32);
	// lfs f7,-112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -112);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f6,f7,f9
	ctx.f6.f64 = static_cast<float>(ctx.f7.f64 - ctx.f9.f64);
	// stw r30,-104(r1)
	PPC_STORE_U32(ctx.r1.u32 + -104, ctx.r30.u32);
	// lfs f5,-104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -104);
	ctx.f5.f64 = double(temp.f32);
	// stw r8,-108(r1)
	PPC_STORE_U32(ctx.r1.u32 + -108, ctx.r8.u32);
	// lfs f4,-108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -108);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f6,f8
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f8.f64));
	// fadds f2,f9,f3
	ctx.f2.f64 = double(float(ctx.f9.f64 + ctx.f3.f64));
	// stfs f2,-112(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + -112, temp.u32);
	// lwz r9,-112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -112);
	// stw r9,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r9.u32);
	// fsubs f1,f5,f11
	ctx.f1.f64 = static_cast<float>(ctx.f5.f64 - ctx.f11.f64);
	// fsubs f13,f4,f10
	ctx.f13.f64 = static_cast<float>(ctx.f4.f64 - ctx.f10.f64);
	// fmuls f9,f1,f8
	ctx.f9.f64 = double(float(ctx.f1.f64 * ctx.f8.f64));
	// fmuls f8,f13,f8
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// fadds f7,f11,f9
	ctx.f7.f64 = double(float(ctx.f11.f64 + ctx.f9.f64));
	// stfs f7,-104(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + -104, temp.u32);
	// lwz r8,-104(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + -104);
	// fadds f6,f10,f8
	ctx.f6.f64 = double(float(ctx.f10.f64 + ctx.f8.f64));
	// stfs f6,-108(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + -108, temp.u32);
	// lwz r9,-108(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -108);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
loc_8213AA68:
	// divwu r9,r6,r7
	ctx.r9.u32 = ctx.r6.u32 / ctx.r7.u32;
	// addi r8,r1,-80
	ctx.r8.s64 = ctx.r1.s64 + -80;
	// mullw r9,r9,r7
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r7.s32);
	// subf r9,r9,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r9.s64;
	// twllei r7,0
	if (ctx.r7.u32 <= 0) __builtin_debugtrap();
	// rlwinm r30,r9,2,0,29
	ctx.r30.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f13,r30,r8
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r8.u32);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f12
	ctx.cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// bgt cr6,0x8213ab24
	if (ctx.cr6.gt) goto loc_8213AB24;
	// rlwinm r8,r9,1,0,30
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r30,0(r10)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// fsubs f0,f13,f0
	ctx.f0.f64 = static_cast<float>(ctx.f13.f64 - ctx.f0.f64);
	// lwz r28,4(r10)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// lwz r8,8(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r30,-96(r1)
	PPC_STORE_U32(ctx.r1.u32 + -96, ctx.r30.u32);
	// lfs f11,-96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -96);
	ctx.f11.f64 = double(temp.f32);
	// add r9,r9,r31
	ctx.r9.u64 = ctx.r9.u64 + ctx.r31.u64;
	// stw r28,-92(r1)
	PPC_STORE_U32(ctx.r1.u32 + -92, ctx.r28.u32);
	// stw r8,-88(r1)
	PPC_STORE_U32(ctx.r1.u32 + -88, ctx.r8.u32);
	// lfs f9,-88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -88);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,-92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -92);
	ctx.f10.f64 = double(temp.f32);
	// lfs f3,4(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// fdivs f7,f13,f0
	ctx.f7.f64 = double(float(ctx.f13.f64 / ctx.f0.f64));
	// lfs f5,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f1,f10,f3
	ctx.f1.f64 = static_cast<float>(ctx.f10.f64 - ctx.f3.f64);
	// lfs f8,8(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f2,f11,f5
	ctx.f2.f64 = static_cast<float>(ctx.f11.f64 - ctx.f5.f64);
	// fsubs f6,f9,f8
	ctx.f6.f64 = static_cast<float>(ctx.f9.f64 - ctx.f8.f64);
	// fmuls f11,f1,f7
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// fmuls f13,f2,f7
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f7.f64));
	// fmuls f4,f6,f7
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// fadds f9,f3,f11
	ctx.f9.f64 = double(float(ctx.f3.f64 + ctx.f11.f64));
	// stfs f9,-92(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + -92, temp.u32);
	// lwz r8,-92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + -92);
	// stw r8,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r8.u32);
	// fadds f10,f5,f13
	ctx.f10.f64 = double(float(ctx.f5.f64 + ctx.f13.f64));
	// stfs f10,-96(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + -96, temp.u32);
	// fadds f0,f8,f4
	ctx.f0.f64 = double(float(ctx.f8.f64 + ctx.f4.f64));
	// lwz r8,-96(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + -96);
	// stfs f0,-88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -88, temp.u32);
	// lwz r9,-88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -88);
	// stw r8,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r8.u32);
loc_8213AB18:
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
loc_8213AB24:
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// bne 0x8213a984
	if (!ctx.cr0.eq) goto loc_8213A984;
loc_8213AB38:
	// lfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f30,-56(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213AB48"))) PPC_WEAK_FUNC(sub_8213AB48);
PPC_FUNC_IMPL(__imp__sub_8213AB48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e44c
	ctx.lr = 0x8213AB50;
	__restfpr_21(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r21,0
	ctx.r21.s64 = 0;
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// stw r21,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r21.u32);
	// mr r23,r5
	ctx.r23.u64 = ctx.r5.u64;
	// stw r21,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r21.u32);
	// mr r22,r6
	ctx.r22.u64 = ctx.r6.u64;
	// lwz r11,224(r6)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 224);
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// lwz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// and r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 & ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8213adf0
	if (ctx.cr6.eq) goto loc_8213ADF0;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwz r7,192(r6)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r6.u32 + 192);
	// addi r8,r9,-4
	ctx.r8.s64 = ctx.r9.s64 + -4;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// addi r10,r9,-4
	ctx.r10.s64 = ctx.r9.s64 + -4;
loc_8213ABA4:
	// lwzu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	ctx.r9.u64 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	// stwu r9,4(r8)
	ea = 4 + ctx.r8.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r8.u32 = ea;
	// bdnz 0x8213aba4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213ABA4;
	// li r9,6
	ctx.r9.s64 = 6;
	// lwz r11,20(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// addi r10,r1,108
	ctx.r10.s64 = ctx.r1.s64 + 108;
	// addi r11,r11,-4
	ctx.r11.s64 = ctx.r11.s64 + -4;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8213ABC4:
	// lwzu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	ctx.r9.u64 = PPC_LOAD_U32(ea);
	ctx.r11.u32 = ea;
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x8213abc4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213ABC4;
	// mr r10,r21
	ctx.r10.u64 = ctx.r21.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x8213ac50
	if (ctx.cr6.eq) goto loc_8213AC50;
	// lfs f0,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r22,4
	ctx.r11.s64 = ctx.r22.s64 + 4;
	// lfs f13,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f9.f64 = double(temp.f32);
loc_8213ABF8:
	// lfs f8,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,-4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f8,f10
	ctx.f6.f64 = double(float(ctx.f8.f64 * ctx.f10.f64));
	// fmuls f5,f7,f12
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f12.f64));
	// lfs f4,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f7,f9
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// lfs f2,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f4,f11
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f11.f64));
	// fabs f7,f6
	ctx.f7.u64 = ctx.f6.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f6,f8,f13,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f8.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fabs f5,f3
	ctx.f5.u64 = ctx.f3.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f3,f1
	ctx.f3.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f1,f4,f0,f6
	ctx.f1.f64 = double(std::fma(float(ctx.f4.f64), float(ctx.f0.f64), float(ctx.f6.f64)));
	// fadds f8,f7,f5
	ctx.f8.f64 = double(float(ctx.f7.f64 + ctx.f5.f64));
	// fadds f7,f1,f2
	ctx.f7.f64 = double(float(ctx.f1.f64 + ctx.f2.f64));
	// fadds f6,f8,f3
	ctx.f6.f64 = double(float(ctx.f8.f64 + ctx.f3.f64));
	// fcmpu cr6,f7,f6
	ctx.cr6.compare(ctx.f7.f64, ctx.f6.f64);
	// bgt cr6,0x8213adf0
	if (ctx.cr6.gt) goto loc_8213ADF0;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// cmplw cr6,r10,r7
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, ctx.xer);
	// blt cr6,0x8213abf8
	if (ctx.cr6.lt) goto loc_8213ABF8;
loc_8213AC50:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lwz r9,4(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r8,0(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lis r24,-13569
	ctx.r24.s64 = -889257984;
	// addi r25,r11,4492
	ctx.r25.s64 = ctx.r11.s64 + 4492;
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// addi r7,r11,511
	ctx.r7.s64 = ctx.r11.s64 + 511;
	// rlwinm r11,r7,23,9,31
	ctx.r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 23) & 0x7FFFFF;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r11,r10
	ctx.r6.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r5,r10,15
	ctx.r5.s64 = ctx.r10.s64 + 15;
	// rlwinm r10,r5,0,0,27
	ctx.r10.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFF0;
	// add r4,r9,r10
	ctx.r4.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r4,r8
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r8.u32, ctx.xer);
	// ble cr6,0x8213ac94
	if (!ctx.cr6.gt) goto loc_8213AC94;
	// stw r25,-13570(r24)
	PPC_STORE_U32(ctx.r24.u32 + -13570, ctx.r25.u32);
loc_8213AC94:
	// lwz r9,4(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// add r8,r9,r10
	ctx.r8.u64 = ctx.r9.u64 + ctx.r10.u64;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// add r3,r9,r10
	ctx.r3.u64 = ctx.r9.u64 + ctx.r10.u64;
	// stw r8,4(r29)
	PPC_STORE_U32(ctx.r29.u32 + 4, ctx.r8.u32);
	// stw r11,4(r23)
	PPC_STORE_U32(ctx.r23.u32 + 4, ctx.r11.u32);
	// stw r3,0(r23)
	PPC_STORE_U32(ctx.r23.u32 + 0, ctx.r3.u32);
	// beq cr6,0x8213ad24
	if (ctx.cr6.eq) goto loc_8213AD24;
	// mr r28,r21
	ctx.r28.u64 = ctx.r21.u64;
	// mr r30,r21
	ctx.r30.u64 = ctx.r21.u64;
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
loc_8213ACC4:
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// subf r6,r28,r11
	ctx.r6.s64 = ctx.r11.s64 - ctx.r28.s64;
	// cmplwi cr6,r6,512
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 512, ctx.xer);
	// blt cr6,0x8213acd8
	if (ctx.cr6.lt) goto loc_8213ACD8;
	// li r6,512
	ctx.r6.s64 = 512;
loc_8213ACD8:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213ad00
	if (ctx.cr6.eq) goto loc_8213AD00;
	// lwz r11,8(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// li r7,1
	ctx.r7.s64 = 1;
	// add r5,r11,r30
	ctx.r5.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// bl 0x8213b150
	ctx.lr = 0x8213ACF8;
	sub_8213B150(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x8213ad04
	goto loc_8213AD04;
loc_8213AD00:
	// mr r31,r21
	ctx.r31.u64 = ctx.r21.u64;
loc_8213AD04:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821b60c0
	ctx.lr = 0x8213AD10;
	sub_821B60C0(ctx, base);
	// addic. r27,r27,-1
	ctx.xer.ca = ctx.r27.u32 > 0;
	ctx.r27.s64 = ctx.r27.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// addi r28,r28,512
	ctx.r28.s64 = ctx.r28.s64 + 512;
	// addi r30,r30,14336
	ctx.r30.s64 = ctx.r30.s64 + 14336;
	// addi r3,r31,40
	ctx.r3.s64 = ctx.r31.s64 + 40;
	// bne 0x8213acc4
	if (!ctx.cr0.eq) goto loc_8213ACC4;
loc_8213AD24:
	// lwz r11,12(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// addi r11,r11,511
	ctx.r11.s64 = ctx.r11.s64 + 511;
	// lwz r8,0(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// rlwinm r11,r11,23,9,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 23) & 0x7FFFFF;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r11,r9
	ctx.r7.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r6,r9,15
	ctx.r6.s64 = ctx.r9.s64 + 15;
	// rlwinm r9,r6,0,0,27
	ctx.r9.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFF0;
	// add r5,r10,r9
	ctx.r5.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r5,r8
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r8.u32, ctx.xer);
	// ble cr6,0x8213ad5c
	if (!ctx.cr6.gt) goto loc_8213AD5C;
	// stw r25,-13570(r24)
	PPC_STORE_U32(ctx.r24.u32 + -13570, ctx.r25.u32);
loc_8213AD5C:
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r8,8(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r9,4(r29)
	PPC_STORE_U32(ctx.r29.u32 + 4, ctx.r9.u32);
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// stw r10,8(r23)
	PPC_STORE_U32(ctx.r23.u32 + 8, ctx.r10.u32);
	// stw r11,12(r23)
	PPC_STORE_U32(ctx.r23.u32 + 12, ctx.r11.u32);
	// beq cr6,0x8213adf0
	if (ctx.cr6.eq) goto loc_8213ADF0;
	// mr r28,r21
	ctx.r28.u64 = ctx.r21.u64;
	// mr r30,r21
	ctx.r30.u64 = ctx.r21.u64;
	// mr r27,r11
	ctx.r27.u64 = ctx.r11.u64;
loc_8213AD90:
	// lwz r11,12(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	// subf r6,r28,r11
	ctx.r6.s64 = ctx.r11.s64 - ctx.r28.s64;
	// cmplwi cr6,r6,512
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 512, ctx.xer);
	// blt cr6,0x8213ada4
	if (ctx.cr6.lt) goto loc_8213ADA4;
	// li r6,512
	ctx.r6.s64 = 512;
loc_8213ADA4:
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213adcc
	if (ctx.cr6.eq) goto loc_8213ADCC;
	// lwz r11,16(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// li r7,2
	ctx.r7.s64 = 2;
	// add r5,r11,r30
	ctx.r5.u64 = ctx.r11.u64 + ctx.r30.u64;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// bl 0x8213b150
	ctx.lr = 0x8213ADC4;
	sub_8213B150(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// b 0x8213add0
	goto loc_8213ADD0;
loc_8213ADCC:
	// mr r31,r21
	ctx.r31.u64 = ctx.r21.u64;
loc_8213ADD0:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821b60c0
	ctx.lr = 0x8213ADDC;
	sub_821B60C0(ctx, base);
	// addic. r27,r27,-1
	ctx.xer.ca = ctx.r27.u32 > 0;
	ctx.r27.s64 = ctx.r27.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// addi r28,r28,512
	ctx.r28.s64 = ctx.r28.s64 + 512;
	// addi r30,r30,14336
	ctx.r30.s64 = ctx.r30.s64 + 14336;
	// addi r3,r31,40
	ctx.r3.s64 = ctx.r31.s64 + 40;
	// bne 0x8213ad90
	if (!ctx.cr0.eq) goto loc_8213AD90;
loc_8213ADF0:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213ADF8"))) PPC_WEAK_FUNC(sub_8213ADF8);
PPC_FUNC_IMPL(__imp__sub_8213ADF8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// lwz r4,4(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r30,0
	ctx.r30.s64 = 0;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpwi cr6,r4,2
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 2, ctx.xer);
	// blt cr6,0x8213ae44
	if (ctx.cr6.lt) goto loc_8213AE44;
	// addi r5,r4,-1
	ctx.r5.s64 = ctx.r4.s64 + -1;
	// addi r10,r31,-12
	ctx.r10.s64 = ctx.r31.s64 + -12;
loc_8213AE28:
	// lwz r6,40(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lwzu r7,80(r10)
	ea = 80 + ctx.r10.u32;
	ctx.r7.u64 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	// add r9,r6,r9
	ctx.r9.u64 = ctx.r6.u64 + ctx.r9.u64;
	// add r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 + ctx.r8.u64;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// blt cr6,0x8213ae28
	if (ctx.cr6.lt) goto loc_8213AE28;
loc_8213AE44:
	// cmplw cr6,r11,r4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r4.u32, ctx.xer);
	// bge cr6,0x8213ae60
	if (!ctx.cr6.lt) goto loc_8213AE60;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r11,r31
	ctx.r10.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lwz r30,28(r10)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
loc_8213AE60:
	// add r11,r8,r9
	ctx.r11.u64 = ctx.r8.u64 + ctx.r9.u64;
	// lwz r4,12(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r31,8(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// li r9,0
	ctx.r9.s64 = 0;
	// add r3,r11,r30
	ctx.r3.u64 = ctx.r11.u64 + ctx.r30.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpwi cr6,r4,2
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 2, ctx.xer);
	// blt cr6,0x8213aea8
	if (ctx.cr6.lt) goto loc_8213AEA8;
	// addi r5,r4,-1
	ctx.r5.s64 = ctx.r4.s64 + -1;
	// addi r10,r31,-12
	ctx.r10.s64 = ctx.r31.s64 + -12;
loc_8213AE8C:
	// lwz r6,40(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lwzu r7,80(r10)
	ea = 80 + ctx.r10.u32;
	ctx.r7.u64 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	// add r9,r6,r9
	ctx.r9.u64 = ctx.r6.u64 + ctx.r9.u64;
	// add r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 + ctx.r8.u64;
	// cmplw cr6,r11,r5
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r5.u32, ctx.xer);
	// blt cr6,0x8213ae8c
	if (ctx.cr6.lt) goto loc_8213AE8C;
loc_8213AEA8:
	// cmplw cr6,r11,r4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r4.u32, ctx.xer);
	// bge cr6,0x8213aec8
	if (!ctx.cr6.lt) goto loc_8213AEC8;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r11,r31
	ctx.r10.u64 = ctx.r11.u64 + ctx.r31.u64;
	// lwz r11,28(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
loc_8213AEC8:
	// add r11,r8,r9
	ctx.r11.u64 = ctx.r8.u64 + ctx.r9.u64;
	// add r11,r11,r3
	ctx.r11.u64 = ctx.r11.u64 + ctx.r3.u64;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// ld r30,-16(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213AEE4"))) PPC_WEAK_FUNC(sub_8213AEE4);
PPC_FUNC_IMPL(__imp__sub_8213AEE4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213AEE8"))) PPC_WEAK_FUNC(sub_8213AEE8);
PPC_FUNC_IMPL(__imp__sub_8213AEE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x8213AEF0;
	__restfpr_29(ctx, base);
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// stw r5,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r5.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lbz r30,229(r7)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r7.u32 + 229);
	// beq cr6,0x8213af8c
	if (ctx.cr6.eq) goto loc_8213AF8C;
	// addi r7,r10,32
	ctx.r7.s64 = ctx.r10.s64 + 32;
	// mr r29,r11
	ctx.r29.u64 = ctx.r11.u64;
loc_8213AF14:
	// lwz r11,-4(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + -4);
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213af3c
	if (ctx.cr6.eq) goto loc_8213AF3C;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// addi r9,r31,-4
	ctx.r9.s64 = ctx.r31.s64 + -4;
loc_8213AF30:
	// lwzu r8,4(r10)
	ea = 4 + ctx.r10.u32;
	ctx.r8.u64 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	// stwu r8,4(r9)
	ea = 4 + ctx.r9.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r9.u32 = ea;
	// bdnz 0x8213af30
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213AF30;
loc_8213AF3C:
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,-8(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + -8);
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// add r31,r11,r31
	ctx.r31.u64 = ctx.r11.u64 + ctx.r31.u64;
	// add r11,r9,r10
	ctx.r11.u64 = ctx.r9.u64 + ctx.r10.u64;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r11.u32);
	// lwz r11,-12(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + -12);
	// beq cr6,0x8213af80
	if (ctx.cr6.eq) goto loc_8213AF80;
	// addi r10,r11,-4
	ctx.r10.s64 = ctx.r11.s64 + -4;
	// mtctr r30
	ctx.ctr.u64 = ctx.r30.u64;
	// mr r11,r6
	ctx.r11.u64 = ctx.r6.u64;
loc_8213AF6C:
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwzu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	ctx.r9.u64 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x8213af6c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213AF6C;
loc_8213AF80:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r7,r7,40
	ctx.r7.s64 = ctx.r7.s64 + 40;
	// bne 0x8213af14
	if (!ctx.cr0.eq) goto loc_8213AF14;
loc_8213AF8C:
	// subf r11,r5,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r5.s64;
	// li r30,0
	ctx.r30.s64 = 0;
	// srawi r10,r11,2
	ctx.xer.ca = (ctx.r11.s32 < 0) & ((ctx.r11.u32 & 0x3) != 0);
	ctx.r10.s64 = ctx.r11.s32 >> 2;
	// addi r11,r31,4
	ctx.r11.s64 = ctx.r31.s64 + 4;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// lwz r10,12(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lwz r9,8(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r11.u32);
	// beq cr6,0x8213b000
	if (ctx.cr6.eq) goto loc_8213B000;
	// addi r6,r9,32
	ctx.r6.s64 = ctx.r9.s64 + 32;
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
loc_8213AFC4:
	// lwz r8,-4(r6)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + -4);
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8213afec
	if (ctx.cr6.eq) goto loc_8213AFEC;
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// addi r9,r11,-4
	ctx.r9.s64 = ctx.r11.s64 + -4;
loc_8213AFE0:
	// lwzu r7,4(r10)
	ea = 4 + ctx.r10.u32;
	ctx.r7.u64 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	// stwu r7,4(r9)
	ea = 4 + ctx.r9.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r9.u32 = ea;
	// bdnz 0x8213afe0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213AFE0;
loc_8213AFEC:
	// rlwinm r10,r8,2,0,29
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addic. r4,r4,-1
	ctx.xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r6,r6,40
	ctx.r6.s64 = ctx.r6.s64 + 40;
	// bne 0x8213afc4
	if (!ctx.cr0.eq) goto loc_8213AFC4;
loc_8213B000:
	// subf r9,r31,r11
	ctx.r9.s64 = ctx.r11.s64 - ctx.r31.s64;
	// subf r10,r5,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r5.s64;
	// srawi r8,r9,2
	ctx.xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r8.s64 = ctx.r9.s32 >> 2;
	// stw r8,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r8.u32);
	// addi r3,r10,4
	ctx.r3.s64 = ctx.r10.s64 + 4;
	// stw r30,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r30.u32);
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213B01C"))) PPC_WEAK_FUNC(sub_8213B01C);
PPC_FUNC_IMPL(__imp__sub_8213B01C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213B020"))) PPC_WEAK_FUNC(sub_8213B020);
PPC_FUNC_IMPL(__imp__sub_8213B020) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8213B028;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,12(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// lwz r31,8(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addic. r5,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r5.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// blt 0x8213b060
	if (ctx.cr0.lt) goto loc_8213B060;
	// rlwinm r11,r5,2,0,29
	ctx.r11.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r5,r11
	ctx.r11.u64 = ctx.r5.u64 + ctx.r11.u64;
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r11,r31
	ctx.r3.u64 = ctx.r11.u64 + ctx.r31.u64;
loc_8213B050:
	// bl 0x8213b250
	ctx.lr = 0x8213B054;
	sub_8213B250(ctx, base);
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// addi r3,r3,-40
	ctx.r3.s64 = ctx.r3.s64 + -40;
	// bge 0x8213b050
	if (!ctx.cr0.lt) goto loc_8213B050;
loc_8213B060:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lis r27,-13569
	ctx.r27.s64 = -889257984;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// addi r28,r11,4520
	ctx.r28.s64 = ctx.r11.s64 + 4520;
	// beq cr6,0x8213b0c0
	if (ctx.cr6.eq) goto loc_8213B0C0;
	// rlwinm r11,r30,2,0,29
	ctx.r11.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// add r9,r30,r11
	ctx.r9.u64 = ctx.r30.u64 + ctx.r11.u64;
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r8,r11,15
	ctx.r8.s64 = ctx.r11.s64 + 15;
	// rlwinm r11,r8,0,0,27
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8213b098
	if (!ctx.cr6.gt) goto loc_8213B098;
	// stw r28,-13570(r27)
	PPC_STORE_U32(ctx.r27.u32 + -13570, ctx.r28.u32);
loc_8213B098:
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r9,4(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r9,r31
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x8213b0b4
	if (ctx.cr6.eq) goto loc_8213B0B4;
	// stw r28,-13570(r27)
	PPC_STORE_U32(ctx.r27.u32 + -13570, ctx.r28.u32);
loc_8213B0B4:
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r9,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r9.u32);
loc_8213B0C0:
	// lwz r31,4(r29)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// lwz r30,0(r29)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// addic. r5,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r5.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// blt 0x8213b0f0
	if (ctx.cr0.lt) goto loc_8213B0F0;
	// rlwinm r11,r5,2,0,29
	ctx.r11.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r5,r11
	ctx.r11.u64 = ctx.r5.u64 + ctx.r11.u64;
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r11,r30
	ctx.r3.u64 = ctx.r11.u64 + ctx.r30.u64;
loc_8213B0E0:
	// bl 0x8213b250
	ctx.lr = 0x8213B0E4;
	sub_8213B250(ctx, base);
	// addic. r5,r5,-1
	ctx.xer.ca = ctx.r5.u32 > 0;
	ctx.r5.s64 = ctx.r5.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r5.s32, 0, ctx.xer);
	// addi r3,r3,-40
	ctx.r3.s64 = ctx.r3.s64 + -40;
	// bge 0x8213b0e0
	if (!ctx.cr0.lt) goto loc_8213B0E0;
loc_8213B0F0:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x8213b144
	if (ctx.cr6.eq) goto loc_8213B144;
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// add r9,r31,r11
	ctx.r9.u64 = ctx.r31.u64 + ctx.r11.u64;
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r8,r11,15
	ctx.r8.s64 = ctx.r11.s64 + 15;
	// rlwinm r11,r8,0,0,27
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8213b11c
	if (!ctx.cr6.gt) goto loc_8213B11C;
	// stw r28,-13570(r27)
	PPC_STORE_U32(ctx.r27.u32 + -13570, ctx.r28.u32);
loc_8213B11C:
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r9,4(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r9,r30
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x8213b138
	if (ctx.cr6.eq) goto loc_8213B138;
	// stw r28,-13570(r27)
	PPC_STORE_U32(ctx.r27.u32 + -13570, ctx.r28.u32);
loc_8213B138:
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r9,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r9.u32);
loc_8213B144:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213B14C"))) PPC_WEAK_FUNC(sub_8213B14C);
PPC_FUNC_IMPL(__imp__sub_8213B14C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213B150"))) PPC_WEAK_FUNC(sub_8213B150);
PPC_FUNC_IMPL(__imp__sub_8213B150) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8213B158;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// stw r6,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r6.u32);
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// stw r5,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r5.u32);
	// mr r30,r8
	ctx.r30.u64 = ctx.r8.u64;
	// stw r4,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r4.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r7,36(r3)
	PPC_STORE_U8(ctx.r3.u32 + 36, ctx.r7.u8);
	// addi r8,r9,-29372
	ctx.r8.s64 = ctx.r9.s64 + -29372;
	// li r6,2
	ctx.r6.s64 = 2;
	// stw r10,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r10.u32);
	// lis r9,-32250
	ctx.r9.s64 = -2113536000;
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// stw r6,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r6.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r10,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r10.u32);
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// stw r10,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r10.u32);
	// lis r27,-13569
	ctx.r27.s64 = -889257984;
	// lbz r10,229(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 229);
	// addi r28,r9,4492
	ctx.r28.s64 = ctx.r9.s64 + 4492;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213b204
	if (ctx.cr6.eq) goto loc_8213B204;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r7,r10,15
	ctx.r7.s64 = ctx.r10.s64 + 15;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// rlwinm r9,r7,0,0,27
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFF0;
	// add r6,r10,r9
	ctx.r6.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r6,r8
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, ctx.xer);
	// ble cr6,0x8213b1dc
	if (!ctx.cr6.gt) goto loc_8213B1DC;
	// stw r28,-13570(r27)
	PPC_STORE_U32(ctx.r27.u32 + -13570, ctx.r28.u32);
loc_8213B1DC:
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// add r3,r8,r10
	ctx.r3.u64 = ctx.r8.u64 + ctx.r10.u64;
	// stw r9,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r9.u32);
	// stw r3,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r3.u32);
	// lbz r8,229(r11)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r11.u32 + 229);
	// rotlwi r5,r8,2
	ctx.r5.u64 = rotl32(ctx.r8.u32, 2);
	// bl 0x8233eaf0
	ctx.lr = 0x8213B204;
	sub_8233EAF0(ctx, base);
loc_8213B204:
	// rlwinm r11,r29,2,0,29
	ctx.r11.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// addi r8,r11,15
	ctx.r8.s64 = ctx.r11.s64 + 15;
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// rlwinm r10,r8,0,0,27
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFF0;
	// add r7,r11,r10
	ctx.r7.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r7,r9
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x8213b228
	if (!ctx.cr6.gt) goto loc_8213B228;
	// stw r28,-13570(r27)
	PPC_STORE_U32(ctx.r27.u32 + -13570, ctx.r28.u32);
loc_8213B228:
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// stw r10,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r10.u32);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213B24C"))) PPC_WEAK_FUNC(sub_8213B24C);
PPC_FUNC_IMPL(__imp__sub_8213B24C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213B250"))) PPC_WEAK_FUNC(sub_8213B250);
PPC_FUNC_IMPL(__imp__sub_8213B250) {
	PPC_FUNC_PROLOGUE();
	// lwz r10,32(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lis r6,-13569
	ctx.r6.s64 = -889257984;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// addi r7,r11,4520
	ctx.r7.s64 = ctx.r11.s64 + 4520;
	// beq cr6,0x8213b2b0
	if (ctx.cr6.eq) goto loc_8213B2B0;
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// lwz r9,4(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r11,15
	ctx.r8.s64 = ctx.r11.s64 + 15;
	// rlwinm r11,r8,0,0,27
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x8213b288
	if (!ctx.cr6.gt) goto loc_8213B288;
	// stw r7,-13570(r6)
	PPC_STORE_U32(ctx.r6.u32 + -13570, ctx.r7.u32);
loc_8213B288:
	// lwz r9,8(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r8,4(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r11.s64;
	// add r8,r9,r8
	ctx.r8.u64 = ctx.r9.u64 + ctx.r8.u64;
	// cmplw cr6,r8,r10
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8213b2a4
	if (ctx.cr6.eq) goto loc_8213B2A4;
	// stw r7,-13570(r6)
	PPC_STORE_U32(ctx.r6.u32 + -13570, ctx.r7.u32);
loc_8213B2A4:
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r9,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r9.u32);
loc_8213B2B0:
	// lwz r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lbz r11,229(r11)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + 229);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lwz r8,20(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// addi r9,r11,15
	ctx.r9.s64 = ctx.r11.s64 + 15;
	// rlwinm r11,r9,0,0,27
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8213b2e8
	if (!ctx.cr6.gt) goto loc_8213B2E8;
	// stw r7,-13570(r6)
	PPC_STORE_U32(ctx.r6.u32 + -13570, ctx.r7.u32);
loc_8213B2E8:
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r9,4(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x8213b304
	if (ctx.cr6.eq) goto loc_8213B304;
	// stw r7,-13570(r6)
	PPC_STORE_U32(ctx.r6.u32 + -13570, ctx.r7.u32);
loc_8213B304:
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r9,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213B314"))) PPC_WEAK_FUNC(sub_8213B314);
PPC_FUNC_IMPL(__imp__sub_8213B314) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213B318"))) PPC_WEAK_FUNC(sub_8213B318);
PPC_FUNC_IMPL(__imp__sub_8213B318) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e450
	ctx.lr = 0x8213B320;
	__restfpr_22(ctx, base);
	// lwz r6,16(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// li r27,0
	ctx.r27.s64 = 0;
	// lwz r11,12(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// addi r10,r6,240
	ctx.r10.s64 = ctx.r6.s64 + 240;
	// lwz r26,20(r3)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// addi r10,r6,192
	ctx.r10.s64 = ctx.r6.s64 + 192;
	// lwz r7,8(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r10,r6,229
	ctx.r10.s64 = ctx.r6.s64 + 229;
	// lwz r23,32(r3)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// lwz r9,232(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 232);
	// addi r10,r6,232
	ctx.r10.s64 = ctx.r6.s64 + 232;
	// lwz r25,240(r6)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r6.u32 + 240);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r29,192(r6)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r6.u32 + 192);
	// add r24,r6,r9
	ctx.r24.u64 = ctx.r6.u64 + ctx.r9.u64;
	// lbz r28,229(r6)
	ctx.r28.u64 = PPC_LOAD_U8(ctx.r6.u32 + 229);
	// beq cr6,0x8213b834
	if (ctx.cr6.eq) goto loc_8213B834;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// lfs f8,48(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
loc_8213B374:
	// addi r4,r7,12
	ctx.r4.s64 = ctx.r7.s64 + 12;
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpwi cr6,r29,4
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 4, ctx.xer);
	// blt cr6,0x8213b4e0
	if (ctx.cr6.lt) goto loc_8213B4E0;
	// lfs f0,8(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
loc_8213B3A0:
	// lfs f7,4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f7,f13
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f4,f6,f9
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// lfs f3,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f7,f11
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f3,f10
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmadds f6,f6,f12,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f12.f64), float(ctx.f5.f64)));
	// fabs f5,f4
	ctx.f5.u64 = ctx.f4.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f4,f2
	ctx.f4.u64 = ctx.f2.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f2,f7
	ctx.f2.u64 = ctx.f7.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f7,f3,f0,f6
	ctx.f7.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f0.f64), float(ctx.f6.f64)));
	// fadds f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// fadds f5,f7,f1
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fadds f4,f6,f2
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fcmpu cr6,f5,f4
	ctx.cr6.compare(ctx.f5.f64, ctx.f4.f64);
	// bgt cr6,0x8213b574
	if (ctx.cr6.gt) goto loc_8213B574;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f7,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f7,f13
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f4,f6,f9
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// lfs f3,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f7,f11
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f3,f10
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmadds f6,f6,f12,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f12.f64), float(ctx.f5.f64)));
	// fabs f5,f4
	ctx.f5.u64 = ctx.f4.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f4,f2
	ctx.f4.u64 = ctx.f2.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f2,f7
	ctx.f2.u64 = ctx.f7.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f7,f3,f0,f6
	ctx.f7.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f0.f64), float(ctx.f6.f64)));
	// fadds f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// fadds f5,f7,f1
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fadds f4,f6,f2
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fcmpu cr6,f5,f4
	ctx.cr6.compare(ctx.f5.f64, ctx.f4.f64);
	// bgt cr6,0x8213b560
	if (ctx.cr6.gt) goto loc_8213B560;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f7,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f7,f13
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f4,f6,f9
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// lfs f3,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f7,f11
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f3,f10
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmadds f6,f6,f12,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f12.f64), float(ctx.f5.f64)));
	// fabs f5,f4
	ctx.f5.u64 = ctx.f4.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f4,f2
	ctx.f4.u64 = ctx.f2.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f2,f7
	ctx.f2.u64 = ctx.f7.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f7,f3,f0,f6
	ctx.f7.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f0.f64), float(ctx.f6.f64)));
	// fadds f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// fadds f5,f7,f1
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fadds f4,f6,f2
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fcmpu cr6,f5,f4
	ctx.cr6.compare(ctx.f5.f64, ctx.f4.f64);
	// bgt cr6,0x8213b568
	if (ctx.cr6.gt) goto loc_8213B568;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f7,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f7,f13
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// fmuls f4,f6,f9
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f9.f64));
	// lfs f3,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f7,f11
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f3,f10
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f10.f64));
	// fmadds f6,f6,f12,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f12.f64), float(ctx.f5.f64)));
	// fabs f5,f4
	ctx.f5.u64 = ctx.f4.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f4,f2
	ctx.f4.u64 = ctx.f2.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f2,f7
	ctx.f2.u64 = ctx.f7.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f7,f3,f0,f6
	ctx.f7.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f0.f64), float(ctx.f6.f64)));
	// fadds f6,f5,f4
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// fadds f5,f7,f1
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fadds f4,f6,f2
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fcmpu cr6,f5,f4
	ctx.cr6.compare(ctx.f5.f64, ctx.f4.f64);
	// bgt cr6,0x8213b570
	if (ctx.cr6.gt) goto loc_8213B570;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r9,r29,-3
	ctx.r9.s64 = ctx.r29.s64 + -3;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8213b3a0
	if (ctx.cr6.lt) goto loc_8213B3A0;
loc_8213B4E0:
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// bge cr6,0x8213b578
	if (!ctx.cr6.lt) goto loc_8213B578;
	// lfs f0,8(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lfs f13,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
loc_8213B504:
	// lfs f7,4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f7,f0
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// lfs f4,-4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f11,f6
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// fmuls f2,f4,f9
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f9.f64));
	// lfs f1,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmadds f5,f4,f12,f5
	ctx.f5.f64 = double(std::fma(float(ctx.f4.f64), float(ctx.f12.f64), float(ctx.f5.f64)));
	// fabs f4,f3
	ctx.f4.u64 = ctx.f3.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f3,f2
	ctx.f3.u64 = ctx.f2.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f2,f7
	ctx.f2.u64 = ctx.f7.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f7,f6,f13,f5
	ctx.f7.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fadds f6,f4,f3
	ctx.f6.f64 = double(float(ctx.f4.f64 + ctx.f3.f64));
	// fadds f5,f7,f1
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fadds f4,f6,f2
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fcmpu cr6,f5,f4
	ctx.cr6.compare(ctx.f5.f64, ctx.f4.f64);
	// bgt cr6,0x8213b574
	if (ctx.cr6.gt) goto loc_8213B574;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// blt cr6,0x8213b504
	if (ctx.cr6.lt) goto loc_8213B504;
	// b 0x8213b574
	goto loc_8213B574;
loc_8213B560:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x8213b574
	goto loc_8213B574;
loc_8213B568:
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// b 0x8213b574
	goto loc_8213B574;
loc_8213B570:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
loc_8213B574:
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
loc_8213B578:
	// bne cr6,0x8213b82c
	if (!ctx.cr6.eq) goto loc_8213B82C;
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x8213b820
	if (ctx.cr6.eq) goto loc_8213B820;
	// lbz r31,36(r3)
	ctx.r31.u64 = PPC_LOAD_U8(ctx.r3.u32 + 36);
	// clrlwi r30,r25,31
	ctx.r30.u64 = ctx.r25.u32 & 0x1;
	// addi r8,r24,84
	ctx.r8.s64 = ctx.r24.s64 + 84;
loc_8213B598:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x8213b5e4
	if (!ctx.cr6.eq) goto loc_8213B5E4;
	// clrlwi r10,r31,31
	ctx.r10.u64 = ctx.r31.u32 & 0x1;
	// clrlwi r11,r31,24
	ctx.r11.u64 = ctx.r31.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213b5c0
	if (ctx.cr6.eq) goto loc_8213B5C0;
	// lhz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r8.u32 + 0);
	// rlwinm r9,r10,0,28,28
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x8213b5e4
	if (!ctx.cr6.eq) goto loc_8213B5E4;
loc_8213B5C0:
	// rlwinm r11,r11,0,30,30
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213b5dc
	if (ctx.cr6.eq) goto loc_8213B5DC;
	// lhz r11,0(r8)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r8.u32 + 0);
	// rlwinm r10,r11,0,29,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8213b5e4
	if (!ctx.cr6.eq) goto loc_8213B5E4;
loc_8213B5DC:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x8213b5e8
	goto loc_8213B5E8;
loc_8213B5E4:
	// li r11,1
	ctx.r11.s64 = 1;
loc_8213B5E8:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213b810
	if (ctx.cr6.eq) goto loc_8213B810;
	// lwz r9,-84(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + -84);
	// addi r10,r8,-80
	ctx.r10.s64 = ctx.r8.s64 + -80;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x8213b770
	if (ctx.cr6.lt) goto loc_8213B770;
	// lfs f0,4(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
loc_8213B620:
	// lfs f6,8(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f11,f6
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f4,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f5,f0,f7
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fmuls f2,f4,f12
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmadds f4,f9,f4,f3
	ctx.f4.f64 = double(std::fma(float(ctx.f9.f64), float(ctx.f4.f64), float(ctx.f3.f64)));
	// fabs f5,f5
	ctx.f5.u64 = ctx.f5.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f3,f2
	ctx.f3.u64 = ctx.f2.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f2,f6
	ctx.f2.u64 = ctx.f6.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f7,f10,f7,f4
	ctx.f7.f64 = double(std::fma(float(ctx.f10.f64), float(ctx.f7.f64), float(ctx.f4.f64)));
	// fadds f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fadds f5,f7,f1
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fadds f4,f6,f2
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fadds f3,f4,f5
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fcmpu cr6,f3,f8
	ctx.cr6.compare(ctx.f3.f64, ctx.f8.f64);
	// bgt cr6,0x8213b808
	if (ctx.cr6.gt) goto loc_8213B808;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f6,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f11,f6
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f4,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f5,f0,f7
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fmuls f2,f4,f12
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmadds f4,f9,f4,f3
	ctx.f4.f64 = double(std::fma(float(ctx.f9.f64), float(ctx.f4.f64), float(ctx.f3.f64)));
	// fabs f5,f5
	ctx.f5.u64 = ctx.f5.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f3,f2
	ctx.f3.u64 = ctx.f2.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f2,f6
	ctx.f2.u64 = ctx.f6.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f7,f10,f7,f4
	ctx.f7.f64 = double(std::fma(float(ctx.f10.f64), float(ctx.f7.f64), float(ctx.f4.f64)));
	// fadds f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fadds f5,f7,f1
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fadds f4,f6,f2
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fadds f3,f4,f5
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fcmpu cr6,f3,f8
	ctx.cr6.compare(ctx.f3.f64, ctx.f8.f64);
	// bgt cr6,0x8213b7f4
	if (ctx.cr6.gt) goto loc_8213B7F4;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f6,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f11,f6
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f4,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f5,f0,f7
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fmuls f2,f4,f12
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmadds f4,f9,f4,f3
	ctx.f4.f64 = double(std::fma(float(ctx.f9.f64), float(ctx.f4.f64), float(ctx.f3.f64)));
	// fabs f5,f5
	ctx.f5.u64 = ctx.f5.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f3,f2
	ctx.f3.u64 = ctx.f2.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f2,f6
	ctx.f2.u64 = ctx.f6.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f7,f10,f7,f4
	ctx.f7.f64 = double(std::fma(float(ctx.f10.f64), float(ctx.f7.f64), float(ctx.f4.f64)));
	// fadds f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fadds f5,f7,f1
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fadds f4,f6,f2
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fadds f3,f4,f5
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fcmpu cr6,f3,f8
	ctx.cr6.compare(ctx.f3.f64, ctx.f8.f64);
	// bgt cr6,0x8213b7fc
	if (ctx.cr6.gt) goto loc_8213B7FC;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f6,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f7,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f3,f11,f6
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f6.f64));
	// lfs f4,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f5,f0,f7
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// fmuls f2,f4,f12
	ctx.f2.f64 = double(float(ctx.f4.f64 * ctx.f12.f64));
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f6,f6,f13
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmadds f4,f9,f4,f3
	ctx.f4.f64 = double(std::fma(float(ctx.f9.f64), float(ctx.f4.f64), float(ctx.f3.f64)));
	// fabs f5,f5
	ctx.f5.u64 = ctx.f5.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f3,f2
	ctx.f3.u64 = ctx.f2.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f2,f6
	ctx.f2.u64 = ctx.f6.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f7,f10,f7,f4
	ctx.f7.f64 = double(std::fma(float(ctx.f10.f64), float(ctx.f7.f64), float(ctx.f4.f64)));
	// fadds f6,f5,f3
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f3.f64));
	// fadds f5,f7,f1
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f1.f64));
	// fadds f4,f6,f2
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f2.f64));
	// fadds f3,f4,f5
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fcmpu cr6,f3,f8
	ctx.cr6.compare(ctx.f3.f64, ctx.f8.f64);
	// bgt cr6,0x8213b804
	if (ctx.cr6.gt) goto loc_8213B804;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r22,r9,-3
	ctx.r22.s64 = ctx.r9.s64 + -3;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r22
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r22.u32, ctx.xer);
	// blt cr6,0x8213b620
	if (ctx.cr6.lt) goto loc_8213B620;
loc_8213B770:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x8213b80c
	if (!ctx.cr6.lt) goto loc_8213B80C;
	// lfs f0,4(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lfs f13,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
loc_8213B794:
	// lfs f7,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,-4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f2,f7,f10
	ctx.f2.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmuls f5,f0,f7
	ctx.f5.f64 = double(float(ctx.f0.f64 * ctx.f7.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f4,f6,f12
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f12.f64));
	// lfs f1,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f7,f3,f13
	ctx.f7.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// fmadds f3,f3,f11,f2
	ctx.f3.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f11.f64), float(ctx.f2.f64)));
	// fabs f5,f5
	ctx.f5.u64 = ctx.f5.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f4,f4
	ctx.f4.u64 = ctx.f4.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f2,f7
	ctx.f2.u64 = ctx.f7.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f6,f6,f9,f3
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f9.f64), float(ctx.f3.f64)));
	// fadds f7,f4,f5
	ctx.f7.f64 = double(float(ctx.f4.f64 + ctx.f5.f64));
	// fadds f4,f6,f1
	ctx.f4.f64 = double(float(ctx.f6.f64 + ctx.f1.f64));
	// fadds f5,f7,f2
	ctx.f5.f64 = double(float(ctx.f7.f64 + ctx.f2.f64));
	// fadds f3,f5,f4
	ctx.f3.f64 = double(float(ctx.f5.f64 + ctx.f4.f64));
	// fcmpu cr6,f3,f8
	ctx.cr6.compare(ctx.f3.f64, ctx.f8.f64);
	// bgt cr6,0x8213b808
	if (ctx.cr6.gt) goto loc_8213B808;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8213b794
	if (ctx.cr6.lt) goto loc_8213B794;
	// b 0x8213b808
	goto loc_8213B808;
loc_8213B7F4:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x8213b808
	goto loc_8213B808;
loc_8213B7FC:
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// b 0x8213b808
	goto loc_8213B808;
loc_8213B804:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
loc_8213B808:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
loc_8213B80C:
	// beq cr6,0x8213b84c
	if (ctx.cr6.eq) goto loc_8213B84C;
loc_8213B810:
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r8,r8,88
	ctx.r8.s64 = ctx.r8.s64 + 88;
	// cmplw cr6,r5,r28
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r28.u32, ctx.xer);
	// blt cr6,0x8213b598
	if (ctx.cr6.lt) goto loc_8213B598;
loc_8213B820:
	// lwz r11,24(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 24);
	// stw r11,0(r23)
	PPC_STORE_U32(ctx.r23.u32 + 0, ctx.r11.u32);
	// addi r23,r23,4
	ctx.r23.s64 = ctx.r23.s64 + 4;
loc_8213B82C:
	// addi r7,r7,28
	ctx.r7.s64 = ctx.r7.s64 + 28;
	// bdnz 0x8213b374
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213B374;
loc_8213B834:
	// lwz r11,32(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// stw r27,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r27.u32);
	// subf r10,r11,r23
	ctx.r10.s64 = ctx.r23.s64 - ctx.r11.s64;
	// srawi r9,r10,2
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 2;
	// stw r9,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r9.u32);
	// b 0x8233e4a0
	__restgprlr_22(ctx, base);
	return;
loc_8213B84C:
	// cmplw cr6,r5,r28
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r28.u32, ctx.xer);
	// bge cr6,0x8213b820
	if (!ctx.cr6.lt) goto loc_8213B820;
	// rlwinm r11,r5,2,0,29
	ctx.r11.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r26
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r26.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwx r10,r11,r26
	PPC_STORE_U32(ctx.r11.u32 + ctx.r26.u32, ctx.r10.u32);
	// b 0x8213b82c
	goto loc_8213B82C;
}

__attribute__((alias("__imp__sub_8213B868"))) PPC_WEAK_FUNC(sub_8213B868);
PPC_FUNC_IMPL(__imp__sub_8213B868) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x8213B870;
	__restfpr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x8233fa38
	ctx.lr = 0x8213B878;
	sub_8233FA38(ctx, base);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// li r20,0
	ctx.r20.s64 = 0;
	// lwz r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r9,28(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// mr r18,r20
	ctx.r18.u64 = ctx.r20.u64;
	// addi r8,r11,44
	ctx.r8.s64 = ctx.r11.s64 + 44;
	// lwz r28,8(r3)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r17,24(r3)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lwz r15,20(r3)
	ctx.r15.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// clrlwi r16,r9,29
	ctx.r16.u64 = ctx.r9.u32 & 0x7;
	// lwz r21,32(r3)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// stw r10,-224(r1)
	PPC_STORE_U32(ctx.r1.u32 + -224, ctx.r10.u32);
	// stw r8,-220(r1)
	PPC_STORE_U32(ctx.r1.u32 + -220, ctx.r8.u32);
	// beq cr6,0x8213c168
	if (ctx.cr6.eq) goto loc_8213C168;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r9,r11,31376
	ctx.r9.s64 = ctx.r11.s64 + 31376;
	// lfs f2,92(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 92);
	ctx.f2.f64 = double(temp.f32);
	// lfs f8,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
loc_8213B8C4:
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213c154
	if (ctx.cr6.eq) goto loc_8213C154;
	// lwz r11,20(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 20);
	// fmr f3,f2
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = ctx.f2.f64;
	// lwz r9,24(r28)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// addi r26,r28,44
	ctx.r26.s64 = ctx.r28.s64 + 44;
	// lwz r8,28(r28)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// fmr f4,f2
	ctx.f4.f64 = ctx.f2.f64;
	// lwz r7,32(r28)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r28.u32 + 32);
	// mr r25,r20
	ctx.r25.u64 = ctx.r20.u64;
	// lwz r6,36(r28)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r28.u32 + 36);
	// li r23,1
	ctx.r23.s64 = 1;
	// lwz r5,40(r28)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r28.u32 + 40);
	// cmplwi cr6,r17,0
	ctx.cr6.compare<uint32_t>(ctx.r17.u32, 0, ctx.xer);
	// lwz r19,4(r28)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// stw r20,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r20.u32);
	// stw r11,-216(r1)
	PPC_STORE_U32(ctx.r1.u32 + -216, ctx.r11.u32);
	// stw r9,-212(r1)
	PPC_STORE_U32(ctx.r1.u32 + -212, ctx.r9.u32);
	// stw r8,-208(r1)
	PPC_STORE_U32(ctx.r1.u32 + -208, ctx.r8.u32);
	// stw r7,-200(r1)
	PPC_STORE_U32(ctx.r1.u32 + -200, ctx.r7.u32);
	// stw r6,-196(r1)
	PPC_STORE_U32(ctx.r1.u32 + -196, ctx.r6.u32);
	// stw r5,-192(r1)
	PPC_STORE_U32(ctx.r1.u32 + -192, ctx.r5.u32);
	// beq cr6,0x8213c140
	if (ctx.cr6.eq) goto loc_8213C140;
	// lfs f0,-208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -208);
	ctx.f0.f64 = double(temp.f32);
	// mr r24,r20
	ctx.r24.u64 = ctx.r20.u64;
	// lfs f13,-212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -212);
	ctx.f13.f64 = double(temp.f32);
	// mtctr r17
	ctx.ctr.u64 = ctx.r17.u64;
	// lfs f12,-216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -216);
	ctx.f12.f64 = double(temp.f32);
	// addi r4,r15,224
	ctx.r4.s64 = ctx.r15.s64 + 224;
	// lfs f11,-192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -192);
	ctx.f11.f64 = double(temp.f32);
	// addi r31,r21,12
	ctx.r31.s64 = ctx.r21.s64 + 12;
	// lfs f10,-196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -196);
	ctx.f10.f64 = double(temp.f32);
	// subfic r22,r21,-12
	ctx.xer.ca = ctx.r21.u32 <= 4294967284;
	ctx.r22.s64 = -12 - ctx.r21.s64;
	// lfs f9,-200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -200);
	ctx.f9.f64 = double(temp.f32);
loc_8213B950:
	// lwz r10,32(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// add r11,r22,r31
	ctx.r11.u64 = ctx.r22.u64 + ctx.r31.u64;
	// lwz r9,0(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// add r8,r11,r10
	ctx.r8.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r27,16(r4)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// and r7,r9,r19
	ctx.r7.u64 = ctx.r9.u64 & ctx.r19.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// lwz r9,8(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// add r29,r11,r10
	ctx.r29.u64 = ctx.r11.u64 + ctx.r10.u64;
	// beq cr6,0x8213c128
	if (ctx.cr6.eq) goto loc_8213C128;
	// lfs f7,-28(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -28);
	ctx.f7.f64 = double(temp.f32);
	// fabs f6,f9
	ctx.f6.u64 = ctx.f9.u64 & 0x7FFFFFFFFFFFFFFF;
	// fsubs f5,f7,f12
	ctx.f5.f64 = static_cast<float>(ctx.f7.f64 - ctx.f12.f64);
	// fabs f1,f5
	ctx.f1.u64 = ctx.f5.u64 & 0x7FFFFFFFFFFFFFFF;
	// fsubs f7,f1,f6
	ctx.f7.f64 = static_cast<float>(ctx.f1.f64 - ctx.f6.f64);
	// fcmpu cr6,f7,f8
	ctx.cr6.compare(ctx.f7.f64, ctx.f8.f64);
	// ble cr6,0x8213b9a0
	if (!ctx.cr6.gt) goto loc_8213B9A0;
	// fmr f5,f7
	ctx.f5.f64 = ctx.f7.f64;
	// b 0x8213b9a4
	goto loc_8213B9A4;
loc_8213B9A0:
	// fmr f5,f8
	ctx.fpscr.disableFlushMode();
	ctx.f5.f64 = ctx.f8.f64;
loc_8213B9A4:
	// lfs f7,-24(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -24);
	ctx.f7.f64 = double(temp.f32);
	// fabs f6,f10
	ctx.f6.u64 = ctx.f10.u64 & 0x7FFFFFFFFFFFFFFF;
	// fsubs f1,f7,f13
	ctx.f1.f64 = static_cast<float>(ctx.f7.f64 - ctx.f13.f64);
	// fabs f7,f1
	ctx.f7.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fsubs f7,f7,f6
	ctx.f7.f64 = static_cast<float>(ctx.f7.f64 - ctx.f6.f64);
	// fcmpu cr6,f7,f8
	ctx.cr6.compare(ctx.f7.f64, ctx.f8.f64);
	// ble cr6,0x8213b9c8
	if (!ctx.cr6.gt) goto loc_8213B9C8;
	// fmr f6,f7
	ctx.f6.f64 = ctx.f7.f64;
	// b 0x8213b9cc
	goto loc_8213B9CC;
loc_8213B9C8:
	// fmr f6,f8
	ctx.fpscr.disableFlushMode();
	ctx.f6.f64 = ctx.f8.f64;
loc_8213B9CC:
	// lfs f7,-20(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -20);
	ctx.f7.f64 = double(temp.f32);
	// fabs f1,f11
	ctx.f1.u64 = ctx.f11.u64 & 0x7FFFFFFFFFFFFFFF;
	// fsubs f7,f7,f0
	ctx.f7.f64 = static_cast<float>(ctx.f7.f64 - ctx.f0.f64);
	// fabs f7,f7
	ctx.f7.u64 = ctx.f7.u64 & 0x7FFFFFFFFFFFFFFF;
	// fsubs f7,f7,f1
	ctx.f7.f64 = static_cast<float>(ctx.f7.f64 - ctx.f1.f64);
	// fcmpu cr6,f7,f8
	ctx.cr6.compare(ctx.f7.f64, ctx.f8.f64);
	// bgt cr6,0x8213b9ec
	if (ctx.cr6.gt) goto loc_8213B9EC;
	// fmr f7,f8
	ctx.f7.f64 = ctx.f8.f64;
loc_8213B9EC:
	// fmuls f6,f6,f6
	ctx.fpscr.disableFlushMode();
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// lfs f1,-4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -4);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f7,f7,f7,f6
	ctx.f7.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f7.f64), float(ctx.f6.f64)));
	// fmadds f6,f5,f5,f7
	ctx.f6.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f5.f64), float(ctx.f7.f64)));
	// fsqrts f5,f6
	ctx.f5.f64 = double(simd::sqrt_f32(float(ctx.f6.f64)));
	// fmuls f7,f5,f1
	ctx.f7.f64 = double(float(ctx.f5.f64 * ctx.f1.f64));
	// fcmpu cr6,f7,f4
	ctx.cr6.compare(ctx.f7.f64, ctx.f4.f64);
	// bge cr6,0x8213ba1c
	if (!ctx.cr6.lt) goto loc_8213BA1C;
	// clrlwi r11,r27,31
	ctx.r11.u64 = ctx.r27.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213ba1c
	if (ctx.cr6.eq) goto loc_8213BA1C;
	// fmr f4,f7
	ctx.f4.f64 = ctx.f7.f64;
loc_8213BA1C:
	// lwz r9,-32(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + -32);
	// addi r6,r4,-224
	ctx.r6.s64 = ctx.r4.s64 + -224;
	// mr r11,r20
	ctx.r11.u64 = ctx.r20.u64;
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x8213bb74
	if (ctx.cr6.lt) goto loc_8213BB74;
loc_8213BA34:
	// lfs f6,4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f13
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f30,f5,f9
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f31,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f29,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f11
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f11.f64));
	// fmadds f1,f31,f0,f1
	ctx.f1.f64 = double(std::fma(float(ctx.f31.f64), float(ctx.f0.f64), float(ctx.f1.f64)));
	// fabs f31,f30
	ctx.f31.u64 = ctx.f30.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f6,f6
	ctx.f6.u64 = ctx.f6.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f5,f12,f1
	ctx.f5.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f12.f64), float(ctx.f1.f64)));
	// fadds f1,f6,f31
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// fadds f6,f5,f29
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fcmpu cr6,f6,f5
	ctx.cr6.compare(ctx.f6.f64, ctx.f5.f64);
	// bgt cr6,0x8213bbf0
	if (ctx.cr6.gt) goto loc_8213BBF0;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f6,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f13
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f30,f5,f9
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f31,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f29,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f11
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f11.f64));
	// fmadds f1,f31,f0,f1
	ctx.f1.f64 = double(std::fma(float(ctx.f31.f64), float(ctx.f0.f64), float(ctx.f1.f64)));
	// fabs f31,f30
	ctx.f31.u64 = ctx.f30.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f6,f6
	ctx.f6.u64 = ctx.f6.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f5,f12,f1
	ctx.f5.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f12.f64), float(ctx.f1.f64)));
	// fadds f1,f6,f31
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// fadds f6,f5,f29
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fcmpu cr6,f6,f5
	ctx.cr6.compare(ctx.f6.f64, ctx.f5.f64);
	// bgt cr6,0x8213bbdc
	if (ctx.cr6.gt) goto loc_8213BBDC;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f6,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f13
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f30,f5,f9
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f31,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f29,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f11
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f11.f64));
	// fmadds f1,f31,f0,f1
	ctx.f1.f64 = double(std::fma(float(ctx.f31.f64), float(ctx.f0.f64), float(ctx.f1.f64)));
	// fabs f31,f30
	ctx.f31.u64 = ctx.f30.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f6,f6
	ctx.f6.u64 = ctx.f6.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f5,f12,f1
	ctx.f5.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f12.f64), float(ctx.f1.f64)));
	// fadds f1,f6,f31
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// fadds f6,f5,f29
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fcmpu cr6,f6,f5
	ctx.cr6.compare(ctx.f6.f64, ctx.f5.f64);
	// bgt cr6,0x8213bbe4
	if (ctx.cr6.gt) goto loc_8213BBE4;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f6,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f13
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f13.f64));
	// fmuls f30,f5,f9
	ctx.f30.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f31,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f31.f64 = double(temp.f32);
	// fmuls f6,f6,f10
	ctx.f6.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// lfs f29,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f31,f11
	ctx.f28.f64 = double(float(ctx.f31.f64 * ctx.f11.f64));
	// fmadds f1,f31,f0,f1
	ctx.f1.f64 = double(std::fma(float(ctx.f31.f64), float(ctx.f0.f64), float(ctx.f1.f64)));
	// fabs f31,f30
	ctx.f31.u64 = ctx.f30.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f6,f6
	ctx.f6.u64 = ctx.f6.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f5,f12,f1
	ctx.f5.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f12.f64), float(ctx.f1.f64)));
	// fadds f1,f6,f31
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f31.f64));
	// fadds f6,f5,f29
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f29.f64));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fcmpu cr6,f6,f5
	ctx.cr6.compare(ctx.f6.f64, ctx.f5.f64);
	// bgt cr6,0x8213bbec
	if (ctx.cr6.gt) goto loc_8213BBEC;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r8,r9,-3
	ctx.r8.s64 = ctx.r9.s64 + -3;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// blt cr6,0x8213ba34
	if (ctx.cr6.lt) goto loc_8213BA34;
loc_8213BB74:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x8213bbf4
	if (!ctx.cr6.lt) goto loc_8213BBF4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_8213BB80:
	// lfs f5,-4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	ctx.f5.f64 = double(temp.f32);
	// lfs f6,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f31,f5,f12
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// fmuls f1,f10,f6
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f6.f64));
	// lfs f30,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f9
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f29,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f11,f30
	ctx.f28.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fmadds f31,f0,f30,f31
	ctx.f31.f64 = double(std::fma(float(ctx.f0.f64), float(ctx.f30.f64), float(ctx.f31.f64)));
	// fabs f1,f1
	ctx.f1.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f5,f5
	ctx.f5.u64 = ctx.f5.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f6,f13,f6,f31
	ctx.f6.f64 = double(std::fma(float(ctx.f13.f64), float(ctx.f6.f64), float(ctx.f31.f64)));
	// fadds f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fadds f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fadds f6,f5,f30
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f30.f64));
	// fcmpu cr6,f1,f6
	ctx.cr6.compare(ctx.f1.f64, ctx.f6.f64);
	// bgt cr6,0x8213bbf0
	if (ctx.cr6.gt) goto loc_8213BBF0;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8213bb80
	if (ctx.cr6.lt) goto loc_8213BB80;
	// b 0x8213bbf0
	goto loc_8213BBF0;
loc_8213BBDC:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x8213bbf0
	goto loc_8213BBF0;
loc_8213BBE4:
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// b 0x8213bbf0
	goto loc_8213BBF0;
loc_8213BBEC:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
loc_8213BBF0:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
loc_8213BBF4:
	// bne cr6,0x8213c128
	if (!ctx.cr6.eq) goto loc_8213C128;
	// lbz r11,6(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 6);
	// clrlwi r10,r18,29
	ctx.r10.u64 = ctx.r18.u32 & 0x7;
	// lbz r9,4(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 4);
	// subf r8,r10,r16
	ctx.r8.s64 = ctx.r16.s64 - ctx.r10.s64;
	// lbz r30,7(r4)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r4.u32 + 7);
	// cntlzw r7,r8
	ctx.r7.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// lbzx r11,r11,r26
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r26.u32);
	// rlwinm r10,r7,27,31,31
	ctx.r10.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x1;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x8213be8c
	if (!ctx.cr6.lt) goto loc_8213BE8C;
	// lwz r10,12(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// add r10,r10,r6
	ctx.r10.u64 = ctx.r10.u64 + ctx.r6.u64;
	// lbzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r11.u32);
	// cmplwi cr6,r8,255
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 255, ctx.xer);
	// beq cr6,0x8213be80
	if (ctx.cr6.eq) goto loc_8213BE80;
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// mulli r11,r8,88
	ctx.r11.s64 = ctx.r8.s64 * 88;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// clrlwi r10,r27,31
	ctx.r10.u64 = ctx.r27.u32 & 0x1;
	// add r11,r11,r6
	ctx.r11.u64 = ctx.r11.u64 + ctx.r6.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bne cr6,0x8213bc64
	if (!ctx.cr6.eq) goto loc_8213BC64;
	// lhz r11,84(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 84);
	// rlwinm r11,r11,31,31,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x1;
	// b 0x8213bc68
	goto loc_8213BC68;
loc_8213BC64:
	// li r11,1
	ctx.r11.s64 = 1;
loc_8213BC68:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213be80
	if (ctx.cr6.eq) goto loc_8213BE80;
	// mr r11,r20
	ctx.r11.u64 = ctx.r20.u64;
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x8213bdd0
	if (ctx.cr6.lt) goto loc_8213BDD0;
loc_8213BC80:
	// lfs f6,4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f10
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f31,f5,f9
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f30,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f29,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f30,f11
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fabs f1,f1
	ctx.f1.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f31,f31
	ctx.f31.u64 = ctx.f31.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f30,f0,f5
	ctx.f5.f64 = double(std::fma(float(ctx.f30.f64), float(ctx.f0.f64), float(ctx.f5.f64)));
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmadds f6,f6,f13,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fadds f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fcmpu cr6,f6,f8
	ctx.cr6.compare(ctx.f6.f64, ctx.f8.f64);
	// bgt cr6,0x8213be50
	if (ctx.cr6.gt) goto loc_8213BE50;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f6,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f10
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f31,f5,f9
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f30,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f29,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f30,f11
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fabs f1,f1
	ctx.f1.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f31,f31
	ctx.f31.u64 = ctx.f31.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f30,f0,f5
	ctx.f5.f64 = double(std::fma(float(ctx.f30.f64), float(ctx.f0.f64), float(ctx.f5.f64)));
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmadds f6,f6,f13,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fadds f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fcmpu cr6,f6,f8
	ctx.cr6.compare(ctx.f6.f64, ctx.f8.f64);
	// bgt cr6,0x8213be3c
	if (ctx.cr6.gt) goto loc_8213BE3C;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f6,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f10
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f31,f5,f9
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f30,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f29,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f30,f11
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fabs f1,f1
	ctx.f1.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f31,f31
	ctx.f31.u64 = ctx.f31.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f30,f0,f5
	ctx.f5.f64 = double(std::fma(float(ctx.f30.f64), float(ctx.f0.f64), float(ctx.f5.f64)));
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmadds f6,f6,f13,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fadds f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fcmpu cr6,f6,f8
	ctx.cr6.compare(ctx.f6.f64, ctx.f8.f64);
	// bgt cr6,0x8213be44
	if (ctx.cr6.gt) goto loc_8213BE44;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f6,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f10
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f31,f5,f9
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f30,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f29,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f30,f11
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fabs f1,f1
	ctx.f1.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f31,f31
	ctx.f31.u64 = ctx.f31.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f30,f0,f5
	ctx.f5.f64 = double(std::fma(float(ctx.f30.f64), float(ctx.f0.f64), float(ctx.f5.f64)));
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmadds f6,f6,f13,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fadds f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fcmpu cr6,f6,f8
	ctx.cr6.compare(ctx.f6.f64, ctx.f8.f64);
	// bgt cr6,0x8213be4c
	if (ctx.cr6.gt) goto loc_8213BE4C;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r7,r9,-3
	ctx.r7.s64 = ctx.r9.s64 + -3;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r7.u32, ctx.xer);
	// blt cr6,0x8213bc80
	if (ctx.cr6.lt) goto loc_8213BC80;
loc_8213BDD0:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x8213be54
	if (!ctx.cr6.lt) goto loc_8213BE54;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_8213BDDC:
	// lfs f6,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,-4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f10
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f31,f5,f9
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f30,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f29,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f30,f11
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fabs f1,f1
	ctx.f1.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f31,f31
	ctx.f31.u64 = ctx.f31.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f30,f0,f5
	ctx.f5.f64 = double(std::fma(float(ctx.f30.f64), float(ctx.f0.f64), float(ctx.f5.f64)));
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmadds f6,f6,f13,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fadds f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fcmpu cr6,f6,f8
	ctx.cr6.compare(ctx.f6.f64, ctx.f8.f64);
	// bgt cr6,0x8213be50
	if (ctx.cr6.gt) goto loc_8213BE50;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8213bddc
	if (ctx.cr6.lt) goto loc_8213BDDC;
	// b 0x8213be50
	goto loc_8213BE50;
loc_8213BE3C:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x8213be50
	goto loc_8213BE50;
loc_8213BE44:
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// b 0x8213be50
	goto loc_8213BE50;
loc_8213BE4C:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
loc_8213BE50:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
loc_8213BE54:
	// bne cr6,0x8213be80
	if (!ctx.cr6.eq) goto loc_8213BE80;
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// clrlwi r9,r8,24
	ctx.r9.u64 = ctx.r8.u32 & 0xFF;
	// lwzx r10,r11,r29
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r29.u32);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stwx r8,r11,r29
	PPC_STORE_U32(ctx.r11.u32 + ctx.r29.u32, ctx.r8.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r7,r11,1
	ctx.r7.s64 = ctx.r11.s64 + 1;
	// stw r7,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r7.u32);
	// stbx r9,r30,r26
	PPC_STORE_U8(ctx.r30.u32 + ctx.r26.u32, ctx.r9.u8);
	// b 0x8213c128
	goto loc_8213C128;
loc_8213BE80:
	// li r11,255
	ctx.r11.s64 = 255;
	// li r10,1
	ctx.r10.s64 = 1;
	// stbx r11,r30,r26
	PPC_STORE_U8(ctx.r30.u32 + ctx.r26.u32, ctx.r11.u8);
loc_8213BE8C:
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213c0e0
	if (ctx.cr6.eq) goto loc_8213C0E0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r7,r20
	ctx.r7.u64 = ctx.r20.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// lbz r5,5(r4)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r4.u32 + 5);
	// lwz r11,8(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// add r8,r11,r6
	ctx.r8.u64 = ctx.r11.u64 + ctx.r6.u64;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x8213c0e0
	if (ctx.cr6.eq) goto loc_8213C0E0;
	// clrlwi r6,r27,31
	ctx.r6.u64 = ctx.r27.u32 & 0x1;
loc_8213BEC0:
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// addi r10,r8,4
	ctx.r10.s64 = ctx.r8.s64 + 4;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne cr6,0x8213bedc
	if (!ctx.cr6.eq) goto loc_8213BEDC;
	// lhz r11,84(r8)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r8.u32 + 84);
	// rlwinm r11,r11,31,31,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x1;
	// b 0x8213bee0
	goto loc_8213BEE0;
loc_8213BEDC:
	// li r11,1
	ctx.r11.s64 = 1;
loc_8213BEE0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213c0d0
	if (ctx.cr6.eq) goto loc_8213C0D0;
	// mr r11,r20
	ctx.r11.u64 = ctx.r20.u64;
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x8213c048
	if (ctx.cr6.lt) goto loc_8213C048;
loc_8213BEF8:
	// lfs f6,4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f10
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f31,f5,f9
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f30,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f29,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f30,f11
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fabs f1,f1
	ctx.f1.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f31,f31
	ctx.f31.u64 = ctx.f31.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f30,f0,f5
	ctx.f5.f64 = double(std::fma(float(ctx.f30.f64), float(ctx.f0.f64), float(ctx.f5.f64)));
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmadds f6,f6,f13,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fadds f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fcmpu cr6,f6,f8
	ctx.cr6.compare(ctx.f6.f64, ctx.f8.f64);
	// bgt cr6,0x8213c0c8
	if (ctx.cr6.gt) goto loc_8213C0C8;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f6,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f10
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f31,f5,f9
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f30,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f29,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f30,f11
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fabs f1,f1
	ctx.f1.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f31,f31
	ctx.f31.u64 = ctx.f31.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f30,f0,f5
	ctx.f5.f64 = double(std::fma(float(ctx.f30.f64), float(ctx.f0.f64), float(ctx.f5.f64)));
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmadds f6,f6,f13,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fadds f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fcmpu cr6,f6,f8
	ctx.cr6.compare(ctx.f6.f64, ctx.f8.f64);
	// bgt cr6,0x8213c0b4
	if (ctx.cr6.gt) goto loc_8213C0B4;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f6,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f10
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f31,f5,f9
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f30,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f29,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f30,f11
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fabs f1,f1
	ctx.f1.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f31,f31
	ctx.f31.u64 = ctx.f31.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f30,f0,f5
	ctx.f5.f64 = double(std::fma(float(ctx.f30.f64), float(ctx.f0.f64), float(ctx.f5.f64)));
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmadds f6,f6,f13,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fadds f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fcmpu cr6,f6,f8
	ctx.cr6.compare(ctx.f6.f64, ctx.f8.f64);
	// bgt cr6,0x8213c0bc
	if (ctx.cr6.gt) goto loc_8213C0BC;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f6,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f10
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f31,f5,f9
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f30,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f29,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f30,f11
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fabs f1,f1
	ctx.f1.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f31,f31
	ctx.f31.u64 = ctx.f31.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f30,f0,f5
	ctx.f5.f64 = double(std::fma(float(ctx.f30.f64), float(ctx.f0.f64), float(ctx.f5.f64)));
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmadds f6,f6,f13,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fadds f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fcmpu cr6,f6,f8
	ctx.cr6.compare(ctx.f6.f64, ctx.f8.f64);
	// bgt cr6,0x8213c0c4
	if (ctx.cr6.gt) goto loc_8213C0C4;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r14,r9,-3
	ctx.r14.s64 = ctx.r9.s64 + -3;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r14
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r14.u32, ctx.xer);
	// blt cr6,0x8213bef8
	if (ctx.cr6.lt) goto loc_8213BEF8;
loc_8213C048:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x8213c0cc
	if (!ctx.cr6.lt) goto loc_8213C0CC;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_8213C054:
	// lfs f6,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,-4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f1,f6,f10
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f10.f64));
	// fmuls f31,f5,f9
	ctx.f31.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// lfs f30,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f30.f64 = double(temp.f32);
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f29,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f29.f64 = double(temp.f32);
	// fmuls f28,f30,f11
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f11.f64));
	// fabs f1,f1
	ctx.f1.u64 = ctx.f1.u64 & 0x7FFFFFFFFFFFFFFF;
	// fabs f31,f31
	ctx.f31.u64 = ctx.f31.u64 & 0x7FFFFFFFFFFFFFFF;
	// fmadds f5,f30,f0,f5
	ctx.f5.f64 = double(std::fma(float(ctx.f30.f64), float(ctx.f0.f64), float(ctx.f5.f64)));
	// fabs f30,f28
	ctx.f30.u64 = ctx.f28.u64 & 0x7FFFFFFFFFFFFFFF;
	// fadds f1,f31,f1
	ctx.f1.f64 = double(float(ctx.f31.f64 + ctx.f1.f64));
	// fmadds f6,f6,f13,f5
	ctx.f6.f64 = double(std::fma(float(ctx.f6.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fadds f5,f1,f30
	ctx.f5.f64 = double(float(ctx.f1.f64 + ctx.f30.f64));
	// fadds f1,f6,f29
	ctx.f1.f64 = double(float(ctx.f6.f64 + ctx.f29.f64));
	// fadds f6,f5,f1
	ctx.f6.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fcmpu cr6,f6,f8
	ctx.cr6.compare(ctx.f6.f64, ctx.f8.f64);
	// bgt cr6,0x8213c0c8
	if (ctx.cr6.gt) goto loc_8213C0C8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8213c054
	if (ctx.cr6.lt) goto loc_8213C054;
	// b 0x8213c0c8
	goto loc_8213C0C8;
loc_8213C0B4:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x8213c0c8
	goto loc_8213C0C8;
loc_8213C0BC:
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// b 0x8213c0c8
	goto loc_8213C0C8;
loc_8213C0C4:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
loc_8213C0C8:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
loc_8213C0CC:
	// beq cr6,0x8213c174
	if (ctx.cr6.eq) goto loc_8213C174;
loc_8213C0D0:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,88
	ctx.r8.s64 = ctx.r8.s64 + 88;
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// blt cr6,0x8213bec0
	if (ctx.cr6.lt) goto loc_8213BEC0;
loc_8213C0E0:
	// lwz r11,-8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// or r25,r23,r25
	ctx.r25.u64 = ctx.r23.u64 | ctx.r25.u64;
	// lwz r10,-12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + -12);
	// fcmpu cr6,f7,f3
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f7.f64, ctx.f3.f64);
	// add r9,r24,r11
	ctx.r9.u64 = ctx.r24.u64 + ctx.r11.u64;
	// addi r8,r11,1
	ctx.r8.s64 = ctx.r11.s64 + 1;
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r8,-8(r31)
	PPC_STORE_U32(ctx.r31.u32 + -8, ctx.r8.u32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r7,0(r28)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// add r11,r11,r21
	ctx.r11.u64 = ctx.r11.u64 + ctx.r21.u64;
	// stfs f7,4(r11)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + 4, temp.u32);
	// stw r7,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r7.u32);
	// bge cr6,0x8213c128
	if (!ctx.cr6.lt) goto loc_8213C128;
	// clrlwi r11,r27,31
	ctx.r11.u64 = ctx.r27.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213c128
	if (ctx.cr6.eq) goto loc_8213C128;
	// fmr f3,f7
	ctx.f3.f64 = ctx.f7.f64;
loc_8213C128:
	// addi r24,r24,2
	ctx.r24.s64 = ctx.r24.s64 + 2;
	// addi r31,r31,16
	ctx.r31.s64 = ctx.r31.s64 + 16;
	// rotlwi r23,r23,1
	ctx.r23.u64 = rotl32(ctx.r23.u32, 1);
	// addi r4,r4,244
	ctx.r4.s64 = ctx.r4.s64 + 244;
	// bdnz 0x8213b950
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213B950;
	// lwz r10,-224(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -224);
loc_8213C140:
	// lwz r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// stfs f3,12(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r28.u32 + 12, temp.u32);
	// stfs f4,16(r28)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r28.u32 + 16, temp.u32);
	// or r9,r11,r25
	ctx.r9.u64 = ctx.r11.u64 | ctx.r25.u64;
	// stw r9,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r9.u32);
loc_8213C154:
	// lwz r11,-220(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -220);
	// addi r18,r18,1
	ctx.r18.s64 = ctx.r18.s64 + 1;
	// add r28,r11,r28
	ctx.r28.u64 = ctx.r11.u64 + ctx.r28.u64;
	// cmplw cr6,r18,r10
	ctx.cr6.compare<uint32_t>(ctx.r18.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x8213b8c4
	if (ctx.cr6.lt) goto loc_8213B8C4;
loc_8213C168:
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x8233fa84
	ctx.lr = 0x8213C170;
	__savefpr_28(ctx, base);
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
loc_8213C174:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// lwzx r10,r11,r29
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r29.u32);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stwx r8,r11,r29
	PPC_STORE_U32(ctx.r11.u32 + ctx.r29.u32, ctx.r8.u32);
	// stbx r7,r30,r26
	PPC_STORE_U8(ctx.r30.u32 + ctx.r26.u32, ctx.r7.u8);
	// bge cr6,0x8213c0e0
	if (!ctx.cr6.lt) goto loc_8213C0E0;
	// rotlwi r11,r23,16
	ctx.r11.u64 = rotl32(ctx.r23.u32, 16);
	// or r25,r11,r25
	ctx.r25.u64 = ctx.r11.u64 | ctx.r25.u64;
	// b 0x8213c128
	goto loc_8213C128;
}

__attribute__((alias("__imp__sub_8213C19C"))) PPC_WEAK_FUNC(sub_8213C19C);
PPC_FUNC_IMPL(__imp__sub_8213C19C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213C1A0"))) PPC_WEAK_FUNC(sub_8213C1A0);
PPC_FUNC_IMPL(__imp__sub_8213C1A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x8213C1A8;
	__restfpr_14(ctx, base);
	// lwz r10,12(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// li r19,0
	ctx.r19.s64 = 0;
	// lwz r11,16(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r17,r19
	ctx.r17.u64 = ctx.r19.u64;
	// lwz r8,28(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// addi r7,r11,36
	ctx.r7.s64 = ctx.r11.s64 + 36;
	// lwz r24,8(r3)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lwz r16,24(r3)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// clrlwi r15,r8,29
	ctx.r15.u64 = ctx.r8.u32 & 0x7;
	// lwz r21,32(r3)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// stw r10,-204(r1)
	PPC_STORE_U32(ctx.r1.u32 + -204, ctx.r10.u32);
	// stw r7,-200(r1)
	PPC_STORE_U32(ctx.r1.u32 + -200, ctx.r7.u32);
	// stw r9,-208(r1)
	PPC_STORE_U32(ctx.r1.u32 + -208, ctx.r9.u32);
	// beq cr6,0x8213c87c
	if (ctx.cr6.eq) goto loc_8213C87C;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r9,r11,31376
	ctx.r9.s64 = ctx.r11.s64 + 31376;
	// lfs f6,92(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 92);
	ctx.f6.f64 = double(temp.f32);
	// lfs f10,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f10.f64 = double(temp.f32);
loc_8213C1F8:
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213c868
	if (ctx.cr6.eq) goto loc_8213C868;
	// lwz r11,20(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 20);
	// lfs f0,32(r24)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r24.u32 + 32);
	ctx.f0.f64 = double(temp.f32);
	// lwz r9,24(r24)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r24.u32 + 24);
	// addi r25,r24,36
	ctx.r25.s64 = ctx.r24.s64 + 36;
	// lwz r8,28(r24)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r24.u32 + 28);
	// fmr f7,f6
	ctx.f7.f64 = ctx.f6.f64;
	// lwz r18,4(r24)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r24.u32 + 4);
	// fmr f8,f6
	ctx.f8.f64 = ctx.f6.f64;
	// stw r19,8(r24)
	PPC_STORE_U32(ctx.r24.u32 + 8, ctx.r19.u32);
	// mr r28,r19
	ctx.r28.u64 = ctx.r19.u64;
	// stw r11,-192(r1)
	PPC_STORE_U32(ctx.r1.u32 + -192, ctx.r11.u32);
	// li r26,1
	ctx.r26.s64 = 1;
	// stw r9,-188(r1)
	PPC_STORE_U32(ctx.r1.u32 + -188, ctx.r9.u32);
	// cmplwi cr6,r16,0
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, 0, ctx.xer);
	// stw r8,-184(r1)
	PPC_STORE_U32(ctx.r1.u32 + -184, ctx.r8.u32);
	// beq cr6,0x8213c854
	if (ctx.cr6.eq) goto loc_8213C854;
	// lwz r11,-208(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -208);
	// lfs f13,-184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -184);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,-188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -188);
	ctx.f12.f64 = double(temp.f32);
	// mr r23,r19
	ctx.r23.u64 = ctx.r19.u64;
	// lfs f11,-192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -192);
	ctx.f11.f64 = double(temp.f32);
	// addi r31,r21,12
	ctx.r31.s64 = ctx.r21.s64 + 12;
	// addi r4,r11,224
	ctx.r4.s64 = ctx.r11.s64 + 224;
	// subfic r22,r21,-12
	ctx.xer.ca = ctx.r21.u32 <= 4294967284;
	ctx.r22.s64 = -12 - ctx.r21.s64;
	// mr r20,r16
	ctx.r20.u64 = ctx.r16.u64;
loc_8213C268:
	// lwz r10,32(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// add r11,r22,r31
	ctx.r11.u64 = ctx.r22.u64 + ctx.r31.u64;
	// lwz r9,0(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// add r8,r10,r11
	ctx.r8.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r27,16(r4)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// and r7,r9,r18
	ctx.r7.u64 = ctx.r9.u64 & ctx.r18.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// lwz r9,8(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// add r29,r10,r11
	ctx.r29.u64 = ctx.r10.u64 + ctx.r11.u64;
	// beq cr6,0x8213c838
	if (ctx.cr6.eq) goto loc_8213C838;
	// lwz r11,-20(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + -20);
	// lwz r10,-28(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + -28);
	// lwz r9,-24(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + -24);
	// stw r11,-168(r1)
	PPC_STORE_U32(ctx.r1.u32 + -168, ctx.r11.u32);
	// lfs f9,-168(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -168);
	ctx.f9.f64 = double(temp.f32);
	// stw r10,-176(r1)
	PPC_STORE_U32(ctx.r1.u32 + -176, ctx.r10.u32);
	// lfs f5,-176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -176);
	ctx.f5.f64 = double(temp.f32);
	// stw r9,-172(r1)
	PPC_STORE_U32(ctx.r1.u32 + -172, ctx.r9.u32);
	// lfs f4,-172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -172);
	ctx.f4.f64 = double(temp.f32);
	// fsubs f3,f4,f12
	ctx.f3.f64 = static_cast<float>(ctx.f4.f64 - ctx.f12.f64);
	// fsubs f2,f9,f13
	ctx.f2.f64 = static_cast<float>(ctx.f9.f64 - ctx.f13.f64);
	// fmuls f1,f3,f3
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f3.f64));
	// fsubs f9,f5,f11
	ctx.f9.f64 = static_cast<float>(ctx.f5.f64 - ctx.f11.f64);
	// fmadds f5,f2,f2,f1
	ctx.f5.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f2.f64), float(ctx.f1.f64)));
	// fmadds f4,f9,f9,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f9.f64), float(ctx.f9.f64), float(ctx.f5.f64)));
	// fsqrts f3,f4
	ctx.f3.f64 = double(simd::sqrt_f32(float(ctx.f4.f64)));
	// fsubs f9,f3,f0
	ctx.f9.f64 = static_cast<float>(ctx.f3.f64 - ctx.f0.f64);
	// fcmpu cr6,f9,f10
	ctx.cr6.compare(ctx.f9.f64, ctx.f10.f64);
	// bgt cr6,0x8213c2e4
	if (ctx.cr6.gt) goto loc_8213C2E4;
	// fmr f9,f10
	ctx.f9.f64 = ctx.f10.f64;
loc_8213C2E4:
	// lfs f5,-4(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + -4);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f9,f5,f9
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f9.f64));
	// fcmpu cr6,f9,f8
	ctx.cr6.compare(ctx.f9.f64, ctx.f8.f64);
	// bge cr6,0x8213c304
	if (!ctx.cr6.lt) goto loc_8213C304;
	// clrlwi r11,r27,31
	ctx.r11.u64 = ctx.r27.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213c304
	if (ctx.cr6.eq) goto loc_8213C304;
	// fmr f8,f9
	ctx.f8.f64 = ctx.f9.f64;
loc_8213C304:
	// lwz r9,-32(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + -32);
	// addi r6,r4,-224
	ctx.r6.s64 = ctx.r4.s64 + -224;
	// mr r11,r19
	ctx.r11.u64 = ctx.r19.u64;
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x8213c3dc
	if (ctx.cr6.lt) goto loc_8213C3DC;
loc_8213C31C:
	// lfs f5,8(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f13
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f12,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fcmpu cr6,f3,f0
	ctx.cr6.compare(ctx.f3.f64, ctx.f0.f64);
	// bgt cr6,0x8213c438
	if (ctx.cr6.gt) goto loc_8213C438;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f13
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f12,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fcmpu cr6,f3,f0
	ctx.cr6.compare(ctx.f3.f64, ctx.f0.f64);
	// bgt cr6,0x8213c424
	if (ctx.cr6.gt) goto loc_8213C424;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f13
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f12,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fcmpu cr6,f3,f0
	ctx.cr6.compare(ctx.f3.f64, ctx.f0.f64);
	// bgt cr6,0x8213c42c
	if (ctx.cr6.gt) goto loc_8213C42C;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f13
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f12,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fcmpu cr6,f3,f0
	ctx.cr6.compare(ctx.f3.f64, ctx.f0.f64);
	// bgt cr6,0x8213c434
	if (ctx.cr6.gt) goto loc_8213C434;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r8,r9,-3
	ctx.r8.s64 = ctx.r9.s64 + -3;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r8
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r8.u32, ctx.xer);
	// blt cr6,0x8213c31c
	if (ctx.cr6.lt) goto loc_8213C31C;
loc_8213C3DC:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x8213c43c
	if (!ctx.cr6.lt) goto loc_8213C43C;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
loc_8213C3E8:
	// lfs f5,-4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f12
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f3,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,-8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f13,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f13.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fcmpu cr6,f3,f0
	ctx.cr6.compare(ctx.f3.f64, ctx.f0.f64);
	// bgt cr6,0x8213c438
	if (ctx.cr6.gt) goto loc_8213C438;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8213c3e8
	if (ctx.cr6.lt) goto loc_8213C3E8;
	// b 0x8213c438
	goto loc_8213C438;
loc_8213C424:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x8213c438
	goto loc_8213C438;
loc_8213C42C:
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// b 0x8213c438
	goto loc_8213C438;
loc_8213C434:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
loc_8213C438:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
loc_8213C43C:
	// bne cr6,0x8213c838
	if (!ctx.cr6.eq) goto loc_8213C838;
	// lbz r11,6(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 6);
	// clrlwi r10,r17,29
	ctx.r10.u64 = ctx.r17.u32 & 0x7;
	// lbz r9,4(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 4);
	// subf r8,r10,r15
	ctx.r8.s64 = ctx.r15.s64 - ctx.r10.s64;
	// lbz r30,7(r4)
	ctx.r30.u64 = PPC_LOAD_U8(ctx.r4.u32 + 7);
	// cntlzw r7,r8
	ctx.r7.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// lbzx r11,r11,r25
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r11.u32 + ctx.r25.u32);
	// rlwinm r10,r7,27,31,31
	ctx.r10.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x1;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x8213c63c
	if (!ctx.cr6.lt) goto loc_8213C63C;
	// lwz r10,12(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// add r10,r10,r6
	ctx.r10.u64 = ctx.r10.u64 + ctx.r6.u64;
	// lbzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r11.u32);
	// cmplwi cr6,r8,255
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 255, ctx.xer);
	// beq cr6,0x8213c630
	if (ctx.cr6.eq) goto loc_8213C630;
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// mulli r11,r8,88
	ctx.r11.s64 = ctx.r8.s64 * 88;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// clrlwi r10,r27,31
	ctx.r10.u64 = ctx.r27.u32 & 0x1;
	// add r11,r11,r6
	ctx.r11.u64 = ctx.r11.u64 + ctx.r6.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bne cr6,0x8213c4ac
	if (!ctx.cr6.eq) goto loc_8213C4AC;
	// lhz r11,84(r11)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r11.u32 + 84);
	// rlwinm r11,r11,31,31,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x1;
	// b 0x8213c4b0
	goto loc_8213C4B0;
loc_8213C4AC:
	// li r11,1
	ctx.r11.s64 = 1;
loc_8213C4B0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213c630
	if (ctx.cr6.eq) goto loc_8213C630;
	// mr r11,r19
	ctx.r11.u64 = ctx.r19.u64;
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x8213c598
	if (ctx.cr6.lt) goto loc_8213C598;
loc_8213C4C8:
	// lfs f5,8(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f13
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f12,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f2,f3,f0
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// fcmpu cr6,f2,f10
	ctx.cr6.compare(ctx.f2.f64, ctx.f10.f64);
	// bgt cr6,0x8213c5f8
	if (ctx.cr6.gt) goto loc_8213C5F8;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f13
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f12,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f2,f3,f0
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// fcmpu cr6,f2,f10
	ctx.cr6.compare(ctx.f2.f64, ctx.f10.f64);
	// bgt cr6,0x8213c5e4
	if (ctx.cr6.gt) goto loc_8213C5E4;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f13
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f12,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f2,f3,f0
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// fcmpu cr6,f2,f10
	ctx.cr6.compare(ctx.f2.f64, ctx.f10.f64);
	// bgt cr6,0x8213c5ec
	if (ctx.cr6.gt) goto loc_8213C5EC;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f13
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f12,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f2,f3,f0
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// fcmpu cr6,f2,f10
	ctx.cr6.compare(ctx.f2.f64, ctx.f10.f64);
	// bgt cr6,0x8213c5f4
	if (ctx.cr6.gt) goto loc_8213C5F4;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r7,r9,-3
	ctx.r7.s64 = ctx.r9.s64 + -3;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r7.u32, ctx.xer);
	// blt cr6,0x8213c4c8
	if (ctx.cr6.lt) goto loc_8213C4C8;
loc_8213C598:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x8213c5fc
	if (!ctx.cr6.lt) goto loc_8213C5FC;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
loc_8213C5A4:
	// lfs f5,-4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f12
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f3,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,-8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f13,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f13.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f2,f3,f0
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// fcmpu cr6,f2,f10
	ctx.cr6.compare(ctx.f2.f64, ctx.f10.f64);
	// bgt cr6,0x8213c5f8
	if (ctx.cr6.gt) goto loc_8213C5F8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8213c5a4
	if (ctx.cr6.lt) goto loc_8213C5A4;
	// b 0x8213c5f8
	goto loc_8213C5F8;
loc_8213C5E4:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x8213c5f8
	goto loc_8213C5F8;
loc_8213C5EC:
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// b 0x8213c5f8
	goto loc_8213C5F8;
loc_8213C5F4:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
loc_8213C5F8:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
loc_8213C5FC:
	// bne cr6,0x8213c630
	if (!ctx.cr6.eq) goto loc_8213C630;
	// rlwinm r11,r8,2,0,29
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// rotlwi r10,r26,16
	ctx.r10.u64 = rotl32(ctx.r26.u32, 16);
	// clrlwi r9,r8,24
	ctx.r9.u64 = ctx.r8.u32 & 0xFF;
	// or r28,r10,r28
	ctx.r28.u64 = ctx.r10.u64 | ctx.r28.u64;
	// lwzx r10,r11,r29
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r29.u32);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stwx r8,r11,r29
	PPC_STORE_U32(ctx.r11.u32 + ctx.r29.u32, ctx.r8.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r7,r11,1
	ctx.r7.s64 = ctx.r11.s64 + 1;
	// stw r7,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r7.u32);
	// stbx r9,r30,r25
	PPC_STORE_U8(ctx.r30.u32 + ctx.r25.u32, ctx.r9.u8);
	// b 0x8213c838
	goto loc_8213C838;
loc_8213C630:
	// li r11,255
	ctx.r11.s64 = 255;
	// li r10,1
	ctx.r10.s64 = 1;
	// stbx r11,r30,r25
	PPC_STORE_U8(ctx.r30.u32 + ctx.r25.u32, ctx.r11.u8);
loc_8213C63C:
	// clrlwi r11,r10,24
	ctx.r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213c7f0
	if (ctx.cr6.eq) goto loc_8213C7F0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r7,r19
	ctx.r7.u64 = ctx.r19.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// lwz r11,8(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// add r8,r11,r6
	ctx.r8.u64 = ctx.r11.u64 + ctx.r6.u64;
	// lbz r5,5(r4)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r4.u32 + 5);
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x8213c7f0
	if (ctx.cr6.eq) goto loc_8213C7F0;
	// clrlwi r6,r27,31
	ctx.r6.u64 = ctx.r27.u32 & 0x1;
loc_8213C670:
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// addi r10,r8,4
	ctx.r10.s64 = ctx.r8.s64 + 4;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne cr6,0x8213c68c
	if (!ctx.cr6.eq) goto loc_8213C68C;
	// lhz r11,84(r8)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r8.u32 + 84);
	// rlwinm r11,r11,31,31,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x1;
	// b 0x8213c690
	goto loc_8213C690;
loc_8213C68C:
	// li r11,1
	ctx.r11.s64 = 1;
loc_8213C690:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213c7e0
	if (ctx.cr6.eq) goto loc_8213C7E0;
	// mr r11,r19
	ctx.r11.u64 = ctx.r19.u64;
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x8213c778
	if (ctx.cr6.lt) goto loc_8213C778;
loc_8213C6A8:
	// lfs f5,8(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f13
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f12,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f2,f3,f0
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// fcmpu cr6,f2,f10
	ctx.cr6.compare(ctx.f2.f64, ctx.f10.f64);
	// bgt cr6,0x8213c7d8
	if (ctx.cr6.gt) goto loc_8213C7D8;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f13
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f12,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f2,f3,f0
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// fcmpu cr6,f2,f10
	ctx.cr6.compare(ctx.f2.f64, ctx.f10.f64);
	// bgt cr6,0x8213c7c4
	if (ctx.cr6.gt) goto loc_8213C7C4;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f13
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f12,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f2,f3,f0
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// fcmpu cr6,f2,f10
	ctx.cr6.compare(ctx.f2.f64, ctx.f10.f64);
	// bgt cr6,0x8213c7cc
	if (ctx.cr6.gt) goto loc_8213C7CC;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f13
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f3,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f12,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f12.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f2,f3,f0
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// fcmpu cr6,f2,f10
	ctx.cr6.compare(ctx.f2.f64, ctx.f10.f64);
	// bgt cr6,0x8213c7d4
	if (ctx.cr6.gt) goto loc_8213C7D4;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r14,r9,-3
	ctx.r14.s64 = ctx.r9.s64 + -3;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r14
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r14.u32, ctx.xer);
	// blt cr6,0x8213c6a8
	if (ctx.cr6.lt) goto loc_8213C6A8;
loc_8213C778:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x8213c7dc
	if (!ctx.cr6.lt) goto loc_8213C7DC;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
loc_8213C784:
	// lfs f5,-4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f5,f12
	ctx.f4.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f3,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,-8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f5,f3,f13,f4
	ctx.f5.f64 = double(std::fma(float(ctx.f3.f64), float(ctx.f13.f64), float(ctx.f4.f64)));
	// fmadds f4,f2,f11,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f11.f64), float(ctx.f5.f64)));
	// fadds f3,f4,f1
	ctx.f3.f64 = double(float(ctx.f4.f64 + ctx.f1.f64));
	// fadds f2,f3,f0
	ctx.f2.f64 = double(float(ctx.f3.f64 + ctx.f0.f64));
	// fcmpu cr6,f2,f10
	ctx.cr6.compare(ctx.f2.f64, ctx.f10.f64);
	// bgt cr6,0x8213c7d8
	if (ctx.cr6.gt) goto loc_8213C7D8;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8213c784
	if (ctx.cr6.lt) goto loc_8213C784;
	// b 0x8213c7d8
	goto loc_8213C7D8;
loc_8213C7C4:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x8213c7d8
	goto loc_8213C7D8;
loc_8213C7CC:
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// b 0x8213c7d8
	goto loc_8213C7D8;
loc_8213C7D4:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
loc_8213C7D8:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
loc_8213C7DC:
	// beq cr6,0x8213c880
	if (ctx.cr6.eq) goto loc_8213C880;
loc_8213C7E0:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r8,r8,88
	ctx.r8.s64 = ctx.r8.s64 + 88;
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// blt cr6,0x8213c670
	if (ctx.cr6.lt) goto loc_8213C670;
loc_8213C7F0:
	// lwz r11,-8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// or r28,r26,r28
	ctx.r28.u64 = ctx.r26.u64 | ctx.r28.u64;
	// lwz r10,-12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + -12);
	// fcmpu cr6,f9,f7
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f9.f64, ctx.f7.f64);
	// addi r8,r11,1
	ctx.r8.s64 = ctx.r11.s64 + 1;
	// add r9,r23,r11
	ctx.r9.u64 = ctx.r23.u64 + ctx.r11.u64;
	// stw r8,-8(r31)
	PPC_STORE_U32(ctx.r31.u32 + -8, ctx.r8.u32);
	// rlwinm r11,r9,3,0,28
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// add r11,r11,r21
	ctx.r11.u64 = ctx.r11.u64 + ctx.r21.u64;
	// lwz r7,0(r24)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// stfs f9,4(r11)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + 4, temp.u32);
	// stw r7,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r7.u32);
	// bge cr6,0x8213c838
	if (!ctx.cr6.lt) goto loc_8213C838;
	// clrlwi r11,r27,31
	ctx.r11.u64 = ctx.r27.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213c838
	if (ctx.cr6.eq) goto loc_8213C838;
	// fmr f7,f9
	ctx.f7.f64 = ctx.f9.f64;
loc_8213C838:
	// addic. r20,r20,-1
	ctx.xer.ca = ctx.r20.u32 > 0;
	ctx.r20.s64 = ctx.r20.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r20.s32, 0, ctx.xer);
	// addi r23,r23,2
	ctx.r23.s64 = ctx.r23.s64 + 2;
	// addi r31,r31,16
	ctx.r31.s64 = ctx.r31.s64 + 16;
	// rotlwi r26,r26,1
	ctx.r26.u64 = rotl32(ctx.r26.u32, 1);
	// addi r4,r4,244
	ctx.r4.s64 = ctx.r4.s64 + 244;
	// bne 0x8213c268
	if (!ctx.cr0.eq) goto loc_8213C268;
	// lwz r10,-204(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -204);
loc_8213C854:
	// lwz r11,8(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 8);
	// stfs f7,12(r24)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r24.u32 + 12, temp.u32);
	// stfs f8,16(r24)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r24.u32 + 16, temp.u32);
	// or r9,r11,r28
	ctx.r9.u64 = ctx.r11.u64 | ctx.r28.u64;
	// stw r9,8(r24)
	PPC_STORE_U32(ctx.r24.u32 + 8, ctx.r9.u32);
loc_8213C868:
	// lwz r11,-200(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -200);
	// addi r17,r17,1
	ctx.r17.s64 = ctx.r17.s64 + 1;
	// add r24,r11,r24
	ctx.r24.u64 = ctx.r11.u64 + ctx.r24.u64;
	// cmplw cr6,r17,r10
	ctx.cr6.compare<uint32_t>(ctx.r17.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x8213c1f8
	if (ctx.cr6.lt) goto loc_8213C1F8;
loc_8213C87C:
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
loc_8213C880:
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// lwzx r10,r11,r29
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r29.u32);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stwx r8,r11,r29
	PPC_STORE_U32(ctx.r11.u32 + ctx.r29.u32, ctx.r8.u32);
	// stbx r7,r30,r25
	PPC_STORE_U8(ctx.r30.u32 + ctx.r25.u32, ctx.r7.u8);
	// bge cr6,0x8213c7f0
	if (!ctx.cr6.lt) goto loc_8213C7F0;
	// rotlwi r11,r26,16
	ctx.r11.u64 = rotl32(ctx.r26.u32, 16);
	// or r28,r11,r28
	ctx.r28.u64 = ctx.r11.u64 | ctx.r28.u64;
	// b 0x8213c838
	goto loc_8213C838;
}

__attribute__((alias("__imp__sub_8213C8A8"))) PPC_WEAK_FUNC(sub_8213C8A8);
PPC_FUNC_IMPL(__imp__sub_8213C8A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x8213C8B0;
	__restfpr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// li r30,0
	ctx.r30.s64 = 0;
	// addi r10,r11,-29576
	ctx.r10.s64 = ctx.r11.s64 + -29576;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// stw r30,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r30.u32);
	// li r4,4000
	ctx.r4.s64 = 4000;
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
	// stw r30,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r30.u32);
	// stw r30,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r30.u32);
	// stw r30,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r30.u32);
	// bl 0x82305000
	ctx.lr = 0x8213C8EC;
	sub_82305000(ctx, base);
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// stw r30,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r30.u32);
	// li r8,4
	ctx.r8.s64 = 4;
	// stw r30,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r30.u32);
	// addi r7,r9,-29364
	ctx.r7.s64 = ctx.r9.s64 + -29364;
	// li r6,1
	ctx.r6.s64 = 1;
	// stw r30,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r30.u32);
	// stw r30,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r30.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r29,44(r31)
	PPC_STORE_U32(ctx.r31.u32 + 44, ctx.r29.u32);
	// stw r7,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r7.u32);
	// stw r8,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r8.u32);
	// stw r30,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r30.u32);
	// stw r30,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r30.u32);
	// stw r30,56(r31)
	PPC_STORE_U32(ctx.r31.u32 + 56, ctx.r30.u32);
	// stw r30,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r30.u32);
	// stw r30,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r30.u32);
	// stb r6,68(r31)
	PPC_STORE_U8(ctx.r31.u32 + 68, ctx.r6.u8);
	// stw r30,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r30.u32);
	// stw r30,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213C944"))) PPC_WEAK_FUNC(sub_8213C944);
PPC_FUNC_IMPL(__imp__sub_8213C944) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213C948"))) PPC_WEAK_FUNC(sub_8213C948);
PPC_FUNC_IMPL(__imp__sub_8213C948) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,72(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 72);
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r10,r11,-29364
	ctx.r10.s64 = ctx.r11.s64 + -29364;
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// beq cr6,0x8213c9b0
	if (ctx.cr6.eq) goto loc_8213C9B0;
	// lwz r10,-4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x8213c99c
	if (ctx.cr6.eq) goto loc_8213C99C;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8213C998;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x8213c9b0
	goto loc_8213C9B0;
loc_8213C99C:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213c9b0
	if (ctx.cr6.eq) goto loc_8213C9B0;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213C9B0;
	sub_82080000(ctx, base);
loc_8213C9B0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82137f30
	ctx.lr = 0x8213C9B8;
	sub_82137F30(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213C9CC"))) PPC_WEAK_FUNC(sub_8213C9CC);
PPC_FUNC_IMPL(__imp__sub_8213C9CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213C9D0"))) PPC_WEAK_FUNC(sub_8213C9D0);
PPC_FUNC_IMPL(__imp__sub_8213C9D0) {
	PPC_FUNC_PROLOGUE();
	// lwz r7,28(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// lwz r9,24(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r11,76(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 76);
	// lwz r10,44(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// lwz r8,40(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// add r5,r10,r8
	ctx.r5.u64 = ctx.r10.u64 + ctx.r8.u64;
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// li r8,0
	ctx.r8.s64 = 0;
loc_8213C9F8:
	// cmplwi cr6,r7,64
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 64, ctx.xer);
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
	// blt cr6,0x8213ca08
	if (ctx.cr6.lt) goto loc_8213CA08;
	// li r10,64
	ctx.r10.s64 = 64;
loc_8213CA08:
	// lwz r11,72(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 72);
	// mullw r6,r10,r5
	ctx.r6.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r5.s32);
	// lwz r4,40(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// add r11,r8,r11
	ctx.r11.u64 = ctx.r8.u64 + ctx.r11.u64;
	// subf r7,r10,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r10.s64;
	// addi r8,r8,40
	ctx.r8.s64 = ctx.r8.s64 + 40;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// add r9,r6,r9
	ctx.r9.u64 = ctx.r6.u64 + ctx.r9.u64;
	// stw r10,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r10.u32);
	// stw r4,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r4.u32);
	// bdnz 0x8213c9f8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213C9F8;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213CA38"))) PPC_WEAK_FUNC(sub_8213CA38);
PPC_FUNC_IMPL(__imp__sub_8213CA38) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x8213CA40;
	__restfpr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x821380b8
	ctx.lr = 0x8213CA50;
	sub_821380B8(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213cae4
	if (ctx.cr6.eq) goto loc_8213CAE4;
	// addi r11,r30,63
	ctx.r11.s64 = ctx.r30.s64 + 63;
	// lwz r10,76(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// rlwinm r30,r11,26,6,31
	ctx.r30.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 26) & 0x3FFFFFF;
	// cmplw cr6,r30,r10
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8213cadc
	if (!ctx.cr6.gt) goto loc_8213CADC;
	// lwz r3,72(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213cabc
	if (ctx.cr6.eq) goto loc_8213CABC;
	// lwz r10,-4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// beq cr6,0x8213caa8
	if (ctx.cr6.eq) goto loc_8213CAA8;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8213CAA4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// b 0x8213cabc
	goto loc_8213CABC;
loc_8213CAA8:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213cabc
	if (ctx.cr6.eq) goto loc_8213CABC;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213CABC;
	sub_82080000(ctx, base);
loc_8213CABC:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8213CAD4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r3,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r3.u32);
	// stw r30,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r30.u32);
loc_8213CADC:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8213c9d0
	ctx.lr = 0x8213CAE4;
	sub_8213C9D0(ctx, base);
loc_8213CAE4:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213CAF0"))) PPC_WEAK_FUNC(sub_8213CAF0);
PPC_FUNC_IMPL(__imp__sub_8213CAF0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// bl 0x82138250
	ctx.lr = 0x8213CB0C;
	sub_82138250(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213cb24
	if (ctx.cr6.eq) goto loc_8213CB24;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8213c9d0
	ctx.lr = 0x8213CB24;
	sub_8213C9D0(ctx, base);
loc_8213CB24:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213CB40"))) PPC_WEAK_FUNC(sub_8213CB40);
PPC_FUNC_IMPL(__imp__sub_8213CB40) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x8213CB48;
	__restfpr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r9,12(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// addi r10,r9,2
	ctx.r10.s64 = ctx.r9.s64 + 2;
	// mr r25,r6
	ctx.r25.u64 = ctx.r6.u64;
	// lwz r6,4(r5)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// mullw r4,r10,r7
	ctx.r4.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r7.s32);
	// rlwinm r10,r4,1,0,30
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// add r3,r10,r8
	ctx.r3.u64 = ctx.r10.u64 + ctx.r8.u64;
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// lwz r5,0(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm r26,r3,2,0,29
	ctx.r26.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r26,15
	ctx.r10.s64 = ctx.r26.s64 + 15;
	// rlwinm r7,r10,0,0,27
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF0;
	// add r6,r6,r7
	ctx.r6.u64 = ctx.r6.u64 + ctx.r7.u64;
	// cmplw cr6,r6,r5
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, ctx.xer);
	// ble cr6,0x8213cba4
	if (!ctx.cr6.gt) goto loc_8213CBA4;
	// lis r10,-13569
	ctx.r10.s64 = -889257984;
	// lis r6,-32250
	ctx.r6.s64 = -2113536000;
	// addi r5,r6,4492
	ctx.r5.s64 = ctx.r6.s64 + 4492;
	// stw r5,-13570(r10)
	PPC_STORE_U32(ctx.r10.u32 + -13570, ctx.r5.u32);
loc_8213CBA4:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// rlwinm r6,r29,4,0,27
	ctx.r6.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 4) & 0xFFFFFFF0;
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// mullw r9,r9,r29
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r29.s32);
	// add r31,r5,r10
	ctx.r31.u64 = ctx.r5.u64 + ctx.r10.u64;
	// rlwinm r9,r9,3,0,28
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r27,r6,r31
	ctx.r27.u64 = ctx.r6.u64 + ctx.r31.u64;
	// add r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 + ctx.r7.u64;
	// add r28,r9,r27
	ctx.r28.u64 = ctx.r9.u64 + ctx.r27.u64;
	// rlwinm r5,r8,2,0,29
	ctx.r5.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r7,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r7.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8233eaf0
	ctx.lr = 0x8213CBDC;
	sub_8233EAF0(ctx, base);
	// stw r25,20(r30)
	PPC_STORE_U32(ctx.r30.u32 + 20, ctx.r25.u32);
	// stw r29,24(r30)
	PPC_STORE_U32(ctx.r30.u32 + 24, ctx.r29.u32);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// lwz r6,64(r24)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r24.u32 + 64);
	// stw r6,28(r30)
	PPC_STORE_U32(ctx.r30.u32 + 28, ctx.r6.u32);
	// stw r31,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r31.u32);
	// stw r26,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r26.u32);
	// beq cr6,0x8213cc40
	if (ctx.cr6.eq) goto loc_8213CC40;
	// addi r11,r25,-15
	ctx.r11.s64 = ctx.r25.s64 + -15;
	// mtctr r29
	ctx.ctr.u64 = ctx.r29.u64;
	// li r9,0
	ctx.r9.s64 = 0;
loc_8213CC08:
	// subf r10,r31,r27
	ctx.r10.s64 = ctx.r27.s64 - ctx.r31.s64;
	// stw r9,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r9.u32);
	// stw r9,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r9.u32);
	// subf r8,r31,r28
	ctx.r8.s64 = ctx.r28.s64 - ctx.r31.s64;
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// lwz r7,12(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r8,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r8.u32);
	// add r27,r10,r27
	ctx.r27.u64 = ctx.r10.u64 + ctx.r27.u64;
	// lbzu r10,244(r11)
	ea = 244 + ctx.r11.u32;
	ctx.r10.u64 = PPC_LOAD_U8(ea);
	ctx.r11.u32 = ea;
	// rotlwi r10,r10,2
	ctx.r10.u64 = rotl32(ctx.r10.u32, 2);
	// addi r31,r31,16
	ctx.r31.s64 = ctx.r31.s64 + 16;
	// add r28,r10,r28
	ctx.r28.u64 = ctx.r10.u64 + ctx.r28.u64;
	// bdnz 0x8213cc08
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213CC08;
loc_8213CC40:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213CC48"))) PPC_WEAK_FUNC(sub_8213CC48);
PPC_FUNC_IMPL(__imp__sub_8213CC48) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x8213CC50;
	__restfpr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,64(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 64);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r10,60(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 60);
	// mr r25,r4
	ctx.r25.u64 = ctx.r4.u64;
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// mr r26,r5
	ctx.r26.u64 = ctx.r5.u64;
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// stw r9,64(r3)
	PPC_STORE_U32(ctx.r3.u32 + 64, ctx.r9.u32);
	// ble cr6,0x8213ccc0
	if (!ctx.cr6.gt) goto loc_8213CCC0;
	// lwz r11,56(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213cc90
	if (ctx.cr6.eq) goto loc_8213CC90;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213CC90;
	sub_82080000(ctx, base);
loc_8213CC90:
	// lis r11,8191
	ctx.r11.s64 = 536805376;
	// rlwinm r3,r26,3,0,28
	ctx.r3.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 3) & 0xFFFFFFF8;
	// ori r10,r11,65535
	ctx.r10.u64 = ctx.r11.u64 | 65535;
	// cmplw cr6,r26,r10
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8213cca8
	if (!ctx.cr6.gt) goto loc_8213CCA8;
	// li r3,-1
	ctx.r3.s64 = -1;
loc_8213CCA8:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x8213CCB8;
	sub_82082030(ctx, base);
	// stw r3,56(r28)
	PPC_STORE_U32(ctx.r28.u32 + 56, ctx.r3.u32);
	// stw r26,60(r28)
	PPC_STORE_U32(ctx.r28.u32 + 60, ctx.r26.u32);
loc_8213CCC0:
	// lwz r11,60(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 60);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,56(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 56);
	// rlwinm r5,r11,3,0,28
	ctx.r5.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x8233eaf0
	ctx.lr = 0x8213CCD4;
	sub_8233EAF0(ctx, base);
	// lwz r10,32(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213cdc8
	if (ctx.cr6.eq) goto loc_8213CDC8;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// li r31,0
	ctx.r31.s64 = 0;
	// li r29,0
	ctx.r29.s64 = 0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8213CCFC;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// lwz r10,36(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 36);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r9,r10,63
	ctx.r9.s64 = ctx.r10.s64 + 63;
	// cmpwi cr6,r26,2
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 2, ctx.xer);
	// rlwinm r30,r9,26,6,31
	ctx.r30.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0x3FFFFFF;
	// blt cr6,0x8213cd3c
	if (ctx.cr6.lt) goto loc_8213CD3C;
	// addi r7,r26,-1
	ctx.r7.s64 = ctx.r26.s64 + -1;
	// addi r10,r25,-15
	ctx.r10.s64 = ctx.r25.s64 + -15;
loc_8213CD20:
	// lbz r8,244(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 244);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// lbzu r9,488(r10)
	ea = 488 + ctx.r10.u32;
	ctx.r9.u64 = PPC_LOAD_U8(ea);
	ctx.r10.u32 = ea;
	// add r31,r8,r31
	ctx.r31.u64 = ctx.r8.u64 + ctx.r31.u64;
	// add r29,r9,r29
	ctx.r29.u64 = ctx.r9.u64 + ctx.r29.u64;
	// cmplw cr6,r11,r7
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r7.u32, ctx.xer);
	// blt cr6,0x8213cd20
	if (ctx.cr6.lt) goto loc_8213CD20;
loc_8213CD3C:
	// cmplw cr6,r11,r26
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r26.u32, ctx.xer);
	// bge cr6,0x8213cd50
	if (!ctx.cr6.lt) goto loc_8213CD50;
	// mulli r11,r11,244
	ctx.r11.s64 = ctx.r11.s64 * 244;
	// add r11,r11,r25
	ctx.r11.u64 = ctx.r11.u64 + ctx.r25.u64;
	// lbz r6,229(r11)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r11.u32 + 229);
loc_8213CD50:
	// lis r10,-32197
	ctx.r10.s64 = -2110062592;
	// add r11,r31,r29
	ctx.r11.u64 = ctx.r31.u64 + ctx.r29.u64;
	// add r27,r11,r6
	ctx.r27.u64 = ctx.r11.u64 + ctx.r6.u64;
	// lwz r3,-27096(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + -27096);
	// bl 0x82388734
	ctx.lr = 0x8213CD64;
	__imp__KeTlsGetValue(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x8213cd70
	if (!ctx.cr6.eq) goto loc_8213CD70;
	// bl 0x821b3000
	ctx.lr = 0x8213CD70;
	sub_821B3000(ctx, base);
loc_8213CD70:
	// lwz r11,40(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 40);
	// addi r29,r3,20
	ctx.r29.s64 = ctx.r3.s64 + 20;
	// lwz r31,72(r28)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r28.u32 + 72);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x8213cdc8
	if (ctx.cr6.eq) goto loc_8213CDC8;
loc_8213CD84:
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// mr r6,r25
	ctx.r6.u64 = ctx.r25.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// bl 0x8213cb40
	ctx.lr = 0x8213CDA4;
	sub_8213CB40(ctx, base);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// li r4,1
	ctx.r4.s64 = 1;
	// ori r10,r11,2
	ctx.r10.u64 = ctx.r11.u64 | 2;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r10,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r10.u32);
	// bl 0x821b60c0
	ctx.lr = 0x8213CDBC;
	sub_821B60C0(ctx, base);
	// addi r31,r31,40
	ctx.r31.s64 = ctx.r31.s64 + 40;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x8213cd84
	if (!ctx.cr6.eq) goto loc_8213CD84;
loc_8213CDC8:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213CDD0"))) PPC_WEAK_FUNC(sub_8213CDD0);
PPC_FUNC_IMPL(__imp__sub_8213CDD0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e448
	ctx.lr = 0x8213CDD8;
	__restfpr_20(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// mr r21,r6
	ctx.r21.u64 = ctx.r6.u64;
	// mr r20,r7
	ctx.r20.u64 = ctx.r7.u64;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x8213d068
	if (ctx.cr6.eq) goto loc_8213D068;
	// lwz r11,36(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// li r28,0
	ctx.r28.s64 = 0;
	// lwz r24,56(r3)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	// addi r10,r11,63
	ctx.r10.s64 = ctx.r11.s64 + 63;
	// lwz r11,72(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 72);
	// rlwinm r23,r10,26,6,31
	ctx.r23.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x3FFFFFF;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x8213cec8
	if (ctx.cr6.eq) goto loc_8213CEC8;
	// addi r26,r11,32
	ctx.r26.s64 = ctx.r11.s64 + 32;
	// mr r25,r23
	ctx.r25.u64 = ctx.r23.u64;
loc_8213CE18:
	// lwz r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x8213cebc
	if (ctx.cr6.eq) goto loc_8213CEBC;
	// li r29,0
	ctx.r29.s64 = 0;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// addi r30,r5,229
	ctx.r30.s64 = ctx.r5.s64 + 229;
	// addi r3,r24,4
	ctx.r3.s64 = ctx.r24.s64 + 4;
	// mr r27,r21
	ctx.r27.u64 = ctx.r21.u64;
loc_8213CE38:
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r8,0(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// add r28,r9,r28
	ctx.r28.u64 = ctx.r9.u64 + ctx.r28.u64;
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// lbz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r30.u32 + 0);
	// lwz r8,8(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// add r8,r8,r10
	ctx.r8.u64 = ctx.r8.u64 + ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8213cea0
	if (ctx.cr6.eq) goto loc_8213CEA0;
	// addi r8,r8,-4
	ctx.r8.s64 = ctx.r8.s64 + -4;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8213CE7C:
	// add r9,r29,r11
	ctx.r9.u64 = ctx.r29.u64 + ctx.r11.u64;
	// lwzu r7,4(r8)
	ea = 4 + ctx.r8.u32;
	ctx.r7.u64 = PPC_LOAD_U32(ea);
	ctx.r8.u32 = ea;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r9,r4
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	// add r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 + ctx.r6.u64;
	// stwx r7,r9,r4
	PPC_STORE_U32(ctx.r9.u32 + ctx.r4.u32, ctx.r7.u32);
	// bdnz 0x8213ce7c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213CE7C;
loc_8213CEA0:
	// addic. r27,r27,-1
	ctx.xer.ca = ctx.r27.u32 > 0;
	ctx.r27.s64 = ctx.r27.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// addi r3,r3,8
	ctx.r3.s64 = ctx.r3.s64 + 8;
	// addi r31,r31,260
	ctx.r31.s64 = ctx.r31.s64 + 260;
	// addi r30,r30,244
	ctx.r30.s64 = ctx.r30.s64 + 244;
	// addi r29,r29,65
	ctx.r29.s64 = ctx.r29.s64 + 65;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x8213ce38
	if (!ctx.cr0.eq) goto loc_8213CE38;
loc_8213CEBC:
	// addic. r25,r25,-1
	ctx.xer.ca = ctx.r25.u32 > 0;
	ctx.r25.s64 = ctx.r25.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r25.s32, 0, ctx.xer);
	// addi r26,r26,40
	ctx.r26.s64 = ctx.r26.s64 + 40;
	// bne 0x8213ce18
	if (!ctx.cr0.eq) goto loc_8213CE18;
loc_8213CEC8:
	// lwz r10,52(r22)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r22.u32 + 52);
	// mr r31,r10
	ctx.r31.u64 = ctx.r10.u64;
	// cmplw cr6,r28,r10
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r10.u32, ctx.xer);
	// bgt cr6,0x8213ceec
	if (ctx.cr6.gt) goto loc_8213CEEC;
	// rlwinm r11,r10,1,0,30
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// rlwinm r9,r11,30,2,31
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x3FFFFFFF;
	// cmplw cr6,r28,r9
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x8213cf04
	if (!ctx.cr6.lt) goto loc_8213CF04;
loc_8213CEEC:
	// rlwinm r11,r28,3,0,28
	ctx.r11.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r28,r11
	ctx.r11.u64 = ctx.r28.u64 + ctx.r11.u64;
	// rlwinm r31,r11,29,3,31
	ctx.r31.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// bgt cr6,0x8213cf04
	if (ctx.cr6.gt) goto loc_8213CF04;
	// li r31,64
	ctx.r31.s64 = 64;
loc_8213CF04:
	// cmplw cr6,r31,r10
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8213cf54
	if (ctx.cr6.eq) goto loc_8213CF54;
	// lwz r11,48(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 48);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213cf24
	if (ctx.cr6.eq) goto loc_8213CF24;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213CF24;
	sub_82080000(ctx, base);
loc_8213CF24:
	// lis r11,8191
	ctx.r11.s64 = 536805376;
	// rlwinm r3,r31,3,0,28
	ctx.r3.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 3) & 0xFFFFFFF8;
	// ori r10,r11,65535
	ctx.r10.u64 = ctx.r11.u64 | 65535;
	// cmplw cr6,r31,r10
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8213cf3c
	if (!ctx.cr6.gt) goto loc_8213CF3C;
	// li r3,-1
	ctx.r3.s64 = -1;
loc_8213CF3C:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x8213CF4C;
	sub_82082030(ctx, base);
	// stw r3,48(r22)
	PPC_STORE_U32(ctx.r22.u32 + 48, ctx.r3.u32);
	// stw r31,52(r22)
	PPC_STORE_U32(ctx.r22.u32 + 52, ctx.r31.u32);
loc_8213CF54:
	// lwz r5,48(r22)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r22.u32 + 48);
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x8213cfdc
	if (ctx.cr6.eq) goto loc_8213CFDC;
	// mr r31,r24
	ctx.r31.u64 = ctx.r24.u64;
loc_8213CF68:
	// stw r5,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r5.u32);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// lwz r11,72(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 72);
	// beq cr6,0x8213cfcc
	if (ctx.cr6.eq) goto loc_8213CFCC;
	// rlwinm r6,r3,4,0,27
	ctx.r6.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r7,r11,32
	ctx.r7.s64 = ctx.r11.s64 + 32;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
loc_8213CF84:
	// lwz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// add r10,r11,r6
	ctx.r10.u64 = ctx.r11.u64 + ctx.r6.u64;
	// lwzx r9,r11,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r6.u32);
	// lwz r11,4(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213cfb8
	if (ctx.cr6.eq) goto loc_8213CFB8;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// addi r10,r10,-8
	ctx.r10.s64 = ctx.r10.s64 + -8;
	// addi r9,r5,-8
	ctx.r9.s64 = ctx.r5.s64 + -8;
loc_8213CFAC:
	// ldu r8,8(r10)
	ea = 8 + ctx.r10.u32;
	ctx.r8.u64 = PPC_LOAD_U64(ea);
	ctx.r10.u32 = ea;
	// stdu r8,8(r9)
	ea = 8 + ctx.r9.u32;
	PPC_STORE_U64(ea, ctx.r8.u64);
	ctx.r9.u32 = ea;
	// bdnz 0x8213cfac
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213CFAC;
loc_8213CFB8:
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// addic. r4,r4,-1
	ctx.xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// add r5,r11,r5
	ctx.r5.u64 = ctx.r11.u64 + ctx.r5.u64;
	// addi r7,r7,40
	ctx.r7.s64 = ctx.r7.s64 + 40;
	// bne 0x8213cf84
	if (!ctx.cr0.eq) goto loc_8213CF84;
loc_8213CFCC:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r31,r31,8
	ctx.r31.s64 = ctx.r31.s64 + 8;
	// cmplw cr6,r3,r21
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r21.u32, ctx.xer);
	// blt cr6,0x8213cf68
	if (ctx.cr6.lt) goto loc_8213CF68;
loc_8213CFDC:
	// rlwinm r11,r23,2,0,29
	ctx.r11.u64 = rotl64(ctx.r23.u32 | (ctx.r23.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,72(r22)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r22.u32 + 72);
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// add r11,r23,r11
	ctx.r11.u64 = ctx.r23.u64 + ctx.r11.u64;
	// rlwinm r11,r11,3,0,28
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r11,r11,-40
	ctx.r11.s64 = ctx.r11.s64 + -40;
	// beq cr6,0x8213d068
	if (ctx.cr6.eq) goto loc_8213D068;
	// addi r7,r11,36
	ctx.r7.s64 = ctx.r11.s64 + 36;
	// mtctr r23
	ctx.ctr.u64 = ctx.r23.u64;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lis r5,-13569
	ctx.r5.s64 = -889257984;
	// addi r6,r11,4520
	ctx.r6.s64 = ctx.r11.s64 + 4520;
loc_8213D010:
	// lwz r8,-4(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + -4);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8213d060
	if (ctx.cr6.eq) goto loc_8213D060;
	// lwz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// lwz r10,4(r20)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r20.u32 + 4);
	// addi r9,r11,15
	ctx.r9.s64 = ctx.r11.s64 + 15;
	// rlwinm r11,r9,0,0,27
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8213d038
	if (!ctx.cr6.gt) goto loc_8213D038;
	// stw r6,-13570(r5)
	PPC_STORE_U32(ctx.r5.u32 + -13570, ctx.r6.u32);
loc_8213D038:
	// lwz r10,8(r20)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r20.u32 + 8);
	// lwz r9,4(r20)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r20.u32 + 4);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x8213d054
	if (ctx.cr6.eq) goto loc_8213D054;
	// stw r6,-13570(r5)
	PPC_STORE_U32(ctx.r5.u32 + -13570, ctx.r6.u32);
loc_8213D054:
	// lwz r10,4(r20)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r20.u32 + 4);
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r9,4(r20)
	PPC_STORE_U32(ctx.r20.u32 + 4, ctx.r9.u32);
loc_8213D060:
	// addi r7,r7,-40
	ctx.r7.s64 = ctx.r7.s64 + -40;
	// bdnz 0x8213d010
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213D010;
loc_8213D068:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e498
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213D070"))) PPC_WEAK_FUNC(sub_8213D070);
PPC_FUNC_IMPL(__imp__sub_8213D070) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e434
	ctx.lr = 0x8213D078;
	__restfpr_15(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,10012(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10012);
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// lwz r18,9876(r3)
	ctx.r18.u64 = PPC_LOAD_U32(ctx.r3.u32 + 9876);
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// lwz r26,256(r3)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r3.u32 + 256);
	// li r19,0
	ctx.r19.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x8213d1d8
	if (!ctx.cr6.gt) goto loc_8213D1D8;
	// rlwinm r23,r26,4,0,27
	ctx.r23.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 4) & 0xFFFFFFF0;
	// lis r10,4095
	ctx.r10.s64 = 268369920;
	// addi r11,r23,15
	ctx.r11.s64 = ctx.r23.s64 + 15;
	// addi r21,r26,7
	ctx.r21.s64 = ctx.r26.s64 + 7;
	// rlwinm r25,r11,0,0,27
	ctx.r25.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFF0;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r24,r3,9884
	ctx.r24.s64 = ctx.r3.s64 + 9884;
	// lis r15,-13569
	ctx.r15.s64 = -889257984;
	// ori r20,r10,65535
	ctx.r20.u64 = ctx.r10.u64 | 65535;
	// li r16,-1
	ctx.r16.s64 = -1;
	// addi r17,r11,4492
	ctx.r17.s64 = ctx.r11.s64 + 4492;
loc_8213D0C8:
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// stw r9,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r9.u32);
	// lwz r8,0(r27)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// lwz r11,4(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// add r7,r11,r25
	ctx.r7.u64 = ctx.r11.u64 + ctx.r25.u64;
	// lwz r30,0(r24)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// cmplw cr6,r7,r8
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, ctx.xer);
	// ble cr6,0x8213d0f4
	if (!ctx.cr6.gt) goto loc_8213D0F4;
	// stw r17,-13570(r15)
	PPC_STORE_U32(ctx.r15.u32 + -13570, ctx.r17.u32);
loc_8213D0F4:
	// lwz r11,4(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// li r4,0
	ctx.r4.s64 = 0;
	// add r9,r11,r25
	ctx.r9.u64 = ctx.r11.u64 + ctx.r25.u64;
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + ctx.r11.u64;
	// stw r9,4(r27)
	PPC_STORE_U32(ctx.r27.u32 + 4, ctx.r9.u32);
	// stw r3,40(r30)
	PPC_STORE_U32(ctx.r30.u32 + 40, ctx.r3.u32);
	// bl 0x8233eaf0
	ctx.lr = 0x8213D118;
	sub_8233EAF0(ctx, base);
	// lwz r11,24(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// cmplw cr6,r26,r11
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, ctx.r11.u32, ctx.xer);
	// bgt cr6,0x8213d12c
	if (ctx.cr6.gt) goto loc_8213D12C;
	// cmplw cr6,r21,r11
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x8213d180
	if (!ctx.cr6.lt) goto loc_8213D180;
loc_8213D12C:
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213d144
	if (ctx.cr6.eq) goto loc_8213D144;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213D144;
	sub_82080000(ctx, base);
loc_8213D144:
	// rlwinm r11,r21,0,0,29
	ctx.r11.u64 = rotl64(ctx.r21.u32 | (ctx.r21.u64 << 32), 0) & 0xFFFFFFFC;
	// stw r11,24(r30)
	PPC_STORE_U32(ctx.r30.u32 + 24, ctx.r11.u32);
	// cmplw cr6,r11,r20
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r20.u32, ctx.xer);
	// rlwinm r3,r11,4,0,27
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// ble cr6,0x8213d15c
	if (!ctx.cr6.gt) goto loc_8213D15C;
	// mr r3,r16
	ctx.r3.u64 = ctx.r16.u64;
loc_8213D15C:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x8213D16C;
	sub_82082030(ctx, base);
	// lwz r11,24(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r3,20(r30)
	PPC_STORE_U32(ctx.r30.u32 + 20, ctx.r3.u32);
	// rlwinm r5,r11,4,0,27
	ctx.r5.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x8233eaf0
	ctx.lr = 0x8213D180;
	sub_8233EAF0(ctx, base);
loc_8213D180:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x8213d1c4
	if (ctx.cr6.eq) goto loc_8213D1C4;
	// li r31,0
	ctx.r31.s64 = 0;
	// mr r28,r18
	ctx.r28.u64 = ctx.r18.u64;
	// mr r29,r26
	ctx.r29.u64 = ctx.r26.u64;
loc_8213D194:
	// lwz r10,40(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// add r5,r10,r31
	ctx.r5.u64 = ctx.r10.u64 + ctx.r31.u64;
	// add r4,r11,r31
	ctx.r4.u64 = ctx.r11.u64 + ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8213ab48
	ctx.lr = 0x8213D1B4;
	sub_8213AB48(ctx, base);
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r28,r28,244
	ctx.r28.s64 = ctx.r28.s64 + 244;
	// addi r31,r31,16
	ctx.r31.s64 = ctx.r31.s64 + 16;
	// bne 0x8213d194
	if (!ctx.cr0.eq) goto loc_8213D194;
loc_8213D1C4:
	// lwz r11,10012(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 10012);
	// addi r19,r19,1
	ctx.r19.s64 = ctx.r19.s64 + 1;
	// addi r24,r24,4
	ctx.r24.s64 = ctx.r24.s64 + 4;
	// cmplw cr6,r19,r11
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x8213d0c8
	if (ctx.cr6.lt) goto loc_8213D0C8;
loc_8213D1D8:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x8233e484
	__restgprlr_15(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213D1E0"))) PPC_WEAK_FUNC(sub_8213D1E0);
PPC_FUNC_IMPL(__imp__sub_8213D1E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e43c
	ctx.lr = 0x8213D1E8;
	__restfpr_17(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,10012(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10012);
	// mr r21,r4
	ctx.r21.u64 = ctx.r4.u64;
	// lwz r20,9876(r3)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r3.u32 + 9876);
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// lwz r26,256(r3)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r3.u32 + 256);
	// addic. r23,r11,-1
	ctx.xer.ca = ctx.r11.u32 > 0;
	ctx.r23.s64 = ctx.r11.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// blt 0x8213d3a0
	if (ctx.cr0.lt) goto loc_8213D3A0;
	// addi r11,r23,2471
	ctx.r11.s64 = ctx.r23.s64 + 2471;
	// addi r17,r26,-1
	ctx.r17.s64 = ctx.r26.s64 + -1;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r24,0
	ctx.r24.s64 = 0;
	// add r22,r11,r3
	ctx.r22.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lis r18,-13569
	ctx.r18.s64 = -889257984;
	// addi r19,r11,4520
	ctx.r19.s64 = ctx.r11.s64 + 4520;
loc_8213D228:
	// lwz r27,0(r22)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// mr r29,r24
	ctx.r29.u64 = ctx.r24.u64;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x8213d25c
	if (ctx.cr6.eq) goto loc_8213D25C;
	// lwz r28,40(r27)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r27.u32 + 40);
	// mr r30,r24
	ctx.r30.u64 = ctx.r24.u64;
	// mr r31,r26
	ctx.r31.u64 = ctx.r26.u64;
loc_8213D244:
	// add r3,r30,r28
	ctx.r3.u64 = ctx.r30.u64 + ctx.r28.u64;
	// bl 0x8213adf8
	ctx.lr = 0x8213D24C;
	sub_8213ADF8(ctx, base);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// add r29,r3,r29
	ctx.r29.u64 = ctx.r3.u64 + ctx.r29.u64;
	// addi r30,r30,16
	ctx.r30.s64 = ctx.r30.s64 + 16;
	// bne 0x8213d244
	if (!ctx.cr0.eq) goto loc_8213D244;
loc_8213D25C:
	// lwz r11,32(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 32);
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// bgt cr6,0x8213d278
	if (ctx.cr6.gt) goto loc_8213D278;
	// addi r10,r29,2048
	ctx.r10.s64 = ctx.r29.s64 + 2048;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x8213d288
	if (!ctx.cr6.lt) goto loc_8213D288;
loc_8213D278:
	// addi r31,r29,1024
	ctx.r31.s64 = ctx.r29.s64 + 1024;
	// cmplwi cr6,r31,1024
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 1024, ctx.xer);
	// bgt cr6,0x8213d288
	if (ctx.cr6.gt) goto loc_8213D288;
	// li r31,1024
	ctx.r31.s64 = 1024;
loc_8213D288:
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8213d2c4
	if (ctx.cr6.eq) goto loc_8213D2C4;
	// lwz r11,28(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 28);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213d2a8
	if (ctx.cr6.eq) goto loc_8213D2A8;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213D2A8;
	sub_82080000(ctx, base);
loc_8213D2A8:
	// stw r31,32(r27)
	PPC_STORE_U32(ctx.r27.u32 + 32, ctx.r31.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82082030
	ctx.lr = 0x8213D2C0;
	sub_82082030(ctx, base);
	// stw r3,28(r27)
	PPC_STORE_U32(ctx.r27.u32 + 28, ctx.r3.u32);
loc_8213D2C4:
	// lwz r5,28(r27)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r27.u32 + 28);
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x8213d314
	if (ctx.cr6.eq) goto loc_8213D314;
	// mr r31,r24
	ctx.r31.u64 = ctx.r24.u64;
	// mr r28,r21
	ctx.r28.u64 = ctx.r21.u64;
	// mr r29,r20
	ctx.r29.u64 = ctx.r20.u64;
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
loc_8213D2E0:
	// lwz r10,40(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 40);
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// add r4,r10,r31
	ctx.r4.u64 = ctx.r10.u64 + ctx.r31.u64;
	// add r3,r31,r11
	ctx.r3.u64 = ctx.r31.u64 + ctx.r11.u64;
	// bl 0x8213aee8
	ctx.lr = 0x8213D2FC;
	sub_8213AEE8(ctx, base);
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// add r5,r3,r5
	ctx.r5.u64 = ctx.r3.u64 + ctx.r5.u64;
	// addi r29,r29,244
	ctx.r29.s64 = ctx.r29.s64 + 244;
	// addi r28,r28,260
	ctx.r28.s64 = ctx.r28.s64 + 260;
	// addi r31,r31,16
	ctx.r31.s64 = ctx.r31.s64 + 16;
	// bne 0x8213d2e0
	if (!ctx.cr0.eq) goto loc_8213D2E0;
loc_8213D314:
	// mr r31,r17
	ctx.r31.u64 = ctx.r17.u64;
	// cmpwi cr6,r17,0
	ctx.cr6.compare<int32_t>(ctx.r17.s32, 0, ctx.xer);
	// blt cr6,0x8213d340
	if (ctx.cr6.lt) goto loc_8213D340;
	// rlwinm r30,r17,4,0,27
	ctx.r30.u64 = rotl64(ctx.r17.u32 | (ctx.r17.u64 << 32), 4) & 0xFFFFFFF0;
loc_8213D324:
	// lwz r11,40(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 40);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// add r3,r11,r30
	ctx.r3.u64 = ctx.r11.u64 + ctx.r30.u64;
	// bl 0x8213b020
	ctx.lr = 0x8213D334;
	sub_8213B020(ctx, base);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// addi r30,r30,-16
	ctx.r30.s64 = ctx.r30.s64 + -16;
	// bge 0x8213d324
	if (!ctx.cr0.lt) goto loc_8213D324;
loc_8213D340:
	// lwz r8,40(r27)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r27.u32 + 40);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8213d390
	if (ctx.cr6.eq) goto loc_8213D390;
	// rlwinm r11,r26,4,0,27
	ctx.r11.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 4) & 0xFFFFFFF0;
	// lwz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// addi r9,r11,15
	ctx.r9.s64 = ctx.r11.s64 + 15;
	// rlwinm r11,r9,0,0,27
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8213d368
	if (!ctx.cr6.gt) goto loc_8213D368;
	// stw r19,-13570(r18)
	PPC_STORE_U32(ctx.r18.u32 + -13570, ctx.r19.u32);
loc_8213D368:
	// lwz r10,8(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	// lwz r9,4(r25)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r9,r8
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x8213d384
	if (ctx.cr6.eq) goto loc_8213D384;
	// stw r19,-13570(r18)
	PPC_STORE_U32(ctx.r18.u32 + -13570, ctx.r19.u32);
loc_8213D384:
	// lwz r10,4(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r9,4(r25)
	PPC_STORE_U32(ctx.r25.u32 + 4, ctx.r9.u32);
loc_8213D390:
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// stw r24,40(r27)
	PPC_STORE_U32(ctx.r27.u32 + 40, ctx.r24.u32);
	// addi r22,r22,-4
	ctx.r22.s64 = ctx.r22.s64 + -4;
	// bge 0x8213d228
	if (!ctx.cr0.lt) goto loc_8213D228;
loc_8213D3A0:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8233e48c
	__restgprlr_17(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213D3A8"))) PPC_WEAK_FUNC(sub_8213D3A8);
PPC_FUNC_IMPL(__imp__sub_8213D3A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e450
	ctx.lr = 0x8213D3B0;
	__restfpr_22(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r22,r3,9860
	ctx.r22.s64 = ctx.r3.s64 + 9860;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// li r31,10
	ctx.r31.s64 = 10;
	// mr r30,r22
	ctx.r30.u64 = ctx.r22.u64;
	// li r29,-1
	ctx.r29.s64 = -1;
loc_8213D3C8:
	// lwzu r11,-4(r30)
	ea = -4 + ctx.r30.u32;
	ctx.r11.u64 = PPC_LOAD_U32(ea);
	ctx.r30.u32 = ea;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r31,r31,-1
	ctx.r31.s64 = ctx.r31.s64 + -1;
	// addi r3,r11,4
	ctx.r3.s64 = ctx.r11.s64 + 4;
	// bl 0x823052d8
	ctx.lr = 0x8213D3DC;
	sub_823052D8(ctx, base);
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bne cr6,0x8213d3c8
	if (!ctx.cr6.eq) goto loc_8213D3C8;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82139248
	ctx.lr = 0x8213D3EC;
	sub_82139248(ctx, base);
	// lis r24,-32197
	ctx.r24.s64 = -2110062592;
	// lwz r3,-27096(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + -27096);
	// bl 0x82388734
	ctx.lr = 0x8213D3F8;
	__imp__KeTlsGetValue(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x8213d404
	if (!ctx.cr6.eq) goto loc_8213D404;
	// bl 0x821b3000
	ctx.lr = 0x8213D404;
	sub_821B3000(ctx, base);
loc_8213D404:
	// lwz r11,256(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 256);
	// lis r23,-13569
	ctx.r23.s64 = -889257984;
	// lwz r9,24(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// addi r27,r3,20
	ctx.r27.s64 = ctx.r3.s64 + 20;
	// mulli r11,r11,260
	ctx.r11.s64 = ctx.r11.s64 * 260;
	// lwz r8,20(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// addi r7,r11,15
	ctx.r7.s64 = ctx.r11.s64 + 15;
	// rlwinm r10,r7,0,0,27
	ctx.r10.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFF0;
	// add r6,r9,r10
	ctx.r6.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r6,r8
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r8.u32, ctx.xer);
	// ble cr6,0x8213d43c
	if (!ctx.cr6.gt) goto loc_8213D43C;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r9,r11,4492
	ctx.r9.s64 = ctx.r11.s64 + 4492;
	// stw r9,-13570(r23)
	PPC_STORE_U32(ctx.r23.u32 + -13570, ctx.r9.u32);
loc_8213D43C:
	// lwz r11,4(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// stw r9,4(r27)
	PPC_STORE_U32(ctx.r27.u32 + 4, ctx.r9.u32);
	// add r26,r10,r11
	ctx.r26.u64 = ctx.r10.u64 + ctx.r11.u64;
	// bl 0x8213d070
	ctx.lr = 0x8213D45C;
	sub_8213D070(ctx, base);
	// li r30,10
	ctx.r30.s64 = 10;
	// mr r31,r22
	ctx.r31.u64 = ctx.r22.u64;
	// lwz r29,9876(r28)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9876);
loc_8213D468:
	// lwz r5,256(r28)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r28.u32 + 256);
	// addi r30,r30,-1
	ctx.r30.s64 = ctx.r30.s64 + -1;
	// addi r31,r31,-4
	ctx.r31.s64 = ctx.r31.s64 + -4;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x8213d488
	if (ctx.cr6.eq) goto loc_8213D488;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x8213cc48
	ctx.lr = 0x8213D488;
	sub_8213CC48(ctx, base);
loc_8213D488:
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// bne cr6,0x8213d468
	if (!ctx.cr6.eq) goto loc_8213D468;
	// bl 0x821b5da8
	ctx.lr = 0x8213D494;
	sub_821B5DA8(ctx, base);
	// addi r31,r28,9820
	ctx.r31.s64 = ctx.r28.s64 + 9820;
	// li r30,10
	ctx.r30.s64 = 10;
	// li r25,0
	ctx.r25.s64 = 0;
loc_8213D4A0:
	// lwz r11,256(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 256);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// mulli r5,r11,260
	ctx.r5.s64 = ctx.r11.s64 * 260;
	// bl 0x8233eaf0
	ctx.lr = 0x8213D4B4;
	sub_8233EAF0(ctx, base);
	// lwz r6,256(r28)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r28.u32 + 256);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r7,r27
	ctx.r7.u64 = ctx.r27.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// bl 0x8213cdd0
	ctx.lr = 0x8213D4CC;
	sub_8213CDD0(ctx, base);
	// lwz r10,256(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 256);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// ble cr6,0x8213d550
	if (!ctx.cr6.gt) goto loc_8213D550;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
loc_8213D4E4:
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r8,0(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// addi r9,r11,324
	ctx.r9.s64 = ctx.r11.s64 + 324;
	// lwz r10,340(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 340);
	// lwz r11,328(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 328);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r10,16(r9)
	PPC_STORE_U32(ctx.r9.u32 + 16, ctx.r10.u32);
	// beq cr6,0x8213d538
	if (ctx.cr6.eq) goto loc_8213D538;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// mr r8,r5
	ctx.r8.u64 = ctx.r5.u64;
loc_8213D514:
	// lwz r11,0(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwzu r7,4(r8)
	ea = 4 + ctx.r8.u32;
	ctx.r7.u64 = PPC_LOAD_U32(ea);
	ctx.r8.u32 = ea;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r10,r10,112
	ctx.r10.s64 = ctx.r10.s64 + 112;
	// addi r6,r11,16
	ctx.r6.s64 = ctx.r11.s64 + 16;
	// lwz r6,16(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// add r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 + ctx.r6.u64;
	// stw r7,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r7.u32);
	// bdnz 0x8213d514
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213D514;
loc_8213D538:
	// lwz r11,256(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 256);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// addi r5,r5,260
	ctx.r5.s64 = ctx.r5.s64 + 260;
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x8213d4e4
	if (ctx.cr6.lt) goto loc_8213D4E4;
loc_8213D550:
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// bne 0x8213d4a0
	if (!ctx.cr0.eq) goto loc_8213D4A0;
	// lwz r11,256(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 256);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// mulli r5,r11,260
	ctx.r5.s64 = ctx.r11.s64 * 260;
	// bl 0x8233eaf0
	ctx.lr = 0x8213D570;
	sub_8233EAF0(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8213d1e0
	ctx.lr = 0x8213D580;
	sub_8213D1E0(ctx, base);
	// lwz r10,256(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 256);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// ble cr6,0x8213d604
	if (!ctx.cr6.gt) goto loc_8213D604;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
loc_8213D598:
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// lwz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// addi r9,r11,324
	ctx.r9.s64 = ctx.r11.s64 + 324;
	// lwz r8,344(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 344);
	// lwz r11,328(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 328);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r10,20(r9)
	PPC_STORE_U32(ctx.r9.u32 + 20, ctx.r10.u32);
	// beq cr6,0x8213d5ec
	if (ctx.cr6.eq) goto loc_8213D5EC;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// mr r8,r5
	ctx.r8.u64 = ctx.r5.u64;
loc_8213D5C8:
	// lwz r11,0(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwzu r7,4(r8)
	ea = 4 + ctx.r8.u32;
	ctx.r7.u64 = PPC_LOAD_U32(ea);
	ctx.r8.u32 = ea;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r10,r10,112
	ctx.r10.s64 = ctx.r10.s64 + 112;
	// addi r6,r11,20
	ctx.r6.s64 = ctx.r11.s64 + 20;
	// lwz r6,20(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// add r7,r6,r7
	ctx.r7.u64 = ctx.r6.u64 + ctx.r7.u64;
	// stw r7,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r7.u32);
	// bdnz 0x8213d5c8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213D5C8;
loc_8213D5EC:
	// lwz r11,256(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 256);
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r4,r4,4
	ctx.r4.s64 = ctx.r4.s64 + 4;
	// addi r5,r5,260
	ctx.r5.s64 = ctx.r5.s64 + 260;
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x8213d598
	if (ctx.cr6.lt) goto loc_8213D598;
loc_8213D604:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// addi r31,r11,4520
	ctx.r31.s64 = ctx.r11.s64 + 4520;
	// beq cr6,0x8213d65c
	if (ctx.cr6.eq) goto loc_8213D65C;
	// lwz r11,256(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 256);
	// lwz r10,4(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// mulli r11,r11,260
	ctx.r11.s64 = ctx.r11.s64 * 260;
	// addi r9,r11,15
	ctx.r9.s64 = ctx.r11.s64 + 15;
	// rlwinm r11,r9,0,0,27
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8213d634
	if (!ctx.cr6.gt) goto loc_8213D634;
	// stw r31,-13570(r23)
	PPC_STORE_U32(ctx.r23.u32 + -13570, ctx.r31.u32);
loc_8213D634:
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// lwz r9,4(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r11.s64;
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r9,r26
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r26.u32, ctx.xer);
	// beq cr6,0x8213d650
	if (ctx.cr6.eq) goto loc_8213D650;
	// stw r31,-13570(r23)
	PPC_STORE_U32(ctx.r23.u32 + -13570, ctx.r31.u32);
loc_8213D650:
	// lwz r10,4(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r9,4(r27)
	PPC_STORE_U32(ctx.r27.u32 + 4, ctx.r9.u32);
loc_8213D65C:
	// lwz r3,-27096(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + -27096);
	// bl 0x82388734
	ctx.lr = 0x8213D664;
	__imp__KeTlsGetValue(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x8213d670
	if (!ctx.cr6.eq) goto loc_8213D670;
	// bl 0x821b3000
	ctx.lr = 0x8213D670;
	sub_821B3000(ctx, base);
loc_8213D670:
	// lwz r7,9876(r28)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9876);
	// addi r11,r3,20
	ctx.r11.s64 = ctx.r3.s64 + 20;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x8213d6c4
	if (ctx.cr6.eq) goto loc_8213D6C4;
	// lwz r10,9880(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 9880);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r8,r10,15
	ctx.r8.s64 = ctx.r10.s64 + 15;
	// rlwinm r10,r8,0,0,27
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFF0;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x8213d69c
	if (!ctx.cr6.gt) goto loc_8213D69C;
	// stw r31,-13570(r23)
	PPC_STORE_U32(ctx.r23.u32 + -13570, ctx.r31.u32);
loc_8213D69C:
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// add r8,r9,r8
	ctx.r8.u64 = ctx.r9.u64 + ctx.r8.u64;
	// cmplw cr6,r8,r7
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, ctx.xer);
	// beq cr6,0x8213d6b8
	if (ctx.cr6.eq) goto loc_8213D6B8;
	// stw r31,-13570(r23)
	PPC_STORE_U32(ctx.r23.u32 + -13570, ctx.r31.u32);
loc_8213D6B8:
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// subf r8,r10,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r10.s64;
	// stw r8,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r8.u32);
loc_8213D6C4:
	// stw r25,9876(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9876, ctx.r25.u32);
	// li r31,10
	ctx.r31.s64 = 10;
	// stw r25,9880(r28)
	PPC_STORE_U32(ctx.r28.u32 + 9880, ctx.r25.u32);
	// mr r30,r22
	ctx.r30.u64 = ctx.r22.u64;
loc_8213D6D4:
	// lwzu r11,-4(r30)
	ea = -4 + ctx.r30.u32;
	ctx.r11.u64 = PPC_LOAD_U32(ea);
	ctx.r30.u32 = ea;
	// addi r31,r31,-1
	ctx.r31.s64 = ctx.r31.s64 + -1;
	// addi r3,r11,4
	ctx.r3.s64 = ctx.r11.s64 + 4;
	// bl 0x823051a8
	ctx.lr = 0x8213D6E4;
	sub_823051A8(ctx, base);
	// cmpwi cr6,r31,0
	ctx.cr6.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bne cr6,0x8213d6d4
	if (!ctx.cr6.eq) goto loc_8213D6D4;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8233e4a0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213D6F4"))) PPC_WEAK_FUNC(sub_8213D6F4);
PPC_FUNC_IMPL(__imp__sub_8213D6F4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213D6F8"))) PPC_WEAK_FUNC(sub_8213D6F8);
PPC_FUNC_IMPL(__imp__sub_8213D6F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8213D700;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// stfs f1,8(r3)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// li r29,0
	ctx.r29.s64 = 0;
	// stfs f2,12(r3)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
	// addi r28,r11,31376
	ctx.r28.s64 = ctx.r11.s64 + 31376;
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r5,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r5.u32);
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// stb r9,16(r3)
	PPC_STORE_U8(ctx.r3.u32 + 16, ctx.r9.u8);
	// addi r7,r5,48
	ctx.r7.s64 = ctx.r5.s64 + 48;
	// sth r29,28(r3)
	PPC_STORE_U16(ctx.r3.u32 + 28, ctx.r29.u16);
	// sth r6,30(r3)
	PPC_STORE_U16(ctx.r3.u32 + 30, ctx.r6.u16);
	// lfs f0,36(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stw r29,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r29.u32);
	// stfs f0,20(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 20, temp.u32);
loc_8213D744:
	// mfmsr r8
	ctx.r8.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r10,0,r7
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r7
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r8,1
	ctx.msr = (ctx.r8.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x8213d744
	if (!ctx.cr0.eq) goto loc_8213D744;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213d778
	if (ctx.cr6.eq) goto loc_8213D778;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82177f68
	ctx.lr = 0x8213D778;
	sub_82177F68(ctx, base);
loc_8213D778:
	// lis r11,2340
	ctx.r11.s64 = 153354240;
	// clrlwi r30,r30,16
	ctx.r30.u64 = ctx.r30.u32 & 0xFFFF;
	// ori r10,r11,37449
	ctx.r10.u64 = ctx.r11.u64 | 37449;
	// cmplw cr6,r30,r10
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r10.u32, ctx.xer);
	// bgt cr6,0x8213d7a0
	if (ctx.cr6.gt) goto loc_8213D7A0;
	// mulli r11,r30,28
	ctx.r11.s64 = ctx.r30.s64 * 28;
	// li r10,-5
	ctx.r10.s64 = -5;
	// addi r3,r11,4
	ctx.r3.s64 = ctx.r11.s64 + 4;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8213d7a4
	if (!ctx.cr6.gt) goto loc_8213D7A4;
loc_8213D7A0:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_8213D7A4:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x8213D7B4;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213d814
	if (ctx.cr6.eq) goto loc_8213D814;
	// addic. r11,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r11.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r30.u32);
	// addi r8,r3,4
	ctx.r8.s64 = ctx.r3.s64 + 4;
	// blt 0x8213d804
	if (ctx.cr0.lt) goto loc_8213D804;
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// lfs f0,48(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r8,-4
	ctx.r11.s64 = ctx.r8.s64 + -4;
	// addi r10,r8,-28
	ctx.r10.s64 = ctx.r8.s64 + -28;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8213D7E0:
	// stfs f0,12(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 12, temp.u32);
	// sth r29,8(r11)
	PPC_STORE_U16(ctx.r11.u32 + 8, ctx.r29.u16);
	// sth r29,10(r11)
	PPC_STORE_U16(ctx.r11.u32 + 10, ctx.r29.u16);
	// stwu r29,28(r10)
	ea = 28 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r29.u32);
	ctx.r10.u32 = ea;
	// stfs f0,16(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 16, temp.u32);
	// stfs f0,20(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 20, temp.u32);
	// stfs f0,24(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 24, temp.u32);
	// stfsu f0,28(r11)
	temp.f32 = float(ctx.f0.f64);
	ea = 28 + ctx.r11.u32;
	PPC_STORE_U32(ea, temp.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x8213d7e0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213D7E0;
loc_8213D804:
	// stw r8,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r8.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
loc_8213D814:
	// stw r29,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r29.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213D824"))) PPC_WEAK_FUNC(sub_8213D824);
PPC_FUNC_IMPL(__imp__sub_8213D824) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213D828"))) PPC_WEAK_FUNC(sub_8213D828);
PPC_FUNC_IMPL(__imp__sub_8213D828) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8213D830;
	__restfpr_27(ctx, base);
	// stfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// fmr f31,f1
	ctx.f31.f64 = ctx.f1.f64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r27,r6
	ctx.r27.u64 = ctx.r6.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// bl 0x8213dff0
	ctx.lr = 0x8213D85C;
	sub_8213DFF0(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8213d88c
	if (!ctx.cr6.eq) goto loc_8213D88C;
	// lwz r31,0(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8213d88c
	if (ctx.cr6.eq) goto loc_8213D88C;
loc_8213D874:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x8213d89c
	if (ctx.cr6.eq) goto loc_8213D89C;
	// lwz r31,32(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x8213d874
	if (!ctx.cr6.eq) goto loc_8213D874;
loc_8213D88C:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
loc_8213D89C:
	// li r30,0
	ctx.r30.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// lis r10,256
	ctx.r10.s64 = 16777216;
	// li r9,64
	ctx.r9.s64 = 64;
	// sth r30,96(r1)
	PPC_STORE_U16(ctx.r1.u32 + 96, ctx.r30.u16);
	// addi r8,r1,100
	ctx.r8.s64 = ctx.r1.s64 + 100;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82105080
	ctx.lr = 0x8213D8D0;
	sub_82105080(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213d88c
	if (ctx.cr6.eq) goto loc_8213D88C;
	// lhz r9,30(r31)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r31.u32 + 30);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lhz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 28);
	// addi r29,r11,31376
	ctx.r29.s64 = ctx.r11.s64 + 31376;
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x8213d954
	if (!ctx.cr6.eq) goto loc_8213D954;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213d934
	if (ctx.cr6.eq) goto loc_8213D934;
	// lfs f0,48(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// addi r9,r9,8
	ctx.r9.s64 = ctx.r9.s64 + 8;
loc_8213D90C:
	// lhz r7,-4(r9)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r9.u32 + -4);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x8213d944
	if (ctx.cr6.eq) goto loc_8213D944;
	// lfs f13,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// beq cr6,0x8213d944
	if (ctx.cr6.eq) goto loc_8213D944;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r9,r9,28
	ctx.r9.s64 = ctx.r9.s64 + 28;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x8213d90c
	if (ctx.cr6.lt) goto loc_8213D90C;
loc_8213D934:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8213da08
	ctx.lr = 0x8213D93C;
	sub_8213DA08(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// b 0x8213d960
	goto loc_8213D960;
loc_8213D944:
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x8213d934
	if (ctx.cr6.eq) goto loc_8213D934;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
	// b 0x8213d960
	goto loc_8213D960;
loc_8213D954:
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
	// mr r30,r10
	ctx.r30.u64 = ctx.r10.u64;
	// sth r11,28(r31)
	PPC_STORE_U16(ctx.r31.u32 + 28, ctx.r11.u16);
loc_8213D960:
	// lwz r9,0(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r8,r1,112
	ctx.r8.s64 = ctx.r1.s64 + 112;
	// lwz r7,4(r27)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// stfs f31,124(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lwz r6,8(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// mulli r11,r30,28
	ctx.r11.s64 = ctx.r30.s64 * 28;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// stw r9,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r9.u32);
	// stw r7,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r7.u32);
	// stw r6,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r6.u32);
	// lwz r3,8(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwz r9,4(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// add r31,r10,r11
	ctx.r31.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwzx r11,r10,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// lwz r4,0(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// addi r10,r31,12
	ctx.r10.s64 = ctx.r31.s64 + 12;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r4,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r4.u32);
	// lwz r5,12(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// stw r3,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r3.u32);
	// stw r9,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r9.u32);
	// stw r5,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r5.u32);
	// beq cr6,0x8213d9c8
	if (ctx.cr6.eq) goto loc_8213D9C8;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213D9C8;
	sub_82080000(ctx, base);
loc_8213D9C8:
	// lhz r11,6(r31)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r31.u32 + 6);
	// lfs f0,36(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stfs f0,8(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 8, temp.u32);
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// lhz r8,96(r1)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r1.u32 + 96);
	// clrlwi r7,r9,16
	ctx.r7.u64 = ctx.r9.u32 & 0xFFFF;
	// rlwinm r6,r7,16,0,15
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 16) & 0xFFFF0000;
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// sth r8,4(r31)
	PPC_STORE_U16(ctx.r31.u32 + 4, ctx.r8.u16);
	// sth r7,6(r31)
	PPC_STORE_U16(ctx.r31.u32 + 6, ctx.r7.u16);
	// or r3,r6,r30
	ctx.r3.u64 = ctx.r6.u64 | ctx.r30.u64;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-56(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213DA04"))) PPC_WEAK_FUNC(sub_8213DA04);
PPC_FUNC_IMPL(__imp__sub_8213DA04) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213DA08"))) PPC_WEAK_FUNC(sub_8213DA08);
PPC_FUNC_IMPL(__imp__sub_8213DA08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x8213DA10;
	__restfpr_24(ctx, base);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// lhz r24,28(r3)
	ctx.r24.u64 = PPC_LOAD_U16(ctx.r3.u32 + 28);
	// lwz r26,24(r3)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// li r25,0
	ctx.r25.s64 = 0;
	// addi r11,r11,-16112
	ctx.r11.s64 = ctx.r11.s64 + -16112;
	// li r28,0
	ctx.r28.s64 = 0;
	// addi r30,r1,112
	ctx.r30.s64 = ctx.r1.s64 + 112;
	// addi r27,r11,224
	ctx.r27.s64 = ctx.r11.s64 + 224;
	// li r29,0
	ctx.r29.s64 = 0;
loc_8213DA38:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r31,0(r27)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// bl 0x8213df78
	ctx.lr = 0x8213DA44;
	sub_8213DF78(ctx, base);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8213daa4
	if (ctx.cr6.eq) goto loc_8213DAA4;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213daa4
	if (ctx.cr6.eq) goto loc_8213DAA4;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// clrlwi r10,r11,24
	ctx.r10.u64 = ctx.r11.u32 & 0xFF;
	// rlwinm r10,r10,0,31,24
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFF81;
	// cmplwi cr6,r10,129
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 129, ctx.xer);
	// bne cr6,0x8213daa4
	if (!ctx.cr6.eq) goto loc_8213DAA4;
	// lwz r11,364(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 364);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwz r9,80(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lwz r7,84(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// addi r6,r3,172
	ctx.r6.s64 = ctx.r3.s64 + 172;
	// lwz r5,88(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// stwx r6,r29,r10
	PPC_STORE_U32(ctx.r29.u32 + ctx.r10.u32, ctx.r6.u32);
	// stwx r11,r29,r8
	PPC_STORE_U32(ctx.r29.u32 + ctx.r8.u32, ctx.r11.u32);
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// stw r9,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r9.u32);
	// stw r7,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r7.u32);
	// stw r5,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r5.u32);
	// addi r30,r30,12
	ctx.r30.s64 = ctx.r30.s64 + 12;
loc_8213DAA4:
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// addi r27,r27,4
	ctx.r27.s64 = ctx.r27.s64 + 4;
	// cmplwi cr6,r28,4
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 4, ctx.xer);
	// blt cr6,0x8213da38
	if (ctx.cr6.lt) goto loc_8213DA38;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r10,-1
	ctx.r10.s64 = -1;
	// addi r11,r11,31376
	ctx.r11.s64 = ctx.r11.s64 + 31376;
	// mr r29,r10
	ctx.r29.u64 = ctx.r10.u64;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// li r30,-1
	ctx.r30.s64 = -1;
	// li r4,0
	ctx.r4.s64 = 0;
	// lfs f8,48(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x8213dce0
	if (ctx.cr6.eq) goto loc_8213DCE0;
	// lfs f7,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f7.f64 = double(temp.f32);
	// addi r6,r26,16
	ctx.r6.s64 = ctx.r26.s64 + 16;
loc_8213DAE4:
	// lhz r5,-10(r6)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r6.u32 + -10);
	// lfs f11,8(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fmr f9,f7
	ctx.f9.f64 = ctx.f7.f64;
	// li r31,0
	ctx.r31.s64 = 0;
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// beq cr6,0x8213dc94
	if (ctx.cr6.eq) goto loc_8213DC94;
	// lfs f0,4(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// addi r7,r1,120
	ctx.r7.s64 = ctx.r1.s64 + 120;
	// lfs f13,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// li r8,0
	ctx.r8.s64 = 0;
	// lfs f12,-4(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + -4);
	ctx.f12.f64 = double(temp.f32);
	// mtctr r25
	ctx.ctr.u64 = ctx.r25.u64;
loc_8213DB14:
	// lfs f10,-4(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -4);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f6,f10,f13
	ctx.f6.f64 = static_cast<float>(ctx.f10.f64 - ctx.f13.f64);
	// lfs f5,-8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + -8);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f4,f5,f12
	ctx.f4.f64 = static_cast<float>(ctx.f5.f64 - ctx.f12.f64);
	// lfs f3,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f2,f3,f0
	ctx.f2.f64 = static_cast<float>(ctx.f3.f64 - ctx.f0.f64);
	// fmuls f1,f6,f6
	ctx.f1.f64 = double(float(ctx.f6.f64 * ctx.f6.f64));
	// fmadds f10,f4,f4,f1
	ctx.f10.f64 = double(std::fma(float(ctx.f4.f64), float(ctx.f4.f64), float(ctx.f1.f64)));
	// fmadds f10,f2,f2,f10
	ctx.f10.f64 = double(std::fma(float(ctx.f2.f64), float(ctx.f2.f64), float(ctx.f10.f64)));
	// fcmpu cr6,f9,f10
	ctx.cr6.compare(ctx.f9.f64, ctx.f10.f64);
	// blt cr6,0x8213db44
	if (ctx.cr6.lt) goto loc_8213DB44;
	// fmr f9,f10
	ctx.f9.f64 = ctx.f10.f64;
loc_8213DB44:
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// addi r28,r1,96
	ctx.r28.s64 = ctx.r1.s64 + 96;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwzx r9,r8,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r10.u32);
	// lwzx r10,r8,r28
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r28.u32);
	// cmpwi cr6,r9,4
	ctx.cr6.compare<int32_t>(ctx.r9.s32, 4, ctx.xer);
	// blt cr6,0x8213dc20
	if (ctx.cr6.lt) goto loc_8213DC20;
loc_8213DB60:
	// lfs f10,4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f10,f13
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f5,f0,f6
	ctx.f2.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f0.f64), float(ctx.f6.f64)));
	// fmadds f1,f12,f4,f2
	ctx.f1.f64 = double(std::fma(float(ctx.f12.f64), float(ctx.f4.f64), float(ctx.f2.f64)));
	// fadds f10,f1,f3
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fcmpu cr6,f10,f11
	ctx.cr6.compare(ctx.f10.f64, ctx.f11.f64);
	// bgt cr6,0x8213dc7c
	if (ctx.cr6.gt) goto loc_8213DC7C;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f10,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f10,f13
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f5,f0,f6
	ctx.f2.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f0.f64), float(ctx.f6.f64)));
	// fmadds f1,f12,f4,f2
	ctx.f1.f64 = double(std::fma(float(ctx.f12.f64), float(ctx.f4.f64), float(ctx.f2.f64)));
	// fadds f10,f1,f3
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fcmpu cr6,f10,f11
	ctx.cr6.compare(ctx.f10.f64, ctx.f11.f64);
	// bgt cr6,0x8213dc68
	if (ctx.cr6.gt) goto loc_8213DC68;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f10,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f10,f13
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f5,f0,f6
	ctx.f2.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f0.f64), float(ctx.f6.f64)));
	// fmadds f1,f12,f4,f2
	ctx.f1.f64 = double(std::fma(float(ctx.f12.f64), float(ctx.f4.f64), float(ctx.f2.f64)));
	// fadds f10,f1,f3
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fcmpu cr6,f10,f11
	ctx.cr6.compare(ctx.f10.f64, ctx.f11.f64);
	// bgt cr6,0x8213dc70
	if (ctx.cr6.gt) goto loc_8213DC70;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// lfs f10,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f10,f13
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f5,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f5,f0,f6
	ctx.f2.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f0.f64), float(ctx.f6.f64)));
	// fmadds f1,f12,f4,f2
	ctx.f1.f64 = double(std::fma(float(ctx.f12.f64), float(ctx.f4.f64), float(ctx.f2.f64)));
	// fadds f10,f1,f3
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fcmpu cr6,f10,f11
	ctx.cr6.compare(ctx.f10.f64, ctx.f11.f64);
	// bgt cr6,0x8213dc78
	if (ctx.cr6.gt) goto loc_8213DC78;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// addi r28,r9,-3
	ctx.r28.s64 = ctx.r9.s64 + -3;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r28
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r28.u32, ctx.xer);
	// blt cr6,0x8213db60
	if (ctx.cr6.lt) goto loc_8213DB60;
loc_8213DC20:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// bge cr6,0x8213dc80
	if (!ctx.cr6.lt) goto loc_8213DC80;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_8213DC2C:
	// lfs f10,4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f0,f10
	ctx.f6.f64 = double(float(ctx.f0.f64 * ctx.f10.f64));
	// lfs f5,-4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f2,f12,f5,f6
	ctx.f2.f64 = double(std::fma(float(ctx.f12.f64), float(ctx.f5.f64), float(ctx.f6.f64)));
	// fmadds f1,f13,f4,f2
	ctx.f1.f64 = double(std::fma(float(ctx.f13.f64), float(ctx.f4.f64), float(ctx.f2.f64)));
	// fadds f10,f1,f3
	ctx.f10.f64 = double(float(ctx.f1.f64 + ctx.f3.f64));
	// fcmpu cr6,f10,f11
	ctx.cr6.compare(ctx.f10.f64, ctx.f11.f64);
	// bgt cr6,0x8213dc7c
	if (ctx.cr6.gt) goto loc_8213DC7C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8213dc2c
	if (ctx.cr6.lt) goto loc_8213DC2C;
	// b 0x8213dc7c
	goto loc_8213DC7C;
loc_8213DC68:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x8213dc7c
	goto loc_8213DC7C;
loc_8213DC70:
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// b 0x8213dc7c
	goto loc_8213DC7C;
loc_8213DC78:
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
loc_8213DC7C:
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
loc_8213DC80:
	// bne cr6,0x8213dc88
	if (!ctx.cr6.eq) goto loc_8213DC88;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
loc_8213DC88:
	// addi r7,r7,12
	ctx.r7.s64 = ctx.r7.s64 + 12;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// bdnz 0x8213db14
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213DB14;
loc_8213DC94:
	// clrlwi r11,r5,16
	ctx.r11.u64 = ctx.r5.u32 & 0xFFFF;
	// clrlwi r10,r30,16
	ctx.r10.u64 = ctx.r30.u32 & 0xFFFF;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x8213dcac
	if (!ctx.cr6.lt) goto loc_8213DCAC;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
loc_8213DCAC:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x8213dcc4
	if (!ctx.cr6.eq) goto loc_8213DCC4;
	// fcmpu cr6,f9,f8
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f9.f64, ctx.f8.f64);
	// ble cr6,0x8213dcc4
	if (!ctx.cr6.gt) goto loc_8213DCC4;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// fmr f8,f9
	ctx.f8.f64 = ctx.f9.f64;
loc_8213DCC4:
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// addi r6,r6,28
	ctx.r6.s64 = ctx.r6.s64 + 28;
	// cmplw cr6,r4,r24
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r24.u32, ctx.xer);
	// blt cr6,0x8213dae4
	if (ctx.cr6.lt) goto loc_8213DAE4;
	// cmpwi cr6,r29,-1
	ctx.cr6.compare<int32_t>(ctx.r29.s32, -1, ctx.xer);
	// beq cr6,0x8213dce0
	if (ctx.cr6.eq) goto loc_8213DCE0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
loc_8213DCE0:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213DCE8"))) PPC_WEAK_FUNC(sub_8213DCE8);
PPC_FUNC_IMPL(__imp__sub_8213DCE8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x8213DCF0;
	__restfpr_25(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213ddb8
	if (ctx.cr6.eq) goto loc_8213DDB8;
	// lis r11,-32180
	ctx.r11.s64 = -2108948480;
	// li r26,0
	ctx.r26.s64 = 0;
	// addi r25,r11,-7224
	ctx.r25.s64 = ctx.r11.s64 + -7224;
loc_8213DD10:
	// lwz r28,0(r27)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// lwz r11,32(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 32);
	// stw r11,0(r27)
	PPC_STORE_U32(ctx.r27.u32 + 0, ctx.r11.u32);
	// lwz r11,24(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213dd74
	if (ctx.cr6.eq) goto loc_8213DD74;
	// lwz r9,-4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// addi r29,r11,-4
	ctx.r29.s64 = ctx.r11.s64 + -4;
	// mulli r10,r9,28
	ctx.r10.s64 = ctx.r9.s64 * 28;
	// addic. r31,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r31.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// add r30,r10,r11
	ctx.r30.u64 = ctx.r10.u64 + ctx.r11.u64;
	// blt 0x8213dd60
	if (ctx.cr0.lt) goto loc_8213DD60;
loc_8213DD40:
	// lwzu r11,-28(r30)
	ea = -28 + ctx.r30.u32;
	ctx.r11.u64 = PPC_LOAD_U32(ea);
	ctx.r30.u32 = ea;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213dd58
	if (ctx.cr6.eq) goto loc_8213DD58;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213DD58;
	sub_82080000(ctx, base);
loc_8213DD58:
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bge 0x8213dd40
	if (!ctx.cr0.lt) goto loc_8213DD40;
loc_8213DD60:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8213dd74
	if (ctx.cr6.eq) goto loc_8213DD74;
	// addi r4,r29,-16
	ctx.r4.s64 = ctx.r29.s64 + -16;
	// lwz r3,-8(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213DD74;
	sub_82080000(ctx, base);
loc_8213DD74:
	// lwz r11,4(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213dd98
	if (ctx.cr6.eq) goto loc_8213DD98;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// sth r26,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, ctx.r26.u16);
	// addi r3,r25,16696
	ctx.r3.s64 = ctx.r25.s64 + 16696;
	// sth r26,82(r1)
	PPC_STORE_U16(ctx.r1.u32 + 82, ctx.r26.u16);
	// bl 0x82173038
	ctx.lr = 0x8213DD98;
	sub_82173038(ctx, base);
loc_8213DD98:
	// lwz r3,4(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// bl 0x82172d60
	ctx.lr = 0x8213DDA0;
	sub_82172D60(ctx, base);
	// addi r4,r28,-16
	ctx.r4.s64 = ctx.r28.s64 + -16;
	// lwz r3,-8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213DDAC;
	sub_82080000(ctx, base);
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8213dd10
	if (!ctx.cr6.eq) goto loc_8213DD10;
loc_8213DDB8:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213DDC0"))) PPC_WEAK_FUNC(sub_8213DDC0);
PPC_FUNC_IMPL(__imp__sub_8213DDC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8213DDC8;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213de28
	if (ctx.cr6.eq) goto loc_8213DE28;
	// lwz r9,-4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + -4);
	// addi r29,r11,-4
	ctx.r29.s64 = ctx.r11.s64 + -4;
	// mulli r10,r9,28
	ctx.r10.s64 = ctx.r9.s64 * 28;
	// addic. r31,r9,-1
	ctx.xer.ca = ctx.r9.u32 > 0;
	ctx.r31.s64 = ctx.r9.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// add r30,r10,r11
	ctx.r30.u64 = ctx.r10.u64 + ctx.r11.u64;
	// blt 0x8213de14
	if (ctx.cr0.lt) goto loc_8213DE14;
loc_8213DDF4:
	// lwzu r11,-28(r30)
	ea = -28 + ctx.r30.u32;
	ctx.r11.u64 = PPC_LOAD_U32(ea);
	ctx.r30.u32 = ea;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213de0c
	if (ctx.cr6.eq) goto loc_8213DE0C;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213DE0C;
	sub_82080000(ctx, base);
loc_8213DE0C:
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// bge 0x8213ddf4
	if (!ctx.cr0.lt) goto loc_8213DDF4;
loc_8213DE14:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8213de28
	if (ctx.cr6.eq) goto loc_8213DE28;
	// addi r4,r29,-16
	ctx.r4.s64 = ctx.r29.s64 + -16;
	// lwz r3,-8(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213DE28;
	sub_82080000(ctx, base);
loc_8213DE28:
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,4(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// bl 0x82178200
	ctx.lr = 0x8213DE34;
	sub_82178200(ctx, base);
	// lwz r3,4(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// bl 0x82172d60
	ctx.lr = 0x8213DE3C;
	sub_82172D60(ctx, base);
	// addi r4,r28,-16
	ctx.r4.s64 = ctx.r28.s64 + -16;
	// lwz r3,-8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213DE48;
	sub_82080000(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213DE54"))) PPC_WEAK_FUNC(sub_8213DE54);
PPC_FUNC_IMPL(__imp__sub_8213DE54) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213DE58"))) PPC_WEAK_FUNC(sub_8213DE58);
PPC_FUNC_IMPL(__imp__sub_8213DE58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x8213DE60;
	__restfpr_26(ctx, base);
	// stfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, ctx.f30.u64);
	// stfd f31,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,8(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r26,4(r3)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// addi r11,r30,1
	ctx.r11.s64 = ctx.r30.s64 + 1;
	// fmr f31,f1
	ctx.f31.f64 = ctx.f1.f64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// fmr f30,f2
	ctx.f30.f64 = ctx.f2.f64;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r11.u32);
	// mr r27,r8
	ctx.r27.u64 = ctx.r8.u64;
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,36
	ctx.r3.s64 = 36;
	// bne cr6,0x8213df28
	if (!ctx.cr6.eq) goto loc_8213DF28;
	// lwz r26,0(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82082030
	ctx.lr = 0x8213DEB4;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213df00
	if (ctx.cr6.eq) goto loc_8213DF00;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// fmr f2,f30
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = ctx.f30.f64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x8213d6f8
	ctx.lr = 0x8213DED8;
	sub_8213D6F8(ctx, base);
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// stw r26,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r26.u32);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_8213DF00:
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r11.u32);
	// stw r26,32(r11)
	PPC_STORE_U32(ctx.r11.u32 + 32, ctx.r26.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_8213DF28:
	// bl 0x82082030
	ctx.lr = 0x8213DF2C;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213df58
	if (ctx.cr6.eq) goto loc_8213DF58;
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// fmr f2,f30
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = ctx.f30.f64;
	// mr r6,r28
	ctx.r6.u64 = ctx.r28.u64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x8213d6f8
	ctx.lr = 0x8213DF50;
	sub_8213D6F8(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// b 0x8213df5c
	goto loc_8213DF5C;
loc_8213DF58:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8213DF5C:
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stw r11,32(r26)
	PPC_STORE_U32(ctx.r26.u32 + 32, ctx.r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213DF78"))) PPC_WEAK_FUNC(sub_8213DF78);
PPC_FUNC_IMPL(__imp__sub_8213DF78) {
	PPC_FUNC_PROLOGUE();
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-16112
	ctx.r11.s64 = ctx.r11.s64 + -16112;
	// addi r9,r11,224
	ctx.r9.s64 = ctx.r11.s64 + 224;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8213dfe4
	if (ctx.cr6.eq) goto loc_8213DFE4;
	// lwz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// clrlwi r9,r10,24
	ctx.r9.u64 = ctx.r10.u32 & 0xFF;
	// rlwinm r9,r9,0,31,24
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFFFF81;
	// cmplwi cr6,r9,129
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 129, ctx.xer);
	// bne cr6,0x8213dfe4
	if (!ctx.cr6.eq) goto loc_8213DFE4;
	// li r9,156
	ctx.r9.s64 = 156;
	// addi r10,r11,156
	ctx.r10.s64 = ctx.r11.s64 + 156;
loc_8213DFB0:
	// lwz r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213dfc8
	if (ctx.cr6.eq) goto loc_8213DFC8;
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplw cr6,r7,r8
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, ctx.xer);
	// beq cr6,0x8213dfdc
	if (ctx.cr6.eq) goto loc_8213DFDC;
loc_8213DFC8:
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r9,220
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 220, ctx.xer);
	// blt cr6,0x8213dfb0
	if (ctx.cr6.lt) goto loc_8213DFB0;
	// li r11,0
	ctx.r11.s64 = 0;
loc_8213DFDC:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// blr 
	return;
loc_8213DFE4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213DFEC"))) PPC_WEAK_FUNC(sub_8213DFEC);
PPC_FUNC_IMPL(__imp__sub_8213DFEC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213DFF0"))) PPC_WEAK_FUNC(sub_8213DFF0);
PPC_FUNC_IMPL(__imp__sub_8213DFF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f0,f13
	ctx.f12.f64 = static_cast<float>(ctx.f0.f64 - ctx.f13.f64);
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// lfs f0,52(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 52);
	ctx.f0.f64 = double(temp.f32);
	// fabs f11,f12
	ctx.f11.u64 = ctx.f12.u64 & 0x7FFFFFFFFFFFFFFF;
	// fcmpu cr6,f11,f0
	ctx.cr6.compare(ctx.f11.f64, ctx.f0.f64);
	// ble cr6,0x8213e01c
	if (!ctx.cr6.gt) goto loc_8213E01C;
loc_8213E014:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_8213E01C:
	// lfs f13,4(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f11,f13,f12
	ctx.f11.f64 = static_cast<float>(ctx.f13.f64 - ctx.f12.f64);
	// fabs f10,f11
	ctx.f10.u64 = ctx.f11.u64 & 0x7FFFFFFFFFFFFFFF;
	// fcmpu cr6,f10,f0
	ctx.cr6.compare(ctx.f10.f64, ctx.f0.f64);
	// bgt cr6,0x8213e014
	if (ctx.cr6.gt) goto loc_8213E014;
	// lfs f13,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f12,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f11,f13,f12
	ctx.f11.f64 = static_cast<float>(ctx.f13.f64 - ctx.f12.f64);
	// fabs f10,f11
	ctx.f10.u64 = ctx.f11.u64 & 0x7FFFFFFFFFFFFFFF;
	// fcmpu cr6,f10,f0
	ctx.cr6.compare(ctx.f10.f64, ctx.f0.f64);
	// bgtlr cr6
	if (ctx.cr6.gt) return;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213E058"))) PPC_WEAK_FUNC(sub_8213E058);
PPC_FUNC_IMPL(__imp__sub_8213E058) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x8213e0b8
	ctx.lr = 0x8213E078;
	sub_8213E0B8(ctx, base);
	// clrlwi r11,r30,31
	ctx.r11.u64 = ctx.r30.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213e098
	if (ctx.cr6.eq) goto loc_8213E098;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8213e098
	if (ctx.cr6.eq) goto loc_8213E098;
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8213E098;
	sub_82080000(ctx, base);
loc_8213E098:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213E0B4"))) PPC_WEAK_FUNC(sub_8213E0B4);
PPC_FUNC_IMPL(__imp__sub_8213E0B4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213E0B8"))) PPC_WEAK_FUNC(sub_8213E0B8);
PPC_FUNC_IMPL(__imp__sub_8213E0B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,40(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r10,r11,-29332
	ctx.r10.s64 = ctx.r11.s64 + -29332;
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// beq cr6,0x8213e0f4
	if (ctx.cr6.eq) goto loc_8213E0F4;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82178200
	ctx.lr = 0x8213E0EC;
	sub_82178200(ctx, base);
	// lwz r3,40(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// bl 0x82172d60
	ctx.lr = 0x8213E0F4;
	sub_82172D60(ctx, base);
loc_8213E0F4:
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r11,-31304
	ctx.r9.s64 = ctx.r11.s64 + -31304;
	// stw r10,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r10.u32);
	// stw r9,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r9.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213E11C"))) PPC_WEAK_FUNC(sub_8213E11C);
PPC_FUNC_IMPL(__imp__sub_8213E11C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8213E120"))) PPC_WEAK_FUNC(sub_8213E120);
PPC_FUNC_IMPL(__imp__sub_8213E120) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// clrlwi r10,r6,24
	ctx.r10.u64 = ctx.r6.u32 & 0xFF;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// mr r30,r7
	ctx.r30.u64 = ctx.r7.u64;
	// beq cr6,0x8213e258
	if (ctx.cr6.eq) goto loc_8213E258;
	// cmplwi cr6,r10,68
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 68, ctx.xer);
	// bge cr6,0x8213e168
	if (!ctx.cr6.lt) goto loc_8213E168;
loc_8213E15C:
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// bl 0x821613d0
	ctx.lr = 0x8213E164;
	sub_821613D0(ctx, base);
	// b 0x8213e2f0
	goto loc_8213E2F0;
loc_8213E168:
	// li r5,68
	ctx.r5.s64 = 68;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x8213E178;
	sub_8208CFB0(ctx, base);
	// lis r8,-32171
	ctx.r8.s64 = -2108358656;
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// lwz r9,5600(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 5600);
	// lwz r6,92(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r4,100(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r10,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r10.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(ctx.r31.u32 + 44, ctx.r11.u32);
	// stw r5,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r5.u32);
	// stw r9,5600(r8)
	PPC_STORE_U32(ctx.r8.u32 + 5600, ctx.r9.u32);
	// stw r7,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r7.u32);
	// stw r6,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r6.u32);
	// stw r4,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r4.u32);
	// ble cr6,0x8213e1c4
	if (!ctx.cr6.gt) goto loc_8213E1C4;
	// stw r11,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r11.u32);
loc_8213E1C4:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r9,108(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfs f0,116(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f0.f64 = double(temp.f32);
	// addi r11,r11,31376
	ctx.r11.s64 = ctx.r11.s64 + 31376;
	// lfs f12,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,64(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 64, temp.u32);
	// stfs f0,68(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 68, temp.u32);
	// stw r10,60(r31)
	PPC_STORE_U32(ctx.r31.u32 + 60, ctx.r10.u32);
	// stw r9,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r9.u32);
	// lfs f13,48(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bne cr6,0x8213e200
	if (!ctx.cr6.eq) goto loc_8213E200;
	// lfs f0,92(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,68(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 68, temp.u32);
loc_8213E200:
	// addi r11,r1,120
	ctx.r11.s64 = ctx.r1.s64 + 120;
	// lfs f0,68(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	ctx.f0.f64 = double(temp.f32);
	// lis r10,-32180
	ctx.r10.s64 = -2108948480;
	// lfs f13,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f12,f0,f12
	ctx.f12.f64 = static_cast<float>(ctx.f0.f64 - ctx.f12.f64);
	// lfs f10,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f10.f64 = double(temp.f32);
	// addi r3,r10,-7224
	ctx.r3.s64 = ctx.r10.s64 + -7224;
	// stfs f12,72(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 72, temp.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stfs f13,36(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 36, temp.u32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stfs f11,84(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 84, temp.u32);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// stfs f10,88(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 88, temp.u32);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// addi r11,r31,92
	ctx.r11.s64 = ctx.r31.s64 + 92;
	// stw r9,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r9.u32);
	// stw r8,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r8.u32);
	// stw r7,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r7.u32);
	// stw r6,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r6.u32);
	// b 0x8213e2c8
	goto loc_8213E2C8;
loc_8213E258:
	// cmplwi cr6,r10,40
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 40, ctx.xer);
	// blt cr6,0x8213e15c
	if (ctx.cr6.lt) goto loc_8213E15C;
	// li r5,40
	ctx.r5.s64 = 40;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x8213E270;
	sub_8208CFB0(ctx, base);
	// lis r11,-32180
	ctx.r11.s64 = -2108948480;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lfs f0,108(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f0.f64 = double(temp.f32);
	// addi r3,r11,-7224
	ctx.r3.s64 = ctx.r11.s64 + -7224;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lfs f13,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f13.f64 = double(temp.f32);
	// lwz r8,92(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lfs f12,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f12.f64 = double(temp.f32);
	// lwz r7,96(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stfs f0,36(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 36, temp.u32);
	// lwz r6,100(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stfs f13,84(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 84, temp.u32);
	// stfs f12,88(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 88, temp.u32);
	// stw r5,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r5.u32);
	// stw r10,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r10.u32);
	// stw r9,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r9.u32);
	// stw r8,44(r31)
	PPC_STORE_U32(ctx.r31.u32 + 44, ctx.r8.u32);
	// stw r7,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r7.u32);
	// stw r6,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r6.u32);
	// lwz r11,104(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_8213E2C8:
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x82176780
	ctx.lr = 0x8213E2D0;
	sub_82176780(ctx, base);
	// stw r3,40(r31)
	PPC_STORE_U32(ctx.r31.u32 + 40, ctx.r3.u32);
	// rotlwi r3,r3,0
	ctx.r3.u64 = rotl32(ctx.r3.u32, 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213e2ec
	if (ctx.cr6.eq) goto loc_8213E2EC;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82177f68
	ctx.lr = 0x8213E2EC;
	sub_82177F68(ctx, base);
loc_8213E2EC:
	// stw r30,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r30.u32);
loc_8213E2F0:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213E308"))) PPC_WEAK_FUNC(sub_8213E308);
PPC_FUNC_IMPL(__imp__sub_8213E308) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8213E310;
	__restfpr_28(ctx, base);
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r29,r3,524
	ctx.r29.s64 = ctx.r3.s64 + 524;
	// fmr f31,f1
	ctx.f31.f64 = ctx.f1.f64;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x823052d8
	ctx.lr = 0x8213E330;
	sub_823052D8(ctx, base);
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// li r31,0
	ctx.r31.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x8213e6c4
	if (!ctx.cr6.gt) goto loc_8213E6C4;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lis r11,-32179
	ctx.r11.s64 = -2108882944;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// addi r7,r30,264
	ctx.r7.s64 = ctx.r30.s64 + 264;
	// addi r3,r11,-29208
	ctx.r3.s64 = ctx.r11.s64 + -29208;
	// lfs f10,876(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 876);
	ctx.f10.f64 = double(temp.f32);
	// lfs f0,120(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 120);
	ctx.f0.f64 = double(temp.f32);
	// lfs f9,108(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 108);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,60(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	ctx.f13.f64 = double(temp.f32);
loc_8213E364:
	// lwz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213e6b0
	if (ctx.cr6.eq) goto loc_8213E6B0;
	// lwz r5,-192(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + -192);
	// li r6,0
	ctx.r6.s64 = 0;
	// cmpwi cr6,r5,4
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 4, ctx.xer);
	// blt cr6,0x8213e604
	if (ctx.cr6.lt) goto loc_8213E604;
	// addi r4,r5,-3
	ctx.r4.s64 = ctx.r5.s64 + -3;
	// li r8,0
	ctx.r8.s64 = 0;
loc_8213E388:
	// lwz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// add r10,r11,r8
	ctx.r10.u64 = ctx.r11.u64 + ctx.r8.u64;
	// lwz r11,108(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// cmplwi cr6,r11,4096
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4096, ctx.xer);
	// bge cr6,0x8213e3c0
	if (!ctx.cr6.lt) goto loc_8213E3C0;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r3,8
	ctx.r9.s64 = ctx.r3.s64 + 8;
	// lwzx r11,r11,r9
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213e3c0
	if (ctx.cr6.eq) goto loc_8213E3C0;
	// lwz r11,448(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 448);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bne cr6,0x8213e3c4
	if (!ctx.cr6.eq) goto loc_8213E3C4;
loc_8213E3C0:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8213E3C4:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8213e420
	if (!ctx.cr6.eq) goto loc_8213E420;
	// lfs f12,84(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f8,76(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f31
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmadds f12,f7,f10,f8
	ctx.f12.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f10.f64), float(ctx.f8.f64)));
	// stfs f12,76(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 76, temp.u32);
	// fcmpu cr6,f12,f0
	ctx.cr6.compare(ctx.f12.f64, ctx.f0.f64);
	// ble cr6,0x8213e3f8
	if (!ctx.cr6.gt) goto loc_8213E3F8;
	// fsubs f12,f12,f0
	ctx.f12.f64 = static_cast<float>(ctx.f12.f64 - ctx.f0.f64);
	// stfs f12,76(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 76, temp.u32);
loc_8213E3F8:
	// lfs f12,84(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f8,80(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f31
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmadds f12,f7,f9,f8
	ctx.f12.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f9.f64), float(ctx.f8.f64)));
	// stfs f12,80(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 80, temp.u32);
	// fcmpu cr6,f12,f0
	ctx.cr6.compare(ctx.f12.f64, ctx.f0.f64);
	// ble cr6,0x8213e420
	if (!ctx.cr6.gt) goto loc_8213E420;
	// fsubs f12,f12,f0
	ctx.f12.f64 = static_cast<float>(ctx.f12.f64 - ctx.f0.f64);
	// stfs f12,80(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 80, temp.u32);
loc_8213E420:
	// lwz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// addi r10,r11,232
	ctx.r10.s64 = ctx.r11.s64 + 232;
	// lwz r11,340(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 340);
	// cmplwi cr6,r11,4096
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4096, ctx.xer);
	// bge cr6,0x8213e45c
	if (!ctx.cr6.lt) goto loc_8213E45C;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r3,8
	ctx.r9.s64 = ctx.r3.s64 + 8;
	// lwzx r11,r11,r9
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213e45c
	if (ctx.cr6.eq) goto loc_8213E45C;
	// lwz r11,448(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 448);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bne cr6,0x8213e460
	if (!ctx.cr6.eq) goto loc_8213E460;
loc_8213E45C:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8213E460:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8213e4bc
	if (!ctx.cr6.eq) goto loc_8213E4BC;
	// lfs f12,84(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f8,76(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f31
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmadds f12,f7,f10,f8
	ctx.f12.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f10.f64), float(ctx.f8.f64)));
	// stfs f12,76(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 76, temp.u32);
	// fcmpu cr6,f12,f0
	ctx.cr6.compare(ctx.f12.f64, ctx.f0.f64);
	// ble cr6,0x8213e494
	if (!ctx.cr6.gt) goto loc_8213E494;
	// fsubs f12,f12,f0
	ctx.f12.f64 = static_cast<float>(ctx.f12.f64 - ctx.f0.f64);
	// stfs f12,76(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 76, temp.u32);
loc_8213E494:
	// lfs f12,84(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f8,80(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f31
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmadds f12,f7,f9,f8
	ctx.f12.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f9.f64), float(ctx.f8.f64)));
	// stfs f12,80(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 80, temp.u32);
	// fcmpu cr6,f12,f0
	ctx.cr6.compare(ctx.f12.f64, ctx.f0.f64);
	// ble cr6,0x8213e4bc
	if (!ctx.cr6.gt) goto loc_8213E4BC;
	// fsubs f12,f12,f0
	ctx.f12.f64 = static_cast<float>(ctx.f12.f64 - ctx.f0.f64);
	// stfs f12,80(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 80, temp.u32);
loc_8213E4BC:
	// lwz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// addi r9,r8,696
	ctx.r9.s64 = ctx.r8.s64 + 696;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// addi r10,r11,-232
	ctx.r10.s64 = ctx.r11.s64 + -232;
	// lwz r11,-124(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + -124);
	// cmplwi cr6,r11,4096
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4096, ctx.xer);
	// bge cr6,0x8213e4fc
	if (!ctx.cr6.lt) goto loc_8213E4FC;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r28,r3,8
	ctx.r28.s64 = ctx.r3.s64 + 8;
	// lwzx r11,r11,r28
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r28.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213e4fc
	if (ctx.cr6.eq) goto loc_8213E4FC;
	// lwz r11,448(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 448);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bne cr6,0x8213e500
	if (!ctx.cr6.eq) goto loc_8213E500;
loc_8213E4FC:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8213E500:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8213e55c
	if (!ctx.cr6.eq) goto loc_8213E55C;
	// lfs f12,84(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f8,76(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f31
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmadds f12,f7,f10,f8
	ctx.f12.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f10.f64), float(ctx.f8.f64)));
	// stfs f12,76(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 76, temp.u32);
	// fcmpu cr6,f12,f0
	ctx.cr6.compare(ctx.f12.f64, ctx.f0.f64);
	// ble cr6,0x8213e534
	if (!ctx.cr6.gt) goto loc_8213E534;
	// fsubs f12,f12,f0
	ctx.f12.f64 = static_cast<float>(ctx.f12.f64 - ctx.f0.f64);
	// stfs f12,76(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 76, temp.u32);
loc_8213E534:
	// lfs f12,84(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f8,80(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f31
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmadds f12,f7,f9,f8
	ctx.f12.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f9.f64), float(ctx.f8.f64)));
	// stfs f12,80(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 80, temp.u32);
	// fcmpu cr6,f12,f0
	ctx.cr6.compare(ctx.f12.f64, ctx.f0.f64);
	// ble cr6,0x8213e55c
	if (!ctx.cr6.gt) goto loc_8213E55C;
	// fsubs f12,f12,f0
	ctx.f12.f64 = static_cast<float>(ctx.f12.f64 - ctx.f0.f64);
	// stfs f12,80(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 80, temp.u32);
loc_8213E55C:
	// lwz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// add r10,r11,r9
	ctx.r10.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lwz r11,108(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// cmplwi cr6,r11,4096
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4096, ctx.xer);
	// bge cr6,0x8213e594
	if (!ctx.cr6.lt) goto loc_8213E594;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r3,8
	ctx.r9.s64 = ctx.r3.s64 + 8;
	// lwzx r11,r11,r9
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213e594
	if (ctx.cr6.eq) goto loc_8213E594;
	// lwz r11,448(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 448);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bne cr6,0x8213e598
	if (!ctx.cr6.eq) goto loc_8213E598;
loc_8213E594:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8213E598:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8213e5f4
	if (!ctx.cr6.eq) goto loc_8213E5F4;
	// lfs f12,84(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f8,76(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f31
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmadds f12,f7,f10,f8
	ctx.f12.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f10.f64), float(ctx.f8.f64)));
	// stfs f12,76(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 76, temp.u32);
	// fcmpu cr6,f12,f0
	ctx.cr6.compare(ctx.f12.f64, ctx.f0.f64);
	// ble cr6,0x8213e5cc
	if (!ctx.cr6.gt) goto loc_8213E5CC;
	// fsubs f12,f12,f0
	ctx.f12.f64 = static_cast<float>(ctx.f12.f64 - ctx.f0.f64);
	// stfs f12,76(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 76, temp.u32);
loc_8213E5CC:
	// lfs f12,84(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f8,80(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f31
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmadds f12,f7,f9,f8
	ctx.f12.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f9.f64), float(ctx.f8.f64)));
	// stfs f12,80(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 80, temp.u32);
	// fcmpu cr6,f12,f0
	ctx.cr6.compare(ctx.f12.f64, ctx.f0.f64);
	// ble cr6,0x8213e5f4
	if (!ctx.cr6.gt) goto loc_8213E5F4;
	// fsubs f12,f12,f0
	ctx.f12.f64 = static_cast<float>(ctx.f12.f64 - ctx.f0.f64);
	// stfs f12,80(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 80, temp.u32);
loc_8213E5F4:
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// addi r8,r8,928
	ctx.r8.s64 = ctx.r8.s64 + 928;
	// cmplw cr6,r6,r4
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r4.u32, ctx.xer);
	// blt cr6,0x8213e388
	if (ctx.cr6.lt) goto loc_8213E388;
loc_8213E604:
	// cmplw cr6,r6,r5
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r5.u32, ctx.xer);
	// bge cr6,0x8213e6b0
	if (!ctx.cr6.lt) goto loc_8213E6B0;
	// subf r11,r6,r5
	ctx.r11.s64 = ctx.r5.s64 - ctx.r6.s64;
	// mulli r9,r6,232
	ctx.r9.s64 = ctx.r6.s64 * 232;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
loc_8213E618:
	// lwz r11,0(r7)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// add r10,r11,r9
	ctx.r10.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lwz r11,108(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// cmplwi cr6,r11,4096
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4096, ctx.xer);
	// bge cr6,0x8213e650
	if (!ctx.cr6.lt) goto loc_8213E650;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r3,8
	ctx.r8.s64 = ctx.r3.s64 + 8;
	// lwzx r11,r11,r8
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8213e650
	if (ctx.cr6.eq) goto loc_8213E650;
	// lwz r11,448(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 448);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bne cr6,0x8213e654
	if (!ctx.cr6.eq) goto loc_8213E654;
loc_8213E650:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8213E654:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8213e6a8
	if (!ctx.cr6.eq) goto loc_8213E6A8;
	// lfs f12,84(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f8,76(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f11,f31
	ctx.f7.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// fmadds f12,f7,f10,f8
	ctx.f12.f64 = double(std::fma(float(ctx.f7.f64), float(ctx.f10.f64), float(ctx.f8.f64)));
	// stfs f12,76(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 76, temp.u32);
	// fcmpu cr6,f12,f0
	ctx.cr6.compare(ctx.f12.f64, ctx.f0.f64);
	// ble cr6,0x8213e688
	if (!ctx.cr6.gt) goto loc_8213E688;
	// fsubs f12,f12,f0
	ctx.f12.f64 = static_cast<float>(ctx.f12.f64 - ctx.f0.f64);
	// stfs f12,76(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 76, temp.u32);
loc_8213E688:
	// fmuls f12,f11,f31
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f31.f64));
	// lfs f11,80(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f12,f12,f9,f11
	ctx.f12.f64 = double(std::fma(float(ctx.f12.f64), float(ctx.f9.f64), float(ctx.f11.f64)));
	// stfs f12,80(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 80, temp.u32);
	// fcmpu cr6,f12,f0
	ctx.cr6.compare(ctx.f12.f64, ctx.f0.f64);
	// ble cr6,0x8213e6a8
	if (!ctx.cr6.gt) goto loc_8213E6A8;
	// fsubs f12,f12,f0
	ctx.f12.f64 = static_cast<float>(ctx.f12.f64 - ctx.f0.f64);
	// stfs f12,80(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 80, temp.u32);
loc_8213E6A8:
	// addi r9,r9,232
	ctx.r9.s64 = ctx.r9.s64 + 232;
	// bdnz 0x8213e618
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213E618;
loc_8213E6B0:
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r7,r7,12
	ctx.r7.s64 = ctx.r7.s64 + 12;
	// cmplw cr6,r31,r11
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x8213e364
	if (ctx.cr6.lt) goto loc_8213E364;
loc_8213E6C4:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x823051a8
	ctx.lr = 0x8213E6CC;
	sub_823051A8(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213E6D8"))) PPC_WEAK_FUNC(sub_8213E6D8);
PPC_FUNC_IMPL(__imp__sub_8213E6D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r31.u64);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r31,0
	ctx.r31.s64 = 0;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213ea18
	if (ctx.cr6.eq) goto loc_8213EA18;
	// addi r11,r3,8
	ctx.r11.s64 = ctx.r3.s64 + 8;
loc_8213E6F0:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplw cr6,r9,r4
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x8213e714
	if (ctx.cr6.eq) goto loc_8213E714;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmplw cr6,r31,r10
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x8213e6f0
	if (ctx.cr6.lt) goto loc_8213E6F0;
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
loc_8213E714:
	// addi r11,r31,6
	ctx.r11.s64 = ctx.r31.s64 + 6;
	// lis r9,-32250
	ctx.r9.s64 = -2113536000;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r8,r9,31376
	ctx.r8.s64 = ctx.r9.s64 + 31376;
	// add r7,r11,r10
	ctx.r7.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r4,r7,2,0,29
	ctx.r4.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f0,92(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// lwzx r4,r4,r3
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r3.u32);
	// cmpwi cr6,r4,4
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 4, ctx.xer);
	// blt cr6,0x8213e854
	if (ctx.cr6.lt) goto loc_8213E854;
	// addi r11,r31,22
	ctx.r11.s64 = ctx.r31.s64 + 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_8213E754:
	// lwzx r11,r8,r3
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	// add r11,r7,r11
	ctx.r11.u64 = ctx.r7.u64 + ctx.r11.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213e8ac
	if (ctx.cr6.eq) goto loc_8213E8AC;
	// stw r5,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r5.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213e78c
	if (ctx.cr6.eq) goto loc_8213E78C;
	// stw r5,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r5.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,16(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 16, temp.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,12(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 12, temp.u32);
loc_8213E78C:
	// lwzx r11,r8,r3
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	// add r11,r7,r11
	ctx.r11.u64 = ctx.r7.u64 + ctx.r11.u64;
	// addi r11,r11,232
	ctx.r11.s64 = ctx.r11.s64 + 232;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213e8ac
	if (ctx.cr6.eq) goto loc_8213E8AC;
	// stw r5,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r5.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213e7c8
	if (ctx.cr6.eq) goto loc_8213E7C8;
	// stw r5,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r5.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,16(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 16, temp.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,12(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 12, temp.u32);
loc_8213E7C8:
	// lwzx r11,r8,r3
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	// addi r10,r7,696
	ctx.r10.s64 = ctx.r7.s64 + 696;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r11,r11,-232
	ctx.r11.s64 = ctx.r11.s64 + -232;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8213e8ac
	if (ctx.cr6.eq) goto loc_8213E8AC;
	// stw r5,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r5.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8213e808
	if (ctx.cr6.eq) goto loc_8213E808;
	// stw r5,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r5.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,16(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 16, temp.u32);
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,12(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 12, temp.u32);
loc_8213E808:
	// lwzx r11,r8,r3
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213e8ac
	if (ctx.cr6.eq) goto loc_8213E8AC;
	// stw r5,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r5.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213e840
	if (ctx.cr6.eq) goto loc_8213E840;
	// stw r5,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r5.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,16(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 16, temp.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,12(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 12, temp.u32);
loc_8213E840:
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// addi r11,r4,-3
	ctx.r11.s64 = ctx.r4.s64 + -3;
	// addi r7,r7,928
	ctx.r7.s64 = ctx.r7.s64 + 928;
	// cmplw cr6,r6,r11
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x8213e754
	if (ctx.cr6.lt) goto loc_8213E754;
loc_8213E854:
	// cmplw cr6,r6,r4
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r4.u32, ctx.xer);
	// bge cr6,0x8213e8ac
	if (!ctx.cr6.lt) goto loc_8213E8AC;
	// addi r11,r31,22
	ctx.r11.s64 = ctx.r31.s64 + 22;
	// mulli r10,r6,232
	ctx.r10.s64 = ctx.r6.s64 * 232;
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r8,r11,2,0,29
	ctx.r8.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
loc_8213E870:
	// lwzx r11,r8,r3
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8213e8ac
	if (ctx.cr6.eq) goto loc_8213E8AC;
	// stw r5,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r5.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// stw r5,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r5.u32);
	// addi r10,r10,232
	ctx.r10.s64 = ctx.r10.s64 + 232;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,16(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 16, temp.u32);
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,12(r7)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 12, temp.u32);
	// cmplw cr6,r6,r4
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r4.u32, ctx.xer);
	// blt cr6,0x8213e870
	if (ctx.cr6.lt) goto loc_8213E870;
loc_8213E8AC:
	// rlwinm r11,r31,1,0,30
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// li r6,0
	ctx.r6.s64 = 0;
	// add r11,r31,r11
	ctx.r11.u64 = ctx.r31.u64 + ctx.r11.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r11,r3
	ctx.r8.u64 = ctx.r11.u64 + ctx.r3.u64;
	// lwz r4,80(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 80);
	// cmpwi cr6,r4,4
	ctx.cr6.compare<int32_t>(ctx.r4.s32, 4, ctx.xer);
	// blt cr6,0x8213e9d0
	if (ctx.cr6.lt) goto loc_8213E9D0;
	// li r7,0
	ctx.r7.s64 = 0;
loc_8213E8D0:
	// lwz r11,272(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 272);
	// add r11,r7,r11
	ctx.r11.u64 = ctx.r7.u64 + ctx.r11.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213ea18
	if (ctx.cr6.eq) goto loc_8213EA18;
	// stw r5,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r5.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213e908
	if (ctx.cr6.eq) goto loc_8213E908;
	// stw r5,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r5.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,16(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 16, temp.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,12(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 12, temp.u32);
loc_8213E908:
	// lwz r11,272(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 272);
	// add r11,r7,r11
	ctx.r11.u64 = ctx.r7.u64 + ctx.r11.u64;
	// addi r11,r11,116
	ctx.r11.s64 = ctx.r11.s64 + 116;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213ea18
	if (ctx.cr6.eq) goto loc_8213EA18;
	// stw r5,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r5.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213e944
	if (ctx.cr6.eq) goto loc_8213E944;
	// stw r5,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r5.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,16(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 16, temp.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,12(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 12, temp.u32);
loc_8213E944:
	// lwz r11,272(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 272);
	// addi r10,r7,348
	ctx.r10.s64 = ctx.r7.s64 + 348;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r11,r11,-116
	ctx.r11.s64 = ctx.r11.s64 + -116;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8213ea18
	if (ctx.cr6.eq) goto loc_8213EA18;
	// stw r5,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r5.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8213e984
	if (ctx.cr6.eq) goto loc_8213E984;
	// stw r5,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r5.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,16(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 16, temp.u32);
	// lwz r3,12(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,12(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
loc_8213E984:
	// lwz r11,272(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 272);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213ea18
	if (ctx.cr6.eq) goto loc_8213EA18;
	// stw r5,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r5.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8213e9bc
	if (ctx.cr6.eq) goto loc_8213E9BC;
	// stw r5,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r5.u32);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,16(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 16, temp.u32);
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,12(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 12, temp.u32);
loc_8213E9BC:
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// addi r11,r4,-3
	ctx.r11.s64 = ctx.r4.s64 + -3;
	// addi r7,r7,464
	ctx.r7.s64 = ctx.r7.s64 + 464;
	// cmplw cr6,r6,r11
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x8213e8d0
	if (ctx.cr6.lt) goto loc_8213E8D0;
loc_8213E9D0:
	// cmplw cr6,r6,r4
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r4.u32, ctx.xer);
	// bge cr6,0x8213ea18
	if (!ctx.cr6.lt) goto loc_8213EA18;
	// mulli r10,r6,116
	ctx.r10.s64 = ctx.r6.s64 * 116;
loc_8213E9DC:
	// lwz r11,272(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 272);
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8213ea18
	if (ctx.cr6.eq) goto loc_8213EA18;
	// stw r5,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r5.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// stw r5,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r5.u32);
	// addi r10,r10,116
	ctx.r10.s64 = ctx.r10.s64 + 116;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stfs f0,16(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 16, temp.u32);
	// lwz r7,12(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r6,r4
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, ctx.r4.u32, ctx.xer);
	// stfs f0,12(r7)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 12, temp.u32);
	// blt cr6,0x8213e9dc
	if (ctx.cr6.lt) goto loc_8213E9DC;
loc_8213EA18:
	// ld r31,-8(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8213EA20"))) PPC_WEAK_FUNC(sub_8213EA20);
PPC_FUNC_IMPL(__imp__sub_8213EA20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x8213EA28;
	__restfpr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x8233fa38
	ctx.lr = 0x8213EA30;
	sub_8233FA38(ctx, base);
	// stwu r1,-416(r1)
	ea = -416 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r31,0
	ctx.r31.s64 = 0;
	// li r25,1
	ctx.r25.s64 = 1;
	// stw r31,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r31.u32);
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// sth r31,196(r1)
	PPC_STORE_U16(ctx.r1.u32 + 196, ctx.r31.u16);
	// mr r23,r4
	ctx.r23.u64 = ctx.r4.u64;
	// stw r31,200(r1)
	PPC_STORE_U32(ctx.r1.u32 + 200, ctx.r31.u32);
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// sth r31,198(r1)
	PPC_STORE_U16(ctx.r1.u32 + 198, ctx.r31.u16);
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// stb r25,204(r1)
	PPC_STORE_U8(ctx.r1.u32 + 204, ctx.r25.u8);
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r14,r6
	ctx.r14.u64 = ctx.r6.u64;
	// bl 0x82161240
	ctx.lr = 0x8213EA6C;
	sub_82161240(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208d070
	ctx.lr = 0x8213EA74;
	sub_8208D070(ctx, base);
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r31.u32);
	// sth r31,84(r1)
	PPC_STORE_U16(ctx.r1.u32 + 84, ctx.r31.u16);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r31.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// sth r31,86(r1)
	PPC_STORE_U16(ctx.r1.u32 + 86, ctx.r31.u16);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// stb r25,92(r1)
	PPC_STORE_U8(ctx.r1.u32 + 92, ctx.r25.u8);
	// bl 0x82161240
	ctx.lr = 0x8213EA98;
	sub_82161240(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208d070
	ctx.lr = 0x8213EAA0;
	sub_8208D070(ctx, base);
	// mr r19,r3
	ctx.r19.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208d070
	ctx.lr = 0x8213EAAC;
	sub_8208D070(ctx, base);
	// mr r15,r3
	ctx.r15.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208d070
	ctx.lr = 0x8213EAB8;
	sub_8208D070(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lis r10,282
	ctx.r10.s64 = 18481152;
	// stw r3,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r3.u32);
	// addi r9,r11,31376
	ctx.r9.s64 = ctx.r11.s64 + 31376;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r17,r31
	ctx.r17.u64 = ctx.r31.u64;
	// mr r20,r31
	ctx.r20.u64 = ctx.r31.u64;
	// lfs f30,396(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 396);
	ctx.f30.f64 = double(temp.f32);
	// ori r24,r10,31638
	ctx.r24.u64 = ctx.r10.u64 | 31638;
	// lfs f28,60(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 60);
	ctx.f28.f64 = double(temp.f32);
	// li r18,-5
	ctx.r18.s64 = -5;
	// lfs f31,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// li r27,-1
	ctx.r27.s64 = -1;
	// lfs f29,36(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f29.f64 = double(temp.f32);
	// li r21,15
	ctx.r21.s64 = 15;
	// mr r16,r31
	ctx.r16.u64 = ctx.r31.u64;
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// addi r26,r11,-29328
	ctx.r26.s64 = ctx.r11.s64 + -29328;
	// beq cr6,0x8213ec58
	if (ctx.cr6.eq) goto loc_8213EC58;
	// cmplw cr6,r19,r24
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, ctx.r24.u32, ctx.xer);
	// bgt cr6,0x8213eb20
	if (ctx.cr6.gt) goto loc_8213EB20;
	// mulli r11,r19,232
	ctx.r11.s64 = ctx.r19.s64 * 232;
	// cmplw cr6,r11,r18
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r18.u32, ctx.xer);
	// addi r3,r11,4
	ctx.r3.s64 = ctx.r11.s64 + 4;
	// ble cr6,0x8213eb24
	if (!ctx.cr6.gt) goto loc_8213EB24;
loc_8213EB20:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
loc_8213EB24:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x8213EB34;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213ebe8
	if (ctx.cr6.eq) goto loc_8213EBE8;
	// addic. r11,r19,-1
	ctx.xer.ca = ctx.r19.u32 > 0;
	ctx.r11.s64 = ctx.r19.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r19,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r19.u32);
	// addi r8,r3,4
	ctx.r8.s64 = ctx.r3.s64 + 4;
	// blt 0x8213ebe0
	if (ctx.cr0.lt) goto loc_8213EBE0;
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// addi r11,r8,-4
	ctx.r11.s64 = ctx.r8.s64 + -4;
	// addi r10,r8,-232
	ctx.r10.s64 = ctx.r8.s64 + -232;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8213EB5C:
	// stfs f29,40(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stw r21,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r21.u32);
	// stfs f30,68(r11)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + 68, temp.u32);
	// stw r27,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r27.u32);
	// stfs f30,72(r11)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + 72, temp.u32);
	// stw r31,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r31.u32);
	// stfs f31,76(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 76, temp.u32);
	// stw r31,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r31.u32);
	// stfs f31,80(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 80, temp.u32);
	// stw r31,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r31.u32);
	// stfs f31,84(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 84, temp.u32);
	// stw r31,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r31.u32);
	// stfs f28,88(r11)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + 88, temp.u32);
	// stw r31,32(r11)
	PPC_STORE_U32(ctx.r11.u32 + 32, ctx.r31.u32);
	// stfs f31,92(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 92, temp.u32);
	// stw r31,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r31.u32);
	// stfs f29,108(r11)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + 108, temp.u32);
	// stw r31,44(r11)
	PPC_STORE_U32(ctx.r11.u32 + 44, ctx.r31.u32);
	// stw r31,48(r11)
	PPC_STORE_U32(ctx.r11.u32 + 48, ctx.r31.u32);
	// stw r31,52(r11)
	PPC_STORE_U32(ctx.r11.u32 + 52, ctx.r31.u32);
	// stw r31,60(r11)
	PPC_STORE_U32(ctx.r11.u32 + 60, ctx.r31.u32);
	// stw r27,64(r11)
	PPC_STORE_U32(ctx.r11.u32 + 64, ctx.r27.u32);
	// stfs f31,96(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 96, temp.u32);
	// stfs f31,100(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 100, temp.u32);
	// stfs f31,104(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 104, temp.u32);
	// stw r31,212(r11)
	PPC_STORE_U32(ctx.r11.u32 + 212, ctx.r31.u32);
	// stw r31,216(r11)
	PPC_STORE_U32(ctx.r11.u32 + 216, ctx.r31.u32);
	// stw r31,220(r11)
	PPC_STORE_U32(ctx.r11.u32 + 220, ctx.r31.u32);
	// stw r31,224(r11)
	PPC_STORE_U32(ctx.r11.u32 + 224, ctx.r31.u32);
	// stw r31,228(r11)
	PPC_STORE_U32(ctx.r11.u32 + 228, ctx.r31.u32);
	// stwu r31,232(r11)
	ea = 232 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r31.u32);
	ctx.r11.u32 = ea;
	// stwu r26,232(r10)
	ea = 232 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r26.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x8213eb5c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213EB5C;
loc_8213EBE0:
	// mr r16,r8
	ctx.r16.u64 = ctx.r8.u64;
	// b 0x8213ebec
	goto loc_8213EBEC;
loc_8213EBE8:
	// mr r16,r31
	ctx.r16.u64 = ctx.r31.u64;
loc_8213EBEC:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82161240
	ctx.lr = 0x8213EBFC;
	sub_82161240(ctx, base);
	// stb r25,140(r1)
	PPC_STORE_U8(ctx.r1.u32 + 140, ctx.r25.u8);
	// stw r31,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r31.u32);
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// sth r31,132(r1)
	PPC_STORE_U16(ctx.r1.u32 + 132, ctx.r31.u16);
	// stw r31,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r31.u32);
	// sth r31,134(r1)
	PPC_STORE_U16(ctx.r1.u32 + 134, ctx.r31.u16);
	// beq cr6,0x8213ec58
	if (ctx.cr6.eq) goto loc_8213EC58;
	// mr r28,r16
	ctx.r28.u64 = ctx.r16.u64;
	// mr r29,r19
	ctx.r29.u64 = ctx.r19.u64;
loc_8213EC20:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82161240
	ctx.lr = 0x8213EC30;
	sub_82161240(ctx, base);
	// mr r7,r14
	ctx.r7.u64 = ctx.r14.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82147130
	ctx.lr = 0x8213EC48;
	sub_82147130(ctx, base);
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r28,r28,232
	ctx.r28.s64 = ctx.r28.s64 + 232;
	// bne 0x8213ec20
	if (!ctx.cr0.eq) goto loc_8213EC20;
	// lwz r29,120(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
loc_8213EC58:
	// cmplwi cr6,r15,0
	ctx.cr6.compare<uint32_t>(ctx.r15.u32, 0, ctx.xer);
	// beq cr6,0x8213edb0
	if (ctx.cr6.eq) goto loc_8213EDB0;
	// cmplw cr6,r15,r24
	ctx.cr6.compare<uint32_t>(ctx.r15.u32, ctx.r24.u32, ctx.xer);
	// bgt cr6,0x8213ec78
	if (ctx.cr6.gt) goto loc_8213EC78;
	// mulli r11,r15,232
	ctx.r11.s64 = ctx.r15.s64 * 232;
	// cmplw cr6,r11,r18
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r18.u32, ctx.xer);
	// addi r3,r11,4
	ctx.r3.s64 = ctx.r11.s64 + 4;
	// ble cr6,0x8213ec7c
	if (!ctx.cr6.gt) goto loc_8213EC7C;
loc_8213EC78:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
loc_8213EC7C:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x8213EC8C;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213ed40
	if (ctx.cr6.eq) goto loc_8213ED40;
	// addic. r11,r15,-1
	ctx.xer.ca = ctx.r15.u32 > 0;
	ctx.r11.s64 = ctx.r15.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r15,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r15.u32);
	// addi r8,r3,4
	ctx.r8.s64 = ctx.r3.s64 + 4;
	// blt 0x8213ed38
	if (ctx.cr0.lt) goto loc_8213ED38;
	// addi r9,r11,1
	ctx.r9.s64 = ctx.r11.s64 + 1;
	// addi r11,r8,-4
	ctx.r11.s64 = ctx.r8.s64 + -4;
	// addi r10,r8,-232
	ctx.r10.s64 = ctx.r8.s64 + -232;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8213ECB4:
	// stfs f29,40(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// stw r21,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r21.u32);
	// stfs f30,68(r11)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + 68, temp.u32);
	// stw r27,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r27.u32);
	// stfs f30,72(r11)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r11.u32 + 72, temp.u32);
	// stw r31,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r31.u32);
	// stfs f31,76(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 76, temp.u32);
	// stw r31,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r31.u32);
	// stfs f31,80(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 80, temp.u32);
	// stw r31,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r31.u32);
	// stfs f31,84(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 84, temp.u32);
	// stw r31,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r31.u32);
	// stfs f28,88(r11)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r11.u32 + 88, temp.u32);
	// stw r31,32(r11)
	PPC_STORE_U32(ctx.r11.u32 + 32, ctx.r31.u32);
	// stfs f31,92(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 92, temp.u32);
	// stw r31,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r31.u32);
	// stfs f29,108(r11)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r11.u32 + 108, temp.u32);
	// stw r31,44(r11)
	PPC_STORE_U32(ctx.r11.u32 + 44, ctx.r31.u32);
	// stw r31,48(r11)
	PPC_STORE_U32(ctx.r11.u32 + 48, ctx.r31.u32);
	// stw r31,52(r11)
	PPC_STORE_U32(ctx.r11.u32 + 52, ctx.r31.u32);
	// stw r31,60(r11)
	PPC_STORE_U32(ctx.r11.u32 + 60, ctx.r31.u32);
	// stw r27,64(r11)
	PPC_STORE_U32(ctx.r11.u32 + 64, ctx.r27.u32);
	// stfs f31,96(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 96, temp.u32);
	// stfs f31,100(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 100, temp.u32);
	// stfs f31,104(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 104, temp.u32);
	// stw r31,212(r11)
	PPC_STORE_U32(ctx.r11.u32 + 212, ctx.r31.u32);
	// stw r31,216(r11)
	PPC_STORE_U32(ctx.r11.u32 + 216, ctx.r31.u32);
	// stw r31,220(r11)
	PPC_STORE_U32(ctx.r11.u32 + 220, ctx.r31.u32);
	// stw r31,224(r11)
	PPC_STORE_U32(ctx.r11.u32 + 224, ctx.r31.u32);
	// stw r31,228(r11)
	PPC_STORE_U32(ctx.r11.u32 + 228, ctx.r31.u32);
	// stwu r31,232(r11)
	ea = 232 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r31.u32);
	ctx.r11.u32 = ea;
	// stwu r26,232(r10)
	ea = 232 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r26.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x8213ecb4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213ECB4;
loc_8213ED38:
	// mr r20,r8
	ctx.r20.u64 = ctx.r8.u64;
	// b 0x8213ed44
	goto loc_8213ED44;
loc_8213ED40:
	// mr r20,r31
	ctx.r20.u64 = ctx.r31.u64;
loc_8213ED44:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82161240
	ctx.lr = 0x8213ED54;
	sub_82161240(ctx, base);
	// stb r25,172(r1)
	PPC_STORE_U8(ctx.r1.u32 + 172, ctx.r25.u8);
	// stw r31,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r31.u32);
	// cmplwi cr6,r15,0
	ctx.cr6.compare<uint32_t>(ctx.r15.u32, 0, ctx.xer);
	// sth r31,164(r1)
	PPC_STORE_U16(ctx.r1.u32 + 164, ctx.r31.u16);
	// stw r31,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r31.u32);
	// sth r31,166(r1)
	PPC_STORE_U16(ctx.r1.u32 + 166, ctx.r31.u16);
	// beq cr6,0x8213edb0
	if (ctx.cr6.eq) goto loc_8213EDB0;
	// mr r28,r20
	ctx.r28.u64 = ctx.r20.u64;
	// mr r29,r15
	ctx.r29.u64 = ctx.r15.u64;
loc_8213ED78:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82161240
	ctx.lr = 0x8213ED88;
	sub_82161240(ctx, base);
	// mr r7,r14
	ctx.r7.u64 = ctx.r14.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82147130
	ctx.lr = 0x8213EDA0;
	sub_82147130(ctx, base);
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r28,r28,232
	ctx.r28.s64 = ctx.r28.s64 + 232;
	// bne 0x8213ed78
	if (!ctx.cr0.eq) goto loc_8213ED78;
	// lwz r29,120(r1)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
loc_8213EDB0:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8213ee68
	if (ctx.cr6.eq) goto loc_8213EE68;
	// lis r11,564
	ctx.r11.s64 = 36962304;
	// ori r10,r11,63276
	ctx.r10.u64 = ctx.r11.u64 | 63276;
	// cmplw cr6,r29,r10
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r10.u32, ctx.xer);
	// bgt cr6,0x8213edd8
	if (ctx.cr6.gt) goto loc_8213EDD8;
	// mulli r11,r29,116
	ctx.r11.s64 = ctx.r29.s64 * 116;
	// cmplw cr6,r11,r18
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r18.u32, ctx.xer);
	// addi r3,r11,4
	ctx.r3.s64 = ctx.r11.s64 + 4;
	// ble cr6,0x8213eddc
	if (!ctx.cr6.gt) goto loc_8213EDDC;
loc_8213EDD8:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
loc_8213EDDC:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x82082030
	ctx.lr = 0x8213EDEC;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8213ee3c
	if (ctx.cr6.eq) goto loc_8213EE3C;
	// addic. r11,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r11.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// stw r29,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r29.u32);
	// addi r9,r3,4
	ctx.r9.s64 = ctx.r3.s64 + 4;
	// blt 0x8213ee34
	if (ctx.cr0.lt) goto loc_8213EE34;
	// addi r10,r11,1
	ctx.r10.s64 = ctx.r11.s64 + 1;
	// addi r11,r9,-4
	ctx.r11.s64 = ctx.r9.s64 + -4;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r10,r10,-29336
	ctx.r10.s64 = ctx.r10.s64 + -29336;
loc_8213EE18:
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// stw r21,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r21.u32);
	// stw r27,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r27.u32);
	// stw r31,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r31.u32);
	// stw r31,84(r11)
	PPC_STORE_U32(ctx.r11.u32 + 84, ctx.r31.u32);
	// stwu r31,116(r11)
	ea = 116 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r31.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x8213ee18
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8213EE18;
loc_8213EE34:
	// mr r17,r9
	ctx.r17.u64 = ctx.r9.u64;
	// b 0x8213ee40
	goto loc_8213EE40;
loc_8213EE3C:
	// mr r17,r31
	ctx.r17.u64 = ctx.r31.u64;
loc_8213EE40:
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82161240
	ctx.lr = 0x8213EE50;
	sub_82161240(ctx, base);
	// mr r7,r20
	ctx.r7.u64 = ctx.r20.u64;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r17
	ctx.r5.u64 = ctx.r17.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8213f0a8
	ctx.lr = 0x8213EE68;
	sub_8213F0A8(ctx, base);
loc_8213EE68:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82161328
	ctx.lr = 0x8213EE74;
	sub_82161328(ctx, base);
	// addi r30,r22,524
	ctx.r30.s64 = ctx.r22.s64 + 524;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x823052d8
	ctx.lr = 0x8213EE84;
	sub_823052D8(ctx, base);
	// lwz r9,4(r22)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r22.u32 + 4);
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8213eec0
	if (ctx.cr6.eq) goto loc_8213EEC0;
	// addi r10,r22,76
	ctx.r10.s64 = ctx.r22.s64 + 76;
loc_8213EE98:
	// lwz r8,-4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x8213eeb0
	if (!ctx.cr6.eq) goto loc_8213EEB0;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8213eec4
	if (ctx.cr6.eq) goto loc_8213EEC4;
loc_8213EEB0:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8213ee98
	if (ctx.cr6.lt) goto loc_8213EE98;
loc_8213EEC0:
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_8213EEC4:
	// rlwinm r8,r11,1,0,30
	ctx.r8.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r10,r11,6
	ctx.r10.s64 = ctx.r11.s64 + 6;
	// addi r9,r11,22
	ctx.r9.s64 = ctx.r11.s64 + 22;
	// add r6,r11,r8
	ctx.r6.u64 = ctx.r11.u64 + ctx.r8.u64;
	// rlwinm r8,r9,1,0,30
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r7,r10,1,0,30
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r5,r11,2
	ctx.r5.s64 = ctx.r11.s64 + 2;
	// add r3,r9,r8
	ctx.r3.u64 = ctx.r9.u64 + ctx.r8.u64;
	// add r4,r10,r7
	ctx.r4.u64 = ctx.r10.u64 + ctx.r7.u64;
	// rlwinm r11,r6,2,0,29
	ctx.r11.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r22
	ctx.r11.u64 = ctx.r11.u64 + ctx.r22.u64;
	// rlwinm r8,r3,2,0,29
	ctx.r8.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r4,2,0,29
	ctx.r9.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stwx r14,r10,r22
	PPC_STORE_U32(ctx.r10.u32 + ctx.r22.u32, ctx.r14.u32);
	// stw r15,76(r11)
	PPC_STORE_U32(ctx.r11.u32 + 76, ctx.r15.u32);
	// stw r29,80(r11)
	PPC_STORE_U32(ctx.r11.u32 + 80, ctx.r29.u32);
	// stwx r19,r9,r22
	PPC_STORE_U32(ctx.r9.u32 + ctx.r22.u32, ctx.r19.u32);
	// stwx r16,r8,r22
	PPC_STORE_U32(ctx.r8.u32 + ctx.r22.u32, ctx.r16.u32);
	// stw r20,268(r11)
	PPC_STORE_U32(ctx.r11.u32 + 268, ctx.r20.u32);
	// stw r17,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r17.u32);
	// bl 0x823051a8
	ctx.lr = 0x8213EF20;
	sub_823051A8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,416
	ctx.r1.s64 = ctx.r1.s64 + 416;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x8233fa84
	ctx.lr = 0x8213EF30;
	__savefpr_28(ctx, base);
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8213EF34"))) PPC_WEAK_FUNC(sub_8213EF34);
PPC_FUNC_IMPL(__imp__sub_8213EF34) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

