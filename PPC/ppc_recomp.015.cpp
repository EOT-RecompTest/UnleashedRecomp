#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_821129E0"))) PPC_WEAK_FUNC(sub_821129E0);
PPC_FUNC_IMPL(__imp__sub_821129E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e440
	ctx.lr = 0x821129E8;
	__restfpr_18(ctx, base);
	// stfd f31,-128(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -128, ctx.f31.u64);
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r5,64
	ctx.r5.s64 = 64;
	// addi r30,r11,28184
	ctx.r30.s64 = ctx.r11.s64 + 28184;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r30,292
	ctx.r3.s64 = ctx.r30.s64 + 292;
	// lwz r31,28184(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28184);
	// bl 0x8233eaf0
	ctx.lr = 0x82112A0C;
	sub_8233EAF0(ctx, base);
	// li r5,1616
	ctx.r5.s64 = 1616;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r3,r30,356
	ctx.r3.s64 = ctx.r30.s64 + 356;
	// bl 0x8233eaf0
	ctx.lr = 0x82112A1C;
	sub_8233EAF0(ctx, base);
	// li r5,5120
	ctx.r5.s64 = 5120;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r3,r30,1972
	ctx.r3.s64 = ctx.r30.s64 + 1972;
	// bl 0x8233eaf0
	ctx.lr = 0x82112A2C;
	sub_8233EAF0(ctx, base);
	// li r28,1
	ctx.r28.s64 = 1;
	// lis r10,2
	ctx.r10.s64 = 131072;
	// stw r28,516(r30)
	PPC_STORE_U32(ctx.r30.u32 + 516, ctx.r28.u32);
	// li r6,3
	ctx.r6.s64 = 3;
	// stw r28,12284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12284, ctx.r28.u32);
	// ori r7,r10,2048
	ctx.r7.u64 = ctx.r10.u64 | 2048;
	// lwz r3,10548(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// li r25,0
	ctx.r25.s64 = 0;
	// li r23,2
	ctx.r23.s64 = 2;
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// lwz r29,12808(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12808);
	// subfic r29,r29,0
	ctx.xer.ca = ctx.r29.u32 <= 0;
	ctx.r29.s64 = 0 - ctx.r29.s64;
	// subfe r29,r29,r29
	temp.u8 = (~ctx.r29.u32 + ctx.r29.u32 < ~ctx.r29.u32) | (~ctx.r29.u32 + ctx.r29.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r29.u64 = ~ctx.r29.u64 + ctx.r29.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r29,r29,r28
	ctx.r29.u64 = ctx.r29.u64 & ctx.r28.u64;
	// rlwimi r3,r29,1,30,30
	ctx.r3.u64 = (rotl32(ctx.r29.u32, 1) & 0x2) | (ctx.r3.u64 & 0xFFFFFFFFFFFFFFFD);
	// stw r3,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r3.u32);
	// ld r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// or r3,r3,r7
	ctx.r3.u64 = ctx.r3.u64 | ctx.r7.u64;
	// std r3,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r3.u64);
	// stw r10,532(r30)
	PPC_STORE_U32(ctx.r30.u32 + 532, ctx.r10.u32);
	// lwz r10,10548(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// rlwimi r10,r6,5,25,27
	ctx.r10.u64 = (rotl32(ctx.r6.u32, 5) & 0x70) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFF8F);
	// stw r10,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r10.u32);
	// ld r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// or r10,r3,r7
	ctx.r10.u64 = ctx.r3.u64 | ctx.r7.u64;
	// std r10,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r10.u64);
	// stw r28,548(r30)
	PPC_STORE_U32(ctx.r30.u32 + 548, ctx.r28.u32);
	// lwz r9,10548(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// ori r3,r9,4
	ctx.r3.u64 = ctx.r9.u64 | 4;
	// stw r3,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r3.u32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r9,r10,2048
	ctx.r9.u64 = ctx.r10.u64 | 2048;
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// stw r25,564(r30)
	PPC_STORE_U32(ctx.r30.u32 + 564, ctx.r25.u32);
	// lwz r8,10568(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10568);
	// rlwinm r3,r8,0,29,20
	ctx.r3.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFF807;
	// stw r3,10568(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10568, ctx.r3.u32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r9,r10,64
	ctx.r9.u64 = ctx.r10.u64 | 64;
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// stw r23,580(r30)
	PPC_STORE_U32(ctx.r30.u32 + 580, ctx.r23.u32);
	// lwz r8,10568(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10568);
	// rlwimi r8,r28,1,29,31
	ctx.r8.u64 = (rotl32(ctx.r28.u32, 1) & 0x7) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFF8);
	// stw r8,10568(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10568, ctx.r8.u32);
	// ld r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r3,r5,64
	ctx.r3.u64 = ctx.r5.u64 | 64;
	// std r3,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r3.u64);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r28,548(r30)
	PPC_STORE_U32(ctx.r30.u32 + 548, ctx.r28.u32);
	// lwz r10,10548(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// ori r9,r10,4
	ctx.r9.u64 = ctx.r10.u64 | 4;
	// stw r9,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r9.u32);
	// ld r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r5,r8,2048
	ctx.r5.u64 = ctx.r8.u64 | 2048;
	// std r5,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r5.u64);
	// stw r25,596(r30)
	PPC_STORE_U32(ctx.r30.u32 + 596, ctx.r25.u32);
	// bl 0x8222a858
	ctx.lr = 0x82112B28;
	sub_8222A858(ctx, base);
	// stw r25,612(r30)
	PPC_STORE_U32(ctx.r30.u32 + 612, ctx.r25.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// bl 0x8222abe8
	ctx.lr = 0x82112B34;
	sub_8222ABE8(ctx, base);
	// stw r25,628(r30)
	PPC_STORE_U32(ctx.r30.u32 + 628, ctx.r25.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// bl 0x8222ad10
	ctx.lr = 0x82112B40;
	sub_8222AD10(ctx, base);
	// stw r28,644(r30)
	PPC_STORE_U32(ctx.r30.u32 + 644, ctx.r28.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// bl 0x8222a978
	ctx.lr = 0x82112B50;
	sub_8222A978(ctx, base);
	// stw r28,660(r30)
	PPC_STORE_U32(ctx.r30.u32 + 660, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// bl 0x8222aa08
	ctx.lr = 0x82112B5C;
	sub_8222AA08(ctx, base);
	// stw r25,676(r30)
	PPC_STORE_U32(ctx.r30.u32 + 676, ctx.r25.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// bl 0x8222a8e8
	ctx.lr = 0x82112B6C;
	sub_8222A8E8(ctx, base);
	// stw r28,692(r30)
	PPC_STORE_U32(ctx.r30.u32 + 692, ctx.r28.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// bl 0x8222ab08
	ctx.lr = 0x82112B7C;
	sub_8222AB08(ctx, base);
	// stw r25,708(r30)
	PPC_STORE_U32(ctx.r30.u32 + 708, ctx.r25.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// bl 0x8222ab78
	ctx.lr = 0x82112B8C;
	sub_8222AB78(ctx, base);
	// stw r25,724(r30)
	PPC_STORE_U32(ctx.r30.u32 + 724, ctx.r25.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// bl 0x8222aa98
	ctx.lr = 0x82112B98;
	sub_8222AA98(ctx, base);
	// stw r25,740(r30)
	PPC_STORE_U32(ctx.r30.u32 + 740, ctx.r25.u32);
	// lis r4,-32250
	ctx.r4.s64 = -2113536000;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// addi r22,r4,31376
	ctx.r22.s64 = ctx.r4.s64 + 31376;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// li r10,6
	ctx.r10.s64 = 6;
	// li r29,255
	ctx.r29.s64 = 255;
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// lfs f0,244(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 244);
	ctx.f0.f64 = double(temp.f32);
	// li r5,6
	ctx.r5.s64 = 6;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r8,10556(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10556);
	// rlwinm r8,r8,0,29,27
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// stw r8,10556(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10556, ctx.r8.u32);
	// ld r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r8,r8,4
	ctx.r8.u64 = ctx.r8.u64 | 262144;
	// ori r8,r8,512
	ctx.r8.u64 = ctx.r8.u64 | 512;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// stw r28,756(r30)
	PPC_STORE_U32(ctx.r30.u32 + 756, ctx.r28.u32);
	// stfs f0,10500(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 10500, temp.u32);
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r8,r11,2048
	ctx.r8.u64 = ctx.r11.u64 | 134217728;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r10,772(r30)
	PPC_STORE_U32(ctx.r30.u32 + 772, ctx.r10.u32);
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// lwz r8,10556(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10556);
	// rlwimi r8,r6,1,29,31
	ctx.r8.u64 = (rotl32(ctx.r6.u32, 1) & 0x7) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFF8);
	// stw r8,10556(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10556, ctx.r8.u32);
	// ld r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r8,r8,512
	ctx.r8.u64 = ctx.r8.u64 | 512;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// stw r25,788(r30)
	PPC_STORE_U32(ctx.r30.u32 + 788, ctx.r25.u32);
	// stw r25,12288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12288, ctx.r25.u32);
	// lwz r27,10548(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// rlwinm r27,r27,0,0,30
	ctx.r27.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r27,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r27.u32);
	// mr r27,r25
	ctx.r27.u64 = ctx.r25.u64;
	// ld r26,16(r31)
	ctx.r26.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// or r26,r26,r7
	ctx.r26.u64 = ctx.r26.u64 | ctx.r7.u64;
	// std r26,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r26.u64);
	// stw r25,804(r30)
	PPC_STORE_U32(ctx.r30.u32 + 804, ctx.r25.u32);
	// lwz r26,10548(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// rlwinm r26,r26,0,25,23
	ctx.r26.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
	// stw r26,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r26.u32);
	// ld r26,16(r31)
	ctx.r26.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// or r26,r26,r7
	ctx.r26.u64 = ctx.r26.u64 | ctx.r7.u64;
	// std r26,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r26.u64);
	// stw r25,820(r30)
	PPC_STORE_U32(ctx.r30.u32 + 820, ctx.r25.u32);
	// lwz r26,10548(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// rlwinm r26,r26,0,21,17
	ctx.r26.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 0) & 0xFFFFFFFFFFFFC7FF;
	// stw r26,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r26.u32);
	// ld r26,16(r31)
	ctx.r26.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// or r26,r26,r7
	ctx.r26.u64 = ctx.r26.u64 | ctx.r7.u64;
	// std r26,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r26.u64);
	// li r11,6
	ctx.r11.s64 = 6;
	// stw r25,836(r30)
	PPC_STORE_U32(ctx.r30.u32 + 836, ctx.r25.u32);
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// lwz r26,10548(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// rlwinm r26,r26,0,15,11
	ctx.r26.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 0) & 0xFFFFFFFFFFF1FFFF;
	// stw r26,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r26.u32);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// ld r26,16(r31)
	ctx.r26.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// or r26,r26,r7
	ctx.r26.u64 = ctx.r26.u64 | ctx.r7.u64;
	// std r26,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r26.u64);
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// stw r25,852(r30)
	PPC_STORE_U32(ctx.r30.u32 + 852, ctx.r25.u32);
	// lwz r26,10548(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// rlwinm r26,r26,0,18,14
	ctx.r26.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 0) & 0xFFFFFFFFFFFE3FFF;
	// stw r26,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r26.u32);
	// ld r26,16(r31)
	ctx.r26.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r26,r26,2048
	ctx.r26.u64 = ctx.r26.u64 | 2048;
	// std r26,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r26.u64);
	// stw r5,868(r30)
	PPC_STORE_U32(ctx.r30.u32 + 868, ctx.r5.u32);
	// lwz r5,10548(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// rlwimi r5,r6,9,21,23
	ctx.r5.u64 = (rotl32(ctx.r6.u32, 9) & 0x700) | (ctx.r5.u64 & 0xFFFFFFFFFFFFF8FF);
	// stw r5,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r5.u32);
	// ld r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r5,r5,2048
	ctx.r5.u64 = ctx.r5.u64 | 2048;
	// std r5,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r5.u64);
	// stw r29,884(r30)
	PPC_STORE_U32(ctx.r30.u32 + 884, ctx.r29.u32);
	// stb r29,10499(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10499, ctx.r29.u8);
	// ld r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r5,r4,4096
	ctx.r5.u64 = ctx.r4.u64 | 268435456;
	// std r5,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r5.u64);
	// stw r29,900(r30)
	PPC_STORE_U32(ctx.r30.u32 + 900, ctx.r29.u32);
	// stb r29,10498(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10498, ctx.r29.u8);
	// ld r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r3,r4,4096
	ctx.r3.u64 = ctx.r4.u64 | 268435456;
	// std r3,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r3.u64);
	// stw r29,916(r30)
	PPC_STORE_U32(ctx.r30.u32 + 916, ctx.r29.u32);
	// stb r29,10497(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10497, ctx.r29.u8);
	// ld r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r4,r5,4096
	ctx.r4.u64 = ctx.r5.u64 | 268435456;
	// std r4,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r4.u64);
	// stw r25,932(r30)
	PPC_STORE_U32(ctx.r30.u32 + 932, ctx.r25.u32);
	// lwz r3,10548(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// rlwinm r5,r3,0,9,5
	ctx.r5.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFFFFC7FFFFF;
	// stw r5,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r5.u32);
	// ld r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// or r3,r4,r7
	ctx.r3.u64 = ctx.r4.u64 | ctx.r7.u64;
	// std r3,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r3.u64);
	// stw r25,948(r30)
	PPC_STORE_U32(ctx.r30.u32 + 948, ctx.r25.u32);
	// lwz r5,10548(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// clrlwi r4,r5,3
	ctx.r4.u64 = ctx.r5.u32 & 0x1FFFFFFF;
	// stw r4,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r4.u32);
	// ld r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// or r7,r3,r7
	ctx.r7.u64 = ctx.r3.u64 | ctx.r7.u64;
	// std r7,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r7.u64);
	// stw r25,964(r30)
	PPC_STORE_U32(ctx.r30.u32 + 964, ctx.r25.u32);
	// lwz r5,10548(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// rlwinm r4,r5,0,6,2
	ctx.r4.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFFE3FFFFFF;
	// stw r4,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r4.u32);
	// ld r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r7,r3,2048
	ctx.r7.u64 = ctx.r3.u64 | 2048;
	// std r7,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r7.u64);
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// stw r11,980(r30)
	PPC_STORE_U32(ctx.r30.u32 + 980, ctx.r11.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r5,10548(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10548);
	// rlwimi r5,r6,21,9,11
	ctx.r5.u64 = (rotl32(ctx.r6.u32, 21) & 0x700000) | (ctx.r5.u64 & 0xFFFFFFFFFF8FFFFF);
	// stw r5,10548(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10548, ctx.r5.u32);
	// ld r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r11,r4,2048
	ctx.r11.u64 = ctx.r4.u64 | 2048;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r29,996(r30)
	PPC_STORE_U32(ctx.r30.u32 + 996, ctx.r29.u32);
	// stb r29,10495(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10495, ctx.r29.u8);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r6,r9,8192
	ctx.r6.u64 = ctx.r9.u64 | 536870912;
	// std r6,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r6.u64);
	// stw r29,1012(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1012, ctx.r29.u32);
	// stb r29,10494(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10494, ctx.r29.u8);
	// ld r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r11,r5,8192
	ctx.r11.u64 = ctx.r5.u64 | 536870912;
	// std r11,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r11.u64);
	// stw r29,1028(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1028, ctx.r29.u32);
	// stb r29,10493(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10493, ctx.r29.u8);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r9,r10,8192
	ctx.r9.u64 = ctx.r10.u64 | 536870912;
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// stw r25,1044(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1044, ctx.r25.u32);
	// bl 0x8222b278
	ctx.lr = 0x82112DDC;
	sub_8222B278(ctx, base);
	// lfs f31,36(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// stfs f31,80(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,1060(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1060, ctx.r11.u32);
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// bl 0x8222b5c0
	ctx.lr = 0x82112DF4;
	sub_8222B5C0(ctx, base);
	// stfs f31,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// stw r11,1076(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1076, ctx.r11.u32);
	// bl 0x8222b620
	ctx.lr = 0x82112E08;
	sub_8222B620(ctx, base);
	// stw r25,1092(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1092, ctx.r25.u32);
	// stfs f31,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// stw r25,12292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12292, ctx.r25.u32);
	// stw r11,1108(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1108, ctx.r11.u32);
	// bl 0x8222b678
	ctx.lr = 0x82112E28;
	sub_8222B678(ctx, base);
	// stw r25,1124(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1124, ctx.r25.u32);
	// lis r8,0
	ctx.r8.s64 = 0;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// li r11,-1
	ctx.r11.s64 = -1;
	// ori r27,r8,65535
	ctx.r27.u64 = ctx.r8.u64 | 65535;
	// addi r4,r31,13028
	ctx.r4.s64 = ctx.r31.s64 + 13028;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// lwz r7,10568(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10568);
	// rlwinm r6,r7,0,17,15
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFFFFFF7FFF;
	// stw r6,10568(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10568, ctx.r6.u32);
	// ld r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r9,r5,64
	ctx.r9.u64 = ctx.r5.u64 | 64;
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// stw r11,1140(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1140, ctx.r11.u32);
	// stw r27,10752(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10752, ctx.r27.u32);
	// ld r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// oris r7,r8,8
	ctx.r7.u64 = ctx.r8.u64 | 524288;
	// std r7,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r7.u64);
	// stw r25,1156(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1156, ctx.r25.u32);
	// stw r25,12264(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12264, ctx.r25.u32);
	// bl 0x8222cad0
	ctx.lr = 0x82112E7C;
	sub_8222CAD0(ctx, base);
	// lfs f11,48(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r9,1172(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1172, ctx.r9.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r4,r9
	ctx.r4.u64 = ctx.r9.u64;
	// bl 0x8222b2e8
	ctx.lr = 0x82112E98;
	sub_8222B2E8(ctx, base);
	// stw r9,1188(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1188, ctx.r9.u32);
	// bl 0x8222b3b0
	ctx.lr = 0x82112EA0;
	sub_8222B3B0(ctx, base);
	// li r10,7
	ctx.r10.s64 = 7;
	// stfs f31,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r10,1204(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1204, ctx.r10.u32);
	// stfs f31,84(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stw r10,12268(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12268, ctx.r10.u32);
	// li r11,15
	ctx.r11.s64 = 15;
	// stw r4,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r4.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r5,12792(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12792);
	// lfs f0,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// lwz r3,10460(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10460);
	// rldicr r6,r6,37,63
	ctx.r6.u64 = rotl64(ctx.r6.u64, 37) & 0xFFFFFFFFFFFFFFFF;
	// subfic r8,r5,0
	ctx.xer.ca = ctx.r5.u32 <= 0;
	ctx.r8.s64 = 0 - ctx.r5.s64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// subfe r5,r5,r5
	temp.u8 = (~ctx.r5.u32 + ctx.r5.u32 < ~ctx.r5.u32) | (~ctx.r5.u32 + ctx.r5.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r5.u64 = ~ctx.r5.u64 + ctx.r5.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// and r26,r5,r10
	ctx.r26.u64 = ctx.r5.u64 & ctx.r10.u64;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// rlwimi r26,r3,0,0,27
	ctx.r26.u64 = (rotl32(ctx.r3.u32, 0) & 0xFFFFFFF0) | (ctx.r26.u64 & 0xFFFFFFFF0000000F);
	// lfs f13,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// stw r26,10460(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10460, ctx.r26.u32);
	// ld r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// li r12,1
	ctx.r12.s64 = 1;
	// or r3,r3,r6
	ctx.r3.u64 = ctx.r3.u64 | ctx.r6.u64;
	// rldicr r12,r12,49,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 49) & 0xFFFFFFFFFFFFFFFF;
	// std r3,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r3.u64);
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// stw r11,1220(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1220, ctx.r11.u32);
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// stw r11,12272(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12272, ctx.r11.u32);
	// lwz r3,10460(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10460);
	// lwz r26,12796(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12796);
	// subfic r26,r26,0
	ctx.xer.ca = ctx.r26.u32 <= 0;
	ctx.r26.s64 = 0 - ctx.r26.s64;
	// subfe r26,r26,r26
	temp.u8 = (~ctx.r26.u32 + ctx.r26.u32 < ~ctx.r26.u32) | (~ctx.r26.u32 + ctx.r26.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r26.u64 = ~ctx.r26.u64 + ctx.r26.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r26,r26,r11
	ctx.r26.u64 = ctx.r26.u64 & ctx.r11.u64;
	// rlwimi r3,r26,4,24,27
	ctx.r3.u64 = (rotl32(ctx.r26.u32, 4) & 0xF0) | (ctx.r3.u64 & 0xFFFFFFFFFFFFFF0F);
	// stw r3,10460(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10460, ctx.r3.u32);
	// ld r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// or r3,r3,r6
	ctx.r3.u64 = ctx.r3.u64 | ctx.r6.u64;
	// std r3,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r3.u64);
	// stw r11,1236(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1236, ctx.r11.u32);
	// stw r11,12276(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12276, ctx.r11.u32);
	// lwz r3,10460(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10460);
	// lwz r26,12800(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12800);
	// subfic r26,r26,0
	ctx.xer.ca = ctx.r26.u32 <= 0;
	ctx.r26.s64 = 0 - ctx.r26.s64;
	// subfe r26,r26,r26
	temp.u8 = (~ctx.r26.u32 + ctx.r26.u32 < ~ctx.r26.u32) | (~ctx.r26.u32 + ctx.r26.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r26.u64 = ~ctx.r26.u64 + ctx.r26.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r26,r26,r11
	ctx.r26.u64 = ctx.r26.u64 & ctx.r11.u64;
	// rlwimi r3,r26,8,20,23
	ctx.r3.u64 = (rotl32(ctx.r26.u32, 8) & 0xF00) | (ctx.r3.u64 & 0xFFFFFFFFFFFFF0FF);
	// stw r3,10460(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10460, ctx.r3.u32);
	// ld r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// or r3,r3,r6
	ctx.r3.u64 = ctx.r3.u64 | ctx.r6.u64;
	// std r3,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r3.u64);
	// stw r11,1252(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1252, ctx.r11.u32);
	// stw r11,12280(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12280, ctx.r11.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// lwz r3,12804(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12804);
	// subfic r3,r3,0
	ctx.xer.ca = ctx.r3.u32 <= 0;
	ctx.r3.s64 = 0 - ctx.r3.s64;
	// subfe r3,r3,r3
	temp.u8 = (~ctx.r3.u32 + ctx.r3.u32 < ~ctx.r3.u32) | (~ctx.r3.u32 + ctx.r3.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r3.u64 = ~ctx.r3.u64 + ctx.r3.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// lwz r26,10460(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10460);
	// and r3,r3,r5
	ctx.r3.u64 = ctx.r3.u64 & ctx.r5.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// rlwimi r26,r3,12,16,19
	ctx.r26.u64 = (rotl32(ctx.r3.u32, 12) & 0xF000) | (ctx.r26.u64 & 0xFFFFFFFFFFFF0FFF);
	// stw r26,10460(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10460, ctx.r26.u32);
	// mr r26,r25
	ctx.r26.u64 = ctx.r25.u64;
	// ld r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// or r3,r3,r6
	ctx.r3.u64 = ctx.r3.u64 | ctx.r6.u64;
	// std r3,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r3.u64);
	// stw r28,1268(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1268, ctx.r28.u32);
	// lwz r9,10616(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10616);
	// rlwimi r9,r28,0,30,31
	ctx.r9.u64 = (rotl32(ctx.r28.u32, 0) & 0x3) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r9,10616(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10616, ctx.r9.u32);
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// ld r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// or r3,r3,r12
	ctx.r3.u64 = ctx.r3.u64 | ctx.r12.u64;
	// std r3,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r3.u64);
	// li r12,1
	ctx.r12.s64 = 1;
	// stw r4,1284(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1284, ctx.r4.u32);
	// stfs f0,10624(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 10624, temp.u32);
	// rldicr r12,r12,47,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 47) & 0xFFFFFFFFFFFFFFFF;
	// ld r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// or r3,r4,r12
	ctx.r3.u64 = ctx.r4.u64 | ctx.r12.u64;
	// std r3,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r3.u64);
	// li r12,1
	ctx.r12.s64 = 1;
	// stw r10,1300(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1300, ctx.r10.u32);
	// stfs f13,10620(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 10620, temp.u32);
	// rldicr r12,r12,48,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 48) & 0xFFFFFFFFFFFFFFFF;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// ld r24,24(r31)
	ctx.r24.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// or r24,r24,r12
	ctx.r24.u64 = ctx.r24.u64 | ctx.r12.u64;
	// std r24,24(r31)
	PPC_STORE_U64(ctx.r31.u32 + 24, ctx.r24.u64);
	// stw r25,1316(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1316, ctx.r25.u32);
	// lwz r24,10540(r31)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10540);
	// rlwinm r24,r24,0,0,27
	ctx.r24.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0xFFFFFFF0;
	// stw r24,10540(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10540, ctx.r24.u32);
	// ld r24,16(r31)
	ctx.r24.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r24,r24,8192
	ctx.r24.u64 = ctx.r24.u64 | 8192;
	// std r24,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r24.u64);
	// stw r25,1332(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1332, ctx.r25.u32);
	// lwz r24,10540(r31)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10540);
	// rlwinm r24,r24,0,28,23
	ctx.r24.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0xFFFFFFFFFFFFFF0F;
	// stw r24,10540(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10540, ctx.r24.u32);
	// ld r24,16(r31)
	ctx.r24.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r24,r24,8192
	ctx.r24.u64 = ctx.r24.u64 | 8192;
	// std r24,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r24.u64);
	// stw r25,1348(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1348, ctx.r25.u32);
	// lwz r24,10540(r31)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10540);
	// rlwinm r24,r24,0,24,19
	ctx.r24.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0xFFFFFFFFFFFFF0FF;
	// stw r24,10540(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10540, ctx.r24.u32);
	// ld r24,16(r31)
	ctx.r24.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r24,r24,8192
	ctx.r24.u64 = ctx.r24.u64 | 8192;
	// std r24,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r24.u64);
	// stw r25,1364(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1364, ctx.r25.u32);
	// lwz r24,10540(r31)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10540);
	// rlwinm r24,r24,0,20,15
	ctx.r24.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0xFFFFFFFFFFFF0FFF;
	// stw r24,10540(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10540, ctx.r24.u32);
	// ld r24,16(r31)
	ctx.r24.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r24,r24,8192
	ctx.r24.u64 = ctx.r24.u64 | 8192;
	// std r24,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r24.u64);
	// stw r25,1380(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1380, ctx.r25.u32);
	// lwz r24,10540(r31)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10540);
	// rlwinm r24,r24,0,16,11
	ctx.r24.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0xFFFFFFFFFFF0FFFF;
	// stw r24,10540(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10540, ctx.r24.u32);
	// mr r24,r25
	ctx.r24.u64 = ctx.r25.u64;
	// ld r21,16(r31)
	ctx.r21.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r21,r21,8192
	ctx.r21.u64 = ctx.r21.u64 | 8192;
	// std r21,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r21.u64);
	// stw r25,1396(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1396, ctx.r25.u32);
	// lwz r10,10540(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10540);
	// rlwinm r10,r10,0,12,7
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFF0FFFFF;
	// stw r10,10540(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10540, ctx.r10.u32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r10,r10,8192
	ctx.r10.u64 = ctx.r10.u64 | 8192;
	// std r10,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r10.u64);
	// stw r25,1412(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1412, ctx.r25.u32);
	// lwz r9,10540(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10540);
	// rlwinm r10,r9,0,8,3
	ctx.r10.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFF0FFFFFF;
	// stw r10,10540(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10540, ctx.r10.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r10,r9,8192
	ctx.r10.u64 = ctx.r9.u64 | 8192;
	// std r10,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r10.u64);
	// stw r25,1428(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1428, ctx.r25.u32);
	// lwz r9,10540(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10540);
	// clrlwi r8,r9,4
	ctx.r8.u64 = ctx.r9.u32 & 0xFFFFFFF;
	// stw r8,10540(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10540, ctx.r8.u32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r9,r10,8192
	ctx.r9.u64 = ctx.r10.u64 | 8192;
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// stw r25,1444(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1444, ctx.r25.u32);
	// lwz r8,10544(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10544);
	// rlwinm r9,r8,0,0,27
	ctx.r9.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFF0;
	// stw r9,10544(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10544, ctx.r9.u32);
	// ld r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r9,r8,4096
	ctx.r9.u64 = ctx.r8.u64 | 4096;
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// stw r25,1460(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1460, ctx.r25.u32);
	// lwz r8,10544(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10544);
	// rlwinm r7,r8,0,28,23
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFFF0F;
	// stw r7,10544(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10544, ctx.r7.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r8,r9,4096
	ctx.r8.u64 = ctx.r9.u64 | 4096;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// stw r25,1476(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1476, ctx.r25.u32);
	// lwz r7,10544(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10544);
	// rlwinm r5,r7,0,24,19
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFFFFFFF0FF;
	// stw r5,10544(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10544, ctx.r5.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r8,r9,4096
	ctx.r8.u64 = ctx.r9.u64 | 4096;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// stw r25,1492(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1492, ctx.r25.u32);
	// lwz r7,10544(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10544);
	// rlwinm r5,r7,0,20,15
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFFFFFF0FFF;
	// stw r5,10544(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10544, ctx.r5.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r8,r9,4096
	ctx.r8.u64 = ctx.r9.u64 | 4096;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// stw r25,1508(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1508, ctx.r25.u32);
	// lwz r7,10544(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10544);
	// rlwinm r5,r7,0,16,11
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFFFFF0FFFF;
	// stw r5,10544(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10544, ctx.r5.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// ori r8,r9,4096
	ctx.r8.u64 = ctx.r9.u64 | 4096;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// stw r25,1524(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1524, ctx.r25.u32);
	// lwz r7,10544(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10544);
	// rlwinm r5,r7,0,12,7
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFFFF0FFFFF;
	// stw r5,10544(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10544, ctx.r5.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r8,r9,4096
	ctx.r8.u64 = ctx.r9.u64 | 4096;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// stw r25,1540(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1540, ctx.r25.u32);
	// lwz r7,10544(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10544);
	// rlwinm r5,r7,0,8,3
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFFF0FFFFFF;
	// stw r5,10544(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10544, ctx.r5.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r8,r9,4096
	ctx.r8.u64 = ctx.r9.u64 | 4096;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// stw r25,1556(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1556, ctx.r25.u32);
	// lwz r7,10544(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10544);
	// clrlwi r5,r7,4
	ctx.r5.u64 = ctx.r7.u32 & 0xFFFFFFF;
	// stw r5,10544(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10544, ctx.r5.u32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r9,r10,4096
	ctx.r9.u64 = ctx.r10.u64 | 4096;
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// stw r28,1572(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1572, ctx.r28.u32);
	// bl 0x8222ba30
	ctx.lr = 0x821131F4;
	sub_8222BA30(ctx, base);
	// stw r25,1588(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1588, ctx.r25.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// bl 0x8222ba80
	ctx.lr = 0x82113204;
	sub_8222BA80(ctx, base);
	// stw r25,1604(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1604, ctx.r25.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// bl 0x8222bb18
	ctx.lr = 0x82113210;
	sub_8222BB18(ctx, base);
	// stw r25,1620(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1620, ctx.r25.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// bl 0x8222bbb0
	ctx.lr = 0x8211321C;
	sub_8222BBB0(ctx, base);
	// stw r25,1636(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1636, ctx.r25.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// bl 0x8222bc48
	ctx.lr = 0x82113228;
	sub_8222BC48(ctx, base);
	// stw r28,1652(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1652, ctx.r28.u32);
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f0,56(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 56);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// rldicr r12,r12,35,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 35) & 0xFFFFFFFFFFFFFFFF;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// lwz r5,10688(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10688);
	// mr r9,r27
	ctx.r9.u64 = ctx.r27.u64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// lfs f12,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// ori r5,r5,1
	ctx.r5.u64 = ctx.r5.u64 | 1;
	// stfs f31,80(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// mr r8,r25
	ctx.r8.u64 = ctx.r25.u64;
	// stw r5,10688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10688, ctx.r5.u32);
	// li r26,135
	ctx.r26.s64 = 135;
	// mr r7,r25
	ctx.r7.u64 = ctx.r25.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// li r10,135
	ctx.r10.s64 = 135;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// ld r5,32(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r5,r5,r12
	ctx.r5.u64 = ctx.r5.u64 | ctx.r12.u64;
	// li r12,1
	ctx.r12.s64 = 1;
	// std r5,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r5.u64);
	// stw r28,1668(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1668, ctx.r28.u32);
	// rldicr r12,r12,38,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 38) & 0xFFFFFFFFFFFFFFFF;
	// lwz r5,10568(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10568);
	// oris r5,r5,32
	ctx.r5.u64 = ctx.r5.u64 | 2097152;
	// stw r5,10568(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10568, ctx.r5.u32);
	// ld r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r5,r5,64
	ctx.r5.u64 = ctx.r5.u64 | 64;
	// std r5,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r5.u64);
	// stw r27,1684(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1684, ctx.r27.u32);
	// stw r27,10456(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10456, ctx.r27.u32);
	// ld r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// or r5,r5,r12
	ctx.r5.u64 = ctx.r5.u64 | ctx.r12.u64;
	// std r5,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r5.u64);
	// stw r25,1700(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1700, ctx.r25.u32);
	// li r12,1
	ctx.r12.s64 = 1;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// rldicr r12,r12,32,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// lwz r27,10556(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10556);
	// rlwinm r27,r27,0,28,26
	ctx.r27.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0xFFFFFFFFFFFFFFEF;
	// stw r27,10556(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10556, ctx.r27.u32);
	// ld r27,16(r31)
	ctx.r27.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r27,r27,512
	ctx.r27.u64 = ctx.r27.u64 | 512;
	// std r27,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r27.u64);
	// stw r10,1716(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1716, ctx.r10.u32);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// stb r26,10556(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10556, ctx.r26.u8);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// ld r27,16(r31)
	ctx.r27.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r27,r27,512
	ctx.r27.u64 = ctx.r27.u64 | 512;
	// std r27,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r27.u64);
	// stw r10,1732(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1732, ctx.r10.u32);
	// stfs f12,10700(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 10700, temp.u32);
	// lfs f9,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// stfs f31,88(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// ld r9,32(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r9,r9,r12
	ctx.r9.u64 = ctx.r9.u64 | ctx.r12.u64;
	// std r9,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r9.u64);
	// li r12,1
	ctx.r12.s64 = 1;
	// stw r10,1748(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1748, ctx.r10.u32);
	// stfs f10,10692(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 10692, temp.u32);
	// rldicr r12,r12,34,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 34) & 0xFFFFFFFFFFFFFFFF;
	// ld r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r9,r10,r12
	ctx.r9.u64 = ctx.r10.u64 | ctx.r12.u64;
	// li r12,1
	ctx.r12.s64 = 1;
	// std r9,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r9.u64);
	// stw r11,1764(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1764, ctx.r11.u32);
	// stfs f9,10704(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 10704, temp.u32);
	// rldicr r12,r12,33,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 33) & 0xFFFFFFFFFFFFFFFF;
	// ld r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// oris r9,r10,32768
	ctx.r9.u64 = ctx.r10.u64 | 2147483648;
	// std r9,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r9.u64);
	// stw r11,1780(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1780, ctx.r11.u32);
	// stfs f8,10696(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 10696, temp.u32);
	// ld r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r10.u64);
	// li r11,8
	ctx.r11.s64 = 8;
	// stw r25,1796(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1796, ctx.r25.u32);
	// lwz r9,10560(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10560);
	// rlwinm r8,r9,0,29,27
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// stw r8,10560(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10560, ctx.r8.u32);
	// mr r9,r28
	ctx.r9.u64 = ctx.r28.u64;
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 256;
	// std r10,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r10.u64);
	// stw r25,1812(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1812, ctx.r25.u32);
	// lwz r8,88(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r4,r8
	ctx.r4.u64 = ctx.r8.u64;
	// lwz r7,10560(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10560);
	// rlwinm r10,r7,0,30,28
	ctx.r10.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// stw r10,10560(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10560, ctx.r10.u32);
	// ld r7,16(r31)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r10,r7,256
	ctx.r10.u64 = ctx.r7.u64 | 256;
	// std r10,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r10.u64);
	// stw r25,1828(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1828, ctx.r25.u32);
	// lwz r7,10560(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10560);
	// rlwinm r5,r7,0,27,25
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFFFFFFFFDF;
	// stw r5,10560(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10560, ctx.r5.u32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r7,r10,256
	ctx.r7.u64 = ctx.r10.u64 | 256;
	// std r7,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r7.u64);
	// stw r29,1844(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1844, ctx.r29.u32);
	// stb r29,10562(r31)
	PPC_STORE_U8(ctx.r31.u32 + 10562, ctx.r29.u8);
	// ld r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// ori r10,r5,256
	ctx.r10.u64 = ctx.r5.u64 | 256;
	// std r10,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r10.u64);
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
	// stw r23,1860(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1860, ctx.r23.u32);
	// stw r23,13984(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13984, ctx.r23.u32);
	// stw r11,1876(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1876, ctx.r11.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lwz r7,12260(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12260);
	// rlwimi r7,r28,26,2,8
	ctx.r7.u64 = (rotl32(ctx.r28.u32, 26) & 0x3F800000) | (ctx.r7.u64 & 0xFFFFFFFFC07FFFFF);
	// stw r7,12260(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12260, ctx.r7.u32);
	// stw r23,1892(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1892, ctx.r23.u32);
	// lwz r5,12260(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12260);
	// rlwimi r5,r28,21,9,11
	ctx.r5.u64 = (rotl32(ctx.r28.u32, 21) & 0x700000) | (ctx.r5.u64 & 0xFFFFFFFFFF8FFFFF);
	// stw r5,12260(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12260, ctx.r5.u32);
	// ld r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r10,r3,2
	ctx.r10.u64 = ctx.r3.u64 | 131072;
	// std r10,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r10.u64);
	// stw r28,1908(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1908, ctx.r28.u32);
	// lwz r7,12260(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12260);
	// rlwimi r7,r28,20,9,11
	ctx.r7.u64 = (rotl32(ctx.r28.u32, 20) & 0x700000) | (ctx.r7.u64 & 0xFFFFFFFFFF8FFFFF);
	// stw r7,12260(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12260, ctx.r7.u32);
	// ld r5,16(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r3,r5,2
	ctx.r3.u64 = ctx.r5.u64 | 131072;
	// std r3,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r3.u64);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r28,1924(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1924, ctx.r28.u32);
	// lwz r11,10680(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 10680);
	// ori r10,r11,1024
	ctx.r10.u64 = ctx.r11.u64 | 1024;
	// stw r10,10680(r31)
	PPC_STORE_U32(ctx.r31.u32 + 10680, ctx.r10.u32);
	// ld r9,32(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 32);
	// or r7,r9,r6
	ctx.r7.u64 = ctx.r9.u64 | ctx.r6.u64;
	// std r7,32(r31)
	PPC_STORE_U64(ctx.r31.u32 + 32, ctx.r7.u64);
	// stw r8,1940(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1940, ctx.r8.u32);
	// bl 0x8222ae50
	ctx.lr = 0x8211347C;
	sub_8222AE50(ctx, base);
	// stfs f11,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stfs f11,84(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// lwz r20,84(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// stw r25,288(r30)
	PPC_STORE_U32(ctx.r30.u32 + 288, ctx.r25.u32);
	// mr r27,r25
	ctx.r27.u64 = ctx.r25.u64;
	// stw r25,7108(r30)
	PPC_STORE_U32(ctx.r30.u32 + 7108, ctx.r25.u32);
	// mr r26,r25
	ctx.r26.u64 = ctx.r25.u64;
	// addi r29,r30,1956
	ctx.r29.s64 = ctx.r30.s64 + 1956;
	// li r24,16
	ctx.r24.s64 = 16;
	// li r19,13
	ctx.r19.s64 = 13;
	// rldicr r22,r11,63,63
	ctx.r22.u64 = rotl64(ctx.r11.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// lwz r21,88(r1)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_821134B8:
	// stw r23,16(r29)
	PPC_STORE_U32(ctx.r29.u32 + 16, ctx.r23.u32);
	// addi r10,r27,32
	ctx.r10.s64 = ctx.r27.s64 + 32;
	// addi r11,r26,1152
	ctx.r11.s64 = ctx.r26.s64 + 1152;
	// clrldi r9,r10,32
	ctx.r9.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// li r5,1
	ctx.r5.s64 = 1;
	// srd r18,r22,r9
	ctx.r18.u64 = ctx.r9.u8 & 0x40 ? 0 : (ctx.r22.u64 >> (ctx.r9.u8 & 0x7F));
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// lwzx r7,r11,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// rlwimi r7,r28,11,19,21
	ctx.r7.u64 = (rotl32(ctx.r28.u32, 11) & 0x1C00) | (ctx.r7.u64 & 0xFFFFFFFFFFFFE3FF);
	// stwx r7,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r7.u32);
	// ld r6,24(r10)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// or r3,r18,r6
	ctx.r3.u64 = ctx.r18.u64 | ctx.r6.u64;
	// std r3,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r3.u64);
	// stw r23,32(r29)
	PPC_STORE_U32(ctx.r29.u32 + 32, ctx.r23.u32);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// lwzx r8,r11,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// rlwimi r8,r28,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r28.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stwx r8,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r8.u32);
	// ld r7,24(r10)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// or r6,r18,r7
	ctx.r6.u64 = ctx.r18.u64 | ctx.r7.u64;
	// std r6,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r6.u64);
	// stw r23,48(r29)
	PPC_STORE_U32(ctx.r29.u32 + 48, ctx.r23.u32);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// rlwimi r9,r28,17,13,15
	ctx.r9.u64 = (rotl32(ctx.r28.u32, 17) & 0x70000) | (ctx.r9.u64 & 0xFFFFFFFFFFF8FFFF);
	// stwx r9,r11,r10
	PPC_STORE_U32(ctx.r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// ld r8,24(r10)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// or r7,r18,r8
	ctx.r7.u64 = ctx.r18.u64 | ctx.r8.u64;
	// std r7,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r7.u64);
	// stw r25,64(r29)
	PPC_STORE_U32(ctx.r29.u32 + 64, ctx.r25.u32);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r11,r26,r10
	ctx.r11.u64 = ctx.r26.u64 + ctx.r10.u64;
	// lwz r6,1172(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// rlwinm r3,r6,0,0,29
	ctx.r3.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFC;
	// stw r3,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r3.u32);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// addi r10,r11,1172
	ctx.r10.s64 = ctx.r11.s64 + 1172;
	// ld r8,24(r9)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r9.u32 + 24);
	// or r7,r18,r8
	ctx.r7.u64 = ctx.r18.u64 | ctx.r8.u64;
	// std r7,24(r9)
	PPC_STORE_U64(ctx.r9.u32 + 24, ctx.r7.u64);
	// stw r28,80(r29)
	PPC_STORE_U32(ctx.r29.u32 + 80, ctx.r28.u32);
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x8222c248
	ctx.lr = 0x82113574;
	sub_8222C248(ctx, base);
	// stw r28,96(r29)
	PPC_STORE_U32(ctx.r29.u32 + 96, ctx.r28.u32);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x8222c0a0
	ctx.lr = 0x82113584;
	sub_8222C0A0(ctx, base);
	// stw r28,112(r29)
	PPC_STORE_U32(ctx.r29.u32 + 112, ctx.r28.u32);
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r11,r26,r10
	ctx.r11.u64 = ctx.r26.u64 + ctx.r10.u64;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// addi r10,r11,1164
	ctx.r10.s64 = ctx.r11.s64 + 1164;
	// lwz r6,1164(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r6,r28,23,7,8
	ctx.r6.u64 = (rotl32(ctx.r28.u32, 23) & 0x1800000) | (ctx.r6.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r6,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r6.u32);
	// ld r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 24);
	// or r10,r18,r11
	ctx.r10.u64 = ctx.r18.u64 | ctx.r11.u64;
	// std r10,24(r3)
	PPC_STORE_U64(ctx.r3.u32 + 24, ctx.r10.u64);
	// stw r21,128(r29)
	PPC_STORE_U32(ctx.r29.u32 + 128, ctx.r21.u32);
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x8222c608
	ctx.lr = 0x821135C4;
	sub_8222C608(ctx, base);
	// stw r25,144(r29)
	PPC_STORE_U32(ctx.r29.u32 + 144, ctx.r25.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x8222c6b0
	ctx.lr = 0x821135D4;
	sub_8222C6B0(ctx, base);
	// stw r28,160(r29)
	PPC_STORE_U32(ctx.r29.u32 + 160, ctx.r28.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x8222c4e8
	ctx.lr = 0x821135E4;
	sub_8222C4E8(ctx, base);
	// stw r28,176(r29)
	PPC_STORE_U32(ctx.r29.u32 + 176, ctx.r28.u32);
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x8222c348
	ctx.lr = 0x821135F0;
	sub_8222C348(ctx, base);
	// stw r28,192(r29)
	PPC_STORE_U32(ctx.r29.u32 + 192, ctx.r28.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x8222c1a0
	ctx.lr = 0x82113604;
	sub_8222C1A0(ctx, base);
	// stw r25,208(r29)
	PPC_STORE_U32(ctx.r29.u32 + 208, ctx.r25.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x8222c440
	ctx.lr = 0x82113618;
	sub_8222C440(ctx, base);
	// stw r19,224(r29)
	PPC_STORE_U32(ctx.r29.u32 + 224, ctx.r19.u32);
	// li r5,13
	ctx.r5.s64 = 13;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x8222c730
	ctx.lr = 0x8211362C;
	sub_8222C730(ctx, base);
	// stw r25,240(r29)
	PPC_STORE_U32(ctx.r29.u32 + 240, ctx.r25.u32);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r11,r26,r10
	ctx.r11.u64 = ctx.r26.u64 + ctx.r10.u64;
	// lwz r8,1172(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// mr r5,r20
	ctx.r5.u64 = ctx.r20.u64;
	// rlwinm r7,r8,0,29,26
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFFFE7;
	// addi r10,r11,1172
	ctx.r10.s64 = ctx.r11.s64 + 1172;
	// stw r7,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r7.u32);
	// ld r6,24(r9)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r9.u32 + 24);
	// or r3,r18,r6
	ctx.r3.u64 = ctx.r18.u64 | ctx.r6.u64;
	// std r3,24(r9)
	PPC_STORE_U64(ctx.r9.u32 + 24, ctx.r3.u64);
	// stw r20,256(r29)
	PPC_STORE_U32(ctx.r29.u32 + 256, ctx.r20.u32);
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x8222c560
	ctx.lr = 0x82113668;
	sub_8222C560(ctx, base);
	// stw r25,272(r29)
	PPC_STORE_U32(ctx.r29.u32 + 272, ctx.r25.u32);
	// addic. r24,r24,-1
	ctx.xer.ca = ctx.r24.u32 > 0;
	ctx.r24.s64 = ctx.r24.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r11,r26,r10
	ctx.r11.u64 = ctx.r26.u64 + ctx.r10.u64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// addi r10,r11,1168
	ctx.r10.s64 = ctx.r11.s64 + 1168;
	// lwz r8,1168(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1168);
	// rlwinm r7,r8,0,10,4
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFF83FFFFF;
	// stw r7,1168(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1168, ctx.r7.u32);
	// ld r6,24(r9)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r9.u32 + 24);
	// or r5,r18,r6
	ctx.r5.u64 = ctx.r18.u64 | ctx.r6.u64;
	// std r5,24(r9)
	PPC_STORE_U64(ctx.r9.u32 + 24, ctx.r5.u64);
	// stw r25,288(r29)
	PPC_STORE_U32(ctx.r29.u32 + 288, ctx.r25.u32);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r11,r26,r10
	ctx.r11.u64 = ctx.r26.u64 + ctx.r10.u64;
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
	// addi r10,r11,1168
	ctx.r10.s64 = ctx.r11.s64 + 1168;
	// lwz r3,1168(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1168);
	// clrlwi r10,r3,5
	ctx.r10.u64 = ctx.r3.u32 & 0x7FFFFFF;
	// stw r10,1168(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1168, ctx.r10.u32);
	// ld r9,24(r4)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r4.u32 + 24);
	// or r8,r18,r9
	ctx.r8.u64 = ctx.r18.u64 | ctx.r9.u64;
	// std r8,24(r4)
	PPC_STORE_U64(ctx.r4.u32 + 24, ctx.r8.u64);
	// stw r25,304(r29)
	PPC_STORE_U32(ctx.r29.u32 + 304, ctx.r25.u32);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r11,r26,r10
	ctx.r11.u64 = ctx.r26.u64 + ctx.r10.u64;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addi r10,r11,1172
	ctx.r10.s64 = ctx.r11.s64 + 1172;
	// lwz r6,1172(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// rlwinm r5,r6,0,30,28
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// stw r5,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r5.u32);
	// ld r4,24(r7)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r7.u32 + 24);
	// or r3,r18,r4
	ctx.r3.u64 = ctx.r18.u64 | ctx.r4.u64;
	// std r3,24(r7)
	PPC_STORE_U64(ctx.r7.u32 + 24, ctx.r3.u64);
	// stwu r28,320(r29)
	ea = 320 + ctx.r29.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r29.u32 = ea;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r11,r26,r10
	ctx.r11.u64 = ctx.r26.u64 + ctx.r10.u64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// addi r10,r11,1156
	ctx.r10.s64 = ctx.r11.s64 + 1156;
	// addi r26,r26,24
	ctx.r26.s64 = ctx.r26.s64 + 24;
	// lwz r9,1156(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1156);
	// rlwinm r7,r9,0,21,19
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFFF7FF;
	// stw r7,1156(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1156, ctx.r7.u32);
	// ld r6,24(r8)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r8.u32 + 24);
	// or r5,r18,r6
	ctx.r5.u64 = ctx.r18.u64 | ctx.r6.u64;
	// std r5,24(r8)
	PPC_STORE_U64(ctx.r8.u32 + 24, ctx.r5.u64);
	// bne 0x821134b8
	if (!ctx.cr0.eq) goto loc_821134B8;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x820c0290
	ctx.lr = 0x82113730;
	sub_820C0290(ctx, base);
	// mr r28,r25
	ctx.r28.u64 = ctx.r25.u64;
	// li r29,41
	ctx.r29.s64 = 41;
loc_82113738:
	// addi r11,r30,7112
	ctx.r11.s64 = ctx.r30.s64 + 7112;
	// addi r10,r29,1
	ctx.r10.s64 = ctx.r29.s64 + 1;
	// rlwinm r9,r29,30,2,31
	ctx.r9.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 30) & 0x3FFFFFFF;
	// rlwinm r8,r10,30,2,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// li r6,2
	ctx.r6.s64 = 2;
	// stbx r25,r11,r28
	PPC_STORE_U8(ctx.r11.u32 + ctx.r28.u32, ctx.r25.u8);
	// subf r7,r9,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r9.s64;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// clrldi r3,r7,32
	ctx.r3.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// srad r11,r22,r3
	temp.u64 = ctx.r3.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r22.s64 < 0) & (((ctx.r22.s64 >> temp.u64) << temp.u64) != ctx.r22.s64);
	ctx.r11.s64 = ctx.r22.s64 >> temp.u64;
	// srd r7,r11,r9
	ctx.r7.u64 = ctx.r9.u8 & 0x40 ? 0 : (ctx.r11.u64 >> (ctx.r9.u8 & 0x7F));
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238048
	ctx.lr = 0x82113770;
	sub_82238048(ctx, base);
	// addi r29,r29,2
	ctx.r29.s64 = ctx.r29.s64 + 2;
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// cmpwi cr6,r29,53
	ctx.cr6.compare<int32_t>(ctx.r29.s32, 53, ctx.xer);
	// blt cr6,0x82113738
	if (ctx.cr6.lt) goto loc_82113738;
	// bl 0x82238ad0
	ctx.lr = 0x82113784;
	sub_82238AD0(ctx, base);
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// lfd f31,-128(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -128);
	// b 0x8233e490
	__restgprlr_18(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82113790"))) PPC_WEAK_FUNC(sub_82113790);
PPC_FUNC_IMPL(__imp__sub_82113790) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lis r10,2
	ctx.r10.s64 = 131072;
	// addi r8,r11,28184
	ctx.r8.s64 = ctx.r11.s64 + 28184;
	// ori r9,r10,2048
	ctx.r9.u64 = ctx.r10.u64 | 2048;
	// lwz r11,28184(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28184);
	// lwz r10,516(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 516);
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// stw r10,12284(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12284, ctx.r10.u32);
	// lwz r6,10548(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 10548);
	// lwz r5,12808(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12808);
	// subfic r4,r5,0
	ctx.xer.ca = ctx.r5.u32 <= 0;
	ctx.r4.s64 = 0 - ctx.r5.s64;
	// subfe r11,r3,r3
	temp.u8 = (~ctx.r3.u32 + ctx.r3.u32 < ~ctx.r3.u32) | (~ctx.r3.u32 + ctx.r3.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r3.u64 + ctx.r3.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 & ctx.r10.u64;
	// rlwimi r6,r10,1,30,30
	ctx.r6.u64 = (rotl32(ctx.r10.u32, 1) & 0x2) | (ctx.r6.u64 & 0xFFFFFFFFFFFFFFFD);
	// stw r6,10548(r7)
	PPC_STORE_U32(ctx.r7.u32 + 10548, ctx.r6.u32);
	// ld r6,16(r7)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r7.u32 + 16);
	// or r5,r6,r9
	ctx.r5.u64 = ctx.r6.u64 | ctx.r9.u64;
	// std r5,16(r7)
	PPC_STORE_U64(ctx.r7.u32 + 16, ctx.r5.u64);
	// lwz r11,532(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 532);
	// lwz r4,10548(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 10548);
	// rlwimi r4,r11,4,25,27
	ctx.r4.u64 = (rotl32(ctx.r11.u32, 4) & 0x70) | (ctx.r4.u64 & 0xFFFFFFFFFFFFFF8F);
	// stw r4,10548(r7)
	PPC_STORE_U32(ctx.r7.u32 + 10548, ctx.r4.u32);
	// ld r3,16(r7)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r7.u32 + 16);
	// or r11,r3,r9
	ctx.r11.u64 = ctx.r3.u64 | ctx.r9.u64;
	// std r11,16(r7)
	PPC_STORE_U64(ctx.r7.u32 + 16, ctx.r11.u64);
	// lwz r11,548(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 548);
	// lwz r10,10548(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 10548);
	// rlwimi r10,r11,2,29,29
	ctx.r10.u64 = (rotl32(ctx.r11.u32, 2) & 0x4) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFFB);
	// stw r10,10548(r7)
	PPC_STORE_U32(ctx.r7.u32 + 10548, ctx.r10.u32);
	// ld r6,16(r7)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r7.u32 + 16);
	// ori r5,r6,2048
	ctx.r5.u64 = ctx.r6.u64 | 2048;
	// std r5,16(r7)
	PPC_STORE_U64(ctx.r7.u32 + 16, ctx.r5.u64);
	// lwz r11,1892(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 1892);
	// lwz r4,12260(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12260);
	// rlwimi r4,r11,20,9,11
	ctx.r4.u64 = (rotl32(ctx.r11.u32, 20) & 0x700000) | (ctx.r4.u64 & 0xFFFFFFFFFF8FFFFF);
	// stw r4,12260(r7)
	PPC_STORE_U32(ctx.r7.u32 + 12260, ctx.r4.u32);
	// ld r3,16(r7)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r7.u32 + 16);
	// oris r11,r3,2
	ctx.r11.u64 = ctx.r3.u64 | 131072;
	// std r11,16(r7)
	PPC_STORE_U64(ctx.r7.u32 + 16, ctx.r11.u64);
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// lwz r4,1908(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 1908);
	// bl 0x8222bf58
	ctx.lr = 0x82113844;
	sub_8222BF58(ctx, base);
	// lwz r11,788(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 788);
	// stw r11,12288(r7)
	PPC_STORE_U32(ctx.r7.u32 + 12288, ctx.r11.u32);
	// lwz r10,10548(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 10548);
	// lwz r6,12808(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 12808);
	// subfic r5,r6,0
	ctx.xer.ca = ctx.r6.u32 <= 0;
	ctx.r5.s64 = 0 - ctx.r6.s64;
	// subfe r3,r4,r4
	temp.u8 = (~ctx.r4.u32 + ctx.r4.u32 < ~ctx.r4.u32) | (~ctx.r4.u32 + ctx.r4.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r3.u64 = ~ctx.r4.u64 + ctx.r4.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r11,r3,r11
	ctx.r11.u64 = ctx.r3.u64 & ctx.r11.u64;
	// rlwimi r11,r10,0,0,30
	ctx.r11.u64 = (rotl32(ctx.r10.u32, 0) & 0xFFFFFFFE) | (ctx.r11.u64 & 0xFFFFFFFF00000001);
	// stw r11,10548(r7)
	PPC_STORE_U32(ctx.r7.u32 + 10548, ctx.r11.u32);
	// ld r10,16(r7)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r7.u32 + 16);
	// or r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 | ctx.r9.u64;
	// std r9,16(r7)
	PPC_STORE_U64(ctx.r7.u32 + 16, ctx.r9.u64);
	// lwz r11,868(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 868);
	// lwz r6,10548(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 10548);
	// rlwimi r6,r11,8,21,23
	ctx.r6.u64 = (rotl32(ctx.r11.u32, 8) & 0x700) | (ctx.r6.u64 & 0xFFFFFFFFFFFFF8FF);
	// stw r6,10548(r7)
	PPC_STORE_U32(ctx.r7.u32 + 10548, ctx.r6.u32);
	// ld r5,16(r7)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r7.u32 + 16);
	// ori r4,r5,2048
	ctx.r4.u64 = ctx.r5.u64 | 2048;
	// std r4,16(r7)
	PPC_STORE_U64(ctx.r7.u32 + 16, ctx.r4.u64);
	// lwz r11,980(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 980);
	// lwz r3,10548(r7)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + 10548);
	// rlwimi r3,r11,20,9,11
	ctx.r3.u64 = (rotl32(ctx.r11.u32, 20) & 0x700000) | (ctx.r3.u64 & 0xFFFFFFFFFF8FFFFF);
	// stw r3,10548(r7)
	PPC_STORE_U32(ctx.r7.u32 + 10548, ctx.r3.u32);
	// ld r11,16(r7)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r7.u32 + 16);
	// ori r10,r11,2048
	ctx.r10.u64 = ctx.r11.u64 | 2048;
	// std r10,16(r7)
	PPC_STORE_U64(ctx.r7.u32 + 16, ctx.r10.u64);
	// lwz r11,1796(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 1796);
	// lwz r9,10560(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 10560);
	// rlwimi r9,r11,3,28,28
	ctx.r9.u64 = (rotl32(ctx.r11.u32, 3) & 0x8) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFF7);
	// stw r9,10560(r7)
	PPC_STORE_U32(ctx.r7.u32 + 10560, ctx.r9.u32);
	// ld r6,16(r7)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r7.u32 + 16);
	// ori r5,r6,256
	ctx.r5.u64 = ctx.r6.u64 | 256;
	// std r5,16(r7)
	PPC_STORE_U64(ctx.r7.u32 + 16, ctx.r5.u64);
	// lwz r11,1812(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 1812);
	// lwz r4,10560(r7)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + 10560);
	// rlwimi r4,r11,2,29,29
	ctx.r4.u64 = (rotl32(ctx.r11.u32, 2) & 0x4) | (ctx.r4.u64 & 0xFFFFFFFFFFFFFFFB);
	// stw r4,10560(r7)
	PPC_STORE_U32(ctx.r7.u32 + 10560, ctx.r4.u32);
	// ld r3,16(r7)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r7.u32 + 16);
	// ori r11,r3,256
	ctx.r11.u64 = ctx.r3.u64 | 256;
	// std r11,16(r7)
	PPC_STORE_U64(ctx.r7.u32 + 16, ctx.r11.u64);
	// lwz r11,1828(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 1828);
	// lwz r10,10560(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 10560);
	// rlwimi r10,r11,5,26,26
	ctx.r10.u64 = (rotl32(ctx.r11.u32, 5) & 0x20) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFDF);
	// stw r10,10560(r7)
	PPC_STORE_U32(ctx.r7.u32 + 10560, ctx.r10.u32);
	// ld r9,16(r7)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r7.u32 + 16);
	// ori r8,r9,256
	ctx.r8.u64 = ctx.r9.u64 | 256;
	// std r8,16(r7)
	PPC_STORE_U64(ctx.r7.u32 + 16, ctx.r8.u64);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82113910"))) PPC_WEAK_FUNC(sub_82113910);
PPC_FUNC_IMPL(__imp__sub_82113910) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lfs f0,8(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f13,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fctiwz f12,f0
	ctx.f12.u64 = uint64_t(int32_t(std::trunc(ctx.f0.f64)));
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fctiwz f10,f13
	ctx.f10.u64 = uint64_t(int32_t(std::trunc(ctx.f13.f64)));
	// lfs f8,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// fctiwz f9,f11
	ctx.f9.u64 = uint64_t(int32_t(std::trunc(ctx.f11.f64)));
	// stfd f12,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f12.u64);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// lwz r9,92(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fctiwz f7,f8
	ctx.f7.u64 = uint64_t(int32_t(std::trunc(ctx.f8.f64)));
	// stfd f9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f9.u64);
	// stfd f7,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f7.u64);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r5,92(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r7,r11,31376
	ctx.r7.s64 = ctx.r11.s64 + 31376;
	// stw r10,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r10.u32);
	// lis r6,-32183
	ctx.r6.s64 = -2109145088;
	// lfs f0,36(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stw r9,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r9.u32);
	// lfs f13,48(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// stfs f0,112(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stw r8,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r8.u32);
	// stfs f13,116(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stw r5,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r5.u32);
	// lwz r3,28184(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 28184);
	// bl 0x8222cbc8
	ctx.lr = 0x82113994;
	sub_8222CBC8(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821139A4"))) PPC_WEAK_FUNC(sub_821139A4);
PPC_FUNC_IMPL(__imp__sub_821139A4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821139A8"))) PPC_WEAK_FUNC(sub_821139A8);
PPC_FUNC_IMPL(__imp__sub_821139A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x821139B0;
	__restfpr_28(ctx, base);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r5,64
	ctx.r5.s64 = 64;
	// lwz r28,28184(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28184);
	// addi r3,r31,100
	ctx.r3.s64 = ctx.r31.s64 + 100;
	// bl 0x8233e4e0
	ctx.lr = 0x821139D8;
	sub_8233E4E0(ctx, base);
	// addi r3,r31,164
	ctx.r3.s64 = ctx.r31.s64 + 164;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// li r5,64
	ctx.r5.s64 = 64;
	// bl 0x8233e4e0
	ctx.lr = 0x821139E8;
	sub_8233E4E0(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,36
	ctx.r3.s64 = ctx.r31.s64 + 36;
	// bl 0x822578d8
	ctx.lr = 0x821139F8;
	sub_822578D8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r31,36
	ctx.r4.s64 = ctx.r31.s64 + 36;
	// bl 0x82257a50
	ctx.lr = 0x82113A04;
	sub_82257A50(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// rldicr r7,r7,63,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82238048
	ctx.lr = 0x82113A20;
	sub_82238048(ctx, base);
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,4
	ctx.r6.s64 = 4;
	// rldicr r7,r7,62,1
	ctx.r7.u64 = rotl64(ctx.r7.u64, 62) & 0xC000000000000000;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x82238120
	ctx.lr = 0x82113A38;
	sub_82238120(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r31,100
	ctx.r4.s64 = ctx.r31.s64 + 100;
	// bl 0x82257a50
	ctx.lr = 0x82113A44;
	sub_82257A50(ctx, base);
	// li r7,3
	ctx.r7.s64 = 3;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// rldicr r7,r7,61,2
	ctx.r7.u64 = rotl64(ctx.r7.u64, 61) & 0xE000000000000000;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,7
	ctx.r4.s64 = 7;
	// bl 0x82238048
	ctx.lr = 0x82113A60;
	sub_82238048(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,4
	ctx.r6.s64 = 4;
	// rldicr r7,r7,63,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82238120
	ctx.lr = 0x82113A78;
	sub_82238120(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r5,r31,100
	ctx.r5.s64 = ctx.r31.s64 + 100;
	// bl 0x82257cb8
	ctx.lr = 0x82113A88;
	sub_82257CB8(ctx, base);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82257a50
	ctx.lr = 0x82113A94;
	sub_82257A50(ctx, base);
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,3
	ctx.r6.s64 = 3;
	// rldicr r7,r7,61,2
	ctx.r7.u64 = rotl64(ctx.r7.u64, 61) & 0xE000000000000000;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,7
	ctx.r4.s64 = 7;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82238120
	ctx.lr = 0x82113AB0;
	sub_82238120(ctx, base);
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82113AB8"))) PPC_WEAK_FUNC(sub_82113AB8);
PPC_FUNC_IMPL(__imp__sub_82113AB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x82113AC0;
	__restfpr_29(ctx, base);
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82113b5c
	if (!ctx.cr6.eq) goto loc_82113B5C;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lis r30,-32183
	ctx.r30.s64 = -2109145088;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,3
	ctx.r6.s64 = 3;
	// rldicr r7,r7,62,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 62) & 0xFFFFFFFFFFFFFFFF;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r3,28184(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28184);
	// lfs f0,48(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// li r4,4
	ctx.r4.s64 = 4;
	// lfs f13,36(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// addi r31,r30,28184
	ctx.r31.s64 = ctx.r30.s64 + 28184;
	// stfs f0,136(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f0,132(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stfs f0,128(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f0,124(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f0,112(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f0,104(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f0,92(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f13,140(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// stfs f13,120(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// bl 0x82238048
	ctx.lr = 0x82113B44;
	sub_82238048(ctx, base);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// addi r4,r31,100
	ctx.r4.s64 = ctx.r31.s64 + 100;
	// bl 0x82257a50
	ctx.lr = 0x82113B50;
	sub_82257A50(ctx, base);
	// lwz r3,28184(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28184);
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// b 0x82113ba4
	goto loc_82113BA4;
loc_82113B5C:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x82257a50
	ctx.lr = 0x82113B68;
	sub_82257A50(ctx, base);
	// lis r29,-32183
	ctx.r29.s64 = -2109145088;
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,3
	ctx.r6.s64 = 3;
	// rldicr r7,r7,62,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 62) & 0xFFFFFFFFFFFFFFFF;
	// addi r5,r1,208
	ctx.r5.s64 = ctx.r1.s64 + 208;
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r3,28184(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28184);
	// addi r30,r29,28184
	ctx.r30.s64 = ctx.r29.s64 + 28184;
	// bl 0x82238048
	ctx.lr = 0x82113B8C;
	sub_82238048(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r1,272
	ctx.r3.s64 = ctx.r1.s64 + 272;
	// addi r5,r30,100
	ctx.r5.s64 = ctx.r30.s64 + 100;
	// bl 0x82257b38
	ctx.lr = 0x82113B9C;
	sub_82257B38(ctx, base);
	// lwz r3,28184(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28184);
	// addi r5,r1,272
	ctx.r5.s64 = ctx.r1.s64 + 272;
loc_82113BA4:
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,4
	ctx.r6.s64 = 4;
	// rldicr r7,r7,60,3
	ctx.r7.u64 = rotl64(ctx.r7.u64, 60) & 0xF000000000000000;
	// li r4,11
	ctx.r4.s64 = 11;
	// bl 0x82238048
	ctx.lr = 0x82113BB8;
	sub_82238048(ctx, base);
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82113BC0"))) PPC_WEAK_FUNC(sub_82113BC0);
PPC_FUNC_IMPL(__imp__sub_82113BC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r10,r11,28184
	ctx.r10.s64 = ctx.r11.s64 + 28184;
	// li r3,100
	ctx.r3.s64 = 100;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// stw r31,288(r10)
	PPC_STORE_U32(ctx.r10.u32 + 288, ctx.r31.u32);
	// bl 0x82111340
	ctx.lr = 0x82113BF0;
	sub_82111340(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// li r3,96
	ctx.r3.s64 = 96;
	// li r4,1
	ctx.r4.s64 = 1;
	// bne cr6,0x82113c04
	if (!ctx.cr6.eq) goto loc_82113C04;
	// li r4,0
	ctx.r4.s64 = 0;
loc_82113C04:
	// bl 0x82111340
	ctx.lr = 0x82113C08;
	sub_82111340(ctx, base);
	// clrlwi r11,r31,31
	ctx.r11.u64 = ctx.r31.u32 & 0x1;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bne cr6,0x82113c2c
	if (!ctx.cr6.eq) goto loc_82113C2C;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x82113C20;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,308
	ctx.r3.s64 = 308;
	// b 0x82113ca4
	goto loc_82113CA4;
loc_82113C2C:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x82113C38;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x82113C44;
	sub_82111340(ctx, base);
	// rlwinm r11,r31,0,23,23
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x100;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82113c58
	if (ctx.cr6.eq) goto loc_82113C58;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x82113c68
	goto loc_82113C68;
loc_82113C58:
	// rlwinm r11,r31,0,22,22
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x200;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// beq cr6,0x82113c70
	if (ctx.cr6.eq) goto loc_82113C70;
	// li r4,4
	ctx.r4.s64 = 4;
loc_82113C68:
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x82113C70;
	sub_82111340(ctx, base);
loc_82113C70:
	// rlwinm r11,r31,0,19,19
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x1000;
	// li r3,72
	ctx.r3.s64 = 72;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// li r4,6
	ctx.r4.s64 = 6;
	// bne cr6,0x82113c88
	if (!ctx.cr6.eq) goto loc_82113C88;
	// li r4,1
	ctx.r4.s64 = 1;
loc_82113C88:
	// bl 0x82111340
	ctx.lr = 0x82113C8C;
	sub_82111340(ctx, base);
	// rlwinm r11,r31,0,18,18
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0x2000;
	// li r3,76
	ctx.r3.s64 = 76;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// li r4,7
	ctx.r4.s64 = 7;
	// bne cr6,0x82113ca4
	if (!ctx.cr6.eq) goto loc_82113CA4;
	// li r4,1
	ctx.r4.s64 = 1;
loc_82113CA4:
	// bl 0x82111340
	ctx.lr = 0x82113CA8;
	sub_82111340(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82113CC0"))) PPC_WEAK_FUNC(sub_82113CC0);
PPC_FUNC_IMPL(__imp__sub_82113CC0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r30,0
	ctx.r30.s64 = 0;
	// li r4,4000
	ctx.r4.s64 = 4000;
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r30.u32);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// stw r30,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r30.u32);
	// stw r30,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r30.u32);
	// bl 0x82305000
	ctx.lr = 0x82113CF8;
	sub_82305000(ctx, base);
	// stw r30,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r30.u32);
	// stw r30,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r30.u32);
	// addi r3,r31,20
	ctx.r3.s64 = ctx.r31.s64 + 20;
	// stw r30,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r30.u32);
	// li r4,4000
	ctx.r4.s64 = 4000;
	// stw r30,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r30.u32);
	// stw r30,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r30.u32);
	// bl 0x82305000
	ctx.lr = 0x82113D18;
	sub_82305000(ctx, base);
	// stw r30,2344(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2344, ctx.r30.u32);
	// stw r30,2348(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2348, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,2180
	ctx.r3.s64 = 2180;
	// bl 0x82082030
	ctx.lr = 0x82113D34;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82113d54
	if (ctx.cr6.eq) goto loc_82113D54;
	// li r10,109
	ctx.r10.s64 = 109;
	// addi r11,r3,-4
	ctx.r11.s64 = ctx.r3.s64 + -4;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_82113D48:
	// stwu r30,20(r11)
	ea = 20 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r30.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x82113d48
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82113D48;
	// b 0x82113d58
	goto loc_82113D58;
loc_82113D54:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_82113D58:
	// li r11,109
	ctx.r11.s64 = 109;
	// stw r3,2352(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2352, ctx.r3.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
loc_82113D68:
	// lwz r11,2352(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2352);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r10,r10,20
	ctx.r10.s64 = ctx.r10.s64 + 20;
	// stw r11,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r11.u32);
	// stw r11,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r11.u32);
	// bdnz 0x82113d68
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82113D68;
	// li r11,109
	ctx.r11.s64 = 109;
	// stw r30,2360(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2360, ctx.r30.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r11.u32);
	// stw r30,2364(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2364, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82113DAC"))) PPC_WEAK_FUNC(sub_82113DAC);
PPC_FUNC_IMPL(__imp__sub_82113DAC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82113DB0"))) PPC_WEAK_FUNC(sub_82113DB0);
PPC_FUNC_IMPL(__imp__sub_82113DB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r31,r11,-30232
	ctx.r31.s64 = ctx.r11.s64 + -30232;
	// addi r3,r31,20
	ctx.r3.s64 = ctx.r31.s64 + 20;
	// bl 0x823052d8
	ctx.lr = 0x82113DD4;
	sub_823052D8(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r31,2352
	ctx.r4.s64 = ctx.r31.s64 + 2352;
	// bl 0x82115768
	ctx.lr = 0x82113DE0;
	sub_82115768(ctx, base);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82113e18
	if (ctx.cr6.eq) goto loc_82113E18;
loc_82113DEC:
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82113e04
	if (ctx.cr6.eq) goto loc_82113E04;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82113E04;
	sub_82080000(ctx, base);
loc_82113E04:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82115958
	ctx.lr = 0x82113E0C;
	sub_82115958(ctx, base);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82113dec
	if (!ctx.cr6.eq) goto loc_82113DEC;
loc_82113E18:
	// addi r3,r31,2352
	ctx.r3.s64 = ctx.r31.s64 + 2352;
	// bl 0x82115858
	ctx.lr = 0x82113E20;
	sub_82115858(ctx, base);
	// addi r3,r31,20
	ctx.r3.s64 = ctx.r31.s64 + 20;
	// bl 0x823051a8
	ctx.lr = 0x82113E28;
	sub_823051A8(ctx, base);
	// addi r3,r31,2352
	ctx.r3.s64 = ctx.r31.s64 + 2352;
	// bl 0x82115858
	ctx.lr = 0x82113E30;
	sub_82115858(ctx, base);
	// lwz r11,2352(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2352);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82113e48
	if (ctx.cr6.eq) goto loc_82113E48;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82113E48;
	sub_82080000(ctx, base);
loc_82113E48:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82113e5c
	if (ctx.cr6.eq) goto loc_82113E5C;
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// bl 0x82246e18
	ctx.lr = 0x82113E5C;
	sub_82246E18(ctx, base);
loc_82113E5C:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82113e70
	if (ctx.cr6.eq) goto loc_82113E70;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82113E70;
	sub_82246E18(ctx, base);
loc_82113E70:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82113E84"))) PPC_WEAK_FUNC(sub_82113E84);
PPC_FUNC_IMPL(__imp__sub_82113E84) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82113E88"))) PPC_WEAK_FUNC(sub_82113E88);
PPC_FUNC_IMPL(__imp__sub_82113E88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e450
	ctx.lr = 0x82113E90;
	__restfpr_22(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r30,r11,-30232
	ctx.r30.s64 = ctx.r11.s64 + -30232;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r3,r30,20
	ctx.r3.s64 = ctx.r30.s64 + 20;
	// bl 0x823052d8
	ctx.lr = 0x82113EAC;
	sub_823052D8(ctx, base);
	// lwz r11,2344(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2344);
	// lwz r10,2348(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2348);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82114004
	if (ctx.cr6.eq) goto loc_82114004;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// lis r8,-32249
	ctx.r8.s64 = -2113470464;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// clrlwi r23,r31,24
	ctx.r23.u64 = ctx.r31.u32 & 0xFF;
	// lis r22,-32768
	ctx.r22.s64 = -2147483648;
	// lis r27,-13569
	ctx.r27.s64 = -889257984;
	// addi r26,r9,-30048
	ctx.r26.s64 = ctx.r9.s64 + -30048;
	// addi r25,r8,-30108
	ctx.r25.s64 = ctx.r8.s64 + -30108;
	// addi r24,r10,-30344
	ctx.r24.s64 = ctx.r10.s64 + -30344;
	// addi r28,r11,-27800
	ctx.r28.s64 = ctx.r11.s64 + -27800;
loc_82113EE8:
	// lwz r11,2344(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2344);
	// addi r10,r30,40
	ctx.r10.s64 = ctx.r30.s64 + 40;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r11,r10
	ctx.r31.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bne cr6,0x82113f24
	if (!ctx.cr6.eq) goto loc_82113F24;
	// lwz r10,2144(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2144);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bgt cr6,0x82114004
	if (ctx.cr6.gt) goto loc_82114004;
	// subf r11,r11,r10
	ctx.r11.s64 = ctx.r10.s64 - ctx.r11.s64;
	// cmplw cr6,r11,r22
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r22.u32, ctx.xer);
	// bgt cr6,0x82114004
	if (ctx.cr6.gt) goto loc_82114004;
loc_82113F24:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82113f80
	if (ctx.cr6.lt) goto loc_82113F80;
	// beq cr6,0x82113f50
	if (ctx.cr6.eq) goto loc_82113F50;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// blt cr6,0x82113f44
	if (ctx.cr6.lt) goto loc_82113F44;
	// stw r24,-13570(r27)
	PPC_STORE_U32(ctx.r27.u32 + -13570, ctx.r24.u32);
	// b 0x82113fd4
	goto loc_82113FD4;
loc_82113F44:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82115568
	ctx.lr = 0x82113F4C;
	sub_82115568(ctx, base);
	// b 0x82113fd4
	goto loc_82113FD4;
loc_82113F50:
	// addi r5,r31,4
	ctx.r5.s64 = ctx.r31.s64 + 4;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r30,2352
	ctx.r4.s64 = ctx.r30.s64 + 2352;
	// bl 0x820f6340
	ctx.lr = 0x82113F60;
	sub_820F6340(ctx, base);
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82113f70
	if (!ctx.cr6.eq) goto loc_82113F70;
	// stw r26,-13570(r27)
	PPC_STORE_U32(ctx.r27.u32 + -13570, ctx.r26.u32);
loc_82113F70:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// lwz r3,12(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// bl 0x82115648
	ctx.lr = 0x82113F7C;
	sub_82115648(ctx, base);
	// b 0x82113fd4
	goto loc_82113FD4;
loc_82113F80:
	// addi r29,r31,4
	ctx.r29.s64 = ctx.r31.s64 + 4;
	// addi r4,r30,2352
	ctx.r4.s64 = ctx.r30.s64 + 2352;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x820f6340
	ctx.lr = 0x82113F94;
	sub_820F6340(ctx, base);
	// lwz r11,96(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82113fa4
	if (ctx.cr6.eq) goto loc_82113FA4;
	// stw r25,-13570(r27)
	PPC_STORE_U32(ctx.r27.u32 + -13570, ctx.r25.u32);
loc_82113FA4:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,3036
	ctx.r3.s64 = 3036;
	// bl 0x82082030
	ctx.lr = 0x82113FB8;
	sub_82082030(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// stw r3,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r3.u32);
	// bl 0x82115648
	ctx.lr = 0x82113FC4;
	sub_82115648(ctx, base);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r3,r30,2352
	ctx.r3.s64 = ctx.r30.s64 + 2352;
	// bl 0x82115a70
	ctx.lr = 0x82113FD4;
	sub_82115A70(ctx, base);
loc_82113FD4:
	// lwz r11,2344(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2344);
	// cmplwi cr6,r11,63
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 63, ctx.xer);
	// bne cr6,0x82113fe8
	if (!ctx.cr6.eq) goto loc_82113FE8;
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82113ff0
	goto loc_82113FF0;
loc_82113FE8:
	// lwz r11,2344(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2344);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
loc_82113FF0:
	// stw r11,2344(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2344, ctx.r11.u32);
	// lwz r11,2344(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2344);
	// lwz r10,2348(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2348);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// bne cr6,0x82113ee8
	if (!ctx.cr6.eq) goto loc_82113EE8;
loc_82114004:
	// addi r3,r30,20
	ctx.r3.s64 = ctx.r30.s64 + 20;
	// bl 0x823051a8
	ctx.lr = 0x8211400C;
	sub_823051A8(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e4a0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82114014"))) PPC_WEAK_FUNC(sub_82114014);
PPC_FUNC_IMPL(__imp__sub_82114014) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82114018"))) PPC_WEAK_FUNC(sub_82114018);
PPC_FUNC_IMPL(__imp__sub_82114018) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e434
	ctx.lr = 0x82114020;
	__restfpr_15(ctx, base);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// lis r8,-32178
	ctx.r8.s64 = -2108817408;
	// lis r7,-32178
	ctx.r7.s64 = -2108817408;
	// li r30,0
	ctx.r30.s64 = 0;
	// lbz r6,25549(r11)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r11.u32 + 25549);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// stw r3,25568(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25568, ctx.r3.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r4,25572(r8)
	PPC_STORE_U32(ctx.r8.u32 + 25572, ctx.r4.u32);
	// li r24,4
	ctx.r24.s64 = 4;
	// stw r30,25576(r7)
	PPC_STORE_U32(ctx.r7.u32 + 25576, ctx.r30.u32);
	// li r23,2
	ctx.r23.s64 = 2;
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// bne cr6,0x8211406c
	if (!ctx.cr6.eq) goto loc_8211406C;
	// li r24,2
	ctx.r24.s64 = 2;
	// li r23,1
	ctx.r23.s64 = 1;
loc_8211406C:
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// lis r4,6184
	ctx.r4.s64 = 405274624;
	// addi r31,r11,-3072
	ctx.r31.s64 = ctx.r11.s64 + -3072;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// ori r4,r4,310
	ctx.r4.u64 = ctx.r4.u64 | 310;
	// addi r3,r31,96
	ctx.r3.s64 = ctx.r31.s64 + 96;
	// bl 0x82115e10
	ctx.lr = 0x821140A0;
	sub_82115E10(ctx, base);
	// lis r11,6690
	ctx.r11.s64 = 438435840;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// ori r27,r11,346
	ctx.r27.u64 = ctx.r11.u64 | 346;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,-11
	ctx.r5.s64 = -11;
	// addi r3,r31,192
	ctx.r3.s64 = ctx.r31.s64 + 192;
	// bl 0x82115e10
	ctx.lr = 0x821140D0;
	sub_82115E10(ctx, base);
	// lis r10,6690
	ctx.r10.s64 = 438435840;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// ori r21,r10,407
	ctx.r21.u64 = ctx.r10.u64 | 407;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// bl 0x82115e10
	ctx.lr = 0x82114100;
	sub_82115E10(ctx, base);
	// lis r9,11552
	ctx.r9.s64 = 757071872;
	// li r8,1
	ctx.r8.s64 = 1;
	// ori r22,r9,406
	ctx.r22.u64 = ctx.r9.u64 | 406;
	// stb r8,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r8.u8);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// li r8,2048
	ctx.r8.s64 = 2048;
	// li r7,2048
	ctx.r7.s64 = 2048;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// addi r3,r31,288
	ctx.r3.s64 = ctx.r31.s64 + 288;
	// bl 0x82115e10
	ctx.lr = 0x82114134;
	sub_82115E10(ctx, base);
	// lis r4,6690
	ctx.r4.s64 = 438435840;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,-15
	ctx.r5.s64 = -15;
	// ori r4,r4,21850
	ctx.r4.u64 = ctx.r4.u64 | 21850;
	// addi r3,r31,384
	ctx.r3.s64 = ctx.r31.s64 + 384;
	// bl 0x82115e10
	ctx.lr = 0x82114160;
	sub_82115E10(ctx, base);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,-11
	ctx.r5.s64 = -11;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// addi r3,r31,480
	ctx.r3.s64 = ctx.r31.s64 + 480;
	// bl 0x82115e10
	ctx.lr = 0x82114188;
	sub_82115E10(ctx, base);
	// lis r7,6184
	ctx.r7.s64 = 405274624;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// ori r25,r7,390
	ctx.r25.u64 = ctx.r7.u64 | 390;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// addi r3,r31,576
	ctx.r3.s64 = ctx.r31.s64 + 576;
	// bl 0x82115e10
	ctx.lr = 0x821141B8;
	sub_82115E10(ctx, base);
	// lis r4,1168
	ctx.r4.s64 = 76546048;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// ori r4,r4,258
	ctx.r4.u64 = ctx.r4.u64 | 258;
	// addi r3,r31,672
	ctx.r3.s64 = ctx.r31.s64 + 672;
	// bl 0x82115e10
	ctx.lr = 0x821141E4;
	sub_82115E10(ctx, base);
	// lis r6,6688
	ctx.r6.s64 = 438304768;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// ori r26,r6,32690
	ctx.r26.u64 = ctx.r6.u64 | 32690;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,768
	ctx.r3.s64 = ctx.r31.s64 + 768;
	// bl 0x82115e10
	ctx.lr = 0x82114214;
	sub_82115E10(ctx, base);
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,864
	ctx.r3.s64 = ctx.r31.s64 + 864;
	// bl 0x82115e10
	ctx.lr = 0x8211423C;
	sub_82115E10(ctx, base);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r21
	ctx.r4.u64 = ctx.r21.u64;
	// addi r3,r31,960
	ctx.r3.s64 = ctx.r31.s64 + 960;
	// bl 0x82115e10
	ctx.lr = 0x82114264;
	sub_82115E10(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,-11
	ctx.r5.s64 = -11;
	// addi r3,r31,1056
	ctx.r3.s64 = ctx.r31.s64 + 1056;
	// bl 0x82115e10
	ctx.lr = 0x8211428C;
	sub_82115E10(ctx, base);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// addi r3,r31,1152
	ctx.r3.s64 = ctx.r31.s64 + 1152;
	// bl 0x82115e10
	ctx.lr = 0x821142B4;
	sub_82115E10(ctx, base);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,-11
	ctx.r5.s64 = -11;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// addi r3,r31,1248
	ctx.r3.s64 = ctx.r31.s64 + 1248;
	// bl 0x82115e10
	ctx.lr = 0x821142DC;
	sub_82115E10(ctx, base);
	// lis r5,6184
	ctx.r5.s64 = 405274624;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// ori r17,r5,438
	ctx.r17.u64 = ctx.r5.u64 | 438;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r17
	ctx.r4.u64 = ctx.r17.u64;
	// addi r3,r31,1344
	ctx.r3.s64 = ctx.r31.s64 + 1344;
	// bl 0x82115e10
	ctx.lr = 0x8211430C;
	sub_82115E10(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,1440
	ctx.r3.s64 = ctx.r31.s64 + 1440;
	// bl 0x82115e10
	ctx.lr = 0x82114334;
	sub_82115E10(ctx, base);
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// li r5,-11
	ctx.r5.s64 = -11;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// addi r3,r31,1536
	ctx.r3.s64 = ctx.r31.s64 + 1536;
	// bl 0x82115e10
	ctx.lr = 0x8211435C;
	sub_82115E10(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r6,r24
	ctx.r6.u64 = ctx.r24.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,1632
	ctx.r3.s64 = ctx.r31.s64 + 1632;
	// bl 0x82115e10
	ctx.lr = 0x82114384;
	sub_82115E10(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,1728
	ctx.r3.s64 = ctx.r31.s64 + 1728;
	// bl 0x82115e10
	ctx.lr = 0x821143AC;
	sub_82115E10(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,1824
	ctx.r3.s64 = ctx.r31.s64 + 1824;
	// bl 0x82115e10
	ctx.lr = 0x821143D4;
	sub_82115E10(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,1920
	ctx.r3.s64 = ctx.r31.s64 + 1920;
	// bl 0x82115e10
	ctx.lr = 0x821143FC;
	sub_82115E10(ctx, base);
	// lis r4,1168
	ctx.r4.s64 = 76546048;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// ori r4,r4,258
	ctx.r4.u64 = ctx.r4.u64 | 258;
	// addi r3,r31,2016
	ctx.r3.s64 = ctx.r31.s64 + 2016;
	// bl 0x82115e10
	ctx.lr = 0x82114428;
	sub_82115E10(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,2112
	ctx.r3.s64 = ctx.r31.s64 + 2112;
	// bl 0x82115e10
	ctx.lr = 0x82114450;
	sub_82115E10(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// li r5,-11
	ctx.r5.s64 = -11;
	// addi r3,r31,2208
	ctx.r3.s64 = ctx.r31.s64 + 2208;
	// bl 0x82115e10
	ctx.lr = 0x82114478;
	sub_82115E10(ctx, base);
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,2304
	ctx.r3.s64 = ctx.r31.s64 + 2304;
	// bl 0x82115e10
	ctx.lr = 0x821144A0;
	sub_82115E10(ctx, base);
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,-11
	ctx.r5.s64 = -11;
	// addi r3,r31,2400
	ctx.r3.s64 = ctx.r31.s64 + 2400;
	// bl 0x82115e10
	ctx.lr = 0x821144C8;
	sub_82115E10(ctx, base);
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// addi r3,r31,2496
	ctx.r3.s64 = ctx.r31.s64 + 2496;
	// bl 0x82115e10
	ctx.lr = 0x821144F0;
	sub_82115E10(ctx, base);
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,-11
	ctx.r5.s64 = -11;
	// addi r3,r31,2592
	ctx.r3.s64 = ctx.r31.s64 + 2592;
	// bl 0x82115e10
	ctx.lr = 0x82114518;
	sub_82115E10(ctx, base);
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// li r5,-11
	ctx.r5.s64 = -11;
	// addi r3,r31,2688
	ctx.r3.s64 = ctx.r31.s64 + 2688;
	// bl 0x82115e10
	ctx.lr = 0x82114540;
	sub_82115E10(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,2
	ctx.r6.s64 = 2;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r3,r31,2784
	ctx.r3.s64 = ctx.r31.s64 + 2784;
	// bl 0x82115e10
	ctx.lr = 0x82114568;
	sub_82115E10(ctx, base);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// addi r3,r31,2880
	ctx.r3.s64 = ctx.r31.s64 + 2880;
	// bl 0x82115e10
	ctx.lr = 0x82114590;
	sub_82115E10(ctx, base);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// addi r3,r31,2976
	ctx.r3.s64 = ctx.r31.s64 + 2976;
	// bl 0x82115e10
	ctx.lr = 0x821145B8;
	sub_82115E10(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,-11
	ctx.r5.s64 = -11;
	// addi r3,r31,3072
	ctx.r3.s64 = ctx.r31.s64 + 3072;
	// bl 0x82115e10
	ctx.lr = 0x821145E0;
	sub_82115E10(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,4
	ctx.r6.s64 = 4;
	// li r5,-11
	ctx.r5.s64 = -11;
	// addi r3,r31,3168
	ctx.r3.s64 = ctx.r31.s64 + 3168;
	// bl 0x82115e10
	ctx.lr = 0x82114608;
	sub_82115E10(ctx, base);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r9,1
	ctx.r9.s64 = 1;
	// stb r30,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r30.u8);
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// mr r7,r29
	ctx.r7.u64 = ctx.r29.u64;
	// li r6,8
	ctx.r6.s64 = 8;
	// li r5,-11
	ctx.r5.s64 = -11;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// addi r3,r31,3264
	ctx.r3.s64 = ctx.r31.s64 + 3264;
	// bl 0x82115e10
	ctx.lr = 0x82114630;
	sub_82115E10(ctx, base);
	// lbz r4,25(r31)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r31.u32 + 25);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x8211464c
	if (ctx.cr6.eq) goto loc_8211464C;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r30.u32);
loc_8211464C:
	// lbz r11,217(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 217);
	// stw r10,188(r31)
	PPC_STORE_U32(ctx.r31.u32 + 188, ctx.r10.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82114668
	if (ctx.cr6.eq) goto loc_82114668;
	// lwz r11,212(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 212);
	// stw r10,284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 284, ctx.r10.u32);
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
loc_82114668:
	// lbz r9,313(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + 313);
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82114684
	if (ctx.cr6.eq) goto loc_82114684;
	// lwz r9,308(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 308);
	// stw r10,380(r31)
	PPC_STORE_U32(ctx.r31.u32 + 380, ctx.r10.u32);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
loc_82114684:
	// lbz r8,409(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 409);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x821146a0
	if (ctx.cr6.eq) goto loc_821146A0;
	// lwz r8,404(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 404);
	// stw r10,476(r31)
	PPC_STORE_U32(ctx.r31.u32 + 476, ctx.r10.u32);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
loc_821146A0:
	// lbz r8,505(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 505);
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x821146bc
	if (ctx.cr6.eq) goto loc_821146BC;
	// lwz r8,500(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 500);
	// stw r10,572(r31)
	PPC_STORE_U32(ctx.r31.u32 + 572, ctx.r10.u32);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
loc_821146BC:
	// lbz r8,601(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 601);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x821146d4
	if (ctx.cr6.eq) goto loc_821146D4;
	// lwz r8,596(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 596);
	// stw r10,668(r31)
	PPC_STORE_U32(ctx.r31.u32 + 668, ctx.r10.u32);
	// add r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 + ctx.r10.u64;
loc_821146D4:
	// lbz r8,697(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 697);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x821146ec
	if (ctx.cr6.eq) goto loc_821146EC;
	// lwz r8,692(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 692);
	// stw r7,764(r31)
	PPC_STORE_U32(ctx.r31.u32 + 764, ctx.r7.u32);
	// add r7,r8,r7
	ctx.r7.u64 = ctx.r8.u64 + ctx.r7.u64;
loc_821146EC:
	// cmplw cr6,r7,r10
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x821146f8
	if (!ctx.cr6.gt) goto loc_821146F8;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
loc_821146F8:
	// lbz r8,793(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 793);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82114710
	if (ctx.cr6.eq) goto loc_82114710;
	// lwz r8,788(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 788);
	// stw r9,860(r31)
	PPC_STORE_U32(ctx.r31.u32 + 860, ctx.r9.u32);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
loc_82114710:
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8211471c
	if (!ctx.cr6.gt) goto loc_8211471C;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
loc_8211471C:
	// lbz r8,889(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 889);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82114734
	if (ctx.cr6.eq) goto loc_82114734;
	// lwz r8,884(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 884);
	// stw r9,956(r31)
	PPC_STORE_U32(ctx.r31.u32 + 956, ctx.r9.u32);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
loc_82114734:
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82114740
	if (!ctx.cr6.gt) goto loc_82114740;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
loc_82114740:
	// lbz r8,985(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 985);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82114758
	if (ctx.cr6.eq) goto loc_82114758;
	// lwz r8,980(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 980);
	// stw r9,1052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1052, ctx.r9.u32);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
loc_82114758:
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82114764
	if (!ctx.cr6.gt) goto loc_82114764;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
loc_82114764:
	// li r8,4
	ctx.r8.s64 = 4;
	// addi r9,r31,1148
	ctx.r9.s64 = ctx.r31.s64 + 1148;
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
loc_82114770:
	// lbz r7,-67(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + -67);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82114788
	if (ctx.cr6.eq) goto loc_82114788;
	// lwz r8,-72(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + -72);
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r11.u32);
	// add r11,r8,r11
	ctx.r11.u64 = ctx.r8.u64 + ctx.r11.u64;
loc_82114788:
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82114794
	if (!ctx.cr6.gt) goto loc_82114794;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82114794:
	// lbz r7,29(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 29);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x821147ac
	if (ctx.cr6.eq) goto loc_821147AC;
	// lwz r8,24(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// stw r11,96(r9)
	PPC_STORE_U32(ctx.r9.u32 + 96, ctx.r11.u32);
	// add r11,r8,r11
	ctx.r11.u64 = ctx.r8.u64 + ctx.r11.u64;
loc_821147AC:
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x821147b8
	if (!ctx.cr6.gt) goto loc_821147B8;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_821147B8:
	// lbz r7,125(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 125);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x821147d0
	if (ctx.cr6.eq) goto loc_821147D0;
	// lwz r8,120(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 120);
	// stw r11,192(r9)
	PPC_STORE_U32(ctx.r9.u32 + 192, ctx.r11.u32);
	// add r11,r8,r11
	ctx.r11.u64 = ctx.r8.u64 + ctx.r11.u64;
loc_821147D0:
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x821147dc
	if (!ctx.cr6.gt) goto loc_821147DC;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_821147DC:
	// lbz r7,221(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 221);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x821147f4
	if (ctx.cr6.eq) goto loc_821147F4;
	// lwz r8,216(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 216);
	// stw r11,288(r9)
	PPC_STORE_U32(ctx.r9.u32 + 288, ctx.r11.u32);
	// add r11,r8,r11
	ctx.r11.u64 = ctx.r8.u64 + ctx.r11.u64;
loc_821147F4:
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82114800
	if (!ctx.cr6.gt) goto loc_82114800;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82114800:
	// lbz r7,317(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 317);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x82114818
	if (ctx.cr6.eq) goto loc_82114818;
	// lwz r8,312(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 312);
	// stw r11,384(r9)
	PPC_STORE_U32(ctx.r9.u32 + 384, ctx.r11.u32);
	// add r11,r8,r11
	ctx.r11.u64 = ctx.r8.u64 + ctx.r11.u64;
loc_82114818:
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82114824
	if (!ctx.cr6.gt) goto loc_82114824;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82114824:
	// lbz r7,413(r9)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r9.u32 + 413);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x8211483c
	if (ctx.cr6.eq) goto loc_8211483C;
	// lwz r8,408(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 408);
	// stw r11,480(r9)
	PPC_STORE_U32(ctx.r9.u32 + 480, ctx.r11.u32);
	// add r11,r8,r11
	ctx.r11.u64 = ctx.r8.u64 + ctx.r11.u64;
loc_8211483C:
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82114848
	if (!ctx.cr6.gt) goto loc_82114848;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
loc_82114848:
	// addi r9,r9,576
	ctx.r9.s64 = ctx.r9.s64 + 576;
	// bdnz 0x82114770
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82114770;
	// addi r11,r10,4095
	ctx.r11.s64 = ctx.r10.s64 + 4095;
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r26,r11,0,0,19
	ctx.r26.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFF000;
	// li r5,-1
	ctx.r5.s64 = -1;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// li r4,4096
	ctx.r4.s64 = 4096;
	// bl 0x82082030
	ctx.lr = 0x8211486C;
	sub_82082030(ctx, base);
	// li r5,1028
	ctx.r5.s64 = 1028;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// bl 0x822472e0
	ctx.lr = 0x8211487C;
	sub_822472E0(ctx, base);
	// lis r26,-32178
	ctx.r26.s64 = -2108817408;
	// mr r10,r27
	ctx.r10.u64 = ctx.r27.u64;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// mr r27,r30
	ctx.r27.u64 = ctx.r30.u64;
	// addi r31,r31,92
	ctx.r31.s64 = ctx.r31.s64 + 92;
	// li r24,35
	ctx.r24.s64 = 35;
	// stw r10,25580(r26)
	PPC_STORE_U32(ctx.r26.u32 + 25580, ctx.r10.u32);
	// lis r15,-13569
	ctx.r15.s64 = -889257984;
	// addi r23,r11,-30208
	ctx.r23.s64 = ctx.r11.s64 + -30208;
loc_821148A0:
	// lwz r11,-72(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -72);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821148b0
	if (!ctx.cr6.eq) goto loc_821148B0;
	// stw r23,-13570(r15)
	PPC_STORE_U32(ctx.r15.u32 + -13570, ctx.r23.u32);
loc_821148B0:
	// lbz r9,-67(r31)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r31.u32 + -67);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x821148c4
	if (!ctx.cr6.eq) goto loc_821148C4;
	// add r27,r11,r27
	ctx.r27.u64 = ctx.r11.u64 + ctx.r27.u64;
	// b 0x821148dc
	goto loc_821148DC;
loc_821148C4:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r3,r31,-60
	ctx.r3.s64 = ctx.r31.s64 + -60;
	// add r4,r11,r10
	ctx.r4.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r4,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r4.u32);
	// bl 0x822986a8
	ctx.lr = 0x821148D8;
	sub_822986A8(ctx, base);
	// lwz r10,25580(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 25580);
loc_821148DC:
	// addic. r24,r24,-1
	ctx.xer.ca = ctx.r24.u32 > 0;
	ctx.r24.s64 = ctx.r24.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r24.s32, 0, ctx.xer);
	// addi r31,r31,96
	ctx.r31.s64 = ctx.r31.s64 + 96;
	// bne 0x821148a0
	if (!ctx.cr0.eq) goto loc_821148A0;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// lis r7,-32178
	ctx.r7.s64 = -2108817408;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// addi r31,r11,432
	ctx.r31.s64 = ctx.r11.s64 + 432;
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// addi r6,r29,79
	ctx.r6.s64 = ctx.r29.s64 + 79;
	// li r5,80
	ctx.r5.s64 = 80;
	// stw r27,25584(r7)
	PPC_STORE_U32(ctx.r7.u32 + 25584, ctx.r27.u32);
	// mr r11,r17
	ctx.r11.u64 = ctx.r17.u64;
	// stw r9,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r9.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r17,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r17.u32);
	// divwu r11,r6,r5
	ctx.r11.u32 = ctx.r6.u32 / ctx.r5.u32;
	// stw r30,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r30.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r30.u32);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r30,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r30.u32);
	// addi r4,r28,15
	ctx.r4.s64 = ctx.r28.s64 + 15;
	// stw r30,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r30.u32);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stb r30,36(r31)
	PPC_STORE_U8(ctx.r31.u32 + 36, ctx.r30.u8);
	// rlwinm r18,r4,28,4,31
	ctx.r18.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 28) & 0xFFFFFFF;
	// stw r29,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r29.u32);
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// stw r28,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r28.u32);
	// rlwinm r8,r11,4,0,27
	ctx.r8.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r3,r18,4,0,27
	ctx.r3.u64 = rotl64(ctx.r18.u32 | (ctx.r18.u64 << 32), 4) & 0xFFFFFFF0;
	// li r10,5120
	ctx.r10.s64 = 5120;
	// mullw r7,r3,r8
	ctx.r7.s64 = int64_t(ctx.r3.s32) * int64_t(ctx.r8.s32);
	// rlwinm r11,r7,3,0,28
	ctx.r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// addi r9,r31,88
	ctx.r9.s64 = ctx.r31.s64 + 88;
	// addi r8,r31,40
	ctx.r8.s64 = ctx.r31.s64 + 40;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r17
	ctx.r5.u64 = ctx.r17.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// divwu r16,r11,r10
	ctx.r16.u32 = ctx.r11.u32 / ctx.r10.u32;
	// bl 0x82298188
	ctx.lr = 0x82114998;
	sub_82298188(ctx, base);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r3,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r3.u32);
	// addi r8,r31,132
	ctx.r8.s64 = ctx.r31.s64 + 132;
	// stw r9,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r9.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r29,104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 104, ctx.r29.u32);
	// addi r9,r31,180
	ctx.r9.s64 = ctx.r31.s64 + 180;
	// stw r21,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r21.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r30,116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 116, ctx.r30.u32);
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// stw r28,108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 108, ctx.r28.u32);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// stw r30,124(r31)
	PPC_STORE_U32(ctx.r31.u32 + 124, ctx.r30.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r30,120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 120, ctx.r30.u32);
	// mr r11,r21
	ctx.r11.u64 = ctx.r21.u64;
	// stb r30,128(r31)
	PPC_STORE_U8(ctx.r31.u32 + 128, ctx.r30.u8);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82114A04;
	sub_82298188(ctx, base);
	// lis r10,6688
	ctx.r10.s64 = 438304768;
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r3,112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 112, ctx.r3.u32);
	// ori r24,r10,43861
	ctx.r24.u64 = ctx.r10.u64 | 43861;
	// stw r30,188(r31)
	PPC_STORE_U32(ctx.r31.u32 + 188, ctx.r30.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r9,192(r31)
	PPC_STORE_U32(ctx.r31.u32 + 192, ctx.r9.u32);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// stw r24,184(r31)
	PPC_STORE_U32(ctx.r31.u32 + 184, ctx.r24.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,208(r31)
	PPC_STORE_U32(ctx.r31.u32 + 208, ctx.r30.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r29,196(r31)
	PPC_STORE_U32(ctx.r31.u32 + 196, ctx.r29.u32);
	// addi r9,r31,272
	ctx.r9.s64 = ctx.r31.s64 + 272;
	// stw r30,216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 216, ctx.r30.u32);
	// addi r8,r31,224
	ctx.r8.s64 = ctx.r31.s64 + 224;
	// stw r28,200(r31)
	PPC_STORE_U32(ctx.r31.u32 + 200, ctx.r28.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,212(r31)
	PPC_STORE_U32(ctx.r31.u32 + 212, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stb r30,220(r31)
	PPC_STORE_U8(ctx.r31.u32 + 220, ctx.r30.u8);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82114A78;
	sub_82298188(ctx, base);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r3,204(r31)
	PPC_STORE_U32(ctx.r31.u32 + 204, ctx.r3.u32);
	// addi r8,r31,316
	ctx.r8.s64 = ctx.r31.s64 + 316;
	// stw r9,284(r31)
	PPC_STORE_U32(ctx.r31.u32 + 284, ctx.r9.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r16,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r16.u32);
	// addi r9,r31,364
	ctx.r9.s64 = ctx.r31.s64 + 364;
	// stw r21,276(r31)
	PPC_STORE_U32(ctx.r31.u32 + 276, ctx.r21.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,280(r31)
	PPC_STORE_U32(ctx.r31.u32 + 280, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r29,288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 288, ctx.r29.u32);
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// stw r28,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r28.u32);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// stb r30,312(r31)
	PPC_STORE_U8(ctx.r31.u32 + 312, ctx.r30.u8);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r16,300(r31)
	PPC_STORE_U32(ctx.r31.u32 + 300, ctx.r16.u32);
	// mr r11,r21
	ctx.r11.u64 = ctx.r21.u64;
	// stw r30,304(r31)
	PPC_STORE_U32(ctx.r31.u32 + 304, ctx.r30.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 308, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82114AE4;
	sub_82298188(ctx, base);
	// li r9,1
	ctx.r9.s64 = 1;
	// mr r11,r22
	ctx.r11.u64 = ctx.r22.u64;
	// stw r3,296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 296, ctx.r3.u32);
	// stw r9,376(r31)
	PPC_STORE_U32(ctx.r31.u32 + 376, ctx.r9.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// li r11,1024
	ctx.r11.s64 = 1024;
	// stw r22,368(r31)
	PPC_STORE_U32(ctx.r31.u32 + 368, ctx.r22.u32);
	// li r10,1024
	ctx.r10.s64 = 1024;
	// stw r30,372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 372, ctx.r30.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r11,380(r31)
	PPC_STORE_U32(ctx.r31.u32 + 380, ctx.r11.u32);
	// stw r10,384(r31)
	PPC_STORE_U32(ctx.r31.u32 + 384, ctx.r10.u32);
	// addi r8,r31,408
	ctx.r8.s64 = ctx.r31.s64 + 408;
	// stb r9,404(r31)
	PPC_STORE_U8(ctx.r31.u32 + 404, ctx.r9.u8);
	// addi r9,r31,456
	ctx.r9.s64 = ctx.r31.s64 + 456;
	// stw r30,392(r31)
	PPC_STORE_U32(ctx.r31.u32 + 392, ctx.r30.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,396(r31)
	PPC_STORE_U32(ctx.r31.u32 + 396, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r30,400(r31)
	PPC_STORE_U32(ctx.r31.u32 + 400, ctx.r30.u32);
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// li r4,1024
	ctx.r4.s64 = 1024;
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// li r3,1024
	ctx.r3.s64 = 1024;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// bl 0x82298188
	ctx.lr = 0x82114B60;
	sub_82298188(ctx, base);
	// lis r9,6690
	ctx.r9.s64 = 438435840;
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r29,472(r31)
	PPC_STORE_U32(ctx.r31.u32 + 472, ctx.r29.u32);
	// ori r5,r9,43872
	ctx.r5.u64 = ctx.r9.u64 | 43872;
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r3,388(r31)
	PPC_STORE_U32(ctx.r31.u32 + 388, ctx.r3.u32);
	// stw r28,476(r31)
	PPC_STORE_U32(ctx.r31.u32 + 476, ctx.r28.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r9,468(r31)
	PPC_STORE_U32(ctx.r31.u32 + 468, ctx.r9.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r30,464(r31)
	PPC_STORE_U32(ctx.r31.u32 + 464, ctx.r30.u32);
	// addi r9,r31,548
	ctx.r9.s64 = ctx.r31.s64 + 548;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r5,460(r31)
	PPC_STORE_U32(ctx.r31.u32 + 460, ctx.r5.u32);
	// addi r8,r31,500
	ctx.r8.s64 = ctx.r31.s64 + 500;
	// stw r30,484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 484, ctx.r30.u32);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// stw r30,488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 488, ctx.r30.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r30,492(r31)
	PPC_STORE_U32(ctx.r31.u32 + 492, ctx.r30.u32);
	// mr r11,r5
	ctx.r11.u64 = ctx.r5.u64;
	// stb r30,496(r31)
	PPC_STORE_U8(ctx.r31.u32 + 496, ctx.r30.u8);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82114BD0;
	sub_82298188(ctx, base);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r3,480(r31)
	PPC_STORE_U32(ctx.r31.u32 + 480, ctx.r3.u32);
	// stw r29,564(r31)
	PPC_STORE_U32(ctx.r31.u32 + 564, ctx.r29.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r11,560(r31)
	PPC_STORE_U32(ctx.r31.u32 + 560, ctx.r11.u32);
	// addi r9,r31,640
	ctx.r9.s64 = ctx.r31.s64 + 640;
	// stw r24,552(r31)
	PPC_STORE_U32(ctx.r31.u32 + 552, ctx.r24.u32);
	// addi r8,r31,592
	ctx.r8.s64 = ctx.r31.s64 + 592;
	// stw r30,556(r31)
	PPC_STORE_U32(ctx.r31.u32 + 556, ctx.r30.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,576(r31)
	PPC_STORE_U32(ctx.r31.u32 + 576, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r28,568(r31)
	PPC_STORE_U32(ctx.r31.u32 + 568, ctx.r28.u32);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// stw r30,584(r31)
	PPC_STORE_U32(ctx.r31.u32 + 584, ctx.r30.u32);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// stw r30,580(r31)
	PPC_STORE_U32(ctx.r31.u32 + 580, ctx.r30.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stb r30,588(r31)
	PPC_STORE_U8(ctx.r31.u32 + 588, ctx.r30.u8);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82114C3C;
	sub_82298188(ctx, base);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r3,572(r31)
	PPC_STORE_U32(ctx.r31.u32 + 572, ctx.r3.u32);
	// addi r8,r31,684
	ctx.r8.s64 = ctx.r31.s64 + 684;
	// stw r9,652(r31)
	PPC_STORE_U32(ctx.r31.u32 + 652, ctx.r9.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r29,656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 656, ctx.r29.u32);
	// addi r9,r31,732
	ctx.r9.s64 = ctx.r31.s64 + 732;
	// stw r25,644(r31)
	PPC_STORE_U32(ctx.r31.u32 + 644, ctx.r25.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,648(r31)
	PPC_STORE_U32(ctx.r31.u32 + 648, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r30,668(r31)
	PPC_STORE_U32(ctx.r31.u32 + 668, ctx.r30.u32);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// stw r28,660(r31)
	PPC_STORE_U32(ctx.r31.u32 + 660, ctx.r28.u32);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// stw r30,676(r31)
	PPC_STORE_U32(ctx.r31.u32 + 676, ctx.r30.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r30,672(r31)
	PPC_STORE_U32(ctx.r31.u32 + 672, ctx.r30.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stb r30,680(r31)
	PPC_STORE_U8(ctx.r31.u32 + 680, ctx.r30.u8);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82114CA8;
	sub_82298188(ctx, base);
	// lis r8,6184
	ctx.r8.s64 = 405274624;
	// lwz r11,296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 296);
	// ori r25,r8,32646
	ctx.r25.u64 = ctx.r8.u64 | 32646;
	// lwz r10,204(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 204);
	// rlwinm r27,r29,31,1,31
	ctx.r27.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 31) & 0x7FFFFFFF;
	// li r7,2
	ctx.r7.s64 = 2;
	// stw r3,664(r31)
	PPC_STORE_U32(ctx.r31.u32 + 664, ctx.r3.u32);
	// add r19,r11,r10
	ctx.r19.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// rlwinm r26,r28,31,1,31
	ctx.r26.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 31) & 0x7FFFFFFF;
	// stw r7,744(r31)
	PPC_STORE_U32(ctx.r31.u32 + 744, ctx.r7.u32);
	// stw r27,748(r31)
	PPC_STORE_U32(ctx.r31.u32 + 748, ctx.r27.u32);
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
	// stw r25,736(r31)
	PPC_STORE_U32(ctx.r31.u32 + 736, ctx.r25.u32);
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// stw r19,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r19.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r30,740(r31)
	PPC_STORE_U32(ctx.r31.u32 + 740, ctx.r30.u32);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// stw r26,752(r31)
	PPC_STORE_U32(ctx.r31.u32 + 752, ctx.r26.u32);
	// addi r9,r31,824
	ctx.r9.s64 = ctx.r31.s64 + 824;
	// stw r19,760(r31)
	PPC_STORE_U32(ctx.r31.u32 + 760, ctx.r19.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,764(r31)
	PPC_STORE_U32(ctx.r31.u32 + 764, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stb r30,772(r31)
	PPC_STORE_U8(ctx.r31.u32 + 772, ctx.r30.u8);
	// addi r8,r31,776
	ctx.r8.s64 = ctx.r31.s64 + 776;
	// stw r30,768(r31)
	PPC_STORE_U32(ctx.r31.u32 + 768, ctx.r30.u32);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// bl 0x82298188
	ctx.lr = 0x82114D34;
	sub_82298188(ctx, base);
	// li r9,4
	ctx.r9.s64 = 4;
	// rlwinm r23,r29,30,2,31
	ctx.r23.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 30) & 0x3FFFFFFF;
	// stw r3,756(r31)
	PPC_STORE_U32(ctx.r31.u32 + 756, ctx.r3.u32);
	// rlwinm r22,r28,30,2,31
	ctx.r22.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 30) & 0x3FFFFFFF;
	// stw r9,836(r31)
	PPC_STORE_U32(ctx.r31.u32 + 836, ctx.r9.u32);
	// stw r19,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r19.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r25,828(r31)
	PPC_STORE_U32(ctx.r31.u32 + 828, ctx.r25.u32);
	// addi r9,r31,916
	ctx.r9.s64 = ctx.r31.s64 + 916;
	// stw r30,832(r31)
	PPC_STORE_U32(ctx.r31.u32 + 832, ctx.r30.u32);
	// addi r8,r31,868
	ctx.r8.s64 = ctx.r31.s64 + 868;
	// stb r30,864(r31)
	PPC_STORE_U8(ctx.r31.u32 + 864, ctx.r30.u8);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r23,840(r31)
	PPC_STORE_U32(ctx.r31.u32 + 840, ctx.r23.u32);
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// stw r22,844(r31)
	PPC_STORE_U32(ctx.r31.u32 + 844, ctx.r22.u32);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// stw r19,852(r31)
	PPC_STORE_U32(ctx.r31.u32 + 852, ctx.r19.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r30,856(r31)
	PPC_STORE_U32(ctx.r31.u32 + 856, ctx.r30.u32);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// stw r30,860(r31)
	PPC_STORE_U32(ctx.r31.u32 + 860, ctx.r30.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82114DA8;
	sub_82298188(ctx, base);
	// addi r7,r29,31
	ctx.r7.s64 = ctx.r29.s64 + 31;
	// lwz r11,756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// li r9,2
	ctx.r9.s64 = 2;
	// rlwinm r6,r7,27,5,31
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x7FFFFFF;
	// stw r27,932(r31)
	PPC_STORE_U32(ctx.r31.u32 + 932, ctx.r27.u32);
	// add r20,r11,r19
	ctx.r20.u64 = ctx.r11.u64 + ctx.r19.u64;
	// stw r30,924(r31)
	PPC_STORE_U32(ctx.r31.u32 + 924, ctx.r30.u32);
	// mullw r5,r6,r18
	ctx.r5.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r18.s32);
	// stw r26,936(r31)
	PPC_STORE_U32(ctx.r31.u32 + 936, ctx.r26.u32);
	// stw r20,944(r31)
	PPC_STORE_U32(ctx.r31.u32 + 944, ctx.r20.u32);
	// stw r21,920(r31)
	PPC_STORE_U32(ctx.r31.u32 + 920, ctx.r21.u32);
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r20.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// stw r3,848(r31)
	PPC_STORE_U32(ctx.r31.u32 + 848, ctx.r3.u32);
	// stw r9,928(r31)
	PPC_STORE_U32(ctx.r31.u32 + 928, ctx.r9.u32);
	// mr r11,r21
	ctx.r11.u64 = ctx.r21.u64;
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// clrlwi r18,r5,9
	ctx.r18.u64 = ctx.r5.u32 & 0x7FFFFF;
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r18,948(r31)
	PPC_STORE_U32(ctx.r31.u32 + 948, ctx.r18.u32);
	// addi r9,r31,1008
	ctx.r9.s64 = ctx.r31.s64 + 1008;
	// stw r30,952(r31)
	PPC_STORE_U32(ctx.r31.u32 + 952, ctx.r30.u32);
	// addi r8,r31,960
	ctx.r8.s64 = ctx.r31.s64 + 960;
	// stb r30,956(r31)
	PPC_STORE_U8(ctx.r31.u32 + 956, ctx.r30.u8);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r18,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r18.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82298188
	ctx.lr = 0x82114E28;
	sub_82298188(ctx, base);
	// li r9,4
	ctx.r9.s64 = 4;
	// stw r3,940(r31)
	PPC_STORE_U32(ctx.r31.u32 + 940, ctx.r3.u32);
	// addi r8,r31,1052
	ctx.r8.s64 = ctx.r31.s64 + 1052;
	// stw r9,1020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1020, ctx.r9.u32);
	// addi r9,r31,1100
	ctx.r9.s64 = ctx.r31.s64 + 1100;
	// stw r23,1024(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1024, ctx.r23.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r21,1012(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1012, ctx.r21.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r30,1016(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1016, ctx.r30.u32);
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// stw r22,1028(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1028, ctx.r22.u32);
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// stw r20,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r20.u32);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// stw r20,1036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1036, ctx.r20.u32);
	// mr r11,r21
	ctx.r11.u64 = ctx.r21.u64;
	// stw r18,1040(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1040, ctx.r18.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,1044(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1044, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stb r30,1048(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1048, ctx.r30.u8);
	// stw r18,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r18.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82114E90;
	sub_82298188(ctx, base);
	// lwz r11,940(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 940);
	// stw r3,1032(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1032, ctx.r3.u32);
	// add r4,r11,r20
	ctx.r4.u64 = ctx.r11.u64 + ctx.r20.u64;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// cmplw cr6,r4,r16
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r16.u32, ctx.xer);
	// addi r11,r11,-30168
	ctx.r11.s64 = ctx.r11.s64 + -30168;
	// ble cr6,0x82114ec4
	if (!ctx.cr6.gt) goto loc_82114EC4;
	// lwz r10,296(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 296);
	// lwz r9,300(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 300);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r20,r10
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82114ec4
	if (!ctx.cr6.lt) goto loc_82114EC4;
	// stw r11,-13570(r15)
	PPC_STORE_U32(ctx.r15.u32 + -13570, ctx.r11.u32);
loc_82114EC4:
	// lwz r9,756(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 756);
	// lwz r10,208(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 208);
	// add r9,r9,r19
	ctx.r9.u64 = ctx.r9.u64 + ctx.r19.u64;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x82114eec
	if (!ctx.cr6.gt) goto loc_82114EEC;
	// lwz r9,204(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 204);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r19,r10
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, ctx.r10.u32, ctx.xer);
	// bge cr6,0x82114eec
	if (!ctx.cr6.lt) goto loc_82114EEC;
	// stw r11,-13570(r15)
	PPC_STORE_U32(ctx.r15.u32 + -13570, ctx.r11.u32);
loc_82114EEC:
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r29,1116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1116, ctx.r29.u32);
	// stw r28,1120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1120, ctx.r28.u32);
	// addi r8,r31,1144
	ctx.r8.s64 = ctx.r31.s64 + 1144;
	// stw r9,1112(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1112, ctx.r9.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r24,1104(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1104, ctx.r24.u32);
	// addi r9,r31,1192
	ctx.r9.s64 = ctx.r31.s64 + 1192;
	// stw r30,1108(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1108, ctx.r30.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,1128(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1128, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r30,1132(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1132, ctx.r30.u32);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// stw r30,1136(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1136, ctx.r30.u32);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// stb r30,1140(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1140, ctx.r30.u8);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82114F54;
	sub_82298188(ctx, base);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r3,1124(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1124, ctx.r3.u32);
	// addi r8,r31,1236
	ctx.r8.s64 = ctx.r31.s64 + 1236;
	// stw r9,1204(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1204, ctx.r9.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r29,1208(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1208, ctx.r29.u32);
	// addi r9,r31,1284
	ctx.r9.s64 = ctx.r31.s64 + 1284;
	// stw r25,1196(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1196, ctx.r25.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,1200(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1200, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r30,1220(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1220, ctx.r30.u32);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// stw r28,1212(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1212, ctx.r28.u32);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// stw r30,1228(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1228, ctx.r30.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r30,1224(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1224, ctx.r30.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stb r30,1232(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1232, ctx.r30.u8);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82114FC0;
	sub_82298188(ctx, base);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// li r11,2
	ctx.r11.s64 = 2;
	// stw r3,1216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1216, ctx.r3.u32);
	// stw r27,1300(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1300, ctx.r27.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r11,1296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1296, ctx.r11.u32);
	// addi r9,r31,1376
	ctx.r9.s64 = ctx.r31.s64 + 1376;
	// stw r24,1288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1288, ctx.r24.u32);
	// addi r8,r31,1328
	ctx.r8.s64 = ctx.r31.s64 + 1328;
	// stw r30,1292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1292, ctx.r30.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,1312(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1312, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r30,1320(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1320, ctx.r30.u32);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// stw r26,1304(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1304, ctx.r26.u32);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// stw r30,1316(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1316, ctx.r30.u32);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stb r30,1324(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1324, ctx.r30.u8);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x8211502C;
	sub_82298188(ctx, base);
	// mr r11,r17
	ctx.r11.u64 = ctx.r17.u64;
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r3,1308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1308, ctx.r3.u32);
	// stw r27,1392(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1392, ctx.r27.u32);
	// addi r8,r31,1420
	ctx.r8.s64 = ctx.r31.s64 + 1420;
	// stw r9,1388(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1388, ctx.r9.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r17,1380(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1380, ctx.r17.u32);
	// addi r9,r31,1468
	ctx.r9.s64 = ctx.r31.s64 + 1468;
	// stw r30,1384(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1384, ctx.r30.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,1404(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1404, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r26,1396(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1396, ctx.r26.u32);
	// mr r5,r17
	ctx.r5.u64 = ctx.r17.u64;
	// stw r30,1412(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1412, ctx.r30.u32);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stw r30,1408(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1408, ctx.r30.u32);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// stb r30,1416(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1416, ctx.r30.u8);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82115098;
	sub_82298188(ctx, base);
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r3,1400(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1400, ctx.r3.u32);
	// addi r8,r31,1512
	ctx.r8.s64 = ctx.r31.s64 + 1512;
	// stw r9,1480(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1480, ctx.r9.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r27,1484(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1484, ctx.r27.u32);
	// addi r9,r31,1560
	ctx.r9.s64 = ctx.r31.s64 + 1560;
	// stw r25,1472(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1472, ctx.r25.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,1476(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1476, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r30,1496(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1496, ctx.r30.u32);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// stw r26,1488(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1488, ctx.r26.u32);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// stw r30,1504(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1504, ctx.r30.u32);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stw r30,1500(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1500, ctx.r30.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stb r30,1508(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1508, ctx.r30.u8);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82115104;
	sub_82298188(ctx, base);
	// li r9,4
	ctx.r9.s64 = 4;
	// stw r3,1492(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1492, ctx.r3.u32);
	// addi r8,r31,1604
	ctx.r8.s64 = ctx.r31.s64 + 1604;
	// stw r9,1572(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1572, ctx.r9.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r23,1576(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1576, ctx.r23.u32);
	// addi r9,r31,1652
	ctx.r9.s64 = ctx.r31.s64 + 1652;
	// stw r24,1564(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1564, ctx.r24.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,1568(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1568, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r22,1580(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1580, ctx.r22.u32);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// stw r30,1588(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1588, ctx.r30.u32);
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// stw r30,1596(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1596, ctx.r30.u32);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// stw r30,1592(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1592, ctx.r30.u32);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// stb r30,1600(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1600, ctx.r30.u8);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82115170;
	sub_82298188(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// li r9,4
	ctx.r9.s64 = 4;
	// stw r3,1584(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1584, ctx.r3.u32);
	// stw r23,1668(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1668, ctx.r23.u32);
	// addi r8,r31,1696
	ctx.r8.s64 = ctx.r31.s64 + 1696;
	// stw r9,1664(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1664, ctx.r9.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r25,1656(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1656, ctx.r25.u32);
	// addi r9,r31,1744
	ctx.r9.s64 = ctx.r31.s64 + 1744;
	// stw r30,1660(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1660, ctx.r30.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,1680(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1680, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r22,1672(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1672, ctx.r22.u32);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// stw r30,1688(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1688, ctx.r30.u32);
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// stw r30,1684(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1684, ctx.r30.u32);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// stb r30,1692(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1692, ctx.r30.u8);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x821151DC;
	sub_82298188(ctx, base);
	// li r9,8
	ctx.r9.s64 = 8;
	// rlwinm r23,r29,29,3,31
	ctx.r23.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r3,1676(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1676, ctx.r3.u32);
	// rlwinm r22,r28,29,3,31
	ctx.r22.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 29) & 0x1FFFFFFF;
	// stw r9,1756(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1756, ctx.r9.u32);
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r24,1748(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1748, ctx.r24.u32);
	// addi r9,r31,1836
	ctx.r9.s64 = ctx.r31.s64 + 1836;
	// stw r30,1752(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1752, ctx.r30.u32);
	// addi r8,r31,1788
	ctx.r8.s64 = ctx.r31.s64 + 1788;
	// stw r30,1772(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1772, ctx.r30.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r23,1760(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1760, ctx.r23.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r22,1764(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1764, ctx.r22.u32);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// stw r30,1776(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1776, ctx.r30.u32);
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// stw r30,1780(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1780, ctx.r30.u32);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// stb r30,1784(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1784, ctx.r30.u8);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82115250;
	sub_82298188(ctx, base);
	// li r9,8
	ctx.r9.s64 = 8;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r3,1768(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1768, ctx.r3.u32);
	// stw r9,1848(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1848, ctx.r9.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r23,1852(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1852, ctx.r23.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r25,1840(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1840, ctx.r25.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r22,1856(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1856, ctx.r22.u32);
	// addi r9,r31,1928
	ctx.r9.s64 = ctx.r31.s64 + 1928;
	// stw r30,1844(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1844, ctx.r30.u32);
	// addi r8,r31,1880
	ctx.r8.s64 = ctx.r31.s64 + 1880;
	// stw r30,1864(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1864, ctx.r30.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,1872(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1872, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r30,1868(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1868, ctx.r30.u32);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// stb r30,1876(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1876, ctx.r30.u8);
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x821152BC;
	sub_82298188(ctx, base);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// li r8,1
	ctx.r8.s64 = 1;
	// stw r3,1860(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1860, ctx.r3.u32);
	// stw r25,1932(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1932, ctx.r25.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r8,1940(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1940, ctx.r8.u32);
	// mr r8,r30
	ctx.r8.u64 = ctx.r30.u64;
	// stw r30,1936(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1936, ctx.r30.u32);
	// addi r9,r31,2020
	ctx.r9.s64 = ctx.r31.s64 + 2020;
	// stw r29,1944(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1944, ctx.r29.u32);
	// addi r8,r31,1972
	ctx.r8.s64 = ctx.r31.s64 + 1972;
	// stw r30,1964(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1964, ctx.r30.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stb r30,1968(r31)
	PPC_STORE_U8(ctx.r31.u32 + 1968, ctx.r30.u8);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r28,1948(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1948, ctx.r28.u32);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// stw r11,1956(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1956, ctx.r11.u32);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// stw r30,1960(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1960, ctx.r30.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x8211532C;
	sub_82298188(ctx, base);
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r3,1952(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1952, ctx.r3.u32);
	// addi r8,r31,2064
	ctx.r8.s64 = ctx.r31.s64 + 2064;
	// stw r9,2032(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2032, ctx.r9.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r9,2056(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2056, ctx.r9.u32);
	// addi r9,r31,2112
	ctx.r9.s64 = ctx.r31.s64 + 2112;
	// stw r27,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r27.u32);
	// li r6,2
	ctx.r6.s64 = 2;
	// stw r24,2024(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2024, ctx.r24.u32);
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// stw r30,2028(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2028, ctx.r30.u32);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// stw r30,2048(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2048, ctx.r30.u32);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stw r26,2040(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2040, ctx.r26.u32);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stb r30,2060(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2060, ctx.r30.u8);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82115394;
	sub_82298188(ctx, base);
	// mr r11,r17
	ctx.r11.u64 = ctx.r17.u64;
	// li r11,2
	ctx.r11.s64 = 2;
	// stw r3,2044(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2044, ctx.r3.u32);
	// stw r27,2128(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2128, ctx.r27.u32);
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// stw r17,2116(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2116, ctx.r17.u32);
	// addi r8,r31,2156
	ctx.r8.s64 = ctx.r31.s64 + 2156;
	// stw r30,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r30.u32);
	// addi r9,r31,2204
	ctx.r9.s64 = ctx.r31.s64 + 2204;
	// stw r11,2124(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2124, ctx.r11.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r30,2140(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2140, ctx.r30.u32);
	// li r6,2
	ctx.r6.s64 = 2;
	// stw r26,2132(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2132, ctx.r26.u32);
	// mr r5,r17
	ctx.r5.u64 = ctx.r17.u64;
	// stw r30,2144(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2144, ctx.r30.u32);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// stb r30,2152(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2152, ctx.r30.u8);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stw r11,2148(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2148, ctx.r11.u32);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x821153FC;
	sub_82298188(ctx, base);
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r3,2136(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2136, ctx.r3.u32);
	// stw r27,2220(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2220, ctx.r27.u32);
	// addi r8,r31,2248
	ctx.r8.s64 = ctx.r31.s64 + 2248;
	// stw r9,2216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2216, ctx.r9.u32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// stw r9,2240(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2240, ctx.r9.u32);
	// addi r9,r31,2296
	ctx.r9.s64 = ctx.r31.s64 + 2296;
	// stw r25,2208(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2208, ctx.r25.u32);
	// li r6,2
	ctx.r6.s64 = 2;
	// stw r30,2212(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2212, ctx.r30.u32);
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// stw r30,2232(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2232, ctx.r30.u32);
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// stw r26,2224(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2224, ctx.r26.u32);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stw r30,2236(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2236, ctx.r30.u32);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stb r30,2244(r31)
	PPC_STORE_U8(ctx.r31.u32 + 2244, ctx.r30.u8);
	// mr r10,r30
	ctx.r10.u64 = ctx.r30.u64;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r30.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r30.u32);
	// bl 0x82298188
	ctx.lr = 0x82115464;
	sub_82298188(ctx, base);
	// stw r3,2228(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2228, ctx.r3.u32);
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x8233e484
	__restgprlr_15(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82115470"))) PPC_WEAK_FUNC(sub_82115470);
PPC_FUNC_IMPL(__imp__sub_82115470) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82115478;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// std r5,160(r1)
	PPC_STORE_U64(ctx.r1.u32 + 160, ctx.r5.u64);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// std r6,168(r1)
	PPC_STORE_U64(ctx.r1.u32 + 168, ctx.r6.u64);
	// addi r31,r11,-30232
	ctx.r31.s64 = ctx.r11.s64 + -30232;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r28,r7
	ctx.r28.u64 = ctx.r7.u64;
	// mr r27,r8
	ctx.r27.u64 = ctx.r8.u64;
	// bl 0x823052d8
	ctx.lr = 0x821154A8;
	sub_823052D8(ctx, base);
	// lwz r11,2348(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2348);
	// lwz r10,2344(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2344);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x821154c4
	if (!ctx.cr6.eq) goto loc_821154C4;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82113e88
	ctx.lr = 0x821154C4;
	sub_82113E88(ctx, base);
loc_821154C4:
	// lwz r11,2348(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2348);
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// addi r10,r31,40
	ctx.r10.s64 = ctx.r31.s64 + 40;
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lis r7,-32178
	ctx.r7.s64 = -2108817408;
	// add r6,r11,r9
	ctx.r6.u64 = ctx.r11.u64 + ctx.r9.u64;
	// lwz r5,0(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// addi r4,r7,22200
	ctx.r4.s64 = ctx.r7.s64 + 22200;
	// rlwinm r11,r6,2,0,29
	ctx.r11.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,4(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// lwz r9,8(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lwz r8,12(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// addi r7,r11,8
	ctx.r7.s64 = ctx.r11.s64 + 8;
	// stw r30,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r30.u32);
	// stw r29,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r29.u32);
	// stw r5,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r5.u32);
	// stw r3,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r3.u32);
	// stw r9,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r9.u32);
	// stw r8,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r8.u32);
	// stw r28,24(r11)
	PPC_STORE_U32(ctx.r11.u32 + 24, ctx.r28.u32);
	// stw r27,28(r11)
	PPC_STORE_U32(ctx.r11.u32 + 28, ctx.r27.u32);
	// lwz r10,984(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 984);
	// stw r10,32(r11)
	PPC_STORE_U32(ctx.r11.u32 + 32, ctx.r10.u32);
	// lwz r6,2348(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2348);
	// cmplwi cr6,r6,63
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 63, ctx.xer);
	// bne cr6,0x82115548
	if (!ctx.cr6.eq) goto loc_82115548;
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,2348(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2348, ctx.r11.u32);
	// bl 0x823051a8
	ctx.lr = 0x82115540;
	sub_823051A8(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
loc_82115548:
	// lwz r11,2348(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2348);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,2348(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2348, ctx.r11.u32);
	// bl 0x823051a8
	ctx.lr = 0x8211555C;
	sub_823051A8(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82115564"))) PPC_WEAK_FUNC(sub_82115564);
PPC_FUNC_IMPL(__imp__sub_82115564) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82115568"))) PPC_WEAK_FUNC(sub_82115568);
PPC_FUNC_IMPL(__imp__sub_82115568) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82115570;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// addi r5,r3,4
	ctx.r5.s64 = ctx.r3.s64 + 4;
	// addi r30,r11,-30232
	ctx.r30.s64 = ctx.r11.s64 + -30232;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r30,2352
	ctx.r4.s64 = ctx.r30.s64 + 2352;
	// bl 0x820f6340
	ctx.lr = 0x8211558C;
	sub_820F6340(ctx, base);
	// lwz r31,80(r1)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x821155a8
	if (!ctx.cr6.eq) goto loc_821155A8;
	// lis r11,-13569
	ctx.r11.s64 = -889257984;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r9,r10,-29988
	ctx.r9.s64 = ctx.r10.s64 + -29988;
	// stw r9,-13570(r11)
	PPC_STORE_U32(ctx.r11.u32 + -13570, ctx.r9.u32);
loc_821155A8:
	// lwz r11,2356(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2356);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// twllei r11,0
	if (ctx.r11.u32 <= 0) __builtin_debugtrap();
	// lwz r10,2352(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2352);
	// divwu r8,r9,r11
	ctx.r8.u32 = ctx.r9.u32 / ctx.r11.u32;
	// lwz r28,12(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// mullw r7,r8,r11
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
	// subf r11,r7,r9
	ctx.r11.s64 = ctx.r9.s64 - ctx.r7.s64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r11,r9
	ctx.r6.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r6,2,0,29
	ctx.r11.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// add r29,r11,r10
	ctx.r29.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x820f63e0
	ctx.lr = 0x821155E0;
	sub_820F63E0(ctx, base);
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r4,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r4.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
	// bl 0x82115b40
	ctx.lr = 0x82115600;
	sub_82115B40(ctx, base);
	// addi r7,r30,2360
	ctx.r7.s64 = ctx.r30.s64 + 2360;
loc_82115604:
	// mfmsr r8
	ctx.r8.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r9,0,r7
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r9.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// stwcx. r9,0,r7
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r9.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r8,1
	ctx.msr = (ctx.r8.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82115604
	if (!ctx.cr0.eq) goto loc_82115604;
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// stw r6,16(r29)
	PPC_STORE_U32(ctx.r29.u32 + 16, ctx.r6.u32);
	// beq cr6,0x8211563c
	if (ctx.cr6.eq) goto loc_8211563C;
	// addi r4,r28,-16
	ctx.r4.s64 = ctx.r28.s64 + -16;
	// lwz r3,-8(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8211563C;
	sub_82080000(ctx, base);
loc_8211563C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82115644"))) PPC_WEAK_FUNC(sub_82115644);
PPC_FUNC_IMPL(__imp__sub_82115644) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82115648"))) PPC_WEAK_FUNC(sub_82115648);
PPC_FUNC_IMPL(__imp__sub_82115648) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e44c
	ctx.lr = 0x82115650;
	__restfpr_21(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r28,r11,-3072
	ctx.r28.s64 = ctx.r11.s64 + -3072;
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// addi r9,r4,8
	ctx.r9.s64 = ctx.r4.s64 + 8;
	// lwz r8,12(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// addi r29,r3,16
	ctx.r29.s64 = ctx.r3.s64 + 16;
	// stw r8,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r8.u32);
	// li r23,35
	ctx.r23.s64 = 35;
	// lwz r7,16(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// lis r21,-13569
	ctx.r21.s64 = -889257984;
	// stw r7,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r7.u32);
	// addi r22,r11,-29968
	ctx.r22.s64 = ctx.r11.s64 + -29968;
	// lwz r6,20(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// stw r6,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r6.u32);
	// lfs f0,16(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,20(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fctidz f12,f0
	ctx.f12.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// fctidz f11,f13
	ctx.f11.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// stfd f12,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f12.u64);
	// stfd f11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f11.u64);
	// lwz r26,84(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r25,92(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r27,28(r4)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// lwz r24,24(r4)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
loc_821156C4:
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82115eb0
	ctx.lr = 0x821156D8;
	sub_82115EB0(ctx, base);
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82115718
	if (ctx.cr6.eq) goto loc_82115718;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82115718
	if (ctx.cr6.eq) goto loc_82115718;
	// lwz r4,24(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// cmpw cr6,r27,r3
	ctx.cr6.compare<int32_t>(ctx.r27.s32, ctx.r3.s32, ctx.xer);
	// blt cr6,0x82115704
	if (ctx.cr6.lt) goto loc_82115704;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// add r24,r3,r24
	ctx.r24.u64 = ctx.r3.u64 + ctx.r24.u64;
	// subf r27,r3,r27
	ctx.r27.s64 = ctx.r27.s64 - ctx.r3.s64;
loc_82115704:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x82115710
	if (!ctx.cr6.gt) goto loc_82115710;
	// stw r22,-13570(r21)
	PPC_STORE_U32(ctx.r21.u32 + -13570, ctx.r22.u32);
loc_82115710:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x822986a8
	ctx.lr = 0x82115718;
	sub_822986A8(ctx, base);
loc_82115718:
	// addic. r23,r23,-1
	ctx.xer.ca = ctx.r23.u32 > 0;
	ctx.r23.s64 = ctx.r23.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// addi r28,r28,96
	ctx.r28.s64 = ctx.r28.s64 + 96;
	// addi r29,r29,52
	ctx.r29.s64 = ctx.r29.s64 + 52;
	// bne 0x821156c4
	if (!ctx.cr0.eq) goto loc_821156C4;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r30,r30,1836
	ctx.r30.s64 = ctx.r30.s64 + 1836;
	// addi r29,r11,432
	ctx.r29.s64 = ctx.r11.s64 + 432;
	// li r31,25
	ctx.r31.s64 = 25;
loc_82115738:
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82115fb8
	ctx.lr = 0x8211574C;
	sub_82115FB8(ctx, base);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// addi r30,r30,48
	ctx.r30.s64 = ctx.r30.s64 + 48;
	// addi r29,r29,92
	ctx.r29.s64 = ctx.r29.s64 + 92;
	// bne 0x82115738
	if (!ctx.cr0.eq) goto loc_82115738;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82115764"))) PPC_WEAK_FUNC(sub_82115764);
PPC_FUNC_IMPL(__imp__sub_82115764) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82115768"))) PPC_WEAK_FUNC(sub_82115768);
PPC_FUNC_IMPL(__imp__sub_82115768) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e454
	ctx.lr = 0x82115770;
	__restfpr_23(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r30,0
	ctx.r30.s64 = 0;
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// mr r25,r30
	ctx.r25.u64 = ctx.r30.u64;
	// mr r24,r30
	ctx.r24.u64 = ctx.r30.u64;
	// mr r28,r30
	ctx.r28.u64 = ctx.r30.u64;
	// li r27,1
	ctx.r27.s64 = 1;
loc_82115790:
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// cmplw cr6,r25,r11
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82115844
	if (!ctx.cr6.lt) goto loc_82115844;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// add r29,r28,r11
	ctx.r29.u64 = ctx.r28.u64 + ctx.r11.u64;
	// addi r31,r29,16
	ctx.r31.s64 = ctx.r29.s64 + 16;
loc_821157A8:
	// mfmsr r9
	ctx.r9.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r10,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r10,r30
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r30.s32, ctx.xer);
	// bne cr6,0x821157cc
	if (!ctx.cr6.eq) goto loc_821157CC;
	// stwcx. r27,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r27.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x821157a8
	if (!ctx.cr0.eq) goto loc_821157A8;
	// b 0x821157d4
	goto loc_821157D4;
loc_821157CC:
	// stwcx. r10,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
loc_821157D4:
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82115820
	if (!ctx.cr6.eq) goto loc_82115820;
loc_821157E0:
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82247328
	ctx.lr = 0x821157E8;
	sub_82247328(ctx, base);
loc_821157E8:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r11,r30
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r30.s32, ctx.xer);
	// bne cr6,0x8211580c
	if (!ctx.cr6.eq) goto loc_8211580C;
	// stwcx. r27,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r27.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x821157e8
	if (!ctx.cr0.eq) goto loc_821157E8;
	// b 0x82115814
	goto loc_82115814;
loc_8211580C:
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
loc_82115814:
	// mr r11,r11
	ctx.r11.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x821157e0
	if (ctx.cr6.eq) goto loc_821157E0;
loc_82115820:
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// cmplw cr6,r11,r29
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r29.u32, ctx.xer);
	// beq cr6,0x82115830
	if (ctx.cr6.eq) goto loc_82115830;
	// mr r24,r11
	ctx.r24.u64 = ctx.r11.u64;
loc_82115830:
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
	// addi r28,r28,20
	ctx.r28.s64 = ctx.r28.s64 + 20;
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x82115790
	if (ctx.cr6.eq) goto loc_82115790;
loc_82115844:
	// stw r24,0(r23)
	PPC_STORE_U32(ctx.r23.u32 + 0, ctx.r24.u32);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// stw r26,4(r23)
	PPC_STORE_U32(ctx.r23.u32 + 4, ctx.r26.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82115858"))) PPC_WEAK_FUNC(sub_82115858);
PPC_FUNC_IMPL(__imp__sub_82115858) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x82115860;
	__restfpr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r28,0
	ctx.r28.s64 = 0;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// mr r24,r28
	ctx.r24.u64 = ctx.r28.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82115948
	if (!ctx.cr6.gt) goto loc_82115948;
	// mr r27,r28
	ctx.r27.u64 = ctx.r28.u64;
	// li r26,1
	ctx.r26.s64 = 1;
loc_82115884:
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// add r31,r27,r11
	ctx.r31.u64 = ctx.r27.u64 + ctx.r11.u64;
	// addi r30,r31,16
	ctx.r30.s64 = ctx.r31.s64 + 16;
loc_82115890:
	// mfmsr r9
	ctx.r9.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r10,0,r30
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r30.u32);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r10,r28
	ctx.cr6.compare<int32_t>(ctx.r10.s32, ctx.r28.s32, ctx.xer);
	// bne cr6,0x821158b4
	if (!ctx.cr6.eq) goto loc_821158B4;
	// stwcx. r26,0,r30
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r30.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r26.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82115890
	if (!ctx.cr0.eq) goto loc_82115890;
	// b 0x821158bc
	goto loc_821158BC;
loc_821158B4:
	// stwcx. r10,0,r30
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r30.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
loc_821158BC:
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// cmpwi cr6,r10,1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 1, ctx.xer);
	// bne cr6,0x82115908
	if (!ctx.cr6.eq) goto loc_82115908;
loc_821158C8:
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82247328
	ctx.lr = 0x821158D0;
	sub_82247328(ctx, base);
loc_821158D0:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r30
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r30.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r11,r28
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r28.s32, ctx.xer);
	// bne cr6,0x821158f4
	if (!ctx.cr6.eq) goto loc_821158F4;
	// stwcx. r26,0,r30
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r30.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r26.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x821158d0
	if (!ctx.cr0.eq) goto loc_821158D0;
	// b 0x821158fc
	goto loc_821158FC;
loc_821158F4:
	// stwcx. r11,0,r30
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r30.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
loc_821158FC:
	// mr r11,r11
	ctx.r11.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x821158c8
	if (ctx.cr6.eq) goto loc_821158C8;
loc_82115908:
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplw cr6,r3,r31
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x82115928
	if (ctx.cr6.eq) goto loc_82115928;
loc_82115914:
	// lwz r29,4(r3)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// bl 0x82115b40
	ctx.lr = 0x8211591C;
	sub_82115B40(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// cmplw cr6,r29,r31
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82115914
	if (!ctx.cr6.eq) goto loc_82115914;
loc_82115928:
	// addi r24,r24,1
	ctx.r24.s64 = ctx.r24.s64 + 1;
	// stw r31,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r31.u32);
	// stw r31,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r31.u32);
	// addi r27,r27,20
	ctx.r27.s64 = ctx.r27.s64 + 20;
	// stw r28,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r28.u32);
	// lwz r11,4(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// cmplw cr6,r24,r11
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82115884
	if (ctx.cr6.lt) goto loc_82115884;
loc_82115948:
	// stw r28,8(r25)
	PPC_STORE_U32(ctx.r25.u32 + 8, ctx.r28.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82115954"))) PPC_WEAK_FUNC(sub_82115954);
PPC_FUNC_IMPL(__imp__sub_82115954) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82115958"))) PPC_WEAK_FUNC(sub_82115958);
PPC_FUNC_IMPL(__imp__sub_82115958) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x82115960;
	__restfpr_25(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r30,0
	ctx.r30.s64 = 0;
	// lwz r27,0(r3)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// li r26,1
	ctx.r26.s64 = 1;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r8,8(r27)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// twllei r9,0
	if (ctx.r9.u32 <= 0) __builtin_debugtrap();
	// divwu r7,r8,r9
	ctx.r7.u32 = ctx.r8.u32 / ctx.r9.u32;
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r30.u32);
	// lwz r25,4(r11)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// mullw r6,r7,r9
	ctx.r6.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r9.s32);
	// subf r28,r6,r8
	ctx.r28.s64 = ctx.r8.s64 - ctx.r6.s64;
	// rlwinm r11,r28,2,0,29
	ctx.r11.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// add r5,r28,r11
	ctx.r5.u64 = ctx.r28.u64 + ctx.r11.u64;
	// rlwinm r11,r5,2,0,29
	ctx.r11.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r31,r11,16
	ctx.r31.s64 = ctx.r11.s64 + 16;
loc_821159B0:
	// cmplw cr6,r28,r25
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r25.u32, ctx.xer);
	// bge cr6,0x82115a60
	if (!ctx.cr6.lt) goto loc_82115A60;
loc_821159B8:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r11,r30
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r30.s32, ctx.xer);
	// bne cr6,0x821159dc
	if (!ctx.cr6.eq) goto loc_821159DC;
	// stwcx. r26,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r26.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x821159b8
	if (!ctx.cr0.eq) goto loc_821159B8;
	// b 0x821159e4
	goto loc_821159E4;
loc_821159DC:
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
loc_821159E4:
	// mr r11,r11
	ctx.r11.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// bne cr6,0x82115a30
	if (!ctx.cr6.eq) goto loc_82115A30;
loc_821159F0:
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82247328
	ctx.lr = 0x821159F8;
	sub_82247328(ctx, base);
loc_821159F8:
	// mfmsr r10
	ctx.r10.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r11,0,r31
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r31.u32);
	ctx.r11.u64 = __builtin_bswap32(ctx.reserved.u32);
	// cmpw cr6,r11,r30
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r30.s32, ctx.xer);
	// bne cr6,0x82115a1c
	if (!ctx.cr6.eq) goto loc_82115A1C;
	// stwcx. r26,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r26.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x821159f8
	if (!ctx.cr0.eq) goto loc_821159F8;
	// b 0x82115a24
	goto loc_82115A24;
loc_82115A1C:
	// stwcx. r11,0,r31
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r31.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r11.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r10,1
	ctx.msr = (ctx.r10.u32 & 0x8020) | (ctx.msr & ~0x8020);
loc_82115A24:
	// mr r11,r11
	ctx.r11.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// beq cr6,0x821159f0
	if (ctx.cr6.eq) goto loc_821159F0;
loc_82115A30:
	// lwz r11,4(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// addi r10,r31,-16
	ctx.r10.s64 = ctx.r31.s64 + -16;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82115a44
	if (ctx.cr6.eq) goto loc_82115A44;
	// stw r11,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r11.u32);
loc_82115A44:
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
	// addi r31,r31,20
	ctx.r31.s64 = ctx.r31.s64 + 20;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// addi r27,r31,-16
	ctx.r27.s64 = ctx.r31.s64 + -16;
	// beq cr6,0x821159b0
	if (ctx.cr6.eq) goto loc_821159B0;
loc_82115A60:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82115A6C"))) PPC_WEAK_FUNC(sub_82115A6C);
PPC_FUNC_IMPL(__imp__sub_82115A6C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82115A70"))) PPC_WEAK_FUNC(sub_82115A70);
PPC_FUNC_IMPL(__imp__sub_82115A70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82115A78;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r9,4(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// twllei r9,0
	if (ctx.r9.u32 <= 0) __builtin_debugtrap();
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// divwu r8,r11,r9
	ctx.r8.u32 = ctx.r11.u32 / ctx.r9.u32;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mullw r7,r8,r9
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r9.s32);
	// subf r11,r7,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r7.s64;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r11,r9
	ctx.r6.u64 = ctx.r11.u64 + ctx.r9.u64;
	// rlwinm r11,r6,2,0,29
	ctx.r11.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r11,r10
	ctx.r31.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x820f63e0
	ctx.lr = 0x82115ABC;
	sub_820F63E0(ctx, base);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// beq cr6,0x82115ae4
	if (ctx.cr6.eq) goto loc_82115AE4;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
loc_82115ACC:
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x82115b28
	if (ctx.cr6.eq) goto loc_82115B28;
	// lwz r11,4(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplw cr6,r11,r31
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r31.u32, ctx.xer);
	// bne cr6,0x82115acc
	if (!ctx.cr6.eq) goto loc_82115ACC;
loc_82115AE4:
	// bl 0x82115c58
	ctx.lr = 0x82115AE8;
	sub_82115C58(ctx, base);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// addi r7,r30,8
	ctx.r7.s64 = ctx.r30.s64 + 8;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// lwz r6,0(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stw r6,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r6.u32);
	// stw r3,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r3.u32);
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
loc_82115B0C:
	// mfmsr r8
	ctx.r8.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r9,0,r7
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r7.u32);
	ctx.r9.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwcx. r9,0,r7
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r7.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r9.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r8,1
	ctx.msr = (ctx.r8.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82115b0c
	if (!ctx.cr0.eq) goto loc_82115B0C;
loc_82115B28:
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r10,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r10.u32);
	// stw r9,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r9.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82115B40"))) PPC_WEAK_FUNC(sub_82115B40);
PPC_FUNC_IMPL(__imp__sub_82115B40) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82115c3c
	if (ctx.cr6.eq) goto loc_82115C3C;
	// lis r11,-32171
	ctx.r11.s64 = -2108358656;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r31,r11,10720
	ctx.r31.s64 = ctx.r11.s64 + 10720;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823052d8
	ctx.lr = 0x82115B74;
	sub_823052D8(ctx, base);
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r10.u32);
	// stw r30,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r30.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r9,r10,-1
	ctx.r9.s64 = ctx.r10.s64 + -1;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r7,r10,-1
	ctx.r7.s64 = ctx.r10.s64 + -1;
	// stw r7,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r7.u32);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// bne cr6,0x82115c30
	if (!ctx.cr6.eq) goto loc_82115C30;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82115c30
	if (ctx.cr6.eq) goto loc_82115C30;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r8,52(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// subf r6,r9,r8
	ctx.r6.s64 = ctx.r8.s64 - ctx.r9.s64;
	// cmpw cr6,r7,r6
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r6.s32, ctx.xer);
	// bge cr6,0x82115c30
	if (!ctx.cr6.lt) goto loc_82115C30;
	// subf r8,r9,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r9.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// stw r8,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r8.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82115c08
	if (ctx.cr6.eq) goto loc_82115C08;
loc_82115BE0:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82115c00
	if (ctx.cr6.eq) goto loc_82115C00;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82115be0
	if (!ctx.cr6.eq) goto loc_82115BE0;
	// b 0x82115c08
	goto loc_82115C08;
loc_82115C00:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
loc_82115C08:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82115c20
	if (!ctx.cr6.eq) goto loc_82115C20;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r9,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r9.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
loc_82115C20:
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82115C2C;
	sub_82080000(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
loc_82115C30:
	// stw r10,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r10.u32);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x82115C3C;
	sub_823051A8(ctx, base);
loc_82115C3C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82115C54"))) PPC_WEAK_FUNC(sub_82115C54);
PPC_FUNC_IMPL(__imp__sub_82115C54) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82115C58"))) PPC_WEAK_FUNC(sub_82115C58);
PPC_FUNC_IMPL(__imp__sub_82115C58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32171
	ctx.r11.s64 = -2108358656;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r31,r11,10720
	ctx.r31.s64 = ctx.r11.s64 + 10720;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823052d8
	ctx.lr = 0x82115C80;
	sub_823052D8(ctx, base);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82115ca4
	if (ctx.cr6.eq) goto loc_82115CA4;
loc_82115C8C:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82115cd4
	if (!ctx.cr6.eq) goto loc_82115CD4;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82115c8c
	if (!ctx.cr6.eq) goto loc_82115C8C;
loc_82115CA4:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82115cfc
	if (!ctx.cr6.eq) goto loc_82115CFC;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82115d58
	ctx.lr = 0x82115CB8;
	sub_82115D58(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82115cfc
	if (!ctx.cr6.eq) goto loc_82115CFC;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x82115CCC;
	sub_823051A8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82115d40
	goto loc_82115D40;
loc_82115CD4:
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// lwz r30,4(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x82115d30
	goto loc_82115D30;
loc_82115CFC:
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// addi r10,r11,16
	ctx.r10.s64 = ctx.r11.s64 + 16;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// addi r11,r10,4
	ctx.r11.s64 = ctx.r10.s64 + 4;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stw r8,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r8.u32);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
loc_82115D30:
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x82115D3C;
	sub_823051A8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_82115D40:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82115D58"))) PPC_WEAK_FUNC(sub_82115D58);
PPC_FUNC_IMPL(__imp__sub_82115D58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// add r11,r3,r11
	ctx.r11.u64 = ctx.r3.u64 + ctx.r11.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r11,32
	ctx.r3.s64 = ctx.r11.s64 + 32;
	// bl 0x82082030
	ctx.lr = 0x82115D8C;
	sub_82082030(ctx, base);
	// lis r11,-32171
	ctx.r11.s64 = -2108358656;
	// addi r11,r11,10720
	ctx.r11.s64 = ctx.r11.s64 + 10720;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82115da8
	if (ctx.cr6.eq) goto loc_82115DA8;
	// stw r3,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r3.u32);
	// b 0x82115dac
	goto loc_82115DAC;
loc_82115DA8:
	// stw r3,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r3.u32);
loc_82115DAC:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// addi r9,r3,32
	ctx.r9.s64 = ctx.r3.s64 + 32;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// stw r3,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r3.u32);
	// stw r3,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r3.u32);
	// stw r31,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r31.u32);
	// beq cr6,0x82115dec
	if (ctx.cr6.eq) goto loc_82115DEC;
	// addi r10,r9,-4
	ctx.r10.s64 = ctx.r9.s64 + -4;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
loc_82115DE4:
	// stwu r3,20(r10)
	ea = 20 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x82115de4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82115DE4;
loc_82115DEC:
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// stw r10,52(r11)
	PPC_STORE_U32(ctx.r11.u32 + 52, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82115E0C"))) PPC_WEAK_FUNC(sub_82115E0C);
PPC_FUNC_IMPL(__imp__sub_82115E0C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82115E10"))) PPC_WEAK_FUNC(sub_82115E10);
PPC_FUNC_IMPL(__imp__sub_82115E10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x82115E18;
	__restfpr_25(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// divwu r3,r7,r6
	ctx.r3.u32 = ctx.r7.u32 / ctx.r6.u32;
	// lbz r7,279(r1)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r1.u32 + 279);
	// divwu r29,r8,r6
	ctx.r29.u32 = ctx.r8.u32 / ctx.r6.u32;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// twllei r6,0
	if (ctx.r6.u32 <= 0) __builtin_debugtrap();
	// twllei r6,0
	if (ctx.r6.u32 <= 0) __builtin_debugtrap();
	// stw r4,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r4.u32);
	// stb r7,24(r31)
	PPC_STORE_U8(ctx.r31.u32 + 24, ctx.r7.u8);
	// mr r8,r5
	ctx.r8.u64 = ctx.r5.u64;
	// stw r5,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r5.u32);
	// mr r7,r4
	ctx.r7.u64 = ctx.r4.u64;
	// stw r10,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r10.u32);
	// li r30,0
	ctx.r30.s64 = 0;
	// stb r9,25(r31)
	PPC_STORE_U8(ctx.r31.u32 + 25, ctx.r9.u8);
	// addi r28,r31,88
	ctx.r28.s64 = ctx.r31.s64 + 88;
	// stw r6,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r6.u32);
	// addi r27,r31,84
	ctx.r27.s64 = ctx.r31.s64 + 84;
	// addi r26,r31,32
	ctx.r26.s64 = ctx.r31.s64 + 32;
	// stw r3,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r3.u32);
	// li r25,-1
	ctx.r25.s64 = -1;
	// stw r29,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r29.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r28,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r28.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r27,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r27.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r26,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r26.u32);
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r25.u32);
	// bl 0x82298488
	ctx.lr = 0x82115EA0;
	sub_82298488(ctx, base);
	// stw r3,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r3.u32);
	// stw r30,92(r31)
	PPC_STORE_U32(ctx.r31.u32 + 92, ctx.r30.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82115EB0"))) PPC_WEAK_FUNC(sub_82115EB0);
PPC_FUNC_IMPL(__imp__sub_82115EB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x82115EB8;
	__restfpr_29(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lbz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 24);
	// mr r30,r6
	ctx.r30.u64 = ctx.r6.u64;
	// divwu r3,r4,r11
	ctx.r3.u32 = ctx.r4.u32 / ctx.r11.u32;
	// twllei r11,0
	if (ctx.r11.u32 <= 0) __builtin_debugtrap();
	// divwu r4,r5,r11
	ctx.r4.u32 = ctx.r5.u32 / ctx.r11.u32;
	// twllei r11,0
	if (ctx.r11.u32 <= 0) __builtin_debugtrap();
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82115f0c
	if (!ctx.cr6.eq) goto loc_82115F0C;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// mullw r10,r4,r3
	ctx.r10.s64 = int64_t(ctx.r4.s32) * int64_t(ctx.r3.s32);
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// mullw r8,r11,r9
	ctx.r8.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r9.s32);
	// cmplw cr6,r10,r8
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, ctx.xer);
	// ble cr6,0x82115f0c
	if (!ctx.cr6.gt) goto loc_82115F0C;
	// lis r11,-13569
	ctx.r11.s64 = -889257984;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// addi r9,r10,-29900
	ctx.r9.s64 = ctx.r10.s64 + -29900;
	// stw r9,-13570(r11)
	PPC_STORE_U32(ctx.r11.u32 + -13570, ctx.r9.u32);
loc_82115F0C:
	// lbz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82115f8c
	if (!ctx.cr6.eq) goto loc_82115F8C;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82115f30
	if (!ctx.cr6.eq) goto loc_82115F30;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplw cr6,r4,r11
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82115f8c
	if (ctx.cr6.eq) goto loc_82115F8C;
loc_82115F30:
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// li r29,-1
	ctx.r29.s64 = -1;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r5,28(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// bl 0x82298488
	ctx.lr = 0x82115F68;
	sub_82298488(ctx, base);
	// lbz r11,25(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 25);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82115fb0
	if (ctx.cr6.eq) goto loc_82115FB0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,92(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// bl 0x822986a8
	ctx.lr = 0x82115F80;
	sub_822986A8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
loc_82115F8C:
	// addi r4,r31,32
	ctx.r4.s64 = ctx.r31.s64 + 32;
	// li r5,52
	ctx.r5.s64 = 52;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x82115F9C;
	sub_8233E4E0(ctx, base);
	// lbz r11,25(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 25);
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82115fb0
	if (!ctx.cr6.eq) goto loc_82115FB0;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
loc_82115FB0:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82115FB8"))) PPC_WEAK_FUNC(sub_82115FB8);
PPC_FUNC_IMPL(__imp__sub_82115FB8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// lbz r7,36(r3)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r3.u32 + 36);
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// divwu r10,r4,r9
	ctx.r10.u32 = ctx.r4.u32 / ctx.r9.u32;
	// twllei r9,0
	if (ctx.r9.u32 <= 0) __builtin_debugtrap();
	// divwu r4,r5,r9
	ctx.r4.u32 = ctx.r5.u32 / ctx.r9.u32;
	// twllei r9,0
	if (ctx.r9.u32 <= 0) __builtin_debugtrap();
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x8211601c
	if (!ctx.cr6.eq) goto loc_8211601C;
	// lwz r9,16(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// mullw r7,r4,r10
	ctx.r7.s64 = int64_t(ctx.r4.s32) * int64_t(ctx.r10.s32);
	// lwz r6,12(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// mullw r5,r9,r6
	ctx.r5.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r6.s32);
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// ble cr6,0x8211601c
	if (!ctx.cr6.gt) goto loc_8211601C;
	// lis r9,-13569
	ctx.r9.s64 = -889257984;
	// lis r7,-32249
	ctx.r7.s64 = -2113470464;
	// addi r6,r7,-29872
	ctx.r6.s64 = ctx.r7.s64 + -29872;
	// stw r6,-13570(r9)
	PPC_STORE_U32(ctx.r9.u32 + -13570, ctx.r6.u32);
loc_8211601C:
	// lbz r9,36(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 36);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x8211607c
	if (!ctx.cr6.eq) goto loc_8211607C;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// cmplw cr6,r10,r9
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, ctx.xer);
	// bne cr6,0x82116040
	if (!ctx.cr6.eq) goto loc_82116040;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmplw cr6,r4,r9
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r9.u32, ctx.xer);
	// beq cr6,0x8211607c
	if (ctx.cr6.eq) goto loc_8211607C;
loc_82116040:
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r31,28(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r30,4(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// stw r3,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r3.u32);
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// lwz r6,32(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// stw r5,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r5.u32);
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r30.u32);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82298188
	ctx.lr = 0x82116078;
	sub_82298188(ctx, base);
	// b 0x8211608c
	goto loc_8211608C;
loc_8211607C:
	// addi r4,r11,40
	ctx.r4.s64 = ctx.r11.s64 + 40;
	// li r5,48
	ctx.r5.s64 = 48;
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x8211608C;
	sub_8233E4E0(ctx, base);
loc_8211608C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821160A4"))) PPC_WEAK_FUNC(sub_821160A4);
PPC_FUNC_IMPL(__imp__sub_821160A4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821160A8"))) PPC_WEAK_FUNC(sub_821160A8);
PPC_FUNC_IMPL(__imp__sub_821160A8) {
	PPC_FUNC_PROLOGUE();
	// addi r9,r1,-16
	ctx.r9.s64 = ctx.r1.s64 + -16;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// addic. r10,r4,-1
	ctx.xer.ca = ctx.r4.u32 > 0;
	ctx.r10.s64 = ctx.r4.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// mr r5,r8
	ctx.r5.u64 = ctx.r8.u64;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// stw r8,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r8.u32);
	// stw r8,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r8.u32);
	// stb r8,12(r9)
	PPC_STORE_U8(ctx.r9.u32 + 12, ctx.r8.u8);
	// beq 0x82116220
	if (ctx.cr0.eq) goto loc_82116220;
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
loc_821160D4:
	// lbz r9,9(r11)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r11.u32 + 9);
	// addi r10,r1,-16
	ctx.r10.s64 = ctx.r1.s64 + -16;
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// sth r8,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r8.u16);
	// clrlwi r7,r7,26
	ctx.r7.u64 = ctx.r7.u32 & 0x3F;
	// sth r5,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r5.u16);
	// stb r8,8(r11)
	PPC_STORE_U8(ctx.r11.u32 + 8, ctx.r8.u8);
	// lbzx r3,r9,r10
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// addi r7,r7,-6
	ctx.r7.s64 = ctx.r7.s64 + -6;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// cmplwi cr6,r7,51
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 51, ctx.xer);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// stb r3,10(r11)
	PPC_STORE_U8(ctx.r11.u32 + 10, ctx.r3.u8);
	// stbx r6,r9,r10
	PPC_STORE_U8(ctx.r9.u32 + ctx.r10.u32, ctx.r6.u8);
	// bgt cr6,0x82116214
	if (ctx.cr6.gt) goto loc_82116214;
	// lis r12,-32239
	ctx.r12.s64 = -2112815104;
	// rlwinm r0,r7,2,0,29
	ctx.r0.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r12,r12,24872
	ctx.r12.s64 = ctx.r12.s64 + 24872;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r7.u64) {
	case 0:
		goto loc_821161F8;
	case 1:
		goto loc_821161F8;
	case 2:
		goto loc_82116214;
	case 3:
		goto loc_82116214;
	case 4:
		goto loc_82116214;
	case 5:
		goto loc_82116214;
	case 6:
		goto loc_82116214;
	case 7:
		goto loc_82116214;
	case 8:
		goto loc_82116214;
	case 9:
		goto loc_82116214;
	case 10:
		goto loc_821161F8;
	case 11:
		goto loc_821161F8;
	case 12:
		goto loc_82116214;
	case 13:
		goto loc_82116214;
	case 14:
		goto loc_82116214;
	case 15:
		goto loc_82116214;
	case 16:
		goto loc_82116214;
	case 17:
		goto loc_82116214;
	case 18:
		goto loc_82116214;
	case 19:
		goto loc_821161F8;
	case 20:
		goto loc_82116200;
	case 21:
		goto loc_82116214;
	case 22:
		goto loc_82116214;
	case 23:
		goto loc_82116214;
	case 24:
		goto loc_82116214;
	case 25:
		goto loc_821161F8;
	case 26:
		goto loc_82116200;
	case 27:
		goto loc_821161F8;
	case 28:
		goto loc_82116200;
	case 29:
		goto loc_82116210;
	case 30:
		goto loc_821161F8;
	case 31:
		goto loc_82116200;
	case 32:
		goto loc_82116210;
	case 33:
		goto loc_82116214;
	case 34:
		goto loc_82116214;
	case 35:
		goto loc_82116214;
	case 36:
		goto loc_82116214;
	case 37:
		goto loc_82116214;
	case 38:
		goto loc_82116214;
	case 39:
		goto loc_82116214;
	case 40:
		goto loc_82116214;
	case 41:
		goto loc_82116214;
	case 42:
		goto loc_82116214;
	case 43:
		goto loc_82116214;
	case 44:
		goto loc_82116214;
	case 45:
		goto loc_82116214;
	case 46:
		goto loc_82116214;
	case 47:
		goto loc_82116214;
	case 48:
		goto loc_82116214;
	case 49:
		goto loc_82116214;
	case 50:
		goto loc_82116214;
	case 51:
		goto loc_82116208;
	default:
		__builtin_unreachable();
	}
	// lwz r16,25080(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25080);
	// lwz r16,25080(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25080);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25080(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25080);
	// lwz r16,25080(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25080);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25080(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25080);
	// lwz r16,25088(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25088);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25080(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25080);
	// lwz r16,25088(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25088);
	// lwz r16,25080(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25080);
	// lwz r16,25088(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25088);
	// lwz r16,25104(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25104);
	// lwz r16,25080(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25080);
	// lwz r16,25088(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25088);
	// lwz r16,25104(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25104);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25108);
	// lwz r16,25096(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + 25096);
loc_821161F8:
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// b 0x82116214
	goto loc_82116214;
loc_82116200:
	// addi r5,r5,8
	ctx.r5.s64 = ctx.r5.s64 + 8;
	// b 0x82116214
	goto loc_82116214;
loc_82116208:
	// addi r5,r5,12
	ctx.r5.s64 = ctx.r5.s64 + 12;
	// b 0x82116214
	goto loc_82116214;
loc_82116210:
	// addi r5,r5,16
	ctx.r5.s64 = ctx.r5.s64 + 16;
loc_82116214:
	// addic. r4,r4,-1
	ctx.xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r4.s32, 0, ctx.xer);
	// addi r11,r11,12
	ctx.r11.s64 = ctx.r11.s64 + 12;
	// bne 0x821160d4
	if (!ctx.cr0.eq) goto loc_821160D4;
loc_82116220:
	// li r10,255
	ctx.r10.s64 = 255;
	// sth r8,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r8.u16);
	// li r9,-1
	ctx.r9.s64 = -1;
	// stb r8,8(r11)
	PPC_STORE_U8(ctx.r11.u32 + 8, ctx.r8.u8);
	// sth r10,0(r11)
	PPC_STORE_U16(ctx.r11.u32 + 0, ctx.r10.u16);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// stb r8,9(r11)
	PPC_STORE_U8(ctx.r11.u32 + 9, ctx.r8.u8);
	// stb r8,10(r11)
	PPC_STORE_U8(ctx.r11.u32 + 10, ctx.r8.u8);
}

__attribute__((alias("__imp__sub_82116240"))) PPC_WEAK_FUNC(sub_82116240);
PPC_FUNC_IMPL(__imp__sub_82116240) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82116244"))) PPC_WEAK_FUNC(sub_82116244);
PPC_FUNC_IMPL(__imp__sub_82116244) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82116248"))) PPC_WEAK_FUNC(sub_82116248);
PPC_FUNC_IMPL(__imp__sub_82116248) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82116344
	if (ctx.cr6.eq) goto loc_82116344;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r31,r11,2732
	ctx.r31.s64 = ctx.r11.s64 + 2732;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823052d8
	ctx.lr = 0x8211627C;
	sub_823052D8(ctx, base);
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r10.u32);
	// stw r30,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r30.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r9,r10,-1
	ctx.r9.s64 = ctx.r10.s64 + -1;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r7,r10,-1
	ctx.r7.s64 = ctx.r10.s64 + -1;
	// stw r7,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r7.u32);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// bne cr6,0x82116338
	if (!ctx.cr6.eq) goto loc_82116338;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82116338
	if (ctx.cr6.eq) goto loc_82116338;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r8,52(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// subf r6,r9,r8
	ctx.r6.s64 = ctx.r8.s64 - ctx.r9.s64;
	// cmpw cr6,r7,r6
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r6.s32, ctx.xer);
	// bge cr6,0x82116338
	if (!ctx.cr6.lt) goto loc_82116338;
	// subf r8,r9,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r9.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// stw r8,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r8.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82116310
	if (ctx.cr6.eq) goto loc_82116310;
loc_821162E8:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82116308
	if (ctx.cr6.eq) goto loc_82116308;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x821162e8
	if (!ctx.cr6.eq) goto loc_821162E8;
	// b 0x82116310
	goto loc_82116310;
loc_82116308:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
loc_82116310:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82116328
	if (!ctx.cr6.eq) goto loc_82116328;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r9,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r9.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
loc_82116328:
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82116334;
	sub_82080000(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
loc_82116338:
	// stw r10,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r10.u32);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x82116344;
	sub_823051A8(ctx, base);
loc_82116344:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211635C"))) PPC_WEAK_FUNC(sub_8211635C);
PPC_FUNC_IMPL(__imp__sub_8211635C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82116360"))) PPC_WEAK_FUNC(sub_82116360);
PPC_FUNC_IMPL(__imp__sub_82116360) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r31,r11,2732
	ctx.r31.s64 = ctx.r11.s64 + 2732;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823052d8
	ctx.lr = 0x82116388;
	sub_823052D8(ctx, base);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821163ac
	if (ctx.cr6.eq) goto loc_821163AC;
loc_82116394:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x821163dc
	if (!ctx.cr6.eq) goto loc_821163DC;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82116394
	if (!ctx.cr6.eq) goto loc_82116394;
loc_821163AC:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82116404
	if (!ctx.cr6.eq) goto loc_82116404;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82116460
	ctx.lr = 0x821163C0;
	sub_82116460(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82116404
	if (!ctx.cr6.eq) goto loc_82116404;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x821163D4;
	sub_823051A8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82116448
	goto loc_82116448;
loc_821163DC:
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// lwz r30,4(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x82116438
	goto loc_82116438;
loc_82116404:
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// addi r10,r11,12
	ctx.r10.s64 = ctx.r11.s64 + 12;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// addi r11,r10,20
	ctx.r11.s64 = ctx.r10.s64 + 20;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stw r8,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r8.u32);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
loc_82116438:
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x82116444;
	sub_823051A8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_82116448:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82116460"))) PPC_WEAK_FUNC(sub_82116460);
PPC_FUNC_IMPL(__imp__sub_82116460) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r3,1
	ctx.r11.s64 = ctx.r3.s64 + 1;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// rlwinm r3,r11,5,0,26
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// bl 0x82082030
	ctx.lr = 0x8211648C;
	sub_82082030(ctx, base);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r11,r11,2732
	ctx.r11.s64 = ctx.r11.s64 + 2732;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821164a8
	if (ctx.cr6.eq) goto loc_821164A8;
	// stw r3,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r3.u32);
	// b 0x821164ac
	goto loc_821164AC;
loc_821164A8:
	// stw r3,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r3.u32);
loc_821164AC:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// addi r9,r3,32
	ctx.r9.s64 = ctx.r3.s64 + 32;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// stw r3,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r3.u32);
	// stw r3,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r3.u32);
	// stw r31,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r31.u32);
	// beq cr6,0x821164ec
	if (ctx.cr6.eq) goto loc_821164EC;
	// addi r10,r9,-20
	ctx.r10.s64 = ctx.r9.s64 + -20;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
loc_821164E4:
	// stwu r3,32(r10)
	ea = 32 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x821164e4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_821164E4;
loc_821164EC:
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// stw r10,52(r11)
	PPC_STORE_U32(ctx.r11.u32 + 52, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211650C"))) PPC_WEAK_FUNC(sub_8211650C);
PPC_FUNC_IMPL(__imp__sub_8211650C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82116510"))) PPC_WEAK_FUNC(sub_82116510);
PPC_FUNC_IMPL(__imp__sub_82116510) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e454
	ctx.lr = 0x82116518;
	__restfpr_23(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r23,r5
	ctx.r23.u64 = ctx.r5.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82116538
	if (ctx.cr6.eq) goto loc_82116538;
	// bl 0x821166c0
	ctx.lr = 0x82116538;
	sub_821166C0(ctx, base);
loc_82116538:
	// li r29,512
	ctx.r29.s64 = 512;
	// li r28,1024
	ctx.r28.s64 = 1024;
	// li r27,2048
	ctx.r27.s64 = 2048;
	// li r26,4096
	ctx.r26.s64 = 4096;
	// li r25,8192
	ctx.r25.s64 = 8192;
	// li r24,6144
	ctx.r24.s64 = 6144;
	// cmplwi cr6,r30,512
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 512, ctx.xer);
	// bgt cr6,0x8211656c
	if (ctx.cr6.gt) goto loc_8211656C;
	// stw r29,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r29.u32);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r3,r11,2788
	ctx.r3.s64 = ctx.r11.s64 + 2788;
	// bl 0x821171f0
	ctx.lr = 0x82116568;
	sub_821171F0(ctx, base);
	// b 0x821165ec
	goto loc_821165EC;
loc_8211656C:
	// cmplwi cr6,r30,1024
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 1024, ctx.xer);
	// bgt cr6,0x82116588
	if (ctx.cr6.gt) goto loc_82116588;
	// stw r28,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r28.u32);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r3,r11,2832
	ctx.r3.s64 = ctx.r11.s64 + 2832;
	// bl 0x82117510
	ctx.lr = 0x82116584;
	sub_82117510(ctx, base);
	// b 0x821165ec
	goto loc_821165EC;
loc_82116588:
	// cmplwi cr6,r30,2048
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 2048, ctx.xer);
	// bgt cr6,0x821165a4
	if (ctx.cr6.gt) goto loc_821165A4;
	// stw r27,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r27.u32);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r3,r11,2876
	ctx.r3.s64 = ctx.r11.s64 + 2876;
	// bl 0x82117830
	ctx.lr = 0x821165A0;
	sub_82117830(ctx, base);
	// b 0x821165ec
	goto loc_821165EC;
loc_821165A4:
	// cmplwi cr6,r30,4096
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 4096, ctx.xer);
	// bgt cr6,0x821165c0
	if (ctx.cr6.gt) goto loc_821165C0;
	// stw r26,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r26.u32);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r3,r11,2920
	ctx.r3.s64 = ctx.r11.s64 + 2920;
	// bl 0x82117b50
	ctx.lr = 0x821165BC;
	sub_82117B50(ctx, base);
	// b 0x821165ec
	goto loc_821165EC;
loc_821165C0:
	// cmplwi cr6,r30,6144
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 6144, ctx.xer);
	// bgt cr6,0x821165dc
	if (ctx.cr6.gt) goto loc_821165DC;
	// stw r24,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r24.u32);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r3,r11,2964
	ctx.r3.s64 = ctx.r11.s64 + 2964;
	// bl 0x82117ee0
	ctx.lr = 0x821165D8;
	sub_82117EE0(ctx, base);
	// b 0x821165ec
	goto loc_821165EC;
loc_821165DC:
	// stw r25,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r25.u32);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r3,r11,3004
	ctx.r3.s64 = ctx.r11.s64 + 3004;
	// bl 0x82118208
	ctx.lr = 0x821165EC;
	sub_82118208(ctx, base);
loc_821165EC:
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r23,512
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 512, ctx.xer);
	// bgt cr6,0x82116614
	if (ctx.cr6.gt) goto loc_82116614;
	// stw r29,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r29.u32);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r3,r11,3044
	ctx.r3.s64 = ctx.r11.s64 + 3044;
	// bl 0x82118478
	ctx.lr = 0x82116608;
	sub_82118478(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
loc_82116614:
	// cmplwi cr6,r23,1024
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 1024, ctx.xer);
	// bgt cr6,0x82116638
	if (ctx.cr6.gt) goto loc_82116638;
	// stw r28,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r28.u32);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r3,r11,3088
	ctx.r3.s64 = ctx.r11.s64 + 3088;
	// bl 0x82118790
	ctx.lr = 0x8211662C;
	sub_82118790(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
loc_82116638:
	// cmplwi cr6,r23,2048
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 2048, ctx.xer);
	// bgt cr6,0x8211665c
	if (ctx.cr6.gt) goto loc_8211665C;
	// stw r27,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r27.u32);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r3,r11,3132
	ctx.r3.s64 = ctx.r11.s64 + 3132;
	// bl 0x82118a98
	ctx.lr = 0x82116650;
	sub_82118A98(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
loc_8211665C:
	// cmplwi cr6,r23,4096
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 4096, ctx.xer);
	// bgt cr6,0x82116680
	if (ctx.cr6.gt) goto loc_82116680;
	// stw r26,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r26.u32);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r3,r11,3176
	ctx.r3.s64 = ctx.r11.s64 + 3176;
	// bl 0x82118e88
	ctx.lr = 0x82116674;
	sub_82118E88(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
loc_82116680:
	// cmplwi cr6,r23,6144
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 6144, ctx.xer);
	// bgt cr6,0x821166a4
	if (ctx.cr6.gt) goto loc_821166A4;
	// stw r24,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r24.u32);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r3,r11,3220
	ctx.r3.s64 = ctx.r11.s64 + 3220;
	// bl 0x82119208
	ctx.lr = 0x82116698;
	sub_82119208(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
loc_821166A4:
	// stw r25,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r25.u32);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r3,r11,3260
	ctx.r3.s64 = ctx.r11.s64 + 3260;
	// bl 0x82119520
	ctx.lr = 0x821166B4;
	sub_82119520(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821166C0"))) PPC_WEAK_FUNC(sub_821166C0);
PPC_FUNC_IMPL(__imp__sub_821166C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,4096
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4096, ctx.xer);
	// bgt cr6,0x82116730
	if (ctx.cr6.gt) goto loc_82116730;
	// beq cr6,0x82116724
	if (ctx.cr6.eq) goto loc_82116724;
	// cmplwi cr6,r11,512
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 512, ctx.xer);
	// beq cr6,0x82116718
	if (ctx.cr6.eq) goto loc_82116718;
	// cmplwi cr6,r11,1024
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1024, ctx.xer);
	// beq cr6,0x8211670c
	if (ctx.cr6.eq) goto loc_8211670C;
	// cmplwi cr6,r11,2048
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2048, ctx.xer);
	// bne cr6,0x82116754
	if (!ctx.cr6.eq) goto loc_82116754;
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// bl 0x82117a00
	ctx.lr = 0x82116708;
	sub_82117A00(ctx, base);
	// b 0x82116754
	goto loc_82116754;
loc_8211670C:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x821176e0
	ctx.lr = 0x82116714;
	sub_821176E0(ctx, base);
	// b 0x82116754
	goto loc_82116754;
loc_82116718:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x821173c0
	ctx.lr = 0x82116720;
	sub_821173C0(ctx, base);
	// b 0x82116754
	goto loc_82116754;
loc_82116724:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82117d20
	ctx.lr = 0x8211672C;
	sub_82117D20(ctx, base);
	// b 0x82116754
	goto loc_82116754;
loc_82116730:
	// cmplwi cr6,r11,6144
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6144, ctx.xer);
	// beq cr6,0x8211674c
	if (ctx.cr6.eq) goto loc_8211674C;
	// cmplwi cr6,r11,8192
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8192, ctx.xer);
	// bne cr6,0x82116754
	if (!ctx.cr6.eq) goto loc_82116754;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82118330
	ctx.lr = 0x82116748;
	sub_82118330(ctx, base);
	// b 0x82116754
	goto loc_82116754;
loc_8211674C:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x821180b8
	ctx.lr = 0x82116754;
	sub_821180B8(ctx, base);
loc_82116754:
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// li r30,0
	ctx.r30.s64 = 0;
	// stw r30,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r30.u32);
	// cmplwi cr6,r11,4096
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 4096, ctx.xer);
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
	// bgt cr6,0x821167b8
	if (ctx.cr6.gt) goto loc_821167B8;
	// beq cr6,0x821167ac
	if (ctx.cr6.eq) goto loc_821167AC;
	// cmplwi cr6,r11,512
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 512, ctx.xer);
	// beq cr6,0x821167a0
	if (ctx.cr6.eq) goto loc_821167A0;
	// cmplwi cr6,r11,1024
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1024, ctx.xer);
	// beq cr6,0x82116794
	if (ctx.cr6.eq) goto loc_82116794;
	// cmplwi cr6,r11,2048
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2048, ctx.xer);
	// bne cr6,0x821167dc
	if (!ctx.cr6.eq) goto loc_821167DC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x82118c78
	ctx.lr = 0x82116790;
	sub_82118C78(ctx, base);
	// b 0x821167dc
	goto loc_821167DC;
loc_82116794:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x82118970
	ctx.lr = 0x8211679C;
	sub_82118970(ctx, base);
	// b 0x821167dc
	goto loc_821167DC;
loc_821167A0:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x82118660
	ctx.lr = 0x821167A8;
	sub_82118660(ctx, base);
	// b 0x821167dc
	goto loc_821167DC;
loc_821167AC:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x82119068
	ctx.lr = 0x821167B4;
	sub_82119068(ctx, base);
	// b 0x821167dc
	goto loc_821167DC;
loc_821167B8:
	// cmplwi cr6,r11,6144
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6144, ctx.xer);
	// beq cr6,0x821167d4
	if (ctx.cr6.eq) goto loc_821167D4;
	// cmplwi cr6,r11,8192
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 8192, ctx.xer);
	// bne cr6,0x821167dc
	if (!ctx.cr6.eq) goto loc_821167DC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x82119658
	ctx.lr = 0x821167D0;
	sub_82119658(ctx, base);
	// b 0x821167dc
	goto loc_821167DC;
loc_821167D4:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x821193f0
	ctx.lr = 0x821167DC;
	sub_821193F0(ctx, base);
loc_821167DC:
	// stw r30,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r30.u32);
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821167FC"))) PPC_WEAK_FUNC(sub_821167FC);
PPC_FUNC_IMPL(__imp__sub_821167FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82116800"))) PPC_WEAK_FUNC(sub_82116800);
PPC_FUNC_IMPL(__imp__sub_82116800) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32176
	ctx.r10.s64 = -2108686336;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r31,r10,3432
	ctx.r31.s64 = ctx.r10.s64 + 3432;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x821168b0
	if (ctx.cr6.eq) goto loc_821168B0;
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_82116830:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82116850
	if (!ctx.cr6.eq) goto loc_82116850;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82116830
	if (ctx.cr6.lt) goto loc_82116830;
	// b 0x821168b0
	goto loc_821168B0;
loc_82116850:
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x821168b0
	if (ctx.cr6.eq) goto loc_821168B0;
loc_82116860:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82119dc8
	ctx.lr = 0x82116868;
	sub_82119DC8(ctx, base);
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x821168b0
	if (ctx.cr6.eq) goto loc_821168B0;
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_82116880:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x821168a0
	if (!ctx.cr6.eq) goto loc_821168A0;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82116880
	if (ctx.cr6.lt) goto loc_82116880;
	// b 0x821168b0
	goto loc_821168B0;
loc_821168A0:
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82116860
	if (!ctx.cr6.eq) goto loc_82116860;
loc_821168B0:
	// lis r10,-32176
	ctx.r10.s64 = -2108686336;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r31,r10,3464
	ctx.r31.s64 = ctx.r10.s64 + 3464;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82116970
	if (ctx.cr6.eq) goto loc_82116970;
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_821168D0:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82116900
	if (!ctx.cr6.eq) goto loc_82116900;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x821168d0
	if (ctx.cr6.lt) goto loc_821168D0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82116900:
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82116970
	if (ctx.cr6.eq) goto loc_82116970;
loc_82116910:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82119dc8
	ctx.lr = 0x82116918;
	sub_82119DC8(ctx, base);
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82116970
	if (ctx.cr6.eq) goto loc_82116970;
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_82116930:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// bne cr6,0x82116960
	if (!ctx.cr6.eq) goto loc_82116960;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r11,r9
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82116930
	if (ctx.cr6.lt) goto loc_82116930;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82116960:
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r8
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r8.u32);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82116910
	if (!ctx.cr6.eq) goto loc_82116910;
loc_82116970:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82116984"))) PPC_WEAK_FUNC(sub_82116984);
PPC_FUNC_IMPL(__imp__sub_82116984) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82116988"))) PPC_WEAK_FUNC(sub_82116988);
PPC_FUNC_IMPL(__imp__sub_82116988) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e438
	ctx.lr = 0x82116990;
	__restfpr_16(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x8208d070
	ctx.lr = 0x8211699C;
	sub_8208D070(ctx, base);
	// lis r11,-32197
	ctx.r11.s64 = -2110062592;
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// lwz r3,-27096(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -27096);
	// bl 0x82388734
	ctx.lr = 0x821169AC;
	__imp__KeTlsGetValue(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x821169b8
	if (!ctx.cr6.eq) goto loc_821169B8;
	// bl 0x821b3000
	ctx.lr = 0x821169B8;
	sub_821B3000(ctx, base);
loc_821169B8:
	// addi r10,r22,15
	ctx.r10.s64 = ctx.r22.s64 + 15;
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// lwz r9,20(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// addi r20,r22,31
	ctx.r20.s64 = ctx.r22.s64 + 31;
	// rlwinm r17,r10,0,0,27
	ctx.r17.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF0;
	// addi r21,r3,20
	ctx.r21.s64 = ctx.r3.s64 + 20;
	// add r8,r17,r11
	ctx.r8.u64 = ctx.r17.u64 + ctx.r11.u64;
	// lis r16,-13569
	ctx.r16.s64 = -889257984;
	// rlwinm r18,r20,0,0,26
	ctx.r18.u64 = rotl64(ctx.r20.u32 | (ctx.r20.u64 << 32), 0) & 0xFFFFFFE0;
	// cmplw cr6,r8,r9
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, ctx.xer);
	// ble cr6,0x821169f0
	if (!ctx.cr6.gt) goto loc_821169F0;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,4492
	ctx.r10.s64 = ctx.r11.s64 + 4492;
	// stw r10,-13570(r16)
	PPC_STORE_U32(ctx.r16.u32 + -13570, ctx.r10.u32);
loc_821169F0:
	// lwz r11,4(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 4);
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// lwz r10,8(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// add r9,r11,r17
	ctx.r9.u64 = ctx.r11.u64 + ctx.r17.u64;
	// add r19,r11,r10
	ctx.r19.u64 = ctx.r11.u64 + ctx.r10.u64;
	// stw r9,4(r21)
	PPC_STORE_U32(ctx.r21.u32 + 4, ctx.r9.u32);
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82116A14;
	sub_8208CFB0(ctx, base);
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// add r8,r10,r11
	ctx.r8.u64 = ctx.r10.u64 + ctx.r11.u64;
	// clrldi r11,r8,62
	ctx.r11.u64 = ctx.r8.u64 & 0x3;
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82116a3c
	if (ctx.cr6.eq) goto loc_82116A3C;
	// li r5,1
	ctx.r5.s64 = 1;
	// subfic r4,r11,4
	ctx.xer.ca = ctx.r11.u32 <= 4;
	ctx.r4.s64 = 4 - ctx.r11.s64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82119d10
	ctx.lr = 0x82116A3C;
	sub_82119D10(ctx, base);
loc_82116A3C:
	// li r23,0
	ctx.r23.s64 = 0;
	// li r5,4
	ctx.r5.s64 = 4;
	// std r23,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r23.u64);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82116A54;
	sub_8208CFB0(ctx, base);
	// ld r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// bne cr6,0x82116a70
	if (!ctx.cr6.eq) goto loc_82116A70;
	// li r5,8
	ctx.r5.s64 = 8;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82116A70;
	sub_8208CFB0(ctx, base);
loc_82116A70:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8208d070
	ctx.lr = 0x82116A78;
	sub_8208D070(ctx, base);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8208d070
	ctx.lr = 0x82116A84;
	sub_8208D070(ctx, base);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// li r24,-1
	ctx.r24.s64 = -1;
	// ld r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// addi r27,r11,3412
	ctx.r27.s64 = ctx.r11.s64 + 3412;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823052d8
	ctx.lr = 0x82116AA4;
	sub_823052D8(ctx, base);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r29,r11,3432
	ctx.r29.s64 = ctx.r11.s64 + 3432;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// divdu r9,r28,r11
	ctx.r9.u64 = ctx.r28.u64 / ctx.r11.u64;
	// tdllei r11,0
	if (ctx.r11.u64 <= 0) __builtin_debugtrap();
	// mulld r8,r9,r11
	ctx.r8.s64 = ctx.r9.s64 * ctx.r11.s64;
	// subf r7,r8,r28
	ctx.r7.s64 = ctx.r28.s64 - ctx.r8.s64;
	// rlwinm r6,r7,2,0,29
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r30,r6,r10
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82116b10
	if (ctx.cr6.eq) goto loc_82116B10;
loc_82116AD4:
	// ld r11,24(r30)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r30.u32 + 24);
	// cmpld cr6,r11,r28
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, ctx.r28.u64, ctx.xer);
	// beq cr6,0x82116af0
	if (ctx.cr6.eq) goto loc_82116AF0;
	// lwz r30,16(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82116ad4
	if (!ctx.cr6.eq) goto loc_82116AD4;
	// b 0x82116b10
	goto loc_82116B10;
loc_82116AF0:
	// addi r11,r30,20
	ctx.r11.s64 = ctx.r30.s64 + 20;
loc_82116AF4:
	// mfmsr r9
	ctx.r9.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r10,0,r11
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r11.u32);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r11
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r11.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82116af4
	if (!ctx.cr0.eq) goto loc_82116AF4;
loc_82116B10:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823051a8
	ctx.lr = 0x82116B18;
	sub_823051A8(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// bne cr6,0x82116c78
	if (!ctx.cr6.eq) goto loc_82116C78;
	// bl 0x82119898
	ctx.lr = 0x82116B24;
	sub_82119898(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82116b60
	if (ctx.cr6.eq) goto loc_82116B60;
	// ld r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r23,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r23.u32);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// stw r23,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r23.u32);
	// stw r23,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r23.u32);
	// stw r23,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r23.u32);
	// std r11,24(r3)
	PPC_STORE_U64(ctx.r3.u32 + 24, ctx.r11.u64);
	// stw r23,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r23.u32);
	// stw r10,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r10.u32);
	// stw r23,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r23.u32);
	// stw r23,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, ctx.r23.u32);
	// b 0x82116b64
	goto loc_82116B64;
loc_82116B60:
	// mr r30,r23
	ctx.r30.u64 = ctx.r23.u64;
loc_82116B64:
	// ld r11,24(r30)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r30.u32 + 24);
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82116bc0
	if (ctx.cr6.eq) goto loc_82116BC0;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r4,r24
	ctx.r4.u64 = ctx.r24.u64;
	// bl 0x823052d8
	ctx.lr = 0x82116B7C;
	sub_823052D8(ctx, base);
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// ld r9,24(r30)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r30.u32 + 24);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// tdllei r10,0
	if (ctx.r10.u64 <= 0) __builtin_debugtrap();
	// divdu r8,r9,r10
	ctx.r8.u64 = ctx.r9.u64 / ctx.r10.u64;
	// mulld r7,r8,r10
	ctx.r7.s64 = ctx.r8.s64 * ctx.r10.s64;
	// subf r6,r7,r9
	ctx.r6.s64 = ctx.r9.s64 - ctx.r7.s64;
	// rlwinm r4,r6,2,0,29
	ctx.r4.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r4,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r11.u32);
	// stw r11,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r11.u32);
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// stwx r30,r4,r11
	PPC_STORE_U32(ctx.r4.u32 + ctx.r11.u32, ctx.r30.u32);
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// bl 0x823051a8
	ctx.lr = 0x82116BC0;
	sub_823051A8(ctx, base);
loc_82116BC0:
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// add r4,r26,r18
	ctx.r4.u64 = ctx.r26.u64 + ctx.r18.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82116510
	ctx.lr = 0x82116BD0;
	sub_82116510(ctx, base);
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// lwz r29,0(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r28,8(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x82116BE8;
	sub_8233E4E0(ctx, base);
	// stw r29,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r29.u32);
	// rlwinm r11,r20,0,0,26
	ctx.r11.u64 = rotl64(ctx.r20.u32 | (ctx.r20.u64 << 32), 0) & 0xFFFFFFE0;
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// add r29,r11,r29
	ctx.r29.u64 = ctx.r11.u64 + ctx.r29.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82116C04;
	sub_8208CFB0(ctx, base);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// clrldi r11,r11,62
	ctx.r11.u64 = ctx.r11.u64 & 0x3;
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82116c2c
	if (ctx.cr6.eq) goto loc_82116C2C;
	// li r5,1
	ctx.r5.s64 = 1;
	// subfic r4,r11,4
	ctx.xer.ca = ctx.r11.u32 <= 4;
	ctx.r4.s64 = 4 - ctx.r11.s64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82119d10
	ctx.lr = 0x82116C2C;
	sub_82119D10(ctx, base);
loc_82116C2C:
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82116C3C;
	sub_8208CFB0(ctx, base);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// clrldi r11,r11,62
	ctx.r11.u64 = ctx.r11.u64 & 0x3;
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82116c64
	if (ctx.cr6.eq) goto loc_82116C64;
	// li r5,1
	ctx.r5.s64 = 1;
	// subfic r4,r11,4
	ctx.xer.ca = ctx.r11.u32 <= 4;
	ctx.r4.s64 = 4 - ctx.r11.s64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82119d10
	ctx.lr = 0x82116C64;
	sub_82119D10(ctx, base);
loc_82116C64:
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82238540
	ctx.lr = 0x82116C70;
	sub_82238540(ctx, base);
	// stw r29,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r29.u32);
	// b 0x82116c98
	goto loc_82116C98;
loc_82116C78:
	// li r5,1
	ctx.r5.s64 = 1;
	// clrldi r4,r26,32
	ctx.r4.u64 = ctx.r26.u64 & 0xFFFFFFFF;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82119d10
	ctx.lr = 0x82116C88;
	sub_82119D10(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// clrldi r4,r25,32
	ctx.r4.u64 = ctx.r25.u64 & 0xFFFFFFFF;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82119d10
	ctx.lr = 0x82116C98;
	sub_82119D10(ctx, base);
loc_82116C98:
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x82116ce0
	if (ctx.cr6.eq) goto loc_82116CE0;
	// lwz r10,4(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 4);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// cmplw cr6,r17,r10
	ctx.cr6.compare<uint32_t>(ctx.r17.u32, ctx.r10.u32, ctx.xer);
	// addi r9,r11,4520
	ctx.r9.s64 = ctx.r11.s64 + 4520;
	// ble cr6,0x82116cb8
	if (!ctx.cr6.gt) goto loc_82116CB8;
	// stw r9,-13570(r16)
	PPC_STORE_U32(ctx.r16.u32 + -13570, ctx.r9.u32);
loc_82116CB8:
	// lwz r11,8(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 8);
	// lwz r10,4(r21)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r21.u32 + 4);
	// subf r11,r17,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r17.s64;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r10,r19
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r19.u32, ctx.xer);
	// beq cr6,0x82116cd4
	if (ctx.cr6.eq) goto loc_82116CD4;
	// stw r9,-13570(r16)
	PPC_STORE_U32(ctx.r16.u32 + -13570, ctx.r9.u32);
loc_82116CD4:
	// lwz r11,4(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 4);
	// subf r10,r17,r11
	ctx.r10.s64 = ctx.r11.s64 - ctx.r17.s64;
	// stw r10,4(r21)
	PPC_STORE_U32(ctx.r21.u32 + 4, ctx.r10.u32);
loc_82116CE0:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x8233e488
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82116CEC"))) PPC_WEAK_FUNC(sub_82116CEC);
PPC_FUNC_IMPL(__imp__sub_82116CEC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82116CF0"))) PPC_WEAK_FUNC(sub_82116CF0);
PPC_FUNC_IMPL(__imp__sub_82116CF0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e454
	ctx.lr = 0x82116CF8;
	__restfpr_23(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r23,0
	ctx.r23.s64 = 0;
	// li r5,4
	ctx.r5.s64 = 4;
	// std r23,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r23.u64);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82116D14;
	sub_8208CFB0(ctx, base);
	// ld r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// bne cr6,0x82116d30
	if (!ctx.cr6.eq) goto loc_82116D30;
	// li r5,8
	ctx.r5.s64 = 8;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82116D30;
	sub_8208CFB0(ctx, base);
loc_82116D30:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208d070
	ctx.lr = 0x82116D38;
	sub_8208D070(ctx, base);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208d070
	ctx.lr = 0x82116D44;
	sub_8208D070(ctx, base);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// li r25,-1
	ctx.r25.s64 = -1;
	// ld r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// addi r27,r11,3444
	ctx.r27.s64 = ctx.r11.s64 + 3444;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823052d8
	ctx.lr = 0x82116D64;
	sub_823052D8(ctx, base);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r31,r11,3464
	ctx.r31.s64 = ctx.r11.s64 + 3464;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// divdu r9,r28,r11
	ctx.r9.u64 = ctx.r28.u64 / ctx.r11.u64;
	// tdllei r11,0
	if (ctx.r11.u64 <= 0) __builtin_debugtrap();
	// mulld r8,r9,r11
	ctx.r8.s64 = ctx.r9.s64 * ctx.r11.s64;
	// subf r7,r8,r28
	ctx.r7.s64 = ctx.r28.s64 - ctx.r8.s64;
	// rlwinm r6,r7,2,0,29
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r29,r6,r10
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r10.u32);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82116dd0
	if (ctx.cr6.eq) goto loc_82116DD0;
loc_82116D94:
	// ld r11,24(r29)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r29.u32 + 24);
	// cmpld cr6,r11,r28
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, ctx.r28.u64, ctx.xer);
	// beq cr6,0x82116db0
	if (ctx.cr6.eq) goto loc_82116DB0;
	// lwz r29,16(r29)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82116d94
	if (!ctx.cr6.eq) goto loc_82116D94;
	// b 0x82116dd0
	goto loc_82116DD0;
loc_82116DB0:
	// addi r11,r29,20
	ctx.r11.s64 = ctx.r29.s64 + 20;
loc_82116DB4:
	// mfmsr r9
	ctx.r9.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r10,0,r11
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r11.u32);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r11
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r11.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82116db4
	if (!ctx.cr0.eq) goto loc_82116DB4;
loc_82116DD0:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823051a8
	ctx.lr = 0x82116DD8;
	sub_823051A8(ctx, base);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// bne cr6,0x82116f28
	if (!ctx.cr6.eq) goto loc_82116F28;
	// bl 0x82119ab0
	ctx.lr = 0x82116DE4;
	sub_82119AB0(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82116e1c
	if (ctx.cr6.eq) goto loc_82116E1C;
	// ld r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r23,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r23.u32);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// stw r23,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r23.u32);
	// stw r23,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r23.u32);
	// stw r23,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r23.u32);
	// std r11,24(r3)
	PPC_STORE_U64(ctx.r3.u32 + 24, ctx.r11.u64);
	// stw r23,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r23.u32);
	// stw r10,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r10.u32);
	// stw r23,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r23.u32);
	// b 0x82116e20
	goto loc_82116E20;
loc_82116E1C:
	// mr r29,r23
	ctx.r29.u64 = ctx.r23.u64;
loc_82116E20:
	// ld r11,24(r29)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r29.u32 + 24);
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82116e7c
	if (ctx.cr6.eq) goto loc_82116E7C;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// bl 0x823052d8
	ctx.lr = 0x82116E38;
	sub_823052D8(ctx, base);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// ld r9,24(r29)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r29.u32 + 24);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// tdllei r10,0
	if (ctx.r10.u64 <= 0) __builtin_debugtrap();
	// divdu r8,r9,r10
	ctx.r8.u64 = ctx.r9.u64 / ctx.r10.u64;
	// mulld r7,r8,r10
	ctx.r7.s64 = ctx.r8.s64 * ctx.r10.s64;
	// subf r6,r7,r9
	ctx.r6.s64 = ctx.r9.s64 - ctx.r7.s64;
	// rlwinm r4,r6,2,0,29
	ctx.r4.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r4,r11
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r11.u32);
	// stw r11,16(r29)
	PPC_STORE_U32(ctx.r29.u32 + 16, ctx.r11.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stwx r29,r4,r11
	PPC_STORE_U32(ctx.r4.u32 + ctx.r11.u32, ctx.r29.u32);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// bl 0x823051a8
	ctx.lr = 0x82116E7C;
	sub_823051A8(ctx, base);
loc_82116E7C:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// beq cr6,0x82116f54
	if (ctx.cr6.eq) goto loc_82116F54;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// bl 0x82116510
	ctx.lr = 0x82116E94;
	sub_82116510(ctx, base);
	// mr r5,r26
	ctx.r5.u64 = ctx.r26.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r31,0(r29)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// lwz r28,8(r29)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82116EAC;
	sub_8208CFB0(ctx, base);
	// lwz r11,32(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// ld r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r30.u32 + 16);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// clrldi r11,r11,62
	ctx.r11.u64 = ctx.r11.u64 & 0x3;
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82116ed4
	if (ctx.cr6.eq) goto loc_82116ED4;
	// li r5,1
	ctx.r5.s64 = 1;
	// subfic r4,r11,4
	ctx.xer.ca = ctx.r11.u32 <= 4;
	ctx.r4.s64 = 4 - ctx.r11.s64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82119d10
	ctx.lr = 0x82116ED4;
	sub_82119D10(ctx, base);
loc_82116ED4:
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82116EE4;
	sub_8208CFB0(ctx, base);
	// lwz r11,32(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// ld r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r30.u32 + 16);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// clrldi r11,r11,62
	ctx.r11.u64 = ctx.r11.u64 & 0x3;
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82116f0c
	if (ctx.cr6.eq) goto loc_82116F0C;
	// li r5,1
	ctx.r5.s64 = 1;
	// subfic r4,r11,4
	ctx.xer.ca = ctx.r11.u32 <= 4;
	ctx.r4.s64 = 4 - ctx.r11.s64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82119d10
	ctx.lr = 0x82116F0C;
	sub_82119D10(ctx, base);
loc_82116F0C:
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238258
	ctx.lr = 0x82116F18;
	sub_82238258(ctx, base);
	// stw r31,32(r29)
	PPC_STORE_U32(ctx.r29.u32 + 32, ctx.r31.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
loc_82116F28:
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x82116f50
	if (ctx.cr6.eq) goto loc_82116F50;
	// li r5,1
	ctx.r5.s64 = 1;
	// clrldi r4,r26,32
	ctx.r4.u64 = ctx.r26.u64 & 0xFFFFFFFF;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82119d10
	ctx.lr = 0x82116F40;
	sub_82119D10(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// clrldi r4,r24,32
	ctx.r4.u64 = ctx.r24.u64 & 0xFFFFFFFF;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82119d10
	ctx.lr = 0x82116F50;
	sub_82119D10(ctx, base);
loc_82116F50:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
loc_82116F54:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82116F5C"))) PPC_WEAK_FUNC(sub_82116F5C);
PPC_FUNC_IMPL(__imp__sub_82116F5C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82116F60"))) PPC_WEAK_FUNC(sub_82116F60);
PPC_FUNC_IMPL(__imp__sub_82116F60) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r3,20
	ctx.r11.s64 = ctx.r3.s64 + 20;
loc_82116F7C:
	// mfmsr r9
	ctx.r9.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r10,0,r11
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r11.u32);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r11
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r11.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82116f7c
	if (!ctx.cr0.eq) goto loc_82116F7C;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82117030
	if (!ctx.cr6.eq) goto loc_82117030;
	// ld r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82116fdc
	if (ctx.cr6.eq) goto loc_82116FDC;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r30,r11,3412
	ctx.r30.s64 = ctx.r11.s64 + 3412;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x823052d8
	ctx.lr = 0x82116FC4;
	sub_823052D8(ctx, base);
	// lis r10,-32176
	ctx.r10.s64 = -2108686336;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r10,3432
	ctx.r3.s64 = ctx.r10.s64 + 3432;
	// bl 0x82119dc8
	ctx.lr = 0x82116FD4;
	sub_82119DC8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x823051a8
	ctx.lr = 0x82116FDC;
	sub_823051A8(ctx, base);
loc_82116FDC:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82117000
	if (ctx.cr6.eq) goto loc_82117000;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821166c0
	ctx.lr = 0x82116FF0;
	sub_821166C0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r11.u32);
	// b 0x82117020
	goto loc_82117020;
loc_82117000:
	// lwz r3,32(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82117010
	if (ctx.cr6.eq) goto loc_82117010;
	// bl 0x8222f0f8
	ctx.lr = 0x82117010;
	sub_8222F0F8(ctx, base);
loc_82117010:
	// lwz r3,36(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82117020
	if (ctx.cr6.eq) goto loc_82117020;
	// bl 0x8222f0f8
	ctx.lr = 0x82117020;
	sub_8222F0F8(ctx, base);
loc_82117020:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821166c0
	ctx.lr = 0x82117028;
	sub_821166C0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82119780
	ctx.lr = 0x82117030;
	sub_82119780(ctx, base);
loc_82117030:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82117048"))) PPC_WEAK_FUNC(sub_82117048);
PPC_FUNC_IMPL(__imp__sub_82117048) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r3,20
	ctx.r11.s64 = ctx.r3.s64 + 20;
loc_82117064:
	// mfmsr r9
	ctx.r9.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r10,0,r11
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r11.u32);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwcx. r10,0,r11
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r11.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82117064
	if (!ctx.cr0.eq) goto loc_82117064;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82117104
	if (!ctx.cr6.eq) goto loc_82117104;
	// ld r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 24);
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x821170c4
	if (ctx.cr6.eq) goto loc_821170C4;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r30,r11,3444
	ctx.r30.s64 = ctx.r11.s64 + 3444;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x823052d8
	ctx.lr = 0x821170AC;
	sub_823052D8(ctx, base);
	// lis r10,-32176
	ctx.r10.s64 = -2108686336;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// addi r3,r10,3464
	ctx.r3.s64 = ctx.r10.s64 + 3464;
	// bl 0x82119dc8
	ctx.lr = 0x821170BC;
	sub_82119DC8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x823051a8
	ctx.lr = 0x821170C4;
	sub_823051A8(ctx, base);
loc_821170C4:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821170e4
	if (ctx.cr6.eq) goto loc_821170E4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821166c0
	ctx.lr = 0x821170D8;
	sub_821166C0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// b 0x821170f4
	goto loc_821170F4;
loc_821170E4:
	// lwz r3,32(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821170f4
	if (ctx.cr6.eq) goto loc_821170F4;
	// bl 0x8222f0f8
	ctx.lr = 0x821170F4;
	sub_8222F0F8(ctx, base);
loc_821170F4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821166c0
	ctx.lr = 0x821170FC;
	sub_821166C0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82119998
	ctx.lr = 0x82117104;
	sub_82119998(ctx, base);
loc_82117104:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211711C"))) PPC_WEAK_FUNC(sub_8211711C);
PPC_FUNC_IMPL(__imp__sub_8211711C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82117120"))) PPC_WEAK_FUNC(sub_82117120);
PPC_FUNC_IMPL(__imp__sub_82117120) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x82117128;
	__restfpr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r29,11
	ctx.r29.s64 = 11;
	// li r30,0
	ctx.r30.s64 = 0;
loc_82117138:
	// lwz r3,44(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211714c
	if (ctx.cr6.eq) goto loc_8211714C;
	// bl 0x82117048
	ctx.lr = 0x82117148;
	sub_82117048(ctx, base);
	// stw r30,44(r31)
	PPC_STORE_U32(ctx.r31.u32 + 44, ctx.r30.u32);
loc_8211714C:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82117160
	if (ctx.cr6.eq) goto loc_82117160;
	// bl 0x82116f60
	ctx.lr = 0x8211715C;
	sub_82116F60(ctx, base);
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
loc_82117160:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// bne 0x82117138
	if (!ctx.cr0.eq) goto loc_82117138;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82117174"))) PPC_WEAK_FUNC(sub_82117174);
PPC_FUNC_IMPL(__imp__sub_82117174) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82117178"))) PPC_WEAK_FUNC(sub_82117178);
PPC_FUNC_IMPL(__imp__sub_82117178) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r30,0
	ctx.r30.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stw r30,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r30.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,16384
	ctx.r3.s64 = 16384;
	// bl 0x82082030
	ctx.lr = 0x821171AC;
	sub_82082030(ctx, base);
	// li r10,4096
	ctx.r10.s64 = 4096;
	// stw r3,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r3.u32);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_821171BC:
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stwx r30,r11,r9
	PPC_STORE_U32(ctx.r11.u32 + ctx.r9.u32, ctx.r30.u32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// bdnz 0x821171bc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_821171BC;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r10,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821171EC"))) PPC_WEAK_FUNC(sub_821171EC);
PPC_FUNC_IMPL(__imp__sub_821171EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821171F0"))) PPC_WEAK_FUNC(sub_821171F0);
PPC_FUNC_IMPL(__imp__sub_821171F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x821171F8;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r27,-1
	ctx.r27.s64 = -1;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82117208:
	// addi r28,r30,20
	ctx.r28.s64 = ctx.r30.s64 + 20;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x82117218;
	sub_823052D8(ctx, base);
	// lbz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117334
	if (!ctx.cr6.eq) goto loc_82117334;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211724c
	if (!ctx.cr6.eq) goto loc_8211724C;
	// lis r3,0
	ctx.r3.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,32
	ctx.r4.s64 = 32;
	// ori r3,r3,32768
	ctx.r3.u64 = ctx.r3.u64 | 32768;
	// bl 0x82082030
	ctx.lr = 0x82117248;
	sub_82082030(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
loc_8211724C:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82117250:
	// rlwinm r11,r31,27,5,31
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r31,0,0,26
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// subf r8,r10,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r10.s64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 & ctx.r5.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x8211732c
	if (ctx.cr6.eq) goto loc_8211732C;
	// addi r11,r31,2
	ctx.r11.s64 = ctx.r31.s64 + 2;
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// rlwinm r10,r10,27,5,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x7FFFFFF;
	// addi r9,r10,3
	ctx.r9.s64 = ctx.r10.s64 + 3;
	// rlwinm r8,r10,5,0,26
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r8,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r8.s64;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// slw r4,r29,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// and r3,r4,r5
	ctx.r3.u64 = ctx.r4.u64 & ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82117318
	if (ctx.cr6.eq) goto loc_82117318;
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r9,r11,0,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r8,r10,3
	ctx.r8.s64 = ctx.r10.s64 + 3;
	// subf r10,r9,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r9.s64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,2
	ctx.r6.s64 = ctx.r10.s64 + 2;
	// slw r5,r29,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r4,r7,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r3,r5,r4
	ctx.r3.u64 = ctx.r5.u64 & ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82117320
	if (ctx.cr6.eq) goto loc_82117320;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r11,r11,27,5,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,5,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r9,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r9.s64;
	// addi r7,r11,3
	ctx.r7.s64 = ctx.r11.s64 + 3;
	// lwzx r6,r8,r30
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// slw r5,r29,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r7.u8 & 0x3F));
	// and r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ctx.r6.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82117328
	if (ctx.cr6.eq) goto loc_82117328;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x82117250
	if (ctx.cr6.lt) goto loc_82117250;
	// b 0x82117334
	goto loc_82117334;
loc_82117318:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x8211732c
	goto loc_8211732C;
loc_82117320:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// b 0x8211732c
	goto loc_8211732C;
loc_82117328:
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
loc_8211732C:
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x82117384
	if (ctx.cr6.lt) goto loc_82117384;
loc_82117334:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stb r29,40(r30)
	PPC_STORE_U8(ctx.r30.u32 + 40, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117374
	if (!ctx.cr6.eq) goto loc_82117374;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82082030
	ctx.lr = 0x82117358;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82117368
	if (ctx.cr6.eq) goto loc_82117368;
	// bl 0x82118da0
	ctx.lr = 0x82117364;
	sub_82118DA0(ctx, base);
	// b 0x8211736c
	goto loc_8211736C;
loc_82117368:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8211736C:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
loc_82117374:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823051a8
	ctx.lr = 0x8211737C;
	sub_823051A8(ctx, base);
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82117208
	goto loc_82117208;
loc_82117384:
	// addi r11,r30,12
	ctx.r11.s64 = ctx.r30.s64 + 12;
	// rlwinm r10,r31,29,3,29
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 29) & 0x1FFFFFFC;
	// rlwinm r9,r31,0,0,26
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// subf r8,r9,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r9.s64;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// or r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r5,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r5.u32);
	// bl 0x823051a8
	ctx.lr = 0x821173AC;
	sub_823051A8(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r11,r31,9,0,22
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 9) & 0xFFFFFE00;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821173C0"))) PPC_WEAK_FUNC(sub_821173C0);
PPC_FUNC_IMPL(__imp__sub_821173C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x821173C8;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// lis r10,0
	ctx.r10.s64 = 0;
	// addi r31,r11,2788
	ctx.r31.s64 = ctx.r11.s64 + 2788;
	// ori r10,r10,32768
	ctx.r10.u64 = ctx.r10.u64 | 32768;
	// lwz r11,2788(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2788);
loc_821173E0:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x821173f4
	if (ctx.cr6.lt) goto loc_821173F4;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r3,r9
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82117400
	if (ctx.cr6.lt) goto loc_82117400;
loc_821173F4:
	// lwz r31,8(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// b 0x821173e0
	goto loc_821173E0;
loc_82117400:
	// addi r27,r31,20
	ctx.r27.s64 = ctx.r31.s64 + 20;
	// li r29,-1
	ctx.r29.s64 = -1;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// rlwinm r28,r11,23,9,31
	ctx.r28.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 23) & 0x7FFFFF;
	// bl 0x823052d8
	ctx.lr = 0x8211741C;
	sub_823052D8(ctx, base);
	// rlwinm r11,r28,29,3,29
	ctx.r11.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// rlwinm r10,r28,0,0,26
	ctx.r10.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 0) & 0xFFFFFFE0;
	// li r9,1
	ctx.r9.s64 = 1;
	// subf r8,r10,r28
	ctx.r8.s64 = ctx.r28.s64 - ctx.r10.s64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwzx r5,r11,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// slw r6,r9,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// andc r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ~ctx.r6.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stwx r4,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r4.u32);
	// stb r7,40(r31)
	PPC_STORE_U8(ctx.r31.u32 + 40, ctx.r7.u8);
	// bl 0x823051a8
	ctx.lr = 0x82117450;
	sub_823051A8(ctx, base);
	// lwz r28,4(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82117500
	if (ctx.cr6.eq) goto loc_82117500;
	// addi r26,r28,20
	ctx.r26.s64 = ctx.r28.s64 + 20;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x823052d8
	ctx.lr = 0x8211746C;
	sub_823052D8(ctx, base);
	// lbz r11,40(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821174f8
	if (!ctx.cr6.eq) goto loc_821174F8;
loc_82117478:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82117508
	if (!ctx.cr6.eq) goto loc_82117508;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// blt cr6,0x82117478
	if (ctx.cr6.lt) goto loc_82117478;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82117498:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821174f8
	if (ctx.cr6.eq) goto loc_821174F8;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821174b8
	if (ctx.cr6.eq) goto loc_821174B8;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_821174B8:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r11,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r11.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821174d8
	if (ctx.cr6.eq) goto loc_821174D8;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821174D8;
	sub_82080000(ctx, base);
loc_821174D8:
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821174ec
	if (ctx.cr6.eq) goto loc_821174EC;
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x821174EC;
	sub_82246E18(ctx, base);
loc_821174EC:
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821174F8;
	sub_82080000(ctx, base);
loc_821174F8:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x823051a8
	ctx.lr = 0x82117500;
	sub_823051A8(ctx, base);
loc_82117500:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_82117508:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82117498
	goto loc_82117498;
}

__attribute__((alias("__imp__sub_82117510"))) PPC_WEAK_FUNC(sub_82117510);
PPC_FUNC_IMPL(__imp__sub_82117510) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82117518;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r27,-1
	ctx.r27.s64 = -1;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82117528:
	// addi r28,r30,20
	ctx.r28.s64 = ctx.r30.s64 + 20;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x82117538;
	sub_823052D8(ctx, base);
	// lbz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117650
	if (!ctx.cr6.eq) goto loc_82117650;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117568
	if (!ctx.cr6.eq) goto loc_82117568;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,32
	ctx.r4.s64 = 32;
	// lis r3,1
	ctx.r3.s64 = 65536;
	// bl 0x82082030
	ctx.lr = 0x82117564;
	sub_82082030(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
loc_82117568:
	// li r31,0
	ctx.r31.s64 = 0;
loc_8211756C:
	// rlwinm r11,r31,27,5,31
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r31,0,0,26
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// subf r8,r10,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r10.s64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 & ctx.r5.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82117648
	if (ctx.cr6.eq) goto loc_82117648;
	// addi r11,r31,2
	ctx.r11.s64 = ctx.r31.s64 + 2;
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// rlwinm r10,r10,27,5,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x7FFFFFF;
	// addi r9,r10,3
	ctx.r9.s64 = ctx.r10.s64 + 3;
	// rlwinm r8,r10,5,0,26
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r8,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r8.s64;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// slw r4,r29,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// and r3,r4,r5
	ctx.r3.u64 = ctx.r4.u64 & ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82117634
	if (ctx.cr6.eq) goto loc_82117634;
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r9,r11,0,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r8,r10,3
	ctx.r8.s64 = ctx.r10.s64 + 3;
	// subf r10,r9,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r9.s64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,2
	ctx.r6.s64 = ctx.r10.s64 + 2;
	// slw r5,r29,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r4,r7,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r3,r5,r4
	ctx.r3.u64 = ctx.r5.u64 & ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211763c
	if (ctx.cr6.eq) goto loc_8211763C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r11,r11,27,5,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,5,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r9,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r9.s64;
	// addi r7,r11,3
	ctx.r7.s64 = ctx.r11.s64 + 3;
	// lwzx r6,r8,r30
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// slw r5,r29,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r7.u8 & 0x3F));
	// and r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ctx.r6.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82117644
	if (ctx.cr6.eq) goto loc_82117644;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x8211756c
	if (ctx.cr6.lt) goto loc_8211756C;
	// b 0x82117650
	goto loc_82117650;
loc_82117634:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82117648
	goto loc_82117648;
loc_8211763C:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// b 0x82117648
	goto loc_82117648;
loc_82117644:
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
loc_82117648:
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x821176a0
	if (ctx.cr6.lt) goto loc_821176A0;
loc_82117650:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stb r29,40(r30)
	PPC_STORE_U8(ctx.r30.u32 + 40, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117690
	if (!ctx.cr6.eq) goto loc_82117690;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82082030
	ctx.lr = 0x82117674;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82117684
	if (ctx.cr6.eq) goto loc_82117684;
	// bl 0x82118da0
	ctx.lr = 0x82117680;
	sub_82118DA0(ctx, base);
	// b 0x82117688
	goto loc_82117688;
loc_82117684:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82117688:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
loc_82117690:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823051a8
	ctx.lr = 0x82117698;
	sub_823051A8(ctx, base);
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82117528
	goto loc_82117528;
loc_821176A0:
	// addi r11,r30,12
	ctx.r11.s64 = ctx.r30.s64 + 12;
	// rlwinm r10,r31,29,3,29
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 29) & 0x1FFFFFFC;
	// rlwinm r9,r31,0,0,26
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// subf r8,r9,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r9.s64;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// or r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r5,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r5.u32);
	// bl 0x823051a8
	ctx.lr = 0x821176C8;
	sub_823051A8(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r11,r31,10,0,21
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 10) & 0xFFFFFC00;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821176DC"))) PPC_WEAK_FUNC(sub_821176DC);
PPC_FUNC_IMPL(__imp__sub_821176DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821176E0"))) PPC_WEAK_FUNC(sub_821176E0);
PPC_FUNC_IMPL(__imp__sub_821176E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x821176E8;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// lis r10,1
	ctx.r10.s64 = 65536;
	// addi r31,r11,2832
	ctx.r31.s64 = ctx.r11.s64 + 2832;
	// lwz r11,2832(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2832);
loc_821176FC:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82117710
	if (ctx.cr6.lt) goto loc_82117710;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r3,r9
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8211771c
	if (ctx.cr6.lt) goto loc_8211771C;
loc_82117710:
	// lwz r31,8(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// b 0x821176fc
	goto loc_821176FC;
loc_8211771C:
	// addi r27,r31,20
	ctx.r27.s64 = ctx.r31.s64 + 20;
	// li r29,-1
	ctx.r29.s64 = -1;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// rlwinm r28,r11,22,10,31
	ctx.r28.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 22) & 0x3FFFFF;
	// bl 0x823052d8
	ctx.lr = 0x82117738;
	sub_823052D8(ctx, base);
	// rlwinm r11,r28,29,3,29
	ctx.r11.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// rlwinm r10,r28,0,0,26
	ctx.r10.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 0) & 0xFFFFFFE0;
	// li r9,1
	ctx.r9.s64 = 1;
	// subf r8,r10,r28
	ctx.r8.s64 = ctx.r28.s64 - ctx.r10.s64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwzx r5,r11,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// slw r6,r9,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// andc r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ~ctx.r6.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stwx r4,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r4.u32);
	// stb r7,40(r31)
	PPC_STORE_U8(ctx.r31.u32 + 40, ctx.r7.u8);
	// bl 0x823051a8
	ctx.lr = 0x8211776C;
	sub_823051A8(ctx, base);
	// lwz r28,4(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x8211781c
	if (ctx.cr6.eq) goto loc_8211781C;
	// addi r26,r28,20
	ctx.r26.s64 = ctx.r28.s64 + 20;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x823052d8
	ctx.lr = 0x82117788;
	sub_823052D8(ctx, base);
	// lbz r11,40(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117814
	if (!ctx.cr6.eq) goto loc_82117814;
loc_82117794:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82117824
	if (!ctx.cr6.eq) goto loc_82117824;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// blt cr6,0x82117794
	if (ctx.cr6.lt) goto loc_82117794;
	// li r11,1
	ctx.r11.s64 = 1;
loc_821177B4:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82117814
	if (ctx.cr6.eq) goto loc_82117814;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821177d4
	if (ctx.cr6.eq) goto loc_821177D4;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_821177D4:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r11,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r11.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821177f4
	if (ctx.cr6.eq) goto loc_821177F4;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821177F4;
	sub_82080000(ctx, base);
loc_821177F4:
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82117808
	if (ctx.cr6.eq) goto loc_82117808;
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82117808;
	sub_82246E18(ctx, base);
loc_82117808:
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82117814;
	sub_82080000(ctx, base);
loc_82117814:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x823051a8
	ctx.lr = 0x8211781C;
	sub_823051A8(ctx, base);
loc_8211781C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_82117824:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x821177b4
	goto loc_821177B4;
}

__attribute__((alias("__imp__sub_8211782C"))) PPC_WEAK_FUNC(sub_8211782C);
PPC_FUNC_IMPL(__imp__sub_8211782C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82117830"))) PPC_WEAK_FUNC(sub_82117830);
PPC_FUNC_IMPL(__imp__sub_82117830) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82117838;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r27,-1
	ctx.r27.s64 = -1;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82117848:
	// addi r28,r30,20
	ctx.r28.s64 = ctx.r30.s64 + 20;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x82117858;
	sub_823052D8(ctx, base);
	// lbz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117970
	if (!ctx.cr6.eq) goto loc_82117970;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117888
	if (!ctx.cr6.eq) goto loc_82117888;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,32
	ctx.r4.s64 = 32;
	// lis r3,2
	ctx.r3.s64 = 131072;
	// bl 0x82082030
	ctx.lr = 0x82117884;
	sub_82082030(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
loc_82117888:
	// li r31,0
	ctx.r31.s64 = 0;
loc_8211788C:
	// rlwinm r11,r31,27,5,31
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r31,0,0,26
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// subf r8,r10,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r10.s64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 & ctx.r5.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82117968
	if (ctx.cr6.eq) goto loc_82117968;
	// addi r11,r31,2
	ctx.r11.s64 = ctx.r31.s64 + 2;
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// rlwinm r10,r10,27,5,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x7FFFFFF;
	// addi r9,r10,3
	ctx.r9.s64 = ctx.r10.s64 + 3;
	// rlwinm r8,r10,5,0,26
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r8,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r8.s64;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// slw r4,r29,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// and r3,r4,r5
	ctx.r3.u64 = ctx.r4.u64 & ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82117954
	if (ctx.cr6.eq) goto loc_82117954;
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r9,r11,0,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r8,r10,3
	ctx.r8.s64 = ctx.r10.s64 + 3;
	// subf r10,r9,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r9.s64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,2
	ctx.r6.s64 = ctx.r10.s64 + 2;
	// slw r5,r29,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r4,r7,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r3,r5,r4
	ctx.r3.u64 = ctx.r5.u64 & ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211795c
	if (ctx.cr6.eq) goto loc_8211795C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r11,r11,27,5,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,5,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r9,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r9.s64;
	// addi r7,r11,3
	ctx.r7.s64 = ctx.r11.s64 + 3;
	// lwzx r6,r8,r30
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// slw r5,r29,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r7.u8 & 0x3F));
	// and r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ctx.r6.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82117964
	if (ctx.cr6.eq) goto loc_82117964;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x8211788c
	if (ctx.cr6.lt) goto loc_8211788C;
	// b 0x82117970
	goto loc_82117970;
loc_82117954:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82117968
	goto loc_82117968;
loc_8211795C:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// b 0x82117968
	goto loc_82117968;
loc_82117964:
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
loc_82117968:
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x821179c0
	if (ctx.cr6.lt) goto loc_821179C0;
loc_82117970:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stb r29,40(r30)
	PPC_STORE_U8(ctx.r30.u32 + 40, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821179b0
	if (!ctx.cr6.eq) goto loc_821179B0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82082030
	ctx.lr = 0x82117994;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821179a4
	if (ctx.cr6.eq) goto loc_821179A4;
	// bl 0x82118da0
	ctx.lr = 0x821179A0;
	sub_82118DA0(ctx, base);
	// b 0x821179a8
	goto loc_821179A8;
loc_821179A4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_821179A8:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
loc_821179B0:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823051a8
	ctx.lr = 0x821179B8;
	sub_823051A8(ctx, base);
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82117848
	goto loc_82117848;
loc_821179C0:
	// addi r11,r30,12
	ctx.r11.s64 = ctx.r30.s64 + 12;
	// rlwinm r10,r31,29,3,29
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 29) & 0x1FFFFFFC;
	// rlwinm r9,r31,0,0,26
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// subf r8,r9,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r9.s64;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// or r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r5,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r5.u32);
	// bl 0x823051a8
	ctx.lr = 0x821179E8;
	sub_823051A8(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r11,r31,11,0,20
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 11) & 0xFFFFF800;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821179FC"))) PPC_WEAK_FUNC(sub_821179FC);
PPC_FUNC_IMPL(__imp__sub_821179FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82117A00"))) PPC_WEAK_FUNC(sub_82117A00);
PPC_FUNC_IMPL(__imp__sub_82117A00) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82117A08;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// lis r10,2
	ctx.r10.s64 = 131072;
	// addi r31,r11,2876
	ctx.r31.s64 = ctx.r11.s64 + 2876;
	// lwz r11,2876(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2876);
loc_82117A1C:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82117a30
	if (ctx.cr6.lt) goto loc_82117A30;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r3,r9
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82117a3c
	if (ctx.cr6.lt) goto loc_82117A3C;
loc_82117A30:
	// lwz r31,8(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// b 0x82117a1c
	goto loc_82117A1C;
loc_82117A3C:
	// addi r27,r31,20
	ctx.r27.s64 = ctx.r31.s64 + 20;
	// li r29,-1
	ctx.r29.s64 = -1;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// rlwinm r28,r11,21,11,31
	ctx.r28.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 21) & 0x1FFFFF;
	// bl 0x823052d8
	ctx.lr = 0x82117A58;
	sub_823052D8(ctx, base);
	// rlwinm r11,r28,29,3,29
	ctx.r11.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// rlwinm r10,r28,0,0,26
	ctx.r10.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 0) & 0xFFFFFFE0;
	// li r9,1
	ctx.r9.s64 = 1;
	// subf r8,r10,r28
	ctx.r8.s64 = ctx.r28.s64 - ctx.r10.s64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwzx r5,r11,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// slw r6,r9,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// andc r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ~ctx.r6.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stwx r4,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r4.u32);
	// stb r7,40(r31)
	PPC_STORE_U8(ctx.r31.u32 + 40, ctx.r7.u8);
	// bl 0x823051a8
	ctx.lr = 0x82117A8C;
	sub_823051A8(ctx, base);
	// lwz r28,4(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82117b3c
	if (ctx.cr6.eq) goto loc_82117B3C;
	// addi r26,r28,20
	ctx.r26.s64 = ctx.r28.s64 + 20;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x823052d8
	ctx.lr = 0x82117AA8;
	sub_823052D8(ctx, base);
	// lbz r11,40(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117b34
	if (!ctx.cr6.eq) goto loc_82117B34;
loc_82117AB4:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82117b44
	if (!ctx.cr6.eq) goto loc_82117B44;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// blt cr6,0x82117ab4
	if (ctx.cr6.lt) goto loc_82117AB4;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82117AD4:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82117b34
	if (ctx.cr6.eq) goto loc_82117B34;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82117af4
	if (ctx.cr6.eq) goto loc_82117AF4;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_82117AF4:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r11,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r11.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82117b14
	if (ctx.cr6.eq) goto loc_82117B14;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82117B14;
	sub_82080000(ctx, base);
loc_82117B14:
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82117b28
	if (ctx.cr6.eq) goto loc_82117B28;
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82117B28;
	sub_82246E18(ctx, base);
loc_82117B28:
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82117B34;
	sub_82080000(ctx, base);
loc_82117B34:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x823051a8
	ctx.lr = 0x82117B3C;
	sub_823051A8(ctx, base);
loc_82117B3C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_82117B44:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82117ad4
	goto loc_82117AD4;
}

__attribute__((alias("__imp__sub_82117B4C"))) PPC_WEAK_FUNC(sub_82117B4C);
PPC_FUNC_IMPL(__imp__sub_82117B4C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82117B50"))) PPC_WEAK_FUNC(sub_82117B50);
PPC_FUNC_IMPL(__imp__sub_82117B50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82117B58;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r27,-1
	ctx.r27.s64 = -1;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82117B68:
	// addi r28,r30,20
	ctx.r28.s64 = ctx.r30.s64 + 20;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x82117B78;
	sub_823052D8(ctx, base);
	// lbz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117c90
	if (!ctx.cr6.eq) goto loc_82117C90;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117ba8
	if (!ctx.cr6.eq) goto loc_82117BA8;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,32
	ctx.r4.s64 = 32;
	// lis r3,4
	ctx.r3.s64 = 262144;
	// bl 0x82082030
	ctx.lr = 0x82117BA4;
	sub_82082030(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
loc_82117BA8:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82117BAC:
	// rlwinm r11,r31,27,5,31
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r31,0,0,26
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// subf r8,r10,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r10.s64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 & ctx.r5.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82117c88
	if (ctx.cr6.eq) goto loc_82117C88;
	// addi r11,r31,2
	ctx.r11.s64 = ctx.r31.s64 + 2;
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// rlwinm r10,r10,27,5,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x7FFFFFF;
	// addi r9,r10,3
	ctx.r9.s64 = ctx.r10.s64 + 3;
	// rlwinm r8,r10,5,0,26
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r8,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r8.s64;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// slw r4,r29,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// and r3,r4,r5
	ctx.r3.u64 = ctx.r4.u64 & ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82117c74
	if (ctx.cr6.eq) goto loc_82117C74;
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r9,r11,0,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r8,r10,3
	ctx.r8.s64 = ctx.r10.s64 + 3;
	// subf r10,r9,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r9.s64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,2
	ctx.r6.s64 = ctx.r10.s64 + 2;
	// slw r5,r29,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r4,r7,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r3,r5,r4
	ctx.r3.u64 = ctx.r5.u64 & ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82117c7c
	if (ctx.cr6.eq) goto loc_82117C7C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r11,r11,27,5,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,5,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r9,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r9.s64;
	// addi r7,r11,3
	ctx.r7.s64 = ctx.r11.s64 + 3;
	// lwzx r6,r8,r30
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// slw r5,r29,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r7.u8 & 0x3F));
	// and r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ctx.r6.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82117c84
	if (ctx.cr6.eq) goto loc_82117C84;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x82117bac
	if (ctx.cr6.lt) goto loc_82117BAC;
	// b 0x82117c90
	goto loc_82117C90;
loc_82117C74:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82117c88
	goto loc_82117C88;
loc_82117C7C:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// b 0x82117c88
	goto loc_82117C88;
loc_82117C84:
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
loc_82117C88:
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x82117ce0
	if (ctx.cr6.lt) goto loc_82117CE0;
loc_82117C90:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stb r29,40(r30)
	PPC_STORE_U8(ctx.r30.u32 + 40, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117cd0
	if (!ctx.cr6.eq) goto loc_82117CD0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82082030
	ctx.lr = 0x82117CB4;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82117cc4
	if (ctx.cr6.eq) goto loc_82117CC4;
	// bl 0x82118da0
	ctx.lr = 0x82117CC0;
	sub_82118DA0(ctx, base);
	// b 0x82117cc8
	goto loc_82117CC8;
loc_82117CC4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82117CC8:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
loc_82117CD0:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823051a8
	ctx.lr = 0x82117CD8;
	sub_823051A8(ctx, base);
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82117b68
	goto loc_82117B68;
loc_82117CE0:
	// addi r11,r30,12
	ctx.r11.s64 = ctx.r30.s64 + 12;
	// rlwinm r10,r31,29,3,29
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 29) & 0x1FFFFFFC;
	// rlwinm r9,r31,0,0,26
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// subf r8,r9,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r9.s64;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// or r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r5,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r5.u32);
	// bl 0x823051a8
	ctx.lr = 0x82117D08;
	sub_823051A8(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r11,r31,12,0,19
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 12) & 0xFFFFF000;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82117D1C"))) PPC_WEAK_FUNC(sub_82117D1C);
PPC_FUNC_IMPL(__imp__sub_82117D1C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82117D20"))) PPC_WEAK_FUNC(sub_82117D20);
PPC_FUNC_IMPL(__imp__sub_82117D20) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82117D28;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// lis r10,4
	ctx.r10.s64 = 262144;
	// addi r31,r11,2920
	ctx.r31.s64 = ctx.r11.s64 + 2920;
	// lwz r11,2920(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2920);
loc_82117D3C:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82117d50
	if (ctx.cr6.lt) goto loc_82117D50;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r3,r9
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82117d5c
	if (ctx.cr6.lt) goto loc_82117D5C;
loc_82117D50:
	// lwz r31,8(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// b 0x82117d3c
	goto loc_82117D3C;
loc_82117D5C:
	// addi r27,r31,20
	ctx.r27.s64 = ctx.r31.s64 + 20;
	// li r29,-1
	ctx.r29.s64 = -1;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// rlwinm r28,r11,20,12,31
	ctx.r28.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 20) & 0xFFFFF;
	// bl 0x823052d8
	ctx.lr = 0x82117D78;
	sub_823052D8(ctx, base);
	// rlwinm r11,r28,29,3,29
	ctx.r11.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// rlwinm r10,r28,0,0,26
	ctx.r10.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 0) & 0xFFFFFFE0;
	// li r9,1
	ctx.r9.s64 = 1;
	// subf r8,r10,r28
	ctx.r8.s64 = ctx.r28.s64 - ctx.r10.s64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwzx r5,r11,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// slw r6,r9,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// andc r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ~ctx.r6.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stwx r4,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r4.u32);
	// stb r7,40(r31)
	PPC_STORE_U8(ctx.r31.u32 + 40, ctx.r7.u8);
	// bl 0x823051a8
	ctx.lr = 0x82117DAC;
	sub_823051A8(ctx, base);
	// lwz r28,4(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82117e5c
	if (ctx.cr6.eq) goto loc_82117E5C;
	// addi r26,r28,20
	ctx.r26.s64 = ctx.r28.s64 + 20;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x823052d8
	ctx.lr = 0x82117DC8;
	sub_823052D8(ctx, base);
	// lbz r11,40(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117e54
	if (!ctx.cr6.eq) goto loc_82117E54;
loc_82117DD4:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82117e64
	if (!ctx.cr6.eq) goto loc_82117E64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// blt cr6,0x82117dd4
	if (ctx.cr6.lt) goto loc_82117DD4;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82117DF4:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82117e54
	if (ctx.cr6.eq) goto loc_82117E54;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82117e14
	if (ctx.cr6.eq) goto loc_82117E14;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_82117E14:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r11,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r11.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82117e34
	if (ctx.cr6.eq) goto loc_82117E34;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82117E34;
	sub_82080000(ctx, base);
loc_82117E34:
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82117e48
	if (ctx.cr6.eq) goto loc_82117E48;
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82117E48;
	sub_82246E18(ctx, base);
loc_82117E48:
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82117E54;
	sub_82080000(ctx, base);
loc_82117E54:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x823051a8
	ctx.lr = 0x82117E5C;
	sub_823051A8(ctx, base);
loc_82117E5C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_82117E64:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82117df4
	goto loc_82117DF4;
}

__attribute__((alias("__imp__sub_82117E6C"))) PPC_WEAK_FUNC(sub_82117E6C);
PPC_FUNC_IMPL(__imp__sub_82117E6C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82117E70"))) PPC_WEAK_FUNC(sub_82117E70);
PPC_FUNC_IMPL(__imp__sub_82117E70) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// addi r3,r3,16
	ctx.r3.s64 = ctx.r3.s64 + 16;
	// li r4,4000
	ctx.r4.s64 = 4000;
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
	// stw r30,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r30.u32);
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
	// stw r30,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r30.u32);
	// stw r30,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r30.u32);
	// stw r30,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r30.u32);
	// stw r30,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r30.u32);
	// stw r30,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r30.u32);
	// stw r30,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r30.u32);
	// bl 0x82305000
	ctx.lr = 0x82117EBC;
	sub_82305000(ctx, base);
	// stb r30,36(r31)
	PPC_STORE_U8(ctx.r31.u32 + 36, ctx.r30.u8);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82117EDC"))) PPC_WEAK_FUNC(sub_82117EDC);
PPC_FUNC_IMPL(__imp__sub_82117EDC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82117EE0"))) PPC_WEAK_FUNC(sub_82117EE0);
PPC_FUNC_IMPL(__imp__sub_82117EE0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82117EE8;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r27,-1
	ctx.r27.s64 = -1;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82117EF8:
	// addi r28,r30,16
	ctx.r28.s64 = ctx.r30.s64 + 16;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x82117F08;
	sub_823052D8(ctx, base);
	// lbz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118020
	if (!ctx.cr6.eq) goto loc_82118020;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82117f38
	if (!ctx.cr6.eq) goto loc_82117F38;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,32
	ctx.r4.s64 = 32;
	// lis r3,3
	ctx.r3.s64 = 196608;
	// bl 0x82082030
	ctx.lr = 0x82117F34;
	sub_82082030(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
loc_82117F38:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82117F3C:
	// rlwinm r11,r31,27,5,31
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r31,0,0,26
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// subf r8,r10,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r10.s64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 & ctx.r5.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82118018
	if (ctx.cr6.eq) goto loc_82118018;
	// addi r11,r31,2
	ctx.r11.s64 = ctx.r31.s64 + 2;
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// rlwinm r10,r10,27,5,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x7FFFFFF;
	// addi r9,r10,3
	ctx.r9.s64 = ctx.r10.s64 + 3;
	// rlwinm r8,r10,5,0,26
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r8,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r8.s64;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// slw r4,r29,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// and r3,r4,r5
	ctx.r3.u64 = ctx.r4.u64 & ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82118004
	if (ctx.cr6.eq) goto loc_82118004;
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r9,r11,0,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r8,r10,3
	ctx.r8.s64 = ctx.r10.s64 + 3;
	// subf r10,r9,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r9.s64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,2
	ctx.r6.s64 = ctx.r10.s64 + 2;
	// slw r5,r29,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r4,r7,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r3,r5,r4
	ctx.r3.u64 = ctx.r5.u64 & ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211800c
	if (ctx.cr6.eq) goto loc_8211800C;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r11,r11,27,5,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,5,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r9,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r9.s64;
	// addi r7,r11,3
	ctx.r7.s64 = ctx.r11.s64 + 3;
	// lwzx r6,r8,r30
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// slw r5,r29,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r7.u8 & 0x3F));
	// and r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ctx.r6.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82118014
	if (ctx.cr6.eq) goto loc_82118014;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r31,32
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 32, ctx.xer);
	// blt cr6,0x82117f3c
	if (ctx.cr6.lt) goto loc_82117F3C;
	// b 0x82118020
	goto loc_82118020;
loc_82118004:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82118018
	goto loc_82118018;
loc_8211800C:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// b 0x82118018
	goto loc_82118018;
loc_82118014:
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
loc_82118018:
	// cmplwi cr6,r31,32
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 32, ctx.xer);
	// blt cr6,0x82118070
	if (ctx.cr6.lt) goto loc_82118070;
loc_82118020:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stb r29,36(r30)
	PPC_STORE_U8(ctx.r30.u32 + 36, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118060
	if (!ctx.cr6.eq) goto loc_82118060;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x82082030
	ctx.lr = 0x82118044;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82118054
	if (ctx.cr6.eq) goto loc_82118054;
	// bl 0x82117e70
	ctx.lr = 0x82118050;
	sub_82117E70(ctx, base);
	// b 0x82118058
	goto loc_82118058;
loc_82118054:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82118058:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
loc_82118060:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823051a8
	ctx.lr = 0x82118068;
	sub_823051A8(ctx, base);
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82117ef8
	goto loc_82117EF8;
loc_82118070:
	// addi r11,r30,12
	ctx.r11.s64 = ctx.r30.s64 + 12;
	// rlwinm r10,r31,29,3,29
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 29) & 0x1FFFFFFC;
	// rlwinm r9,r31,0,0,26
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// subf r8,r9,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r9.s64;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// or r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r5,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r5.u32);
	// bl 0x823051a8
	ctx.lr = 0x82118098;
	sub_823051A8(ctx, base);
	// rlwinm r11,r31,1,0,30
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r4,r31,r11
	ctx.r4.u64 = ctx.r31.u64 + ctx.r11.u64;
	// rlwinm r11,r4,11,0,20
	ctx.r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 11) & 0xFFFFF800;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821180B4"))) PPC_WEAK_FUNC(sub_821180B4);
PPC_FUNC_IMPL(__imp__sub_821180B4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821180B8"))) PPC_WEAK_FUNC(sub_821180B8);
PPC_FUNC_IMPL(__imp__sub_821180B8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x821180C0;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// lis r10,3
	ctx.r10.s64 = 196608;
	// addi r31,r11,2964
	ctx.r31.s64 = ctx.r11.s64 + 2964;
	// lwz r11,2964(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 2964);
loc_821180D4:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x821180e8
	if (ctx.cr6.lt) goto loc_821180E8;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r3,r9
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x821180f4
	if (ctx.cr6.lt) goto loc_821180F4;
loc_821180E8:
	// lwz r31,8(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// b 0x821180d4
	goto loc_821180D4;
loc_821180F4:
	// addi r27,r31,16
	ctx.r27.s64 = ctx.r31.s64 + 16;
	// li r29,-1
	ctx.r29.s64 = -1;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// li r10,6144
	ctx.r10.s64 = 6144;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// divwu r28,r11,r10
	ctx.r28.u32 = ctx.r11.u32 / ctx.r10.u32;
	// bl 0x823052d8
	ctx.lr = 0x82118114;
	sub_823052D8(ctx, base);
	// rlwinm r11,r28,29,3,29
	ctx.r11.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// rlwinm r9,r28,0,0,26
	ctx.r9.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 0) & 0xFFFFFFE0;
	// li r8,1
	ctx.r8.s64 = 1;
	// subf r7,r9,r28
	ctx.r7.s64 = ctx.r28.s64 - ctx.r9.s64;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwzx r4,r11,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// slw r5,r8,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r7.u8 & 0x3F));
	// andc r10,r4,r5
	ctx.r10.u64 = ctx.r4.u64 & ~ctx.r5.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stwx r10,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r10.u32);
	// stb r6,36(r31)
	PPC_STORE_U8(ctx.r31.u32 + 36, ctx.r6.u8);
	// bl 0x823051a8
	ctx.lr = 0x82118148;
	sub_823051A8(ctx, base);
	// lwz r28,4(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x821181f8
	if (ctx.cr6.eq) goto loc_821181F8;
	// addi r26,r28,16
	ctx.r26.s64 = ctx.r28.s64 + 16;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x823052d8
	ctx.lr = 0x82118164;
	sub_823052D8(ctx, base);
	// lbz r11,36(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821181f0
	if (!ctx.cr6.eq) goto loc_821181F0;
loc_82118170:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82118200
	if (!ctx.cr6.eq) goto loc_82118200;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82118170
	if (ctx.cr6.lt) goto loc_82118170;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82118190:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821181f0
	if (ctx.cr6.eq) goto loc_821181F0;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821181b0
	if (ctx.cr6.eq) goto loc_821181B0;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_821181B0:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r11,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r11.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821181d0
	if (ctx.cr6.eq) goto loc_821181D0;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821181D0;
	sub_82080000(ctx, base);
loc_821181D0:
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821181e4
	if (ctx.cr6.eq) goto loc_821181E4;
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x821181E4;
	sub_82246E18(ctx, base);
loc_821181E4:
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821181F0;
	sub_82080000(ctx, base);
loc_821181F0:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x823051a8
	ctx.lr = 0x821181F8;
	sub_823051A8(ctx, base);
loc_821181F8:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_82118200:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82118190
	goto loc_82118190;
}

__attribute__((alias("__imp__sub_82118208"))) PPC_WEAK_FUNC(sub_82118208);
PPC_FUNC_IMPL(__imp__sub_82118208) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82118210;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r27,-1
	ctx.r27.s64 = -1;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82118220:
	// addi r28,r30,16
	ctx.r28.s64 = ctx.r30.s64 + 16;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x82118230;
	sub_823052D8(ctx, base);
	// lbz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821182a4
	if (!ctx.cr6.eq) goto loc_821182A4;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118260
	if (!ctx.cr6.eq) goto loc_82118260;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,32
	ctx.r4.s64 = 32;
	// li r3,8192
	ctx.r3.s64 = 8192;
	// bl 0x82082030
	ctx.lr = 0x8211825C;
	sub_82082030(ctx, base);
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
loc_82118260:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82118264:
	// rlwinm r11,r31,27,5,31
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r31,0,0,26
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// subf r8,r10,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r10.s64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 & ctx.r5.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x8211829c
	if (ctx.cr6.eq) goto loc_8211829C;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplwi cr6,r31,1
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 1, ctx.xer);
	// blt cr6,0x82118264
	if (ctx.cr6.lt) goto loc_82118264;
	// b 0x821182a4
	goto loc_821182A4;
loc_8211829C:
	// cmplwi cr6,r31,1
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 1, ctx.xer);
	// blt cr6,0x821182f4
	if (ctx.cr6.lt) goto loc_821182F4;
loc_821182A4:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stb r29,36(r30)
	PPC_STORE_U8(ctx.r30.u32 + 36, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821182e4
	if (!ctx.cr6.eq) goto loc_821182E4;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x82082030
	ctx.lr = 0x821182C8;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821182d8
	if (ctx.cr6.eq) goto loc_821182D8;
	// bl 0x82117e70
	ctx.lr = 0x821182D4;
	sub_82117E70(ctx, base);
	// b 0x821182dc
	goto loc_821182DC;
loc_821182D8:
	// li r3,0
	ctx.r3.s64 = 0;
loc_821182DC:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
loc_821182E4:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823051a8
	ctx.lr = 0x821182EC;
	sub_823051A8(ctx, base);
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82118220
	goto loc_82118220;
loc_821182F4:
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r30,12
	ctx.r10.s64 = ctx.r30.s64 + 12;
	// rlwinm r11,r11,5,0,26
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// subf r8,r11,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r11.s64;
	// lwzx r7,r9,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// or r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r5,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, ctx.r5.u32);
	// bl 0x823051a8
	ctx.lr = 0x8211831C;
	sub_823051A8(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r11,r31,13,0,18
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 13) & 0xFFFFE000;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82118330"))) PPC_WEAK_FUNC(sub_82118330);
PPC_FUNC_IMPL(__imp__sub_82118330) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82118338;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r31,r11,3004
	ctx.r31.s64 = ctx.r11.s64 + 3004;
	// lwz r11,3004(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 3004);
loc_82118348:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x8211835c
	if (ctx.cr6.lt) goto loc_8211835C;
	// addi r10,r11,8192
	ctx.r10.s64 = ctx.r11.s64 + 8192;
	// cmplw cr6,r3,r10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82118368
	if (ctx.cr6.lt) goto loc_82118368;
loc_8211835C:
	// lwz r31,8(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// b 0x82118348
	goto loc_82118348;
loc_82118368:
	// addi r27,r31,16
	ctx.r27.s64 = ctx.r31.s64 + 16;
	// li r29,-1
	ctx.r29.s64 = -1;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// rlwinm r28,r11,19,13,31
	ctx.r28.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 19) & 0x7FFFF;
	// bl 0x823052d8
	ctx.lr = 0x82118384;
	sub_823052D8(ctx, base);
	// rlwinm r11,r28,29,3,29
	ctx.r11.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// rlwinm r10,r28,0,0,26
	ctx.r10.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 0) & 0xFFFFFFE0;
	// li r9,1
	ctx.r9.s64 = 1;
	// subf r8,r10,r28
	ctx.r8.s64 = ctx.r28.s64 - ctx.r10.s64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwzx r5,r11,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// slw r6,r9,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// andc r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ~ctx.r6.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// stwx r4,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r4.u32);
	// stb r7,36(r31)
	PPC_STORE_U8(ctx.r31.u32 + 36, ctx.r7.u8);
	// bl 0x823051a8
	ctx.lr = 0x821183B8;
	sub_823051A8(ctx, base);
	// lwz r28,4(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82118468
	if (ctx.cr6.eq) goto loc_82118468;
	// addi r26,r28,16
	ctx.r26.s64 = ctx.r28.s64 + 16;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x823052d8
	ctx.lr = 0x821183D4;
	sub_823052D8(ctx, base);
	// lbz r11,36(r28)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r28.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118460
	if (!ctx.cr6.eq) goto loc_82118460;
loc_821183E0:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82118470
	if (!ctx.cr6.eq) goto loc_82118470;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x821183e0
	if (ctx.cr6.lt) goto loc_821183E0;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82118400:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82118460
	if (ctx.cr6.eq) goto loc_82118460;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82118420
	if (ctx.cr6.eq) goto loc_82118420;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_82118420:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r11,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r11.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82118440
	if (ctx.cr6.eq) goto loc_82118440;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82118440;
	sub_82080000(ctx, base);
loc_82118440:
	// lwz r11,8(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82118454
	if (ctx.cr6.eq) goto loc_82118454;
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82118454;
	sub_82246E18(ctx, base);
loc_82118454:
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82118460;
	sub_82080000(ctx, base);
loc_82118460:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x823051a8
	ctx.lr = 0x82118468;
	sub_823051A8(ctx, base);
loc_82118468:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_82118470:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82118400
	goto loc_82118400;
}

__attribute__((alias("__imp__sub_82118478"))) PPC_WEAK_FUNC(sub_82118478);
PPC_FUNC_IMPL(__imp__sub_82118478) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82118480;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,0
	ctx.r11.s64 = 0;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r26,-1
	ctx.r26.s64 = -1;
	// ori r27,r11,32768
	ctx.r27.u64 = ctx.r11.u64 | 32768;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82118498:
	// addi r28,r30,20
	ctx.r28.s64 = ctx.r30.s64 + 20;
	// mr r4,r26
	ctx.r4.u64 = ctx.r26.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x821184A8;
	sub_823052D8(ctx, base);
	// lbz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821185d0
	if (!ctx.cr6.eq) goto loc_821185D0;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821184e8
	if (!ctx.cr6.eq) goto loc_821184E8;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,4096
	ctx.r4.s64 = 4096;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82082030
	ctx.lr = 0x821184D4;
	sub_82082030(ctx, base);
	// li r5,1028
	ctx.r5.s64 = 1028;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x822472e0
	ctx.lr = 0x821184E4;
	sub_822472E0(ctx, base);
	// stw r31,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r31.u32);
loc_821184E8:
	// li r31,0
	ctx.r31.s64 = 0;
loc_821184EC:
	// rlwinm r11,r31,27,5,31
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r31,0,0,26
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// subf r8,r10,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r10.s64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 & ctx.r5.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x821185c8
	if (ctx.cr6.eq) goto loc_821185C8;
	// addi r11,r31,2
	ctx.r11.s64 = ctx.r31.s64 + 2;
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// rlwinm r10,r10,27,5,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x7FFFFFF;
	// addi r9,r10,3
	ctx.r9.s64 = ctx.r10.s64 + 3;
	// rlwinm r8,r10,5,0,26
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r8,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r8.s64;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// slw r4,r29,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// and r3,r4,r5
	ctx.r3.u64 = ctx.r4.u64 & ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821185b4
	if (ctx.cr6.eq) goto loc_821185B4;
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r9,r11,0,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r8,r10,3
	ctx.r8.s64 = ctx.r10.s64 + 3;
	// subf r10,r9,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r9.s64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,2
	ctx.r6.s64 = ctx.r10.s64 + 2;
	// slw r5,r29,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r4,r7,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r3,r5,r4
	ctx.r3.u64 = ctx.r5.u64 & ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821185bc
	if (ctx.cr6.eq) goto loc_821185BC;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r11,r11,27,5,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,5,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r9,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r9.s64;
	// addi r7,r11,3
	ctx.r7.s64 = ctx.r11.s64 + 3;
	// lwzx r6,r8,r30
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// slw r5,r29,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r7.u8 & 0x3F));
	// and r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ctx.r6.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x821185c4
	if (ctx.cr6.eq) goto loc_821185C4;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x821184ec
	if (ctx.cr6.lt) goto loc_821184EC;
	// b 0x821185d0
	goto loc_821185D0;
loc_821185B4:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x821185c8
	goto loc_821185C8;
loc_821185BC:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// b 0x821185c8
	goto loc_821185C8;
loc_821185C4:
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
loc_821185C8:
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x82118620
	if (ctx.cr6.lt) goto loc_82118620;
loc_821185D0:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stb r29,40(r30)
	PPC_STORE_U8(ctx.r30.u32 + 40, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118610
	if (!ctx.cr6.eq) goto loc_82118610;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82082030
	ctx.lr = 0x821185F4;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82118604
	if (ctx.cr6.eq) goto loc_82118604;
	// bl 0x82118da0
	ctx.lr = 0x82118600;
	sub_82118DA0(ctx, base);
	// b 0x82118608
	goto loc_82118608;
loc_82118604:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82118608:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
loc_82118610:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823051a8
	ctx.lr = 0x82118618;
	sub_823051A8(ctx, base);
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82118498
	goto loc_82118498;
loc_82118620:
	// addi r11,r30,12
	ctx.r11.s64 = ctx.r30.s64 + 12;
	// rlwinm r10,r31,29,3,29
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 29) & 0x1FFFFFFC;
	// rlwinm r9,r31,0,0,26
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// subf r8,r9,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r9.s64;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// or r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r5,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r5.u32);
	// bl 0x823051a8
	ctx.lr = 0x82118648;
	sub_823051A8(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r11,r31,9,0,22
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 9) & 0xFFFFFE00;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211865C"))) PPC_WEAK_FUNC(sub_8211865C);
PPC_FUNC_IMPL(__imp__sub_8211865C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82118660"))) PPC_WEAK_FUNC(sub_82118660);
PPC_FUNC_IMPL(__imp__sub_82118660) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82118668;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// lis r10,0
	ctx.r10.s64 = 0;
	// addi r31,r11,3044
	ctx.r31.s64 = ctx.r11.s64 + 3044;
	// ori r10,r10,32768
	ctx.r10.u64 = ctx.r10.u64 | 32768;
	// lwz r11,3044(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 3044);
loc_82118680:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82118694
	if (ctx.cr6.lt) goto loc_82118694;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r3,r9
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x821186a0
	if (ctx.cr6.lt) goto loc_821186A0;
loc_82118694:
	// lwz r31,8(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// b 0x82118680
	goto loc_82118680;
loc_821186A0:
	// addi r29,r31,20
	ctx.r29.s64 = ctx.r31.s64 + 20;
	// li r28,-1
	ctx.r28.s64 = -1;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// rlwinm r27,r11,23,9,31
	ctx.r27.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 23) & 0x7FFFFF;
	// bl 0x823052d8
	ctx.lr = 0x821186BC;
	sub_823052D8(ctx, base);
	// rlwinm r11,r27,29,3,29
	ctx.r11.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// rlwinm r10,r27,0,0,26
	ctx.r10.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0xFFFFFFE0;
	// li r9,1
	ctx.r9.s64 = 1;
	// subf r8,r10,r27
	ctx.r8.s64 = ctx.r27.s64 - ctx.r10.s64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwzx r5,r11,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// slw r6,r9,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// andc r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ~ctx.r6.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stwx r4,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r4.u32);
	// stb r7,40(r31)
	PPC_STORE_U8(ctx.r31.u32 + 40, ctx.r7.u8);
	// bl 0x823051a8
	ctx.lr = 0x821186F0;
	sub_823051A8(ctx, base);
	// lwz r29,4(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8211877c
	if (ctx.cr6.eq) goto loc_8211877C;
	// addi r27,r29,20
	ctx.r27.s64 = ctx.r29.s64 + 20;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823052d8
	ctx.lr = 0x8211870C;
	sub_823052D8(ctx, base);
	// lbz r11,40(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118774
	if (!ctx.cr6.eq) goto loc_82118774;
loc_82118718:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82118784
	if (!ctx.cr6.eq) goto loc_82118784;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// blt cr6,0x82118718
	if (ctx.cr6.lt) goto loc_82118718;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82118738:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82118774
	if (ctx.cr6.eq) goto loc_82118774;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82118758
	if (ctx.cr6.eq) goto loc_82118758;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_82118758:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// bl 0x82118e10
	ctx.lr = 0x82118768;
	sub_82118E10(ctx, base);
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82118774;
	sub_82080000(ctx, base);
loc_82118774:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823051a8
	ctx.lr = 0x8211877C;
	sub_823051A8(ctx, base);
loc_8211877C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
loc_82118784:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82118738
	goto loc_82118738;
}

__attribute__((alias("__imp__sub_8211878C"))) PPC_WEAK_FUNC(sub_8211878C);
PPC_FUNC_IMPL(__imp__sub_8211878C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82118790"))) PPC_WEAK_FUNC(sub_82118790);
PPC_FUNC_IMPL(__imp__sub_82118790) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82118798;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r27,-1
	ctx.r27.s64 = -1;
	// li r29,1
	ctx.r29.s64 = 1;
loc_821187A8:
	// addi r28,r30,20
	ctx.r28.s64 = ctx.r30.s64 + 20;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x821187B8;
	sub_823052D8(ctx, base);
	// lbz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821188e0
	if (!ctx.cr6.eq) goto loc_821188E0;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821187f8
	if (!ctx.cr6.eq) goto loc_821187F8;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,4096
	ctx.r4.s64 = 4096;
	// lis r3,1
	ctx.r3.s64 = 65536;
	// bl 0x82082030
	ctx.lr = 0x821187E4;
	sub_82082030(ctx, base);
	// li r5,1028
	ctx.r5.s64 = 1028;
	// lis r4,1
	ctx.r4.s64 = 65536;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x822472e0
	ctx.lr = 0x821187F4;
	sub_822472E0(ctx, base);
	// stw r31,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r31.u32);
loc_821187F8:
	// li r31,0
	ctx.r31.s64 = 0;
loc_821187FC:
	// rlwinm r11,r31,27,5,31
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r31,0,0,26
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// subf r8,r10,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r10.s64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 & ctx.r5.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x821188d8
	if (ctx.cr6.eq) goto loc_821188D8;
	// addi r11,r31,2
	ctx.r11.s64 = ctx.r31.s64 + 2;
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// rlwinm r10,r10,27,5,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x7FFFFFF;
	// addi r9,r10,3
	ctx.r9.s64 = ctx.r10.s64 + 3;
	// rlwinm r8,r10,5,0,26
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r8,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r8.s64;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// slw r4,r29,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// and r3,r4,r5
	ctx.r3.u64 = ctx.r4.u64 & ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821188c4
	if (ctx.cr6.eq) goto loc_821188C4;
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r9,r11,0,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r8,r10,3
	ctx.r8.s64 = ctx.r10.s64 + 3;
	// subf r10,r9,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r9.s64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,2
	ctx.r6.s64 = ctx.r10.s64 + 2;
	// slw r5,r29,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r4,r7,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r3,r5,r4
	ctx.r3.u64 = ctx.r5.u64 & ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821188cc
	if (ctx.cr6.eq) goto loc_821188CC;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r11,r11,27,5,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,5,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r9,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r9.s64;
	// addi r7,r11,3
	ctx.r7.s64 = ctx.r11.s64 + 3;
	// lwzx r6,r8,r30
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// slw r5,r29,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r7.u8 & 0x3F));
	// and r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ctx.r6.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x821188d4
	if (ctx.cr6.eq) goto loc_821188D4;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x821187fc
	if (ctx.cr6.lt) goto loc_821187FC;
	// b 0x821188e0
	goto loc_821188E0;
loc_821188C4:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x821188d8
	goto loc_821188D8;
loc_821188CC:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// b 0x821188d8
	goto loc_821188D8;
loc_821188D4:
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
loc_821188D8:
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x82118930
	if (ctx.cr6.lt) goto loc_82118930;
loc_821188E0:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stb r29,40(r30)
	PPC_STORE_U8(ctx.r30.u32 + 40, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118920
	if (!ctx.cr6.eq) goto loc_82118920;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82082030
	ctx.lr = 0x82118904;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82118914
	if (ctx.cr6.eq) goto loc_82118914;
	// bl 0x82118da0
	ctx.lr = 0x82118910;
	sub_82118DA0(ctx, base);
	// b 0x82118918
	goto loc_82118918;
loc_82118914:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82118918:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
loc_82118920:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823051a8
	ctx.lr = 0x82118928;
	sub_823051A8(ctx, base);
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x821187a8
	goto loc_821187A8;
loc_82118930:
	// addi r11,r30,12
	ctx.r11.s64 = ctx.r30.s64 + 12;
	// rlwinm r10,r31,29,3,29
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 29) & 0x1FFFFFFC;
	// rlwinm r9,r31,0,0,26
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// subf r8,r9,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r9.s64;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// or r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r5,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r5.u32);
	// bl 0x823051a8
	ctx.lr = 0x82118958;
	sub_823051A8(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r11,r31,10,0,21
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 10) & 0xFFFFFC00;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211896C"))) PPC_WEAK_FUNC(sub_8211896C);
PPC_FUNC_IMPL(__imp__sub_8211896C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82118970"))) PPC_WEAK_FUNC(sub_82118970);
PPC_FUNC_IMPL(__imp__sub_82118970) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82118978;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// lis r10,1
	ctx.r10.s64 = 65536;
	// addi r31,r11,3088
	ctx.r31.s64 = ctx.r11.s64 + 3088;
	// lwz r11,3088(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 3088);
loc_8211898C:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x821189a0
	if (ctx.cr6.lt) goto loc_821189A0;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r3,r9
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x821189ac
	if (ctx.cr6.lt) goto loc_821189AC;
loc_821189A0:
	// lwz r31,8(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// b 0x8211898c
	goto loc_8211898C;
loc_821189AC:
	// addi r29,r31,20
	ctx.r29.s64 = ctx.r31.s64 + 20;
	// li r28,-1
	ctx.r28.s64 = -1;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// rlwinm r27,r11,22,10,31
	ctx.r27.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 22) & 0x3FFFFF;
	// bl 0x823052d8
	ctx.lr = 0x821189C8;
	sub_823052D8(ctx, base);
	// rlwinm r11,r27,29,3,29
	ctx.r11.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// rlwinm r10,r27,0,0,26
	ctx.r10.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0xFFFFFFE0;
	// li r9,1
	ctx.r9.s64 = 1;
	// subf r8,r10,r27
	ctx.r8.s64 = ctx.r27.s64 - ctx.r10.s64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwzx r5,r11,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// slw r6,r9,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// andc r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ~ctx.r6.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stwx r4,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r4.u32);
	// stb r7,40(r31)
	PPC_STORE_U8(ctx.r31.u32 + 40, ctx.r7.u8);
	// bl 0x823051a8
	ctx.lr = 0x821189FC;
	sub_823051A8(ctx, base);
	// lwz r29,4(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82118a88
	if (ctx.cr6.eq) goto loc_82118A88;
	// addi r27,r29,20
	ctx.r27.s64 = ctx.r29.s64 + 20;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823052d8
	ctx.lr = 0x82118A18;
	sub_823052D8(ctx, base);
	// lbz r11,40(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118a80
	if (!ctx.cr6.eq) goto loc_82118A80;
loc_82118A24:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82118a90
	if (!ctx.cr6.eq) goto loc_82118A90;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// blt cr6,0x82118a24
	if (ctx.cr6.lt) goto loc_82118A24;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82118A44:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82118a80
	if (ctx.cr6.eq) goto loc_82118A80;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82118a64
	if (ctx.cr6.eq) goto loc_82118A64;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_82118A64:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// bl 0x82118e10
	ctx.lr = 0x82118A74;
	sub_82118E10(ctx, base);
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82118A80;
	sub_82080000(ctx, base);
loc_82118A80:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823051a8
	ctx.lr = 0x82118A88;
	sub_823051A8(ctx, base);
loc_82118A88:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
loc_82118A90:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82118a44
	goto loc_82118A44;
}

__attribute__((alias("__imp__sub_82118A98"))) PPC_WEAK_FUNC(sub_82118A98);
PPC_FUNC_IMPL(__imp__sub_82118A98) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82118AA0;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r27,-1
	ctx.r27.s64 = -1;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82118AB0:
	// addi r28,r30,20
	ctx.r28.s64 = ctx.r30.s64 + 20;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x82118AC0;
	sub_823052D8(ctx, base);
	// lbz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118be8
	if (!ctx.cr6.eq) goto loc_82118BE8;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118b00
	if (!ctx.cr6.eq) goto loc_82118B00;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,4096
	ctx.r4.s64 = 4096;
	// lis r3,2
	ctx.r3.s64 = 131072;
	// bl 0x82082030
	ctx.lr = 0x82118AEC;
	sub_82082030(ctx, base);
	// li r5,1028
	ctx.r5.s64 = 1028;
	// lis r4,2
	ctx.r4.s64 = 131072;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x822472e0
	ctx.lr = 0x82118AFC;
	sub_822472E0(ctx, base);
	// stw r31,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r31.u32);
loc_82118B00:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82118B04:
	// rlwinm r11,r31,27,5,31
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r31,0,0,26
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// subf r8,r10,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r10.s64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 & ctx.r5.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82118be0
	if (ctx.cr6.eq) goto loc_82118BE0;
	// addi r11,r31,2
	ctx.r11.s64 = ctx.r31.s64 + 2;
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// rlwinm r10,r10,27,5,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x7FFFFFF;
	// addi r9,r10,3
	ctx.r9.s64 = ctx.r10.s64 + 3;
	// rlwinm r8,r10,5,0,26
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r8,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r8.s64;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// slw r4,r29,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// and r3,r4,r5
	ctx.r3.u64 = ctx.r4.u64 & ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82118bcc
	if (ctx.cr6.eq) goto loc_82118BCC;
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r9,r11,0,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r8,r10,3
	ctx.r8.s64 = ctx.r10.s64 + 3;
	// subf r10,r9,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r9.s64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,2
	ctx.r6.s64 = ctx.r10.s64 + 2;
	// slw r5,r29,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r4,r7,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r3,r5,r4
	ctx.r3.u64 = ctx.r5.u64 & ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82118bd4
	if (ctx.cr6.eq) goto loc_82118BD4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r11,r11,27,5,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,5,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r9,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r9.s64;
	// addi r7,r11,3
	ctx.r7.s64 = ctx.r11.s64 + 3;
	// lwzx r6,r8,r30
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// slw r5,r29,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r7.u8 & 0x3F));
	// and r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ctx.r6.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82118bdc
	if (ctx.cr6.eq) goto loc_82118BDC;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x82118b04
	if (ctx.cr6.lt) goto loc_82118B04;
	// b 0x82118be8
	goto loc_82118BE8;
loc_82118BCC:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82118be0
	goto loc_82118BE0;
loc_82118BD4:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// b 0x82118be0
	goto loc_82118BE0;
loc_82118BDC:
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
loc_82118BE0:
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x82118c38
	if (ctx.cr6.lt) goto loc_82118C38;
loc_82118BE8:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stb r29,40(r30)
	PPC_STORE_U8(ctx.r30.u32 + 40, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118c28
	if (!ctx.cr6.eq) goto loc_82118C28;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82082030
	ctx.lr = 0x82118C0C;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82118c1c
	if (ctx.cr6.eq) goto loc_82118C1C;
	// bl 0x82118da0
	ctx.lr = 0x82118C18;
	sub_82118DA0(ctx, base);
	// b 0x82118c20
	goto loc_82118C20;
loc_82118C1C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82118C20:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
loc_82118C28:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823051a8
	ctx.lr = 0x82118C30;
	sub_823051A8(ctx, base);
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82118ab0
	goto loc_82118AB0;
loc_82118C38:
	// addi r11,r30,12
	ctx.r11.s64 = ctx.r30.s64 + 12;
	// rlwinm r10,r31,29,3,29
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 29) & 0x1FFFFFFC;
	// rlwinm r9,r31,0,0,26
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// subf r8,r9,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r9.s64;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// or r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r5,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r5.u32);
	// bl 0x823051a8
	ctx.lr = 0x82118C60;
	sub_823051A8(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r11,r31,11,0,20
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 11) & 0xFFFFF800;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82118C74"))) PPC_WEAK_FUNC(sub_82118C74);
PPC_FUNC_IMPL(__imp__sub_82118C74) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82118C78"))) PPC_WEAK_FUNC(sub_82118C78);
PPC_FUNC_IMPL(__imp__sub_82118C78) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82118C80;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// lis r10,2
	ctx.r10.s64 = 131072;
	// addi r31,r11,3132
	ctx.r31.s64 = ctx.r11.s64 + 3132;
	// lwz r11,3132(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 3132);
loc_82118C94:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82118ca8
	if (ctx.cr6.lt) goto loc_82118CA8;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r3,r9
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x82118cb4
	if (ctx.cr6.lt) goto loc_82118CB4;
loc_82118CA8:
	// lwz r31,8(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// b 0x82118c94
	goto loc_82118C94;
loc_82118CB4:
	// addi r29,r31,20
	ctx.r29.s64 = ctx.r31.s64 + 20;
	// li r28,-1
	ctx.r28.s64 = -1;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// rlwinm r27,r11,21,11,31
	ctx.r27.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 21) & 0x1FFFFF;
	// bl 0x823052d8
	ctx.lr = 0x82118CD0;
	sub_823052D8(ctx, base);
	// rlwinm r11,r27,29,3,29
	ctx.r11.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// rlwinm r10,r27,0,0,26
	ctx.r10.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0xFFFFFFE0;
	// li r9,1
	ctx.r9.s64 = 1;
	// subf r8,r10,r27
	ctx.r8.s64 = ctx.r27.s64 - ctx.r10.s64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwzx r5,r11,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// slw r6,r9,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// andc r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ~ctx.r6.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stwx r4,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r4.u32);
	// stb r7,40(r31)
	PPC_STORE_U8(ctx.r31.u32 + 40, ctx.r7.u8);
	// bl 0x823051a8
	ctx.lr = 0x82118D04;
	sub_823051A8(ctx, base);
	// lwz r29,4(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82118d90
	if (ctx.cr6.eq) goto loc_82118D90;
	// addi r27,r29,20
	ctx.r27.s64 = ctx.r29.s64 + 20;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823052d8
	ctx.lr = 0x82118D20;
	sub_823052D8(ctx, base);
	// lbz r11,40(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118d88
	if (!ctx.cr6.eq) goto loc_82118D88;
loc_82118D2C:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82118d98
	if (!ctx.cr6.eq) goto loc_82118D98;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// blt cr6,0x82118d2c
	if (ctx.cr6.lt) goto loc_82118D2C;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82118D4C:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82118d88
	if (ctx.cr6.eq) goto loc_82118D88;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82118d6c
	if (ctx.cr6.eq) goto loc_82118D6C;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_82118D6C:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// bl 0x82118e10
	ctx.lr = 0x82118D7C;
	sub_82118E10(ctx, base);
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82118D88;
	sub_82080000(ctx, base);
loc_82118D88:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823051a8
	ctx.lr = 0x82118D90;
	sub_823051A8(ctx, base);
loc_82118D90:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
loc_82118D98:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82118d4c
	goto loc_82118D4C;
}

__attribute__((alias("__imp__sub_82118DA0"))) PPC_WEAK_FUNC(sub_82118DA0);
PPC_FUNC_IMPL(__imp__sub_82118DA0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// addi r3,r3,20
	ctx.r3.s64 = ctx.r3.s64 + 20;
	// li r4,4000
	ctx.r4.s64 = 4000;
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
	// stw r30,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r30.u32);
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
	// stw r30,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r30.u32);
	// stw r30,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r30.u32);
	// stw r30,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r30.u32);
	// stw r30,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r30.u32);
	// stw r30,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r30.u32);
	// stw r30,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r30.u32);
	// stw r30,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r30.u32);
	// bl 0x82305000
	ctx.lr = 0x82118DF0;
	sub_82305000(ctx, base);
	// stb r30,40(r31)
	PPC_STORE_U8(ctx.r31.u32 + 40, ctx.r30.u8);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82118E10"))) PPC_WEAK_FUNC(sub_82118E10);
PPC_FUNC_IMPL(__imp__sub_82118E10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82118e54
	if (ctx.cr6.eq) goto loc_82118E54;
	// lwz r11,-4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -4);
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// clrlwi r4,r11,2
	ctx.r4.u64 = ctx.r11.u32 & 0x3FFFFFFF;
	// bl 0x822472e0
	ctx.lr = 0x82118E48;
	sub_822472E0(ctx, base);
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82118E54;
	sub_82080000(ctx, base);
loc_82118E54:
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// addi r11,r30,20
	ctx.r11.s64 = ctx.r30.s64 + 20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82118e6c
	if (ctx.cr6.eq) goto loc_82118E6C;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x82118E6C;
	sub_82246E18(ctx, base);
loc_82118E6C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82118E84"))) PPC_WEAK_FUNC(sub_82118E84);
PPC_FUNC_IMPL(__imp__sub_82118E84) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82118E88"))) PPC_WEAK_FUNC(sub_82118E88);
PPC_FUNC_IMPL(__imp__sub_82118E88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82118E90;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r27,-1
	ctx.r27.s64 = -1;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82118EA0:
	// addi r28,r30,20
	ctx.r28.s64 = ctx.r30.s64 + 20;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x82118EB0;
	sub_823052D8(ctx, base);
	// lbz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118fd8
	if (!ctx.cr6.eq) goto loc_82118FD8;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82118ef0
	if (!ctx.cr6.eq) goto loc_82118EF0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,4096
	ctx.r4.s64 = 4096;
	// lis r3,4
	ctx.r3.s64 = 262144;
	// bl 0x82082030
	ctx.lr = 0x82118EDC;
	sub_82082030(ctx, base);
	// li r5,1028
	ctx.r5.s64 = 1028;
	// lis r4,4
	ctx.r4.s64 = 262144;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x822472e0
	ctx.lr = 0x82118EEC;
	sub_822472E0(ctx, base);
	// stw r31,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r31.u32);
loc_82118EF0:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82118EF4:
	// rlwinm r11,r31,27,5,31
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r31,0,0,26
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// subf r8,r10,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r10.s64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 & ctx.r5.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82118fd0
	if (ctx.cr6.eq) goto loc_82118FD0;
	// addi r11,r31,2
	ctx.r11.s64 = ctx.r31.s64 + 2;
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// rlwinm r10,r10,27,5,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x7FFFFFF;
	// addi r9,r10,3
	ctx.r9.s64 = ctx.r10.s64 + 3;
	// rlwinm r8,r10,5,0,26
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r8,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r8.s64;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// slw r4,r29,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// and r3,r4,r5
	ctx.r3.u64 = ctx.r4.u64 & ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82118fbc
	if (ctx.cr6.eq) goto loc_82118FBC;
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r9,r11,0,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r8,r10,3
	ctx.r8.s64 = ctx.r10.s64 + 3;
	// subf r10,r9,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r9.s64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,2
	ctx.r6.s64 = ctx.r10.s64 + 2;
	// slw r5,r29,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r4,r7,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r3,r5,r4
	ctx.r3.u64 = ctx.r5.u64 & ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82118fc4
	if (ctx.cr6.eq) goto loc_82118FC4;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r11,r11,27,5,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,5,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r9,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r9.s64;
	// addi r7,r11,3
	ctx.r7.s64 = ctx.r11.s64 + 3;
	// lwzx r6,r8,r30
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// slw r5,r29,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r7.u8 & 0x3F));
	// and r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ctx.r6.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82118fcc
	if (ctx.cr6.eq) goto loc_82118FCC;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x82118ef4
	if (ctx.cr6.lt) goto loc_82118EF4;
	// b 0x82118fd8
	goto loc_82118FD8;
loc_82118FBC:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82118fd0
	goto loc_82118FD0;
loc_82118FC4:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// b 0x82118fd0
	goto loc_82118FD0;
loc_82118FCC:
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
loc_82118FD0:
	// cmplwi cr6,r31,64
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 64, ctx.xer);
	// blt cr6,0x82119028
	if (ctx.cr6.lt) goto loc_82119028;
loc_82118FD8:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stb r29,40(r30)
	PPC_STORE_U8(ctx.r30.u32 + 40, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82119018
	if (!ctx.cr6.eq) goto loc_82119018;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82082030
	ctx.lr = 0x82118FFC;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211900c
	if (ctx.cr6.eq) goto loc_8211900C;
	// bl 0x82118da0
	ctx.lr = 0x82119008;
	sub_82118DA0(ctx, base);
	// b 0x82119010
	goto loc_82119010;
loc_8211900C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82119010:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
loc_82119018:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823051a8
	ctx.lr = 0x82119020;
	sub_823051A8(ctx, base);
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82118ea0
	goto loc_82118EA0;
loc_82119028:
	// addi r11,r30,12
	ctx.r11.s64 = ctx.r30.s64 + 12;
	// rlwinm r10,r31,29,3,29
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 29) & 0x1FFFFFFC;
	// rlwinm r9,r31,0,0,26
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// subf r8,r9,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r9.s64;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// or r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r5,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r5.u32);
	// bl 0x823051a8
	ctx.lr = 0x82119050;
	sub_823051A8(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r11,r31,12,0,19
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 12) & 0xFFFFF000;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82119064"))) PPC_WEAK_FUNC(sub_82119064);
PPC_FUNC_IMPL(__imp__sub_82119064) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82119068"))) PPC_WEAK_FUNC(sub_82119068);
PPC_FUNC_IMPL(__imp__sub_82119068) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82119070;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// lis r10,4
	ctx.r10.s64 = 262144;
	// addi r31,r11,3176
	ctx.r31.s64 = ctx.r11.s64 + 3176;
	// lwz r11,3176(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 3176);
loc_82119084:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82119098
	if (ctx.cr6.lt) goto loc_82119098;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r3,r9
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x821190a4
	if (ctx.cr6.lt) goto loc_821190A4;
loc_82119098:
	// lwz r31,8(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// b 0x82119084
	goto loc_82119084;
loc_821190A4:
	// addi r29,r31,20
	ctx.r29.s64 = ctx.r31.s64 + 20;
	// li r28,-1
	ctx.r28.s64 = -1;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// rlwinm r27,r11,20,12,31
	ctx.r27.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 20) & 0xFFFFF;
	// bl 0x823052d8
	ctx.lr = 0x821190C0;
	sub_823052D8(ctx, base);
	// rlwinm r11,r27,29,3,29
	ctx.r11.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// rlwinm r10,r27,0,0,26
	ctx.r10.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0xFFFFFFE0;
	// li r9,1
	ctx.r9.s64 = 1;
	// subf r8,r10,r27
	ctx.r8.s64 = ctx.r27.s64 - ctx.r10.s64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwzx r5,r11,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// slw r6,r9,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// andc r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ~ctx.r6.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stwx r4,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r4.u32);
	// stb r7,40(r31)
	PPC_STORE_U8(ctx.r31.u32 + 40, ctx.r7.u8);
	// bl 0x823051a8
	ctx.lr = 0x821190F4;
	sub_823051A8(ctx, base);
	// lwz r29,4(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82119180
	if (ctx.cr6.eq) goto loc_82119180;
	// addi r27,r29,20
	ctx.r27.s64 = ctx.r29.s64 + 20;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823052d8
	ctx.lr = 0x82119110;
	sub_823052D8(ctx, base);
	// lbz r11,40(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82119178
	if (!ctx.cr6.eq) goto loc_82119178;
loc_8211911C:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82119188
	if (!ctx.cr6.eq) goto loc_82119188;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// blt cr6,0x8211911c
	if (ctx.cr6.lt) goto loc_8211911C;
	// li r11,1
	ctx.r11.s64 = 1;
loc_8211913C:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82119178
	if (ctx.cr6.eq) goto loc_82119178;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211915c
	if (ctx.cr6.eq) goto loc_8211915C;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_8211915C:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// bl 0x82118e10
	ctx.lr = 0x8211916C;
	sub_82118E10(ctx, base);
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82119178;
	sub_82080000(ctx, base);
loc_82119178:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823051a8
	ctx.lr = 0x82119180;
	sub_823051A8(ctx, base);
loc_82119180:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
loc_82119188:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x8211913c
	goto loc_8211913C;
}

__attribute__((alias("__imp__sub_82119190"))) PPC_WEAK_FUNC(sub_82119190);
PPC_FUNC_IMPL(__imp__sub_82119190) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x821191d4
	if (ctx.cr6.eq) goto loc_821191D4;
	// lwz r11,-4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -4);
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// clrlwi r4,r11,2
	ctx.r4.u64 = ctx.r11.u32 & 0x3FFFFFFF;
	// bl 0x822472e0
	ctx.lr = 0x821191C8;
	sub_822472E0(ctx, base);
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821191D4;
	sub_82080000(ctx, base);
loc_821191D4:
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// addi r11,r30,16
	ctx.r11.s64 = ctx.r30.s64 + 16;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821191ec
	if (ctx.cr6.eq) goto loc_821191EC;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82246e18
	ctx.lr = 0x821191EC;
	sub_82246E18(ctx, base);
loc_821191EC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82119204"))) PPC_WEAK_FUNC(sub_82119204);
PPC_FUNC_IMPL(__imp__sub_82119204) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82119208"))) PPC_WEAK_FUNC(sub_82119208);
PPC_FUNC_IMPL(__imp__sub_82119208) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82119210;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r27,-1
	ctx.r27.s64 = -1;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82119220:
	// addi r28,r30,16
	ctx.r28.s64 = ctx.r30.s64 + 16;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x82119230;
	sub_823052D8(ctx, base);
	// lbz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82119358
	if (!ctx.cr6.eq) goto loc_82119358;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82119270
	if (!ctx.cr6.eq) goto loc_82119270;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,4096
	ctx.r4.s64 = 4096;
	// lis r3,3
	ctx.r3.s64 = 196608;
	// bl 0x82082030
	ctx.lr = 0x8211925C;
	sub_82082030(ctx, base);
	// li r5,1028
	ctx.r5.s64 = 1028;
	// lis r4,3
	ctx.r4.s64 = 196608;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x822472e0
	ctx.lr = 0x8211926C;
	sub_822472E0(ctx, base);
	// stw r31,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r31.u32);
loc_82119270:
	// li r31,0
	ctx.r31.s64 = 0;
loc_82119274:
	// rlwinm r11,r31,27,5,31
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r31,0,0,26
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// subf r8,r10,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r10.s64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 & ctx.r5.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82119350
	if (ctx.cr6.eq) goto loc_82119350;
	// addi r11,r31,2
	ctx.r11.s64 = ctx.r31.s64 + 2;
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// rlwinm r10,r10,27,5,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x7FFFFFF;
	// addi r9,r10,3
	ctx.r9.s64 = ctx.r10.s64 + 3;
	// rlwinm r8,r10,5,0,26
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r8,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r8.s64;
	// addi r6,r10,1
	ctx.r6.s64 = ctx.r10.s64 + 1;
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// slw r4,r29,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// and r3,r4,r5
	ctx.r3.u64 = ctx.r4.u64 & ctx.r5.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211933c
	if (ctx.cr6.eq) goto loc_8211933C;
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r9,r11,0,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r8,r10,3
	ctx.r8.s64 = ctx.r10.s64 + 3;
	// subf r10,r9,r31
	ctx.r10.s64 = ctx.r31.s64 - ctx.r9.s64;
	// rlwinm r7,r8,2,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,2
	ctx.r6.s64 = ctx.r10.s64 + 2;
	// slw r5,r29,r6
	ctx.r5.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r4,r7,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r3,r5,r4
	ctx.r3.u64 = ctx.r5.u64 & ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82119344
	if (ctx.cr6.eq) goto loc_82119344;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// rlwinm r11,r11,27,5,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r9,r11,5,0,26
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// rlwinm r8,r10,2,0,29
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r9,r31
	ctx.r11.s64 = ctx.r31.s64 - ctx.r9.s64;
	// addi r7,r11,3
	ctx.r7.s64 = ctx.r11.s64 + 3;
	// lwzx r6,r8,r30
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r30.u32);
	// slw r5,r29,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r7.u8 & 0x3F));
	// and r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ctx.r6.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x8211934c
	if (ctx.cr6.eq) goto loc_8211934C;
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// cmplwi cr6,r31,32
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 32, ctx.xer);
	// blt cr6,0x82119274
	if (ctx.cr6.lt) goto loc_82119274;
	// b 0x82119358
	goto loc_82119358;
loc_8211933C:
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// b 0x82119350
	goto loc_82119350;
loc_82119344:
	// mr r31,r11
	ctx.r31.u64 = ctx.r11.u64;
	// b 0x82119350
	goto loc_82119350;
loc_8211934C:
	// addi r31,r31,3
	ctx.r31.s64 = ctx.r31.s64 + 3;
loc_82119350:
	// cmplwi cr6,r31,32
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 32, ctx.xer);
	// blt cr6,0x821193a8
	if (ctx.cr6.lt) goto loc_821193A8;
loc_82119358:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stb r29,36(r30)
	PPC_STORE_U8(ctx.r30.u32 + 36, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82119398
	if (!ctx.cr6.eq) goto loc_82119398;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x82082030
	ctx.lr = 0x8211937C;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211938c
	if (ctx.cr6.eq) goto loc_8211938C;
	// bl 0x82117e70
	ctx.lr = 0x82119388;
	sub_82117E70(ctx, base);
	// b 0x82119390
	goto loc_82119390;
loc_8211938C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82119390:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
loc_82119398:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823051a8
	ctx.lr = 0x821193A0;
	sub_823051A8(ctx, base);
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82119220
	goto loc_82119220;
loc_821193A8:
	// addi r11,r30,12
	ctx.r11.s64 = ctx.r30.s64 + 12;
	// rlwinm r10,r31,29,3,29
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 29) & 0x1FFFFFFC;
	// rlwinm r9,r31,0,0,26
	ctx.r9.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// subf r8,r9,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r9.s64;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r11.u32);
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// or r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r5,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + ctx.r11.u32, ctx.r5.u32);
	// bl 0x823051a8
	ctx.lr = 0x821193D0;
	sub_823051A8(ctx, base);
	// rlwinm r11,r31,1,0,30
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r4,r31,r11
	ctx.r4.u64 = ctx.r31.u64 + ctx.r11.u64;
	// rlwinm r11,r4,11,0,20
	ctx.r11.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 11) & 0xFFFFF800;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821193EC"))) PPC_WEAK_FUNC(sub_821193EC);
PPC_FUNC_IMPL(__imp__sub_821193EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821193F0"))) PPC_WEAK_FUNC(sub_821193F0);
PPC_FUNC_IMPL(__imp__sub_821193F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x821193F8;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// lis r10,3
	ctx.r10.s64 = 196608;
	// addi r31,r11,3220
	ctx.r31.s64 = ctx.r11.s64 + 3220;
	// lwz r11,3220(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 3220);
loc_8211940C:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82119420
	if (ctx.cr6.lt) goto loc_82119420;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r3,r9
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, ctx.xer);
	// blt cr6,0x8211942c
	if (ctx.cr6.lt) goto loc_8211942C;
loc_82119420:
	// lwz r31,8(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// b 0x8211940c
	goto loc_8211940C;
loc_8211942C:
	// addi r29,r31,16
	ctx.r29.s64 = ctx.r31.s64 + 16;
	// li r28,-1
	ctx.r28.s64 = -1;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// li r10,6144
	ctx.r10.s64 = 6144;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// divwu r27,r11,r10
	ctx.r27.u32 = ctx.r11.u32 / ctx.r10.u32;
	// bl 0x823052d8
	ctx.lr = 0x8211944C;
	sub_823052D8(ctx, base);
	// rlwinm r11,r27,29,3,29
	ctx.r11.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// rlwinm r9,r27,0,0,26
	ctx.r9.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0xFFFFFFE0;
	// li r8,1
	ctx.r8.s64 = 1;
	// subf r7,r9,r27
	ctx.r7.s64 = ctx.r27.s64 - ctx.r9.s64;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwzx r4,r11,r30
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// slw r5,r8,r7
	ctx.r5.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r7.u8 & 0x3F));
	// andc r10,r4,r5
	ctx.r10.u64 = ctx.r4.u64 & ~ctx.r5.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stwx r10,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r10.u32);
	// stb r6,36(r31)
	PPC_STORE_U8(ctx.r31.u32 + 36, ctx.r6.u8);
	// bl 0x823051a8
	ctx.lr = 0x82119480;
	sub_823051A8(ctx, base);
	// lwz r29,4(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8211950c
	if (ctx.cr6.eq) goto loc_8211950C;
	// addi r27,r29,16
	ctx.r27.s64 = ctx.r29.s64 + 16;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823052d8
	ctx.lr = 0x8211949C;
	sub_823052D8(ctx, base);
	// lbz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82119504
	if (!ctx.cr6.eq) goto loc_82119504;
loc_821194A8:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82119514
	if (!ctx.cr6.eq) goto loc_82119514;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x821194a8
	if (ctx.cr6.lt) goto loc_821194A8;
	// li r11,1
	ctx.r11.s64 = 1;
loc_821194C8:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82119504
	if (ctx.cr6.eq) goto loc_82119504;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821194e8
	if (ctx.cr6.eq) goto loc_821194E8;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_821194E8:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// bl 0x82119190
	ctx.lr = 0x821194F8;
	sub_82119190(ctx, base);
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82119504;
	sub_82080000(ctx, base);
loc_82119504:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823051a8
	ctx.lr = 0x8211950C;
	sub_823051A8(ctx, base);
loc_8211950C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
loc_82119514:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x821194c8
	goto loc_821194C8;
}

__attribute__((alias("__imp__sub_8211951C"))) PPC_WEAK_FUNC(sub_8211951C);
PPC_FUNC_IMPL(__imp__sub_8211951C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82119520"))) PPC_WEAK_FUNC(sub_82119520);
PPC_FUNC_IMPL(__imp__sub_82119520) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82119528;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// li r27,-1
	ctx.r27.s64 = -1;
	// li r29,1
	ctx.r29.s64 = 1;
loc_82119538:
	// addi r28,r30,16
	ctx.r28.s64 = ctx.r30.s64 + 16;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823052d8
	ctx.lr = 0x82119548;
	sub_823052D8(ctx, base);
	// lbz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821195cc
	if (!ctx.cr6.eq) goto loc_821195CC;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82119588
	if (!ctx.cr6.eq) goto loc_82119588;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,4096
	ctx.r4.s64 = 4096;
	// li r3,8192
	ctx.r3.s64 = 8192;
	// bl 0x82082030
	ctx.lr = 0x82119574;
	sub_82082030(ctx, base);
	// li r5,1028
	ctx.r5.s64 = 1028;
	// li r4,8192
	ctx.r4.s64 = 8192;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x822472e0
	ctx.lr = 0x82119584;
	sub_822472E0(ctx, base);
	// stw r31,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r31.u32);
loc_82119588:
	// li r31,0
	ctx.r31.s64 = 0;
loc_8211958C:
	// rlwinm r11,r31,27,5,31
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r31,0,0,26
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 0) & 0xFFFFFFE0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// subf r8,r10,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r10.s64;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// lwzx r5,r7,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r30.u32);
	// and r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 & ctx.r5.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x821195c4
	if (ctx.cr6.eq) goto loc_821195C4;
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplwi cr6,r31,1
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 1, ctx.xer);
	// blt cr6,0x8211958c
	if (ctx.cr6.lt) goto loc_8211958C;
	// b 0x821195cc
	goto loc_821195CC;
loc_821195C4:
	// cmplwi cr6,r31,1
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 1, ctx.xer);
	// blt cr6,0x8211961c
	if (ctx.cr6.lt) goto loc_8211961C;
loc_821195CC:
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stb r29,36(r30)
	PPC_STORE_U8(ctx.r30.u32 + 36, ctx.r29.u8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211960c
	if (!ctx.cr6.eq) goto loc_8211960C;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,40
	ctx.r3.s64 = 40;
	// bl 0x82082030
	ctx.lr = 0x821195F0;
	sub_82082030(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82119600
	if (ctx.cr6.eq) goto loc_82119600;
	// bl 0x82117e70
	ctx.lr = 0x821195FC;
	sub_82117E70(ctx, base);
	// b 0x82119604
	goto loc_82119604;
loc_82119600:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82119604:
	// stw r3,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r3.u32);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r30.u32);
loc_8211960C:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823051a8
	ctx.lr = 0x82119614;
	sub_823051A8(ctx, base);
	// lwz r30,8(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// b 0x82119538
	goto loc_82119538;
loc_8211961C:
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r30,12
	ctx.r10.s64 = ctx.r30.s64 + 12;
	// rlwinm r11,r11,5,0,26
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 5) & 0xFFFFFFE0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// subf r8,r11,r31
	ctx.r8.s64 = ctx.r31.s64 - ctx.r11.s64;
	// lwzx r7,r9,r10
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// slw r6,r29,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r29.u32 << (ctx.r8.u8 & 0x3F));
	// or r5,r6,r7
	ctx.r5.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r5,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, ctx.r5.u32);
	// bl 0x823051a8
	ctx.lr = 0x82119644;
	sub_823051A8(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r11,r31,13,0,18
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 13) & 0xFFFFE000;
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82119658"))) PPC_WEAK_FUNC(sub_82119658);
PPC_FUNC_IMPL(__imp__sub_82119658) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82119660;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r31,r11,3260
	ctx.r31.s64 = ctx.r11.s64 + 3260;
	// lwz r11,3260(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 3260);
loc_82119670:
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82119684
	if (ctx.cr6.lt) goto loc_82119684;
	// addi r10,r11,8192
	ctx.r10.s64 = ctx.r11.s64 + 8192;
	// cmplw cr6,r3,r10
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82119690
	if (ctx.cr6.lt) goto loc_82119690;
loc_82119684:
	// lwz r31,8(r31)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// b 0x82119670
	goto loc_82119670;
loc_82119690:
	// addi r29,r31,16
	ctx.r29.s64 = ctx.r31.s64 + 16;
	// li r28,-1
	ctx.r28.s64 = -1;
	// subf r11,r11,r3
	ctx.r11.s64 = ctx.r3.s64 - ctx.r11.s64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// rlwinm r27,r11,19,13,31
	ctx.r27.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 19) & 0x7FFFF;
	// bl 0x823052d8
	ctx.lr = 0x821196AC;
	sub_823052D8(ctx, base);
	// rlwinm r11,r27,29,3,29
	ctx.r11.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 29) & 0x1FFFFFFC;
	// addi r30,r31,12
	ctx.r30.s64 = ctx.r31.s64 + 12;
	// rlwinm r10,r27,0,0,26
	ctx.r10.u64 = rotl64(ctx.r27.u32 | (ctx.r27.u64 << 32), 0) & 0xFFFFFFE0;
	// li r9,1
	ctx.r9.s64 = 1;
	// subf r8,r10,r27
	ctx.r8.s64 = ctx.r27.s64 - ctx.r10.s64;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwzx r5,r11,r30
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r30.u32);
	// slw r6,r9,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// andc r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 & ~ctx.r6.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stwx r4,r11,r30
	PPC_STORE_U32(ctx.r11.u32 + ctx.r30.u32, ctx.r4.u32);
	// stb r7,36(r31)
	PPC_STORE_U8(ctx.r31.u32 + 36, ctx.r7.u8);
	// bl 0x823051a8
	ctx.lr = 0x821196E0;
	sub_823051A8(ctx, base);
	// lwz r29,4(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8211976c
	if (ctx.cr6.eq) goto loc_8211976C;
	// addi r27,r29,16
	ctx.r27.s64 = ctx.r29.s64 + 16;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823052d8
	ctx.lr = 0x821196FC;
	sub_823052D8(ctx, base);
	// lbz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82119764
	if (!ctx.cr6.eq) goto loc_82119764;
loc_82119708:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82119774
	if (!ctx.cr6.eq) goto loc_82119774;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// addi r30,r30,4
	ctx.r30.s64 = ctx.r30.s64 + 4;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x82119708
	if (ctx.cr6.lt) goto loc_82119708;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82119728:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82119764
	if (ctx.cr6.eq) goto loc_82119764;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82119748
	if (ctx.cr6.eq) goto loc_82119748;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r10.u32);
loc_82119748:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// bl 0x82119190
	ctx.lr = 0x82119758;
	sub_82119190(ctx, base);
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82119764;
	sub_82080000(ctx, base);
loc_82119764:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x823051a8
	ctx.lr = 0x8211976C;
	sub_823051A8(ctx, base);
loc_8211976C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
loc_82119774:
	// li r11,0
	ctx.r11.s64 = 0;
	// b 0x82119728
	goto loc_82119728;
}

__attribute__((alias("__imp__sub_8211977C"))) PPC_WEAK_FUNC(sub_8211977C);
PPC_FUNC_IMPL(__imp__sub_8211977C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82119780"))) PPC_WEAK_FUNC(sub_82119780);
PPC_FUNC_IMPL(__imp__sub_82119780) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211987c
	if (ctx.cr6.eq) goto loc_8211987C;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r31,r11,3300
	ctx.r31.s64 = ctx.r11.s64 + 3300;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823052d8
	ctx.lr = 0x821197B4;
	sub_823052D8(ctx, base);
	// lwz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r10.u32);
	// stw r30,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r30.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r9,r10,-1
	ctx.r9.s64 = ctx.r10.s64 + -1;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r7,r10,-1
	ctx.r7.s64 = ctx.r10.s64 + -1;
	// stw r7,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r7.u32);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// bne cr6,0x82119870
	if (!ctx.cr6.eq) goto loc_82119870;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82119870
	if (ctx.cr6.eq) goto loc_82119870;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r8,52(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// subf r6,r9,r8
	ctx.r6.s64 = ctx.r8.s64 - ctx.r9.s64;
	// cmpw cr6,r7,r6
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r6.s32, ctx.xer);
	// bge cr6,0x82119870
	if (!ctx.cr6.lt) goto loc_82119870;
	// subf r8,r9,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r9.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// stw r8,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r8.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82119848
	if (ctx.cr6.eq) goto loc_82119848;
loc_82119820:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82119840
	if (ctx.cr6.eq) goto loc_82119840;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82119820
	if (!ctx.cr6.eq) goto loc_82119820;
	// b 0x82119848
	goto loc_82119848;
loc_82119840:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
loc_82119848:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82119860
	if (!ctx.cr6.eq) goto loc_82119860;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r9,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r9.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
loc_82119860:
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8211986C;
	sub_82080000(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
loc_82119870:
	// stw r10,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r10.u32);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x8211987C;
	sub_823051A8(ctx, base);
loc_8211987C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82119894"))) PPC_WEAK_FUNC(sub_82119894);
PPC_FUNC_IMPL(__imp__sub_82119894) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82119898"))) PPC_WEAK_FUNC(sub_82119898);
PPC_FUNC_IMPL(__imp__sub_82119898) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r31,r11,3300
	ctx.r31.s64 = ctx.r11.s64 + 3300;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823052d8
	ctx.lr = 0x821198C0;
	sub_823052D8(ctx, base);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821198e4
	if (ctx.cr6.eq) goto loc_821198E4;
loc_821198CC:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82119914
	if (!ctx.cr6.eq) goto loc_82119914;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821198cc
	if (!ctx.cr6.eq) goto loc_821198CC;
loc_821198E4:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211993c
	if (!ctx.cr6.eq) goto loc_8211993C;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82119bb0
	ctx.lr = 0x821198F8;
	sub_82119BB0(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211993c
	if (!ctx.cr6.eq) goto loc_8211993C;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x8211990C;
	sub_823051A8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82119980
	goto loc_82119980;
loc_82119914:
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// lwz r30,4(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x82119970
	goto loc_82119970;
loc_8211993C:
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// addi r10,r11,40
	ctx.r10.s64 = ctx.r11.s64 + 40;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
	// lwz r9,40(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// addi r11,r10,24
	ctx.r11.s64 = ctx.r10.s64 + 24;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stw r8,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r8.u32);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
loc_82119970:
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x8211997C;
	sub_823051A8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_82119980:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82119998"))) PPC_WEAK_FUNC(sub_82119998);
PPC_FUNC_IMPL(__imp__sub_82119998) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82119a94
	if (ctx.cr6.eq) goto loc_82119A94;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r31,r11,3356
	ctx.r31.s64 = ctx.r11.s64 + 3356;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823052d8
	ctx.lr = 0x821199CC;
	sub_823052D8(ctx, base);
	// lwz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r10.u32);
	// stw r30,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r30.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r9,r10,-1
	ctx.r9.s64 = ctx.r10.s64 + -1;
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r7,r10,-1
	ctx.r7.s64 = ctx.r10.s64 + -1;
	// stw r7,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r7.u32);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// bne cr6,0x82119a88
	if (!ctx.cr6.eq) goto loc_82119A88;
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82119a88
	if (ctx.cr6.eq) goto loc_82119A88;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// lwz r8,52(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// subf r6,r9,r8
	ctx.r6.s64 = ctx.r8.s64 - ctx.r9.s64;
	// cmpw cr6,r7,r6
	ctx.cr6.compare<int32_t>(ctx.r7.s32, ctx.r6.s32, ctx.xer);
	// bge cr6,0x82119a88
	if (!ctx.cr6.lt) goto loc_82119A88;
	// subf r8,r9,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r9.s64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// stw r8,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r8.u32);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82119a60
	if (ctx.cr6.eq) goto loc_82119A60;
loc_82119A38:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82119a58
	if (ctx.cr6.eq) goto loc_82119A58;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82119a38
	if (!ctx.cr6.eq) goto loc_82119A38;
	// b 0x82119a60
	goto loc_82119A60;
loc_82119A58:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
loc_82119A60:
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82119a78
	if (!ctx.cr6.eq) goto loc_82119A78;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r9,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r9.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
loc_82119A78:
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82119A84;
	sub_82080000(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
loc_82119A88:
	// stw r10,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r10.u32);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x82119A94;
	sub_823051A8(ctx, base);
loc_82119A94:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82119AAC"))) PPC_WEAK_FUNC(sub_82119AAC);
PPC_FUNC_IMPL(__imp__sub_82119AAC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82119AB0"))) PPC_WEAK_FUNC(sub_82119AB0);
PPC_FUNC_IMPL(__imp__sub_82119AB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// li r4,-1
	ctx.r4.s64 = -1;
	// addi r31,r11,3356
	ctx.r31.s64 = ctx.r11.s64 + 3356;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823052d8
	ctx.lr = 0x82119AD8;
	sub_823052D8(ctx, base);
	// lwz r11,20(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82119afc
	if (ctx.cr6.eq) goto loc_82119AFC;
loc_82119AE4:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82119b2c
	if (!ctx.cr6.eq) goto loc_82119B2C;
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82119ae4
	if (!ctx.cr6.eq) goto loc_82119AE4;
loc_82119AFC:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82119b54
	if (!ctx.cr6.eq) goto loc_82119B54;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x82119c60
	ctx.lr = 0x82119B10;
	sub_82119C60(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82119b54
	if (!ctx.cr6.eq) goto loc_82119B54;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x82119B24;
	sub_823051A8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82119b98
	goto loc_82119B98;
loc_82119B2C:
	// stw r11,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r11.u32);
	// lwz r30,4(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// b 0x82119b88
	goto loc_82119B88;
loc_82119B54:
	// addi r10,r11,-1
	ctx.r10.s64 = ctx.r11.s64 + -1;
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// stw r10,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r10.u32);
	// addi r10,r11,40
	ctx.r10.s64 = ctx.r11.s64 + 40;
	// mr r30,r11
	ctx.r30.u64 = ctx.r11.u64;
	// lwz r9,40(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 40);
	// addi r11,r10,24
	ctx.r11.s64 = ctx.r10.s64 + 24;
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stw r8,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r8.u32);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// addi r11,r10,1
	ctx.r11.s64 = ctx.r10.s64 + 1;
loc_82119B88:
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x823051a8
	ctx.lr = 0x82119B94;
	sub_823051A8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
loc_82119B98:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82119BB0"))) PPC_WEAK_FUNC(sub_82119BB0);
PPC_FUNC_IMPL(__imp__sub_82119BB0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r11,r3,6,0,25
	ctx.r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0xFFFFFFC0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r11,32
	ctx.r3.s64 = ctx.r11.s64 + 32;
	// bl 0x82082030
	ctx.lr = 0x82119BDC;
	sub_82082030(ctx, base);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r11,r11,3300
	ctx.r11.s64 = ctx.r11.s64 + 3300;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82119bf8
	if (ctx.cr6.eq) goto loc_82119BF8;
	// stw r3,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r3.u32);
	// b 0x82119bfc
	goto loc_82119BFC;
loc_82119BF8:
	// stw r3,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r3.u32);
loc_82119BFC:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// addi r9,r3,32
	ctx.r9.s64 = ctx.r3.s64 + 32;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// stw r3,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r3.u32);
	// stw r3,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r3.u32);
	// stw r31,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r31.u32);
	// beq cr6,0x82119c3c
	if (ctx.cr6.eq) goto loc_82119C3C;
	// addi r10,r9,-24
	ctx.r10.s64 = ctx.r9.s64 + -24;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
loc_82119C34:
	// stwu r3,64(r10)
	ea = 64 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x82119c34
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82119C34;
loc_82119C3C:
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// stw r10,52(r11)
	PPC_STORE_U32(ctx.r11.u32 + 52, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82119C5C"))) PPC_WEAK_FUNC(sub_82119C5C);
PPC_FUNC_IMPL(__imp__sub_82119C5C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82119C60"))) PPC_WEAK_FUNC(sub_82119C60);
PPC_FUNC_IMPL(__imp__sub_82119C60) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r11,r3,6,0,25
	ctx.r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0xFFFFFFC0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r11,32
	ctx.r3.s64 = ctx.r11.s64 + 32;
	// bl 0x82082030
	ctx.lr = 0x82119C8C;
	sub_82082030(ctx, base);
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// addi r11,r11,3356
	ctx.r11.s64 = ctx.r11.s64 + 3356;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82119ca8
	if (ctx.cr6.eq) goto loc_82119CA8;
	// stw r3,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r3.u32);
	// b 0x82119cac
	goto loc_82119CAC;
loc_82119CA8:
	// stw r3,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r3.u32);
loc_82119CAC:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r31,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r31.u32);
	// addi r9,r3,32
	ctx.r9.s64 = ctx.r3.s64 + 32;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r9.u32);
	// stw r3,16(r11)
	PPC_STORE_U32(ctx.r11.u32 + 16, ctx.r3.u32);
	// stw r3,20(r11)
	PPC_STORE_U32(ctx.r11.u32 + 20, ctx.r3.u32);
	// stw r31,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r31.u32);
	// beq cr6,0x82119cec
	if (ctx.cr6.eq) goto loc_82119CEC;
	// addi r10,r9,-24
	ctx.r10.s64 = ctx.r9.s64 + -24;
	// mtctr r31
	ctx.ctr.u64 = ctx.r31.u64;
loc_82119CE4:
	// stwu r3,64(r10)
	ea = 64 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x82119ce4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82119CE4;
loc_82119CEC:
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 52);
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + ctx.r31.u64;
	// stw r10,52(r11)
	PPC_STORE_U32(ctx.r11.u32 + 52, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82119D0C"))) PPC_WEAK_FUNC(sub_82119D0C);
PPC_FUNC_IMPL(__imp__sub_82119D0C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82119D10"))) PPC_WEAK_FUNC(sub_82119D10);
PPC_FUNC_IMPL(__imp__sub_82119D10) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r5,1
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 1, ctx.xer);
	// bne cr6,0x82119d3c
	if (!ctx.cr6.eq) goto loc_82119D3C;
	// lwz r11,32(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// ld r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// add r4,r11,r4
	ctx.r4.u64 = ctx.r11.u64 + ctx.r4.u64;
loc_82119D3C:
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// cmpld cr6,r4,r11
	ctx.cr6.compare<uint64_t>(ctx.r4.u64, ctx.r11.u64, ctx.xer);
	// ble cr6,0x82119d60
	if (!ctx.cr6.gt) goto loc_82119D60;
	// lhz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 36);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// bne cr6,0x82119d60
	if (!ctx.cr6.eq) goto loc_82119D60;
	// cmpldi cr6,r11,0
	ctx.cr6.compare<uint64_t>(ctx.r11.u64, 0, ctx.xer);
	// beq cr6,0x82119d60
	if (ctx.cr6.eq) goto loc_82119D60;
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
loc_82119D60:
	// ld r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// cmpld cr6,r4,r11
	ctx.cr6.compare<uint64_t>(ctx.r4.u64, ctx.r11.u64, ctx.xer);
	// blt cr6,0x82119d90
	if (ctx.cr6.lt) goto loc_82119D90;
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + ctx.r11.u64;
	// cmpld cr6,r4,r10
	ctx.cr6.compare<uint64_t>(ctx.r4.u64, ctx.r10.u64, ctx.xer);
	// bge cr6,0x82119d90
	if (!ctx.cr6.lt) goto loc_82119D90;
	// rotlwi r11,r11,0
	ctx.r11.u64 = rotl32(ctx.r11.u32, 0);
	// rotlwi r10,r4,0
	ctx.r10.u64 = rotl32(ctx.r4.u32, 0);
	// subf r9,r11,r10
	ctx.r9.s64 = ctx.r10.s64 - ctx.r11.s64;
	// stw r9,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r9.u32);
	// b 0x82119da4
	goto loc_82119DA4;
loc_82119D90:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82119DA4;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
loc_82119DA4:
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82119DC4"))) PPC_WEAK_FUNC(sub_82119DC4);
PPC_FUNC_IMPL(__imp__sub_82119DC4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82119DC8"))) PPC_WEAK_FUNC(sub_82119DC8);
PPC_FUNC_IMPL(__imp__sub_82119DC8) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r10,0
	ctx.r10.s64 = 0;
	// ld r9,24(r4)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r4.u32 + 24);
	// lwz r8,0(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// tdllei r11,0
	if (ctx.r11.u64 <= 0) __builtin_debugtrap();
	// divdu r7,r9,r11
	ctx.r7.u64 = ctx.r9.u64 / ctx.r11.u64;
	// mulld r6,r7,r11
	ctx.r6.s64 = ctx.r7.s64 * ctx.r11.s64;
	// subf r5,r6,r9
	ctx.r5.s64 = ctx.r9.s64 - ctx.r6.s64;
	// rlwinm r9,r5,2,0,29
	ctx.r9.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r8
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
loc_82119DF8:
	// cmplw cr6,r11,r4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x82119e14
	if (ctx.cr6.eq) goto loc_82119E14;
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82119df8
	if (!ctx.cr6.eq) goto loc_82119DF8;
	// blr 
	return;
loc_82119E14:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// lwz r11,16(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82119e3c
	if (ctx.cr6.eq) goto loc_82119E3C;
	// stw r11,16(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16, ctx.r11.u32);
	// lwz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r11.u32);
	// blr 
	return;
loc_82119E3C:
	// stwx r11,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, ctx.r11.u32);
	// lwz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82119E50"))) PPC_WEAK_FUNC(sub_82119E50);
PPC_FUNC_IMPL(__imp__sub_82119E50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82119E58;
	__restfpr_26(ctx, base);
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lhz r26,4(r4)
	ctx.r26.u64 = PPC_LOAD_U16(ctx.r4.u32 + 4);
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// bl 0x8208d070
	ctx.lr = 0x82119E7C;
	sub_8208D070(ctx, base);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r26,6
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 6, ctx.xer);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bgt cr6,0x82119ec4
	if (ctx.cr6.gt) goto loc_82119EC4;
	// addi r4,r31,56
	ctx.r4.s64 = ctx.r31.s64 + 56;
	// li r5,12
	ctx.r5.s64 = 12;
	// bl 0x8208cfb0
	ctx.lr = 0x82119E98;
	sub_8208CFB0(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208d070
	ctx.lr = 0x82119EA0;
	sub_8208D070(ctx, base);
	// stw r3,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r3.u32);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// stfs f0,68(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 68, temp.u32);
	// bl 0x8208d070
	ctx.lr = 0x82119EB4;
	sub_8208D070(ctx, base);
	// addic r11,r3,-1
	ctx.xer.ca = ctx.r3.u32 > 0;
	ctx.r11.s64 = ctx.r3.s64 + -1;
	// subfe r10,r11,r3
	temp.u8 = (~ctx.r11.u32 + ctx.r3.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r3.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r10.u64 = ~ctx.r11.u64 + ctx.r3.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// stb r10,52(r31)
	PPC_STORE_U8(ctx.r31.u32 + 52, ctx.r10.u8);
	// b 0x82119f38
	goto loc_82119F38;
loc_82119EC4:
	// bl 0x8208d070
	ctx.lr = 0x82119EC8;
	sub_8208D070(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// clrlwi r9,r3,31
	ctx.r9.u64 = ctx.r3.u32 & 0x1;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// rlwinm r8,r3,30,31,31
	ctx.r8.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 30) & 0x1;
	// stb r9,52(r31)
	PPC_STORE_U8(ctx.r31.u32 + 52, ctx.r9.u8);
	// rlwinm r7,r3,31,31,31
	ctx.r7.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 31) & 0x1;
	// stb r8,53(r31)
	PPC_STORE_U8(ctx.r31.u32 + 53, ctx.r8.u8);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// lfs f31,36(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// beq cr6,0x82119f04
	if (ctx.cr6.eq) goto loc_82119F04;
	// addi r4,r31,56
	ctx.r4.s64 = ctx.r31.s64 + 56;
	// li r5,12
	ctx.r5.s64 = 12;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82119F00;
	sub_8208CFB0(ctx, base);
	// b 0x82119f10
	goto loc_82119F10;
loc_82119F04:
	// stfs f31,56(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 56, temp.u32);
	// stfs f31,60(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 60, temp.u32);
	// stfs f31,64(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 64, temp.u32);
loc_82119F10:
	// lbz r11,53(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 53);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82119f34
	if (ctx.cr6.eq) goto loc_82119F34;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208d070
	ctx.lr = 0x82119F24;
	sub_8208D070(ctx, base);
	// stw r3,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r3.u32);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,68(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 68, temp.u32);
	// b 0x82119f38
	goto loc_82119F38;
loc_82119F34:
	// stfs f31,68(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 68, temp.u32);
loc_82119F38:
	// cmplwi cr6,r29,1
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 1, ctx.xer);
	// stw r29,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r29.u32);
	// beq cr6,0x82119fc0
	if (ctx.cr6.eq) goto loc_82119FC0;
	// cmplwi cr6,r29,2
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 2, ctx.xer);
	// beq cr6,0x82119fac
	if (ctx.cr6.eq) goto loc_82119FAC;
	// li r5,40
	ctx.r5.s64 = 40;
	// addi r4,r31,12
	ctx.r4.s64 = ctx.r31.s64 + 12;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82119F5C;
	sub_8208CFB0(ctx, base);
	// li r5,12
	ctx.r5.s64 = 12;
	// addi r4,r31,84
	ctx.r4.s64 = ctx.r31.s64 + 84;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82119F6C;
	sub_8208CFB0(ctx, base);
	// lis r10,6184
	ctx.r10.s64 = 405274624;
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// ori r9,r10,390
	ctx.r9.u64 = ctx.r10.u64 | 390;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// beq cr6,0x82119fa4
	if (ctx.cr6.eq) goto loc_82119FA4;
	// lis r10,6184
	ctx.r10.s64 = 405274624;
	// ori r9,r10,32646
	ctx.r9.u64 = ctx.r10.u64 | 32646;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// beq cr6,0x82119fa4
	if (ctx.cr6.eq) goto loc_82119FA4;
	// lis r10,6688
	ctx.r10.s64 = 438304768;
	// ori r9,r10,32690
	ctx.r9.u64 = ctx.r10.u64 | 32690;
	// cmpw cr6,r11,r9
	ctx.cr6.compare<int32_t>(ctx.r11.s32, ctx.r9.s32, ctx.xer);
	// li r11,0
	ctx.r11.s64 = 0;
	// bne cr6,0x82119fe4
	if (!ctx.cr6.eq) goto loc_82119FE4;
loc_82119FA4:
	// li r11,1
	ctx.r11.s64 = 1;
	// b 0x82119fe4
	goto loc_82119FE4;
loc_82119FAC:
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8211a3c0
	ctx.lr = 0x82119FBC;
	sub_8211A3C0(ctx, base);
	// b 0x82119fe8
	goto loc_82119FE8;
loc_82119FC0:
	// li r5,32
	ctx.r5.s64 = 32;
	// addi r4,r31,12
	ctx.r4.s64 = ctx.r31.s64 + 12;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82119FD0;
	sub_8208CFB0(ctx, base);
	// li r5,12
	ctx.r5.s64 = 12;
	// addi r4,r31,84
	ctx.r4.s64 = ctx.r31.s64 + 84;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x82119FE0;
	sub_8208CFB0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
loc_82119FE4:
	// stb r11,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r11.u8);
loc_82119FE8:
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x8211a03c
	if (ctx.cr6.eq) goto loc_8211A03C;
	// ld r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r30.u32 + 16);
	// clrlwi r9,r27,24
	ctx.r9.u64 = ctx.r27.u32 & 0xFF;
	// lwz r11,32(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// li r6,0
	ctx.r6.s64 = 0;
	// rotlwi r10,r10,0
	ctx.r10.u64 = rotl32(ctx.r10.u32, 0);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// add r8,r10,r11
	ctx.r8.u64 = ctx.r10.u64 + ctx.r11.u64;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// subf r7,r28,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r28.s64;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// stw r7,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r7.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// beq cr6,0x8211a038
	if (ctx.cr6.eq) goto loc_8211A038;
	// bl 0x8211a208
	ctx.lr = 0x8211A02C;
	sub_8211A208(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_8211A038:
	// bl 0x8211a048
	ctx.lr = 0x8211A03C;
	sub_8211A048(ctx, base);
loc_8211A03C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211A048"))) PPC_WEAK_FUNC(sub_8211A048);
PPC_FUNC_IMPL(__imp__sub_8211A048) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x8211A050;
	__restfpr_24(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x8211a200
	if (ctx.cr6.eq) goto loc_8211A200;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,52
	ctx.r3.s64 = 52;
	// bne cr6,0x8211a0d4
	if (!ctx.cr6.eq) goto loc_8211A0D4;
	// bl 0x82082030
	ctx.lr = 0x8211A08C;
	sub_82082030(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// addi r27,r1,128
	ctx.r27.s64 = ctx.r1.s64 + 128;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// addi r26,r1,132
	ctx.r26.s64 = ctx.r1.s64 + 132;
	// lwz r9,36(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// lwz r7,28(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// stw r27,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r27.u32);
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r26.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82298500
	ctx.lr = 0x8211A0CC;
	sub_82298500(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r3.u32);
	// b 0x8211a148
	goto loc_8211A148;
loc_8211A0D4:
	// bl 0x82082030
	ctx.lr = 0x8211A0D8;
	sub_82082030(ctx, base);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r27,44(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// addi r25,r1,128
	ctx.r25.s64 = ctx.r1.s64 + 128;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// addi r24,r1,132
	ctx.r24.s64 = ctx.r1.s64 + 132;
	// lwz r9,36(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// lwz r7,28(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r26,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r26.u32);
	// stw r25,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r25.u32);
	// stw r24,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r24.u32);
	// stw r26,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r26.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r27.u32);
	// bl 0x82298488
	ctx.lr = 0x8211A128;
	sub_82298488(ctx, base);
	// lis r10,6184
	ctx.r10.s64 = 405274624;
	// lwz r9,28(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// stw r3,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r3.u32);
	// ori r8,r10,32646
	ctx.r8.u64 = ctx.r10.u64 | 32646;
	// cmpw cr6,r9,r8
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, ctx.xer);
	// bne cr6,0x8211a148
	if (!ctx.cr6.eq) goto loc_8211A148;
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r11.u8);
loc_8211A148:
	// lwz r10,80(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 80);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r11,72(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r27,4(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// add r9,r11,r29
	ctx.r9.u64 = ctx.r11.u64 + ctx.r29.u64;
	// stw r10,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r10.u32);
	// clrldi r4,r9,32
	ctx.r4.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// bl 0x82119d10
	ctx.lr = 0x8211A16C;
	sub_82119D10(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// lwz r3,76(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// li r4,4096
	ctx.r4.s64 = 4096;
	// bl 0x82082030
	ctx.lr = 0x8211A180;
	sub_82082030(ctx, base);
	// lwz r5,76(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r11,84(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// stw r3,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r3.u32);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// subf r29,r11,r5
	ctx.r29.s64 = ctx.r5.s64 - ctx.r11.s64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// beq cr6,0x8211a1c4
	if (ctx.cr6.eq) goto loc_8211A1C4;
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x8211A1A8;
	sub_8208CFB0(ctx, base);
	// lwz r10,96(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// lwz r11,84(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r4,96(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 96);
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + ctx.r11.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x8211A1C0;
	sub_8233E4E0(ctx, base);
	// b 0x8211a1c8
	goto loc_8211A1C8;
loc_8211A1C4:
	// bl 0x8208cfb0
	ctx.lr = 0x8211A1C8;
	sub_8208CFB0(ctx, base);
loc_8211A1C8:
	// lwz r10,76(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r4,96(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// cmpwi cr6,r10,0
	ctx.cr6.compare<int32_t>(ctx.r10.s32, 0, ctx.xer);
	// ble cr6,0x8211a1f8
	if (!ctx.cr6.gt) goto loc_8211A1F8;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rlwinm r10,r10,25,7,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x1FFFFFF;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_8211A1EC:
	// dcbf r11,r4
	// addi r11,r11,128
	ctx.r11.s64 = ctx.r11.s64 + 128;
	// bdnz 0x8211a1ec
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8211A1EC;
loc_8211A1F8:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x822986a8
	ctx.lr = 0x8211A200;
	sub_822986A8(ctx, base);
loc_8211A200:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211A208"))) PPC_WEAK_FUNC(sub_8211A208);
PPC_FUNC_IMPL(__imp__sub_8211A208) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x8211A210;
	__restfpr_24(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// cmpwi cr6,r11,2
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 2, ctx.xer);
	// beq cr6,0x8211a3b4
	if (ctx.cr6.eq) goto loc_8211A3B4;
	// cmpwi cr6,r11,1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 1, ctx.xer);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,52
	ctx.r3.s64 = 52;
	// bne cr6,0x8211a290
	if (!ctx.cr6.eq) goto loc_8211A290;
	// bl 0x82082030
	ctx.lr = 0x8211A24C;
	sub_82082030(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// addi r30,r1,128
	ctx.r30.s64 = ctx.r1.s64 + 128;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// addi r26,r1,132
	ctx.r26.s64 = ctx.r1.s64 + 132;
	// lwz r9,36(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// lwz r7,28(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r4,88(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// lhz r3,92(r31)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r31.u32 + 92);
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r30.u32);
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r26.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r11.u32);
	// bl 0x82298500
	ctx.lr = 0x8211A28C;
	sub_82298500(ctx, base);
	// b 0x8211a2e4
	goto loc_8211A2E4;
loc_8211A290:
	// bl 0x82082030
	ctx.lr = 0x8211A294;
	sub_82082030(ctx, base);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r30,44(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// addi r25,r1,128
	ctx.r25.s64 = ctx.r1.s64 + 128;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// addi r24,r1,132
	ctx.r24.s64 = ctx.r1.s64 + 132;
	// lwz r9,36(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// lwz r7,28(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r5,88(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// lhz r4,94(r31)
	ctx.r4.u64 = PPC_LOAD_U16(ctx.r31.u32 + 94);
	// lhz r3,92(r31)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r31.u32 + 92);
	// stw r26,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r26.u32);
	// stw r25,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r25.u32);
	// stw r24,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r24.u32);
	// stw r26,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r26.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r30.u32);
	// bl 0x82298488
	ctx.lr = 0x8211A2E4;
	sub_82298488(ctx, base);
loc_8211A2E4:
	// lwz r9,84(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// li r8,-1
	ctx.r8.s64 = -1;
	// rotlwi r10,r3,0
	ctx.r10.u64 = rotl32(ctx.r3.u32, 0);
	// stw r3,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r3.u32);
	// subf r7,r9,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r9.s64;
	// lwz r26,4(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// li r6,0
	ctx.r6.s64 = 0;
	// subfic r4,r7,0
	ctx.xer.ca = ctx.r7.u32 <= 0;
	ctx.r4.s64 = 0 - ctx.r7.s64;
	// li r5,-1
	ctx.r5.s64 = -1;
	// subfe r11,r3,r3
	temp.u8 = (~ctx.r3.u32 + ctx.r3.u32 < ~ctx.r3.u32) | (~ctx.r3.u32 + ctx.r3.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r3.u64 + ctx.r3.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// li r4,4096
	ctx.r4.s64 = 4096;
	// and r11,r11,r9
	ctx.r11.u64 = ctx.r11.u64 & ctx.r9.u64;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// stw r11,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r11.u32);
	// subf r30,r9,r11
	ctx.r30.s64 = ctx.r11.s64 - ctx.r9.s64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82082030
	ctx.lr = 0x8211A328;
	sub_82082030(ctx, base);
	// lwz r11,84(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// stw r3,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r3.u32);
	// beq cr6,0x8211a34c
	if (ctx.cr6.eq) goto loc_8211A34C;
	// lwz r10,96(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 96);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// add r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + ctx.r11.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x8211A348;
	sub_8233E4E0(ctx, base);
	// b 0x8211a380
	goto loc_8211A380;
loc_8211A34C:
	// lwz r10,72(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// add r11,r11,r27
	ctx.r11.u64 = ctx.r11.u64 + ctx.r27.u64;
	// clrldi r4,r11,32
	ctx.r4.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// bl 0x82119d10
	ctx.lr = 0x8211A368;
	sub_82119D10(ctx, base);
	// lwz r10,76(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r9,84(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 84);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r4,96(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// subf r5,r9,r10
	ctx.r5.s64 = ctx.r10.s64 - ctx.r9.s64;
	// bl 0x8208cfb0
	ctx.lr = 0x8211A380;
	sub_8208CFB0(ctx, base);
loc_8211A380:
	// lwz r4,96(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// li r11,0
	ctx.r11.s64 = 0;
	// cmpwi cr6,r30,0
	ctx.cr6.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// ble cr6,0x8211a3ac
	if (!ctx.cr6.gt) goto loc_8211A3AC;
	// addi r10,r30,-1
	ctx.r10.s64 = ctx.r30.s64 + -1;
	// rlwinm r10,r10,25,7,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x1FFFFFF;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
loc_8211A3A0:
	// dcbf r11,r4
	// addi r11,r11,128
	ctx.r11.s64 = ctx.r11.s64 + 128;
	// bdnz 0x8211a3a0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8211A3A0;
loc_8211A3AC:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x822986a8
	ctx.lr = 0x8211A3B4;
	sub_822986A8(ctx, base);
loc_8211A3B4:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211A3BC"))) PPC_WEAK_FUNC(sub_8211A3BC);
PPC_FUNC_IMPL(__imp__sub_8211A3BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211A3C0"))) PPC_WEAK_FUNC(sub_8211A3C0);
PPC_FUNC_IMPL(__imp__sub_8211A3C0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x8211A3C8;
	__restfpr_25(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// addi r4,r3,12
	ctx.r4.s64 = ctx.r3.s64 + 12;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// li r5,40
	ctx.r5.s64 = 40;
	// bl 0x8208cfb0
	ctx.lr = 0x8211A3E8;
	sub_8208CFB0(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x82082030
	ctx.lr = 0x8211A3FC;
	sub_82082030(ctx, base);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r28,44(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 44);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// addi r26,r1,128
	ctx.r26.s64 = ctx.r1.s64 + 128;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	// addi r25,r1,132
	ctx.r25.s64 = ctx.r1.s64 + 132;
	// lwz r9,36(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// lwz r7,28(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// lwz r6,24(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r5,20(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// stw r27,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r27.u32);
	// stw r26,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r26.u32);
	// stw r25,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r25.u32);
	// stw r27,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r27.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// bl 0x82298578
	ctx.lr = 0x8211A44C;
	sub_82298578(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r3,80(r31)
	PPC_STORE_U32(ctx.r31.u32 + 80, ctx.r3.u32);
	// stb r10,0(r31)
	PPC_STORE_U8(ctx.r31.u32 + 0, ctx.r10.u8);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r3,76(r31)
	PPC_STORE_U32(ctx.r31.u32 + 76, ctx.r3.u32);
	// li r5,-1
	ctx.r5.s64 = -1;
	// lwz r11,32(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// li r4,4096
	ctx.r4.s64 = 4096;
	// ld r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r30.u32 + 16);
	// rotlwi r10,r9,0
	ctx.r10.u64 = rotl32(ctx.r9.u32, 0);
	// add r8,r10,r11
	ctx.r8.u64 = ctx.r10.u64 + ctx.r11.u64;
	// subf r7,r29,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r29.s64;
	// stw r7,72(r31)
	PPC_STORE_U32(ctx.r31.u32 + 72, ctx.r7.u32);
	// bl 0x82082030
	ctx.lr = 0x8211A484;
	sub_82082030(ctx, base);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r5,76(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// stw r6,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r6.u32);
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// bl 0x8208cfb0
	ctx.lr = 0x8211A49C;
	sub_8208CFB0(ctx, base);
	// lwz r11,76(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// lwz r4,96(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// ble cr6,0x8211a4cc
	if (!ctx.cr6.gt) goto loc_8211A4CC;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// rlwinm r11,r11,25,7,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 25) & 0x1FFFFFF;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
loc_8211A4C0:
	// dcbf r10,r4
	// addi r10,r10,128
	ctx.r10.s64 = ctx.r10.s64 + 128;
	// bdnz 0x8211a4c0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8211A4C0;
loc_8211A4CC:
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// bl 0x822986a8
	ctx.lr = 0x8211A4D4;
	sub_822986A8(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211A4DC"))) PPC_WEAK_FUNC(sub_8211A4DC);
PPC_FUNC_IMPL(__imp__sub_8211A4DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211A4E0"))) PPC_WEAK_FUNC(sub_8211A4E0);
PPC_FUNC_IMPL(__imp__sub_8211A4E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211a514
	if (ctx.cr6.eq) goto loc_8211A514;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8211A514;
	sub_82080000(ctx, base);
loc_8211A514:
	// lwz r31,96(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 96);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8211a540
	if (ctx.cr6.eq) goto loc_8211A540;
	// lwz r11,-4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -4);
	// li r5,4
	ctx.r5.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// clrlwi r4,r11,2
	ctx.r4.u64 = ctx.r11.u32 & 0x3FFFFFFF;
	// bl 0x822472e0
	ctx.lr = 0x8211A534;
	sub_822472E0(ctx, base);
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8211A540;
	sub_82080000(ctx, base);
loc_8211A540:
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,96(r30)
	PPC_STORE_U32(ctx.r30.u32 + 96, ctx.r11.u32);
	// stw r11,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211A564"))) PPC_WEAK_FUNC(sub_8211A564);
PPC_FUNC_IMPL(__imp__sub_8211A564) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211A568"))) PPC_WEAK_FUNC(sub_8211A568);
PPC_FUNC_IMPL(__imp__sub_8211A568) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,4(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x8211a58c
	if (!ctx.cr6.eq) goto loc_8211A58C;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x8211a5e0
	goto loc_8211A5E0;
loc_8211A58C:
	// lwz r11,28(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// rlwinm r10,r11,0,28,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xC;
	// cmplwi cr6,r10,12
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 12, ctx.xer);
	// bne cr6,0x8211a5dc
	if (!ctx.cr6.eq) goto loc_8211A5DC;
	// clrlwi r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211a5dc
	if (ctx.cr6.eq) goto loc_8211A5DC;
	// rlwinm r11,r11,0,30,23
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFF03;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8211A5BC;
	sub_82111400(ctx, base);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// ori r9,r10,252
	ctx.r9.u64 = ctx.r10.u64 | 252;
	// stw r9,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r9.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_8211A5DC:
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
loc_8211A5E0:
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8211A5E8;
	sub_82111400(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211A5FC"))) PPC_WEAK_FUNC(sub_8211A5FC);
PPC_FUNC_IMPL(__imp__sub_8211A5FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211A600"))) PPC_WEAK_FUNC(sub_8211A600);
PPC_FUNC_IMPL(__imp__sub_8211A600) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// clrlwi r9,r3,31
	ctx.r9.u64 = ctx.r3.u32 & 0x1;
	// rlwinm r8,r3,27,28,31
	ctx.r8.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 27) & 0xF;
	// rlwinm r10,r3,23,31,31
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 23) & 0x1;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8211a61c
	if (ctx.cr6.eq) goto loc_8211A61C;
	// li r11,12
	ctx.r11.s64 = 12;
loc_8211A61C:
	// rlwinm r9,r3,0,30,30
	ctx.r9.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8211a640
	if (ctx.cr6.eq) goto loc_8211A640;
	// clrlwi r9,r10,24
	ctx.r9.u64 = ctx.r10.u32 & 0xFF;
	// subfic r7,r9,0
	ctx.xer.ca = ctx.r9.u32 <= 0;
	ctx.r7.s64 = 0 - ctx.r9.s64;
	// subfe r6,r7,r7
	temp.u8 = (~ctx.r7.u32 + ctx.r7.u32 < ~ctx.r7.u32) | (~ctx.r7.u32 + ctx.r7.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r6.u64 = ~ctx.r7.u64 + ctx.r7.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r9,r6,0,0,28
	ctx.r9.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFF8;
	// addi r9,r9,12
	ctx.r9.s64 = ctx.r9.s64 + 12;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
loc_8211A640:
	// rlwinm r9,r3,0,28,28
	ctx.r9.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8211a650
	if (ctx.cr6.eq) goto loc_8211A650;
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
loc_8211A650:
	// rlwinm r9,r3,0,29,29
	ctx.r9.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8211a678
	if (ctx.cr6.eq) goto loc_8211A678;
	// clrlwi r9,r10,24
	ctx.r9.u64 = ctx.r10.u32 & 0xFF;
	// subfic r7,r9,0
	ctx.xer.ca = ctx.r9.u32 <= 0;
	ctx.r7.s64 = 0 - ctx.r9.s64;
	// subfe r6,r7,r7
	temp.u8 = (~ctx.r7.u32 + ctx.r7.u32 < ~ctx.r7.u32) | (~ctx.r7.u32 + ctx.r7.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r6.u64 = ~ctx.r7.u64 + ctx.r7.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r9,r6,0,0,29
	ctx.r9.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r9,r9,0,29,27
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// addi r9,r9,16
	ctx.r9.s64 = ctx.r9.s64 + 16;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
loc_8211A678:
	// rlwinm r9,r3,0,27,27
	ctx.r9.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8211a688
	if (ctx.cr6.eq) goto loc_8211A688;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
loc_8211A688:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// rlwinm r9,r3,0,19,19
	ctx.r9.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x1000;
	// subfic r7,r10,0
	ctx.xer.ca = ctx.r10.u32 <= 0;
	ctx.r7.s64 = 0 - ctx.r10.s64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// subfe r6,r7,r7
	temp.u8 = (~ctx.r7.u32 + ctx.r7.u32 < ~ctx.r7.u32) | (~ctx.r7.u32 + ctx.r7.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r6.u64 = ~ctx.r7.u64 + ctx.r7.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r9,r6,0,0,29
	ctx.r9.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFC;
	// addi r5,r9,8
	ctx.r5.s64 = ctx.r9.s64 + 8;
	// mullw r9,r5,r8
	ctx.r9.s64 = int64_t(ctx.r5.s32) * int64_t(ctx.r8.s32);
	// add r3,r9,r11
	ctx.r3.u64 = ctx.r9.u64 + ctx.r11.u64;
	// beqlr cr6
	if (ctx.cr6.eq) return;
	// subfic r11,r10,0
	ctx.xer.ca = ctx.r10.u32 <= 0;
	ctx.r11.s64 = 0 - ctx.r10.s64;
	// subfe r10,r11,r11
	temp.u8 = (~ctx.r11.u32 + ctx.r11.u32 < ~ctx.r11.u32) | (~ctx.r11.u32 + ctx.r11.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r10.u64 = ~ctx.r11.u64 + ctx.r11.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r10,0,0,29
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r11,r11,0,29,27
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// addi r11,r11,20
	ctx.r11.s64 = ctx.r11.s64 + 20;
	// add r3,r11,r3
	ctx.r3.u64 = ctx.r11.u64 + ctx.r3.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211A6CC"))) PPC_WEAK_FUNC(sub_8211A6CC);
PPC_FUNC_IMPL(__imp__sub_8211A6CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211A6D0"))) PPC_WEAK_FUNC(sub_8211A6D0);
PPC_FUNC_IMPL(__imp__sub_8211A6D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e444
	ctx.lr = 0x8211A6D8;
	__restfpr_19(ctx, base);
	// stwu r1,-512(r1)
	ea = -512 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r28,r5
	ctx.r28.u64 = ctx.r5.u64;
	// mr r31,r6
	ctx.r31.u64 = ctx.r6.u64;
	// rlwinm r26,r3,27,28,31
	ctx.r26.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 27) & 0xF;
	// rlwinm r27,r3,23,31,31
	ctx.r27.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 23) & 0x1;
	// bl 0x8211a600
	ctx.lr = 0x8211A6F4;
	sub_8211A600(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// clrlwi r25,r30,31
	ctx.r25.u64 = ctx.r30.u32 & 0x1;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// rlwinm r24,r30,0,30,30
	ctx.r24.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 0) & 0x2;
	// rlwinm r23,r30,0,28,28
	ctx.r23.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 0) & 0x8;
	// rlwinm r22,r30,0,29,29
	ctx.r22.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 0) & 0x4;
	// rlwinm r21,r30,0,27,27
	ctx.r21.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 0) & 0x10;
	// rlwinm r20,r30,0,19,19
	ctx.r20.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 0) & 0x1000;
	// lfs f0,596(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 596);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,244(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 244);
	ctx.f12.f64 = double(temp.f32);
	// li r30,0
	ctx.r30.s64 = 0;
	// lfs f13,180(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// addi r6,r28,12
	ctx.r6.s64 = ctx.r28.s64 + 12;
	// lfs f11,176(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 176);
	ctx.f11.f64 = double(temp.f32);
loc_8211A72C:
	// lhz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r31.u32 + 0);
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// mullw r9,r10,r3
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r3.s32);
	// rlwinm r11,r9,30,2,31
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
	// beq cr6,0x8211a784
	if (ctx.cr6.eq) goto loc_8211A784;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r11,2
	ctx.r9.s64 = ctx.r11.s64 + 2;
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// lfs f10,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// stfs f10,104(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lwz r5,104(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// stfs f8,108(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lwz r10,108(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// lfsx f9,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,112(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lwz r7,112(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r7,-4(r6)
	PPC_STORE_U32(ctx.r6.u32 + -4, ctx.r7.u32);
	// stw r10,-8(r6)
	PPC_STORE_U32(ctx.r6.u32 + -8, ctx.r10.u32);
	// stw r5,-12(r6)
	PPC_STORE_U32(ctx.r6.u32 + -12, ctx.r5.u32);
loc_8211A784:
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x8211a884
	if (ctx.cr6.eq) goto loc_8211A884;
	// clrlwi r10,r27,24
	ctx.r10.u64 = ctx.r27.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// beq cr6,0x8211a844
	if (ctx.cr6.eq) goto loc_8211A844;
	// lwzx r10,r10,r4
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// rlwinm r8,r10,0,21,21
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400;
	// clrlwi r9,r10,21
	ctx.r9.u64 = ctx.r10.u32 & 0x7FF;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// beq cr6,0x8211a7b8
	if (ctx.cr6.eq) goto loc_8211A7B8;
	// clrlwi r9,r9,22
	ctx.r9.u64 = ctx.r9.u32 & 0x3FF;
	// addi r9,r9,-1024
	ctx.r9.s64 = ctx.r9.s64 + -1024;
loc_8211A7B8:
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// rlwinm r8,r10,21,21,21
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 21) & 0x400;
	// std r9,328(r1)
	PPC_STORE_U64(ctx.r1.u32 + 328, ctx.r9.u64);
	// lfd f10,328(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 328);
	// fcfid f9,f10
	ctx.f9.f64 = double(ctx.f10.s64);
	// rlwinm r9,r10,21,21,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 21) & 0x7FF;
	// frsp f8,f9
	ctx.f8.f64 = double(float(ctx.f9.f64));
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// fmuls f7,f8,f11
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// stfs f7,0(r6)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// beq cr6,0x8211a7ec
	if (ctx.cr6.eq) goto loc_8211A7EC;
	// clrlwi r9,r9,22
	ctx.r9.u64 = ctx.r9.u32 & 0x3FF;
	// addi r9,r9,-1024
	ctx.r9.s64 = ctx.r9.s64 + -1024;
loc_8211A7EC:
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// rlwinm r8,r10,10,22,22
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x200;
	// std r9,288(r1)
	PPC_STORE_U64(ctx.r1.u32 + 288, ctx.r9.u64);
	// rlwinm r10,r10,10,22,31
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x3FF;
	// cmpwi cr6,r8,0
	ctx.cr6.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// lfd f10,288(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 288);
	// fcfid f9,f10
	ctx.f9.f64 = double(ctx.f10.s64);
	// frsp f8,f9
	ctx.f8.f64 = double(float(ctx.f9.f64));
	// fmuls f7,f8,f11
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// stfs f7,4(r6)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r6.u32 + 4, temp.u32);
	// beq cr6,0x8211a820
	if (ctx.cr6.eq) goto loc_8211A820;
	// clrlwi r10,r10,23
	ctx.r10.u64 = ctx.r10.u32 & 0x1FF;
	// addi r10,r10,-512
	ctx.r10.s64 = ctx.r10.s64 + -512;
loc_8211A820:
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// std r10,304(r1)
	PPC_STORE_U64(ctx.r1.u32 + 304, ctx.r10.u64);
	// lfd f10,304(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 304);
	// fcfid f9,f10
	ctx.f9.f64 = double(ctx.f10.s64);
	// frsp f8,f9
	ctx.f8.f64 = double(float(ctx.f9.f64));
	// fmuls f7,f8,f13
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// stfs f7,8(r6)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r6.u32 + 8, temp.u32);
	// b 0x8211a884
	goto loc_8211A884;
loc_8211A844:
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// addi r9,r11,2
	ctx.r9.s64 = ctx.r11.s64 + 2;
	// addi r11,r11,3
	ctx.r11.s64 = ctx.r11.s64 + 3;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f10,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// stfs f10,120(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lwz r5,120(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// stfs f8,124(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lwz r10,124(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lfsx f9,r8,r4
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,128(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lwz r7,128(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// stw r7,8(r6)
	PPC_STORE_U32(ctx.r6.u32 + 8, ctx.r7.u32);
	// stw r10,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r10.u32);
	// stw r5,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r5.u32);
loc_8211A884:
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x8211a8f0
	if (ctx.cr6.eq) goto loc_8211A8F0;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// addi r8,r11,2
	ctx.r8.s64 = ctx.r11.s64 + 2;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// rlwinm r5,r8,2,0,29
	ctx.r5.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// addi r8,r6,12
	ctx.r8.s64 = ctx.r6.s64 + 12;
	// lfsx f9,r7,r4
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f9.f64 = double(temp.f32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// lfs f10,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// stfs f9,156(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// stfs f10,144(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f8,148(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f7,152(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lwz r7,8(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r5,4(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r9,12(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// stw r7,20(r6)
	PPC_STORE_U32(ctx.r6.u32 + 20, ctx.r7.u32);
	// stw r5,16(r6)
	PPC_STORE_U32(ctx.r6.u32 + 16, ctx.r5.u32);
	// stw r10,12(r6)
	PPC_STORE_U32(ctx.r6.u32 + 12, ctx.r10.u32);
	// stw r9,24(r6)
	PPC_STORE_U32(ctx.r6.u32 + 24, ctx.r9.u32);
loc_8211A8F0:
	// cmplwi cr6,r22,0
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, 0, ctx.xer);
	// beq cr6,0x8211aa04
	if (ctx.cr6.eq) goto loc_8211AA04;
	// clrlwi r10,r27,24
	ctx.r10.u64 = ctx.r27.u32 & 0xFF;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// beq cr6,0x8211a9a4
	if (ctx.cr6.eq) goto loc_8211A9A4;
	// lwzx r7,r10,r4
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// addi r8,r6,28
	ctx.r8.s64 = ctx.r6.s64 + 28;
	// addi r9,r1,160
	ctx.r9.s64 = ctx.r1.s64 + 160;
	// rlwinm r8,r7,20,26,31
	ctx.r8.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 20) & 0x3F;
	// rlwinm r5,r7,10,22,31
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 10) & 0x3FF;
	// std r8,336(r1)
	PPC_STORE_U64(ctx.r1.u32 + 336, ctx.r8.u64);
	// lfd f8,336(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 336);
	// std r5,352(r1)
	PPC_STORE_U64(ctx.r1.u32 + 352, ctx.r5.u64);
	// clrlwi r5,r7,30
	ctx.r5.u64 = ctx.r7.u32 & 0x3;
	// rlwinm r10,r7,30,22,31
	ctx.r10.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 30) & 0x3FF;
	// std r5,368(r1)
	PPC_STORE_U64(ctx.r1.u32 + 368, ctx.r5.u64);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// std r10,320(r1)
	PPC_STORE_U64(ctx.r1.u32 + 320, ctx.r10.u64);
	// lfd f10,320(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 320);
	// fcfid f9,f10
	ctx.f9.f64 = double(ctx.f10.s64);
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// lfd f6,352(r1)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 352);
	// fcfid f5,f8
	ctx.f5.f64 = double(ctx.f8.s64);
	// fcfid f4,f6
	ctx.f4.f64 = double(ctx.f6.s64);
	// lfd f3,368(r1)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r1.u32 + 368);
	// frsp f7,f9
	ctx.f7.f64 = double(float(ctx.f9.f64));
	// fcfid f2,f3
	ctx.f2.f64 = double(ctx.f3.s64);
	// frsp f10,f5
	ctx.f10.f64 = double(float(ctx.f5.f64));
	// frsp f9,f4
	ctx.f9.f64 = double(float(ctx.f4.f64));
	// fmuls f1,f7,f13
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f13.f64));
	// stfs f1,168(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// frsp f8,f2
	ctx.f8.f64 = double(float(ctx.f2.f64));
	// stfs f8,172(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fmuls f7,f10,f13
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// stfs f7,164(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fmuls f6,f9,f13
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// stfs f6,160(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lwz r5,8(r9)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lwz r7,12(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// stw r8,32(r6)
	PPC_STORE_U32(ctx.r6.u32 + 32, ctx.r8.u32);
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r5,36(r6)
	PPC_STORE_U32(ctx.r6.u32 + 36, ctx.r5.u32);
	// b 0x8211a9fc
	goto loc_8211A9FC;
loc_8211A9A4:
	// addi r9,r11,2
	ctx.r9.s64 = ctx.r11.s64 + 2;
	// addi r7,r11,3
	ctx.r7.s64 = ctx.r11.s64 + 3;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r7,2,0,29
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// addi r7,r6,28
	ctx.r7.s64 = ctx.r6.s64 + 28;
	// lfsx f8,r8,r4
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// lfsx f7,r9,r4
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// stfs f8,184(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// stfs f7,188(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f10,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// stfs f10,176(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// stfs f9,180(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lwz r8,8(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwz r7,12(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// lwz r9,4(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// lwz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// stw r9,32(r6)
	PPC_STORE_U32(ctx.r6.u32 + 32, ctx.r9.u32);
	// stw r8,36(r6)
	PPC_STORE_U32(ctx.r6.u32 + 36, ctx.r8.u32);
loc_8211A9FC:
	// stw r7,40(r6)
	PPC_STORE_U32(ctx.r6.u32 + 40, ctx.r7.u32);
	// stw r10,28(r6)
	PPC_STORE_U32(ctx.r6.u32 + 28, ctx.r10.u32);
loc_8211AA04:
	// cmplwi cr6,r21,0
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, 0, ctx.xer);
	// beq cr6,0x8211aa1c
	if (ctx.cr6.eq) goto loc_8211AA1C;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// lwzx r9,r10,r4
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r9,44(r6)
	PPC_STORE_U32(ctx.r6.u32 + 44, ctx.r9.u32);
loc_8211AA1C:
	// li r7,0
	ctx.r7.s64 = 0;
	// cmpwi cr6,r26,4
	ctx.cr6.compare<int32_t>(ctx.r26.s32, 4, ctx.xer);
	// blt cr6,0x8211ac14
	if (ctx.cr6.lt) goto loc_8211AC14;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// clrlwi r29,r27,24
	ctx.r29.u64 = ctx.r27.u32 & 0xFF;
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// addi r5,r26,-3
	ctx.r5.s64 = ctx.r26.s64 + -3;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
loc_8211AA3C:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8211ab80
	if (ctx.cr6.eq) goto loc_8211AB80;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// addi r8,r11,1
	ctx.r8.s64 = ctx.r11.s64 + 1;
	// add r19,r30,r7
	ctx.r19.u64 = ctx.r30.u64 + ctx.r7.u64;
	// clrlwi r11,r9,16
	ctx.r11.u64 = ctx.r9.u32 & 0xFFFF;
	// rlwinm r9,r9,16,16,31
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0xFFFF;
	// std r11,312(r1)
	PPC_STORE_U64(ctx.r1.u32 + 312, ctx.r11.u64);
	// rlwinm r11,r19,3,0,28
	ctx.r11.u64 = rotl64(ctx.r19.u32 | (ctx.r19.u64 << 32), 3) & 0xFFFFFFF8;
	// std r9,384(r1)
	PPC_STORE_U64(ctx.r1.u32 + 384, ctx.r9.u64);
	// lfd f10,384(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 384);
	// fcfid f9,f10
	ctx.f9.f64 = double(ctx.f10.s64);
	// add r9,r11,r28
	ctx.r9.u64 = ctx.r11.u64 + ctx.r28.u64;
	// lfd f8,312(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 312);
	// frsp f7,f9
	ctx.f7.f64 = double(float(ctx.f9.f64));
	// fcfid f6,f8
	ctx.f6.f64 = double(ctx.f8.s64);
	// addi r11,r10,4
	ctx.r11.s64 = ctx.r10.s64 + 4;
	// fmuls f5,f7,f0
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f0.f64));
	// stfs f5,80(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// frsp f4,f6
	ctx.f4.f64 = double(float(ctx.f6.f64));
	// fmuls f3,f4,f0
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// stfs f3,84(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// ld r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r10,60(r9)
	PPC_STORE_U64(ctx.r9.u32 + 60, ctx.r10.u64);
	// addi r10,r8,1
	ctx.r10.s64 = ctx.r8.s64 + 1;
	// lwz r19,4(r11)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// rlwinm r8,r19,16,16,31
	ctx.r8.u64 = rotl64(ctx.r19.u32 | (ctx.r19.u64 << 32), 16) & 0xFFFF;
	// clrlwi r19,r19,16
	ctx.r19.u64 = ctx.r19.u32 & 0xFFFF;
	// std r8,248(r1)
	PPC_STORE_U64(ctx.r1.u32 + 248, ctx.r8.u64);
	// std r19,376(r1)
	PPC_STORE_U64(ctx.r1.u32 + 376, ctx.r19.u64);
	// lfd f10,248(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 248);
	// lfd f9,376(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 376);
	// fcfid f8,f10
	ctx.f8.f64 = double(ctx.f10.s64);
	// fcfid f7,f9
	ctx.f7.f64 = double(ctx.f9.s64);
	// frsp f6,f8
	ctx.f6.f64 = double(float(ctx.f8.f64));
	// frsp f5,f7
	ctx.f5.f64 = double(float(ctx.f7.f64));
	// fmuls f4,f6,f0
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// stfs f3,84(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// ld r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r8,68(r9)
	PPC_STORE_U64(ctx.r9.u32 + 68, ctx.r8.u64);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// lwz r19,4(r11)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// addi r10,r11,4
	ctx.r10.s64 = ctx.r11.s64 + 4;
	// rlwinm r11,r19,16,16,31
	ctx.r11.u64 = rotl64(ctx.r19.u32 | (ctx.r19.u64 << 32), 16) & 0xFFFF;
	// clrlwi r19,r19,16
	ctx.r19.u64 = ctx.r19.u32 & 0xFFFF;
	// std r11,264(r1)
	PPC_STORE_U64(ctx.r1.u32 + 264, ctx.r11.u64);
	// lfd f10,264(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 264);
	// fcfid f8,f10
	ctx.f8.f64 = double(ctx.f10.s64);
	// std r19,224(r1)
	PPC_STORE_U64(ctx.r1.u32 + 224, ctx.r19.u64);
	// lfd f9,224(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 224);
	// fcfid f7,f9
	ctx.f7.f64 = double(ctx.f9.s64);
	// frsp f6,f8
	ctx.f6.f64 = double(float(ctx.f8.f64));
	// frsp f5,f7
	ctx.f5.f64 = double(float(ctx.f7.f64));
	// fmuls f4,f6,f0
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// stfs f3,84(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// ld r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,76(r9)
	PPC_STORE_U64(ctx.r9.u32 + 76, ctx.r11.u64);
	// addi r11,r8,1
	ctx.r11.s64 = ctx.r8.s64 + 1;
	// lwz r19,4(r10)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// rlwinm r8,r19,16,16,31
	ctx.r8.u64 = rotl64(ctx.r19.u32 | (ctx.r19.u64 << 32), 16) & 0xFFFF;
	// clrlwi r19,r19,16
	ctx.r19.u64 = ctx.r19.u32 & 0xFFFF;
	// std r8,280(r1)
	PPC_STORE_U64(ctx.r1.u32 + 280, ctx.r8.u64);
	// lfd f10,280(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 280);
	// fcfid f8,f10
	ctx.f8.f64 = double(ctx.f10.s64);
	// std r19,360(r1)
	PPC_STORE_U64(ctx.r1.u32 + 360, ctx.r19.u64);
	// lfd f9,360(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 360);
	// fcfid f7,f9
	ctx.f7.f64 = double(ctx.f9.s64);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// frsp f6,f8
	ctx.f6.f64 = double(float(ctx.f8.f64));
	// frsp f5,f7
	ctx.f5.f64 = double(float(ctx.f7.f64));
	// fmuls f4,f6,f0
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// stfs f3,84(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// ld r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// b 0x8211ac04
	goto loc_8211AC04;
loc_8211AB80:
	// lfs f9,4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// add r9,r30,r7
	ctx.r9.u64 = ctx.r30.u64 + ctx.r7.u64;
	// stfs f9,88(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// addi r8,r11,2
	ctx.r8.s64 = ctx.r11.s64 + 2;
	// rlwinm r9,r9,3,0,28
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f10,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,92(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// addi r11,r10,8
	ctx.r11.s64 = ctx.r10.s64 + 8;
	// add r9,r9,r28
	ctx.r9.u64 = ctx.r9.u64 + ctx.r28.u64;
	// ld r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r10,60(r9)
	PPC_STORE_U64(ctx.r9.u32 + 60, ctx.r10.u64);
	// addi r10,r8,2
	ctx.r10.s64 = ctx.r8.s64 + 2;
	// lfs f9,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,88(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// stfs f10,92(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// ld r8,88(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r8,68(r9)
	PPC_STORE_U64(ctx.r9.u32 + 68, ctx.r8.u64);
	// addi r8,r10,2
	ctx.r8.s64 = ctx.r10.s64 + 2;
	// lfs f10,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// addi r10,r11,8
	ctx.r10.s64 = ctx.r11.s64 + 8;
	// lfs f9,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// stfs f10,88(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f9,92(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// ld r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,76(r9)
	PPC_STORE_U64(ctx.r9.u32 + 76, ctx.r11.u64);
	// addi r11,r8,2
	ctx.r11.s64 = ctx.r8.s64 + 2;
	// lfs f10,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// lfsu f9,8(r10)
	ea = 8 + ctx.r10.u32;
	temp.u32 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	ctx.f9.f64 = double(temp.f32);
	// stfs f10,88(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f9,92(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// ld r8,88(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
loc_8211AC04:
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// std r8,84(r9)
	PPC_STORE_U64(ctx.r9.u32 + 84, ctx.r8.u64);
	// cmplw cr6,r7,r5
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r5.u32, ctx.xer);
	// blt cr6,0x8211aa3c
	if (ctx.cr6.lt) goto loc_8211AA3C;
loc_8211AC14:
	// cmplw cr6,r7,r26
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, ctx.r26.u32, ctx.xer);
	// bge cr6,0x8211acc8
	if (!ctx.cr6.lt) goto loc_8211ACC8;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r9,r7,r26
	ctx.r9.s64 = ctx.r26.s64 - ctx.r7.s64;
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// clrlwi r8,r27,24
	ctx.r8.u64 = ctx.r27.u32 & 0xFF;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
loc_8211AC34:
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8211ac98
	if (ctx.cr6.eq) goto loc_8211AC98;
	// lwz r9,4(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// add r5,r30,r7
	ctx.r5.u64 = ctx.r30.u64 + ctx.r7.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// clrlwi r19,r9,16
	ctx.r19.u64 = ctx.r9.u32 & 0xFFFF;
	// rlwinm r29,r9,16,16,31
	ctx.r29.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0xFFFF;
	// std r19,344(r1)
	PPC_STORE_U64(ctx.r1.u32 + 344, ctx.r19.u64);
	// rlwinm r9,r5,3,0,28
	ctx.r9.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 3) & 0xFFFFFFF8;
	// std r29,296(r1)
	PPC_STORE_U64(ctx.r1.u32 + 296, ctx.r29.u64);
	// lfd f10,296(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 296);
	// fcfid f8,f10
	ctx.f8.f64 = double(ctx.f10.s64);
	// add r9,r9,r28
	ctx.r9.u64 = ctx.r9.u64 + ctx.r28.u64;
	// lfd f9,344(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 344);
	// frsp f6,f8
	ctx.f6.f64 = double(float(ctx.f8.f64));
	// fcfid f7,f9
	ctx.f7.f64 = double(ctx.f9.s64);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// fmuls f4,f6,f0
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// stfs f4,80(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// frsp f5,f7
	ctx.f5.f64 = double(float(ctx.f7.f64));
	// fmuls f3,f5,f0
	ctx.f3.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// stfs f3,84(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// ld r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r5,60(r9)
	PPC_STORE_U64(ctx.r9.u32 + 60, ctx.r5.u64);
	// b 0x8211acc0
	goto loc_8211ACC0;
loc_8211AC98:
	// add r9,r30,r7
	ctx.r9.u64 = ctx.r30.u64 + ctx.r7.u64;
	// lfs f10,4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// lfsu f9,8(r10)
	ea = 8 + ctx.r10.u32;
	temp.u32 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	ctx.f9.f64 = double(temp.f32);
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// rlwinm r9,r9,3,0,28
	ctx.r9.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// stfs f9,92(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f10,88(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// add r5,r9,r28
	ctx.r5.u64 = ctx.r9.u64 + ctx.r28.u64;
	// ld r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r9,60(r5)
	PPC_STORE_U64(ctx.r5.u32 + 60, ctx.r9.u64);
loc_8211ACC0:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// bdnz 0x8211ac34
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8211AC34;
loc_8211ACC8:
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x8211adf8
	if (ctx.cr6.eq) goto loc_8211ADF8;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// clrlwi r9,r27,24
	ctx.r9.u64 = ctx.r27.u32 & 0xFF;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// lwzx r8,r10,r4
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	// stw r8,168(r6)
	PPC_STORE_U32(ctx.r6.u32 + 168, ctx.r8.u32);
	// beq cr6,0x8211ad98
	if (ctx.cr6.eq) goto loc_8211AD98;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r6,172
	ctx.r9.s64 = ctx.r6.s64 + 172;
	// addi r10,r1,208
	ctx.r10.s64 = ctx.r1.s64 + 208;
	// lwzx r8,r11,r4
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r4.u32);
	// stw r8,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r8.u32);
	// lbz r5,99(r1)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r1.u32 + 99);
	// lbz r8,96(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 96);
	// lbz r7,98(r1)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r1.u32 + 98);
	// lbz r9,97(r1)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r1.u32 + 97);
	// mr r11,r8
	ctx.r11.u64 = ctx.r8.u64;
	// std r5,232(r1)
	PPC_STORE_U64(ctx.r1.u32 + 232, ctx.r5.u64);
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// std r8,240(r1)
	PPC_STORE_U64(ctx.r1.u32 + 240, ctx.r8.u64);
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
	// std r5,272(r1)
	PPC_STORE_U64(ctx.r1.u32 + 272, ctx.r5.u64);
	// std r9,256(r1)
	PPC_STORE_U64(ctx.r1.u32 + 256, ctx.r9.u64);
	// lfd f10,232(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 232);
	// lfd f9,240(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 240);
	// fcfid f8,f10
	ctx.f8.f64 = double(ctx.f10.s64);
	// lfd f5,272(r1)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 272);
	// fcfid f7,f9
	ctx.f7.f64 = double(ctx.f9.s64);
	// fcfid f3,f5
	ctx.f3.f64 = double(ctx.f5.s64);
	// lfd f6,256(r1)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 256);
	// fcfid f4,f6
	ctx.f4.f64 = double(ctx.f6.s64);
	// frsp f2,f8
	ctx.f2.f64 = double(float(ctx.f8.f64));
	// frsp f1,f7
	ctx.f1.f64 = double(float(ctx.f7.f64));
	// frsp f9,f3
	ctx.f9.f64 = double(float(ctx.f3.f64));
	// frsp f10,f4
	ctx.f10.f64 = double(float(ctx.f4.f64));
	// fmuls f8,f2,f12
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f12.f64));
	// stfs f8,220(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmuls f7,f1,f12
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// stfs f7,208(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fmuls f5,f9,f12
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// stfs f5,216(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// fmuls f6,f10,f12
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// stfs f6,212(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lwz r7,12(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// stw r7,184(r6)
	PPC_STORE_U32(ctx.r6.u32 + 184, ctx.r7.u32);
	// lwz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r9,172(r6)
	PPC_STORE_U32(ctx.r6.u32 + 172, ctx.r9.u32);
	// stw r8,176(r6)
	PPC_STORE_U32(ctx.r6.u32 + 176, ctx.r8.u32);
	// b 0x8211adf0
	goto loc_8211ADF0;
loc_8211AD98:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r11,3
	ctx.r9.s64 = ctx.r11.s64 + 3;
	// addi r8,r11,2
	ctx.r8.s64 = ctx.r11.s64 + 2;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r5,r8,2,0,29
	ctx.r5.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r10,r4
	ctx.r11.u64 = ctx.r10.u64 + ctx.r4.u64;
	// lfsx f10,r10,r4
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r4.u32);
	ctx.f10.f64 = double(temp.f32);
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// stfs f10,192(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// addi r9,r6,172
	ctx.r9.s64 = ctx.r6.s64 + 172;
	// lfsx f8,r7,r4
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r4.u32);
	ctx.f8.f64 = double(temp.f32);
	// lfsx f7,r5,r4
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r4.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfs f9,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,196(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// stfs f8,204(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// stfs f7,200(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// lwz r5,12(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r7,4(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r7,176(r6)
	PPC_STORE_U32(ctx.r6.u32 + 176, ctx.r7.u32);
	// stw r8,172(r6)
	PPC_STORE_U32(ctx.r6.u32 + 172, ctx.r8.u32);
	// stw r5,184(r6)
	PPC_STORE_U32(ctx.r6.u32 + 184, ctx.r5.u32);
loc_8211ADF0:
	// lwz r11,8(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// stw r11,180(r6)
	PPC_STORE_U32(ctx.r6.u32 + 180, ctx.r11.u32);
loc_8211ADF8:
	// addi r30,r30,25
	ctx.r30.s64 = ctx.r30.s64 + 25;
	// addi r31,r31,2
	ctx.r31.s64 = ctx.r31.s64 + 2;
	// addi r6,r6,200
	ctx.r6.s64 = ctx.r6.s64 + 200;
	// cmplwi cr6,r30,100
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 100, ctx.xer);
	// blt cr6,0x8211a72c
	if (ctx.cr6.lt) goto loc_8211A72C;
	// addi r1,r1,512
	ctx.r1.s64 = ctx.r1.s64 + 512;
	// b 0x8233e494
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211AE14"))) PPC_WEAK_FUNC(sub_8211AE14);
PPC_FUNC_IMPL(__imp__sub_8211AE14) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211AE18"))) PPC_WEAK_FUNC(sub_8211AE18);
PPC_FUNC_IMPL(__imp__sub_8211AE18) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8211AE20;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// li r29,4
	ctx.r29.s64 = 4;
	// addi r11,r11,-27864
	ctx.r11.s64 = ctx.r11.s64 + -27864;
	// li r28,0
	ctx.r28.s64 = 0;
	// addi r30,r11,-4
	ctx.r30.s64 = ctx.r11.s64 + -4;
loc_8211AE38:
	// lwz r31,4(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8211ae7c
	if (ctx.cr6.eq) goto loc_8211AE7C;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211ae54
	if (ctx.cr6.eq) goto loc_8211AE54;
	// bl 0x8222f0f8
	ctx.lr = 0x8211AE54;
	sub_8222F0F8(ctx, base);
loc_8211AE54:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211ae64
	if (ctx.cr6.eq) goto loc_8211AE64;
	// bl 0x8222f0f8
	ctx.lr = 0x8211AE64;
	sub_8222F0F8(ctx, base);
loc_8211AE64:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211ae74
	if (ctx.cr6.eq) goto loc_8211AE74;
	// bl 0x8222f0f8
	ctx.lr = 0x8211AE74;
	sub_8222F0F8(ctx, base);
loc_8211AE74:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82116248
	ctx.lr = 0x8211AE7C;
	sub_82116248(ctx, base);
loc_8211AE7C:
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// stwu r28,4(r30)
	ea = 4 + ctx.r30.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r30.u32 = ea;
	// bne 0x8211ae38
	if (!ctx.cr0.eq) goto loc_8211AE38;
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// lwz r3,25608(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25608);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211aea4
	if (ctx.cr6.eq) goto loc_8211AEA4;
	// bl 0x8211af20
	ctx.lr = 0x8211AE9C;
	sub_8211AF20(ctx, base);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// stw r28,25608(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25608, ctx.r28.u32);
loc_8211AEA4:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// lwz r3,25600(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25600);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211aec0
	if (ctx.cr6.eq) goto loc_8211AEC0;
	// bl 0x8211af20
	ctx.lr = 0x8211AEB8;
	sub_8211AF20(ctx, base);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// stw r28,25600(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25600, ctx.r28.u32);
loc_8211AEC0:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// lwz r3,25604(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25604);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211aedc
	if (ctx.cr6.eq) goto loc_8211AEDC;
	// bl 0x8211af20
	ctx.lr = 0x8211AED4;
	sub_8211AF20(ctx, base);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// stw r28,25604(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25604, ctx.r28.u32);
loc_8211AEDC:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// lwz r3,25612(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25612);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211aef8
	if (ctx.cr6.eq) goto loc_8211AEF8;
	// bl 0x8211af20
	ctx.lr = 0x8211AEF0;
	sub_8211AF20(ctx, base);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// stw r28,25612(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25612, ctx.r28.u32);
loc_8211AEF8:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// lwz r3,25616(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25616);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211af14
	if (ctx.cr6.eq) goto loc_8211AF14;
	// bl 0x8211af20
	ctx.lr = 0x8211AF0C;
	sub_8211AF20(ctx, base);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// stw r28,25616(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25616, ctx.r28.u32);
loc_8211AF14:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211AF1C"))) PPC_WEAK_FUNC(sub_8211AF1C);
PPC_FUNC_IMPL(__imp__sub_8211AF1C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211AF20"))) PPC_WEAK_FUNC(sub_8211AF20);
PPC_FUNC_IMPL(__imp__sub_8211AF20) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,4(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211af44
	if (ctx.cr6.eq) goto loc_8211AF44;
	// bl 0x8222f0f8
	ctx.lr = 0x8211AF44;
	sub_8222F0F8(ctx, base);
loc_8211AF44:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211af54
	if (ctx.cr6.eq) goto loc_8211AF54;
	// bl 0x8222f0f8
	ctx.lr = 0x8211AF54;
	sub_8222F0F8(ctx, base);
loc_8211AF54:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211af64
	if (ctx.cr6.eq) goto loc_8211AF64;
	// bl 0x8222f0f8
	ctx.lr = 0x8211AF64;
	sub_8222F0F8(ctx, base);
loc_8211AF64:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82116248
	ctx.lr = 0x8211AF6C;
	sub_82116248(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211AF84"))) PPC_WEAK_FUNC(sub_8211AF84);
PPC_FUNC_IMPL(__imp__sub_8211AF84) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211AF88"))) PPC_WEAK_FUNC(sub_8211AF88);
PPC_FUNC_IMPL(__imp__sub_8211AF88) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x8211AF90;
	__restfpr_29(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,44
	ctx.r11.s64 = 2883584;
	// li r10,5
	ctx.r10.s64 = 5;
	// ori r11,r11,9125
	ctx.r11.u64 = ctx.r11.u64 | 9125;
	// li r29,0
	ctx.r29.s64 = 0;
	// stb r10,133(r1)
	PPC_STORE_U8(ctx.r1.u32 + 133, ctx.r10.u8);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// li r4,3
	ctx.r4.s64 = 3;
	// stb r29,121(r1)
	PPC_STORE_U8(ctx.r1.u32 + 121, ctx.r29.u8);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r11.u32);
	// bl 0x821160a8
	ctx.lr = 0x8211AFC0;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211AFC4;
	sub_82116360(ctx, base);
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r30,r11,7608
	ctx.r30.s64 = ctx.r11.s64 + 7608;
	// beq cr6,0x8211aff8
	if (ctx.cr6.eq) goto loc_8211AFF8;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,6536
	ctx.r6.s64 = ctx.r11.s64 + 6536;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x8211c770
	ctx.lr = 0x8211AFE8;
	sub_8211C770(ctx, base);
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// addi r31,r11,-27864
	ctx.r31.s64 = ctx.r11.s64 + -27864;
	// stw r3,-27864(r11)
	PPC_STORE_U32(ctx.r11.u32 + -27864, ctx.r3.u32);
	// b 0x8211b008
	goto loc_8211B008;
loc_8211AFF8:
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// addi r31,r10,-27864
	ctx.r31.s64 = ctx.r10.s64 + -27864;
	// stw r29,-27864(r10)
	PPC_STORE_U32(ctx.r10.u32 + -27864, ctx.r29.u32);
loc_8211B008:
	// bl 0x82116360
	ctx.lr = 0x8211B00C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211b030
	if (ctx.cr6.eq) goto loc_8211B030;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,7936
	ctx.r6.s64 = ctx.r11.s64 + 7936;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x8211c770
	ctx.lr = 0x8211B028;
	sub_8211C770(ctx, base);
	// stw r3,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r3.u32);
	// b 0x8211b038
	goto loc_8211B038;
loc_8211B030:
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r29.u32);
loc_8211B038:
	// bl 0x82116360
	ctx.lr = 0x8211B03C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211b060
	if (ctx.cr6.eq) goto loc_8211B060;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,9176
	ctx.r6.s64 = ctx.r11.s64 + 9176;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x8211c770
	ctx.lr = 0x8211B058;
	sub_8211C770(ctx, base);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// b 0x8211b068
	goto loc_8211B068;
loc_8211B060:
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r29.u32);
loc_8211B068:
	// bl 0x82116360
	ctx.lr = 0x8211B06C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211b090
	if (ctx.cr6.eq) goto loc_8211B090;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// addi r6,r11,10648
	ctx.r6.s64 = ctx.r11.s64 + 10648;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x8211c770
	ctx.lr = 0x8211B088;
	sub_8211C770(ctx, base);
	// stw r3,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r3.u32);
	// b 0x8211b098
	goto loc_8211B098;
loc_8211B090:
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r29.u32);
loc_8211B098:
	// lis r11,42
	ctx.r11.s64 = 2752512;
	// stb r29,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, ctx.r29.u8);
	// li r4,2
	ctx.r4.s64 = 2;
	// ori r10,r11,9145
	ctx.r10.u64 = ctx.r11.u64 | 9145;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// bl 0x821160a8
	ctx.lr = 0x8211B0B4;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211B0B8;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211b0e4
	if (ctx.cr6.eq) goto loc_8211B0E4;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r6,r11,12400
	ctx.r6.s64 = ctx.r11.s64 + 12400;
	// addi r5,r10,13488
	ctx.r5.s64 = ctx.r10.s64 + 13488;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211B0D8;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25600(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25600, ctx.r3.u32);
	// b 0x8211b0f0
	goto loc_8211B0F0;
loc_8211B0E4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25600(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25600, ctx.r29.u32);
loc_8211B0F0:
	// bl 0x82116360
	ctx.lr = 0x8211B0F4;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211b120
	if (ctx.cr6.eq) goto loc_8211B120;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r6,r11,14136
	ctx.r6.s64 = ctx.r11.s64 + 14136;
	// addi r5,r10,15264
	ctx.r5.s64 = ctx.r10.s64 + 15264;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211B114;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25604(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25604, ctx.r3.u32);
	// b 0x8211b12c
	goto loc_8211B12C;
loc_8211B120:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25604(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25604, ctx.r29.u32);
loc_8211B12C:
	// bl 0x82116360
	ctx.lr = 0x8211B130;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211b15c
	if (ctx.cr6.eq) goto loc_8211B15C;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r6,r11,15912
	ctx.r6.s64 = ctx.r11.s64 + 15912;
	// addi r5,r10,17200
	ctx.r5.s64 = ctx.r10.s64 + 17200;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x8211c770
	ctx.lr = 0x8211B150;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25608(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25608, ctx.r3.u32);
	// b 0x8211b168
	goto loc_8211B168;
loc_8211B15C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25608(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25608, ctx.r29.u32);
loc_8211B168:
	// bl 0x82116360
	ctx.lr = 0x8211B16C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211b198
	if (ctx.cr6.eq) goto loc_8211B198;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r6,r11,17528
	ctx.r6.s64 = ctx.r11.s64 + 17528;
	// addi r5,r10,18688
	ctx.r5.s64 = ctx.r10.s64 + 18688;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211B18C;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25612(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25612, ctx.r3.u32);
	// b 0x8211b1a4
	goto loc_8211B1A4;
loc_8211B198:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25612(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25612, ctx.r29.u32);
loc_8211B1A4:
	// bl 0x82116360
	ctx.lr = 0x8211B1A8;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211b1d8
	if (ctx.cr6.eq) goto loc_8211B1D8;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r6,r11,19336
	ctx.r6.s64 = ctx.r11.s64 + 19336;
	// addi r5,r10,20584
	ctx.r5.s64 = ctx.r10.s64 + 20584;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211B1C8;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25616(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25616, ctx.r3.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
loc_8211B1D8:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25616(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25616, ctx.r29.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211B1EC"))) PPC_WEAK_FUNC(sub_8211B1EC);
PPC_FUNC_IMPL(__imp__sub_8211B1EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211B1F0"))) PPC_WEAK_FUNC(sub_8211B1F0);
PPC_FUNC_IMPL(__imp__sub_8211B1F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8211B1F8;
	__restfpr_27(ctx, base);
	// stfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,20(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// li r27,3
	ctx.r27.s64 = 3;
	// addi r31,r11,16
	ctx.r31.s64 = ctx.r11.s64 + 16;
	// lwz r11,48(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	// clrlwi r30,r11,26
	ctx.r30.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r30,50
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 50, ctx.xer);
	// bne cr6,0x8211b228
	if (!ctx.cr6.eq) goto loc_8211B228;
	// rlwimi r11,r27,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r27.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_8211B228:
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r5,r10,31376
	ctx.r5.s64 = ctx.r10.s64 + 31376;
	// addi r29,r11,27648
	ctx.r29.s64 = ctx.r11.s64 + 27648;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lfs f31,36(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// li r4,20
	ctx.r4.s64 = 20;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82227e30
	ctx.lr = 0x8211B260;
	sub_82227E30(ctx, base);
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// rlwimi r30,r4,0,0,25
	ctx.r30.u64 = (rotl32(ctx.r4.u32, 0) & 0xFFFFFFC0) | (ctx.r30.u64 & 0xFFFFFFFF0000003F);
	// stw r30,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r30.u32);
	// lwz r11,20(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 20);
	// addi r31,r11,224
	ctx.r31.s64 = ctx.r11.s64 + 224;
	// lwz r11,256(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 256);
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// rlwinm r10,r3,0,30,23
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFFFFFFFFF03;
	// clrlwi r30,r11,26
	ctx.r30.u64 = ctx.r11.u32 & 0x3F;
	// stw r10,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r10.u32);
	// cmplwi cr6,r30,50
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 50, ctx.xer);
	// bne cr6,0x8211b298
	if (!ctx.cr6.eq) goto loc_8211B298;
	// rlwimi r11,r27,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r27.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_8211B298:
	// lis r4,16384
	ctx.r4.s64 = 1073741824;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// li r9,0
	ctx.r9.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// ori r4,r4,256
	ctx.r4.u64 = ctx.r4.u64 | 256;
	// bl 0x82227e30
	ctx.lr = 0x8211B2C0;
	sub_82227E30(ctx, base);
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// lwz r9,28(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	// li r11,21
	ctx.r11.s64 = 21;
	// rlwimi r10,r30,0,26,31
	ctx.r10.u64 = (rotl32(ctx.r30.u32, 0) & 0x3F) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFC0);
	// rlwimi r9,r11,3,24,29
	ctx.r9.u64 = (rotl32(ctx.r11.u32, 3) & 0xFC) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFF03);
	// stw r10,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r10.u32);
	// stw r9,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r9.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211B2E8"))) PPC_WEAK_FUNC(sub_8211B2E8);
PPC_FUNC_IMPL(__imp__sub_8211B2E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8211B2F0;
	__restfpr_27(ctx, base);
	// stfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lwz r11,56(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// ble cr6,0x8211b31c
	if (!ctx.cr6.gt) goto loc_8211B31C;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82231210
	ctx.lr = 0x8211B31C;
	sub_82231210(ctx, base);
loc_8211B31C:
	// lis r11,-16384
	ctx.r11.s64 = -1073741824;
	// li r10,15
	ctx.r10.s64 = 15;
	// ori r9,r11,17920
	ctx.r9.u64 = ctx.r11.u64 | 17920;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stwu r9,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r3.u32 = ea;
	// li r4,0
	ctx.r4.s64 = 0;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// lbz r8,11069(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 11069);
	// clrlwi r7,r8,24
	ctx.r7.u64 = ctx.r8.u32 & 0xFF;
	// rlwinm r7,r7,0,30,28
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// stb r7,11069(r31)
	PPC_STORE_U8(ctx.r31.u32 + 11069, ctx.r7.u8);
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// addi r3,r11,276
	ctx.r3.s64 = ctx.r11.s64 + 276;
	// bl 0x822365d8
	ctx.lr = 0x8211B358;
	sub_822365D8(ctx, base);
	// lis r6,-32250
	ctx.r6.s64 = -2113536000;
	// lwz r3,104(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r6,31376
	ctx.r4.s64 = ctx.r6.s64 + 31376;
	// lwz r10,108(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// rldicr r11,r5,36,63
	ctx.r11.u64 = rotl64(ctx.r5.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// stw r3,32(r27)
	PPC_STORE_U32(ctx.r27.u32 + 32, ctx.r3.u32);
	// lfs f0,36(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stw r10,36(r27)
	PPC_STORE_U32(ctx.r27.u32 + 36, ctx.r10.u32);
	// lfs f31,48(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// stfs f0,40(r27)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r27.u32 + 40, temp.u32);
	// stfs f31,44(r27)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r27.u32 + 44, temp.u32);
	// lfs f0,20(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,7744(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7744, temp.u32);
	// lfs f13,24(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,7748(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7748, temp.u32);
	// lfs f12,28(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,7752(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7752, temp.u32);
	// lfs f11,32(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,7756(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7756, temp.u32);
	// ld r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r8,r9,r11
	ctx.r8.u64 = ctx.r9.u64 | ctx.r11.u64;
	// std r8,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r8.u64);
	// lfs f10,36(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,7760(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7760, temp.u32);
	// lfs f9,40(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,7764(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7764, temp.u32);
	// lfs f8,44(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 44);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,7768(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7768, temp.u32);
	// lfs f7,48(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,7772(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7772, temp.u32);
	// ld r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r6,r7,r11
	ctx.r6.u64 = ctx.r7.u64 | ctx.r11.u64;
	// std r6,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r6.u64);
	// lwz r5,16(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// rlwinm r4,r5,0,30,30
	ctx.r4.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x8211b404
	if (ctx.cr6.eq) goto loc_8211B404;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r11,r11,-27800
	ctx.r11.s64 = ctx.r11.s64 + -27800;
	// addi r3,r11,1728
	ctx.r3.s64 = ctx.r11.s64 + 1728;
	// bl 0x82135d20
	ctx.lr = 0x8211B404;
	sub_82135D20(ctx, base);
loc_8211B404:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// lbz r4,116(r30)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r30.u32 + 116);
	// bl 0x8211b7b0
	ctx.lr = 0x8211B410;
	sub_8211B7B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// addi r29,r11,27648
	ctx.r29.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,2124
	ctx.r5.s64 = ctx.r10.s64 + 2124;
	// lwz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8211b43c
	if (ctx.cr6.eq) goto loc_8211B43C;
	// stw r5,36(r29)
	PPC_STORE_U32(ctx.r29.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8211B43C;
	sub_8222CDF8(ctx, base);
loc_8211B43C:
	// lwz r10,20(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// lwz r11,52(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 52);
	// addi r28,r10,1980
	ctx.r28.s64 = ctx.r10.s64 + 1980;
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8211b46c
	if (ctx.cr6.eq) goto loc_8211B46C;
	// stw r28,52(r29)
	PPC_STORE_U32(ctx.r29.u32 + 52, ctx.r28.u32);
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// bl 0x8222d188
	ctx.lr = 0x8211B460;
	sub_8222D188(ctx, base);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x8211b46c
	if (ctx.cr6.eq) goto loc_8211B46C;
	// bl 0x82113790
	ctx.lr = 0x8211B46C;
	sub_82113790(ctx, base);
loc_8211B46C:
	// li r6,0
	ctx.r6.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x8210afd8
	ctx.lr = 0x8211B480;
	sub_8210AFD8(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8211B48C;
	sub_82111340(ctx, base);
	// addi r4,r27,24
	ctx.r4.s64 = ctx.r27.s64 + 24;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cbc8
	ctx.lr = 0x8211B498;
	sub_8222CBC8(ctx, base);
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// clrlwi r10,r11,31
	ctx.r10.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8211b7a0
	if (!ctx.cr6.eq) goto loc_8211B7A0;
	// addi r3,r30,52
	ctx.r3.s64 = ctx.r30.s64 + 52;
	// bl 0x8211c6e8
	ctx.lr = 0x8211B4B0;
	sub_8211C6E8(ctx, base);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// li r11,257
	ctx.r11.s64 = 257;
	// addi r31,r10,28184
	ctx.r31.s64 = ctx.r10.s64 + 28184;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,100
	ctx.r3.s64 = 100;
	// stw r11,288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 288, ctx.r11.u32);
	// bl 0x82111340
	ctx.lr = 0x8211B4CC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82111340
	ctx.lr = 0x8211B4D8;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x8211B4E4;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x8211B4F0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x8211B4FC;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x8211B508;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x82111340
	ctx.lr = 0x8211B514;
	sub_82111340(ctx, base);
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r4,r11,224
	ctx.r4.s64 = ctx.r11.s64 + 224;
	// bl 0x82111400
	ctx.lr = 0x8211B524;
	sub_82111400(ctx, base);
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211b548
	if (ctx.cr6.eq) goto loc_8211B548;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8211B540;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
loc_8211B548:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211b56c
	if (ctx.cr6.eq) goto loc_8211B56C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8211B564;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r11.u32);
loc_8211B56C:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211b5a4
	if (ctx.cr6.eq) goto loc_8211B5A4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_8211B5A4:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211b5d8
	if (ctx.cr6.eq) goto loc_8211B5D8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8211B5D8:
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r4,r11,16
	ctx.r4.s64 = ctx.r11.s64 + 16;
	// bl 0x82111400
	ctx.lr = 0x8211B5E8;
	sub_82111400(ctx, base);
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211b60c
	if (ctx.cr6.eq) goto loc_8211B60C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x8211B604;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r11.u32);
loc_8211B60C:
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211b630
	if (ctx.cr6.eq) goto loc_8211B630;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x8211B628;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r11.u32);
loc_8211B630:
	// lwz r11,2292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2292);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211b664
	if (ctx.cr6.eq) goto loc_8211B664;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2292, ctx.r10.u32);
loc_8211B664:
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211b698
	if (ctx.cr6.eq) goto loc_8211B698;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r10.u32);
loc_8211B698:
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// li r3,2
	ctx.r3.s64 = 2;
	// addi r4,r11,328
	ctx.r4.s64 = ctx.r11.s64 + 328;
	// bl 0x82111400
	ctx.lr = 0x8211B6A8;
	sub_82111400(ctx, base);
	// li r5,6
	ctx.r5.s64 = 6;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x82111390
	ctx.lr = 0x8211B6B8;
	sub_82111390(ctx, base);
	// lwz r11,2628(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2628);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x8211b6f0
	if (ctx.cr6.eq) goto loc_8211B6F0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r9,3
	ctx.r9.s64 = 3;
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1200(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1200);
	// rlwimi r7,r9,14,16,18
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 14) & 0xE000) | (ctx.r7.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r7,1200(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1200, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,8192
	ctx.r5.u64 = ctx.r6.u64 | 536870912;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2628(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2628, ctx.r10.u32);
loc_8211B6F0:
	// lwz r11,2676(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2676);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211b714
	if (ctx.cr6.eq) goto loc_8211B714;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8222c248
	ctx.lr = 0x8211B70C;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2676(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2676, ctx.r11.u32);
loc_8211B714:
	// lwz r11,2692(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2692);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211b738
	if (ctx.cr6.eq) goto loc_8211B738;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8222c0a0
	ctx.lr = 0x8211B730;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2692(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2692, ctx.r11.u32);
loc_8211B738:
	// lwz r11,2708(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2708);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211b76c
	if (ctx.cr6.eq) goto loc_8211B76C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1212(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1212);
	// rlwimi r8,r30,24,7,8
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 24) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1212(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1212, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,8192
	ctx.r6.u64 = ctx.r7.u64 | 536870912;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2708(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2708, ctx.r10.u32);
loc_8211B76C:
	// lwz r11,2660(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2660);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x8211b7a0
	if (ctx.cr6.eq) goto loc_8211B7A0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1220(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1220);
	// rlwimi r8,r30,0,30,31
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 0) & 0x3) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r8,1220(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1220, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,8192
	ctx.r6.u64 = ctx.r7.u64 | 536870912;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2660(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2660, ctx.r10.u32);
loc_8211B7A0:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211B7AC"))) PPC_WEAK_FUNC(sub_8211B7AC);
PPC_FUNC_IMPL(__imp__sub_8211B7AC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211B7B0"))) PPC_WEAK_FUNC(sub_8211B7B0);
PPC_FUNC_IMPL(__imp__sub_8211B7B0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x8211B7B8;
	__restfpr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,368
	ctx.r3.s64 = 368;
	// bl 0x82111340
	ctx.lr = 0x8211B7D4;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x8211B7E0;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,136
	ctx.r3.s64 = 136;
	// bl 0x82111340
	ctx.lr = 0x8211B7EC;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,140
	ctx.r3.s64 = 140;
	// bl 0x82111340
	ctx.lr = 0x8211B7F8;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x82111340
	ctx.lr = 0x8211B804;
	sub_82111340(ctx, base);
	// clrlwi r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211b954
	if (ctx.cr6.eq) goto loc_8211B954;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,1932
	ctx.r5.s64 = ctx.r10.s64 + 1932;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8211b83c
	if (ctx.cr6.eq) goto loc_8211B83C;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8211B83C;
	sub_8222CDF8(ctx, base);
loc_8211B83C:
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// addi r3,r11,1980
	ctx.r3.s64 = ctx.r11.s64 + 1980;
	// bl 0x8210b080
	ctx.lr = 0x8211B848;
	sub_8210B080(ctx, base);
	// addi r4,r30,24
	ctx.r4.s64 = ctx.r30.s64 + 24;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cbc8
	ctx.lr = 0x8211B854;
	sub_8222CBC8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8211B860;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8211B86C;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,372
	ctx.r3.s64 = 372;
	// bl 0x82111340
	ctx.lr = 0x8211B878;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,132
	ctx.r3.s64 = 132;
	// bl 0x82111340
	ctx.lr = 0x8211B884;
	sub_82111340(ctx, base);
	// li r4,5
	ctx.r4.s64 = 5;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82111340
	ctx.lr = 0x8211B890;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x8211B89C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x82111340
	ctx.lr = 0x8211B8A8;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82111340
	ctx.lr = 0x8211B8B4;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8211B8C0;
	sub_821112B0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,25784(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25784);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x8211B8E8;
	sub_82238728(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238380
	ctx.lr = 0x8211B8F4;
	sub_82238380(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x8211B8F8;
	sub_8210B0D8(ctx, base);
	// lwz r3,48(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lwz r7,56(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplw cr6,r3,r7
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r7.u32, ctx.xer);
	// ble cr6,0x8211b910
	if (!ctx.cr6.gt) goto loc_8211B910;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82231210
	ctx.lr = 0x8211B910;
	sub_82231210(ctx, base);
loc_8211B910:
	// lis r11,-16384
	ctx.r11.s64 = -1073741824;
	// li r10,15
	ctx.r10.s64 = 15;
	// ori r9,r11,17920
	ctx.r9.u64 = ctx.r11.u64 | 17920;
	// li r8,1480
	ctx.r8.s64 = 1480;
	// stwu r9,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r3.u32 = ea;
	// lis r7,2
	ctx.r7.s64 = 131072;
	// stwu r10,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r3.u32 = ea;
	// stwu r8,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r3.u32 = ea;
	// stwu r7,4(r3)
	ea = 4 + ctx.r3.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r3.u32 = ea;
	// lbz r5,11069(r31)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r31.u32 + 11069);
	// lbz r6,11071(r31)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r31.u32 + 11071);
	// clrlwi r11,r5,24
	ctx.r11.u64 = ctx.r5.u32 & 0xFF;
	// rlwinm r4,r6,0,0,29
	ctx.r4.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r11,r11,0,30,28
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// stb r4,11071(r31)
	PPC_STORE_U8(ctx.r31.u32 + 11071, ctx.r4.u8);
	// stb r11,11069(r31)
	PPC_STORE_U8(ctx.r31.u32 + 11069, ctx.r11.u8);
loc_8211B954:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8211B960;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8211B96C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,372
	ctx.r3.s64 = 372;
	// bl 0x82111340
	ctx.lr = 0x8211B978;
	sub_82111340(ctx, base);
	// li r4,127
	ctx.r4.s64 = 127;
	// li r3,132
	ctx.r3.s64 = 132;
	// bl 0x82111340
	ctx.lr = 0x8211B984;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82111340
	ctx.lr = 0x8211B990;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x8211B99C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82111340
	ctx.lr = 0x8211B9A8;
	sub_82111340(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211B9B0"))) PPC_WEAK_FUNC(sub_8211B9B0);
PPC_FUNC_IMPL(__imp__sub_8211B9B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e444
	ctx.lr = 0x8211B9B8;
	__restfpr_19(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lwz r27,0(r3)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,360
	ctx.r3.s64 = 360;
	// lwz r29,16(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r21,24(r11)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// bl 0x82111340
	ctx.lr = 0x8211B9D8;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8211B9E4;
	sub_821112B0(ctx, base);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// addi r9,r10,27648
	ctx.r9.s64 = ctx.r10.s64 + 27648;
	// lwz r20,36(r9)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x8211ba00
	if (ctx.cr6.eq) goto loc_8211BA00;
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x8222f080
	ctx.lr = 0x8211BA00;
	sub_8222F080(ctx, base);
loc_8211BA00:
	// li r28,0
	ctx.r28.s64 = 0;
	// lwz r11,36(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 36);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// rlwinm r3,r11,14,18,31
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 14) & 0x3FFF;
	// bl 0x8210c6e0
	ctx.lr = 0x8211BA18;
	sub_8210C6E0(ctx, base);
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8211bafc
	if (ctx.cr6.eq) goto loc_8211BAFC;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lis r26,-32178
	ctx.r26.s64 = -2108817408;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r23,r11,r10
	ctx.r23.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// rldicr r25,r10,63,63
	ctx.r25.u64 = rotl64(ctx.r10.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// addi r24,r11,-27864
	ctx.r24.s64 = ctx.r11.s64 + -27864;
loc_8211BA44:
	// cmplwi cr6,r29,4
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 4, ctx.xer);
	// mr r31,r29
	ctx.r31.u64 = ctx.r29.u64;
	// blt cr6,0x8211ba54
	if (ctx.cr6.lt) goto loc_8211BA54;
	// li r31,4
	ctx.r31.s64 = 4;
loc_8211BA54:
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r3,25592(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 25592);
	// rlwinm r11,r31,1,0,30
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r24
	ctx.r10.u64 = ctx.r10.u64 + ctx.r24.u64;
	// add r30,r31,r11
	ctx.r30.u64 = ctx.r31.u64 + ctx.r11.u64;
	// lwz r19,-4(r10)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	// lwz r9,4(r19)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r19.u32 + 4);
	// stw r9,12216(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12216, ctx.r9.u32);
	// ld r8,16(r3)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// oris r7,r8,8
	ctx.r7.u64 = ctx.r8.u64 | 524288;
	// std r7,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r7.u64);
	// lwz r4,8(r19)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r19.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x8211BA88;
	sub_82238728(ctx, base);
	// lwz r3,25592(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 25592);
	// lwz r4,0(r19)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r19.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x8211BA94;
	sub_82238380(ctx, base);
	// addi r6,r30,109
	ctx.r6.s64 = ctx.r30.s64 + 109;
	// rlwinm r11,r28,2,0,29
	ctx.r11.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r6,30,2,31
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3FFFFFFF;
	// add r5,r11,r21
	ctx.r5.u64 = ctx.r11.u64 + ctx.r21.u64;
	// addi r4,r10,-27
	ctx.r4.s64 = ctx.r10.s64 + -27;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// clrldi r3,r4,32
	ctx.r3.u64 = ctx.r4.u64 & 0xFFFFFFFF;
	// li r4,110
	ctx.r4.s64 = 110;
	// srad r11,r25,r3
	temp.u64 = ctx.r3.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r25.s64 < 0) & (((ctx.r25.s64 >> temp.u64) << temp.u64) != ctx.r25.s64);
	ctx.r11.s64 = ctx.r25.s64 >> temp.u64;
	// rldicl r7,r11,37,27
	ctx.r7.u64 = rotl64(ctx.r11.u64, 37) & 0x1FFFFFFFFF;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82238120
	ctx.lr = 0x8211BAC4;
	sub_82238120(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,16
	ctx.r7.s64 = 16;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cc48
	ctx.lr = 0x8211BADC;
	sub_8222CC48(ctx, base);
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x8211BAF0;
	sub_8222DFC8(ctx, base);
	// subf. r29,r31,r29
	ctx.r29.s64 = ctx.r29.s64 - ctx.r31.s64;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// add r28,r30,r28
	ctx.r28.u64 = ctx.r30.u64 + ctx.r28.u64;
	// bne 0x8211ba44
	if (!ctx.cr0.eq) goto loc_8211BA44;
loc_8211BAFC:
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x8211BB04;
	sub_8222F0F8(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8233e494
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211BB0C"))) PPC_WEAK_FUNC(sub_8211BB0C);
PPC_FUNC_IMPL(__imp__sub_8211BB0C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211BB10"))) PPC_WEAK_FUNC(sub_8211BB10);
PPC_FUNC_IMPL(__imp__sub_8211BB10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x8211BB18;
	__restfpr_24(ctx, base);
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lwz r25,0(r3)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r26,r3
	ctx.r26.u64 = ctx.r3.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,360
	ctx.r3.s64 = 360;
	// lwz r30,16(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r28,24(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r27,32(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// bl 0x82111340
	ctx.lr = 0x8211BB40;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x8211BB4C;
	sub_82113BC0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8211BB58;
	sub_821112B0(ctx, base);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// addi r9,r10,27648
	ctx.r9.s64 = ctx.r10.s64 + 27648;
	// lwz r24,36(r9)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	// cmplwi cr6,r24,0
	ctx.cr6.compare<uint32_t>(ctx.r24.u32, 0, ctx.xer);
	// beq cr6,0x8211bb74
	if (ctx.cr6.eq) goto loc_8211BB74;
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x8222f080
	ctx.lr = 0x8211BB74;
	sub_8222F080(ctx, base);
loc_8211BB74:
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r10,36(r24)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r24.u32 + 36);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// rlwinm r3,r10,14,18,31
	ctx.r3.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 14) & 0x3FFF;
	// bl 0x8210c6e0
	ctx.lr = 0x8211BB8C;
	sub_8210C6E0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r5,r31,100
	ctx.r5.s64 = ctx.r31.s64 + 100;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82257cb8
	ctx.lr = 0x8211BBA8;
	sub_82257CB8(ctx, base);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x82257a50
	ctx.lr = 0x8211BBB4;
	sub_82257A50(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,16
	ctx.r7.s64 = 16;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8211BBD0;
	sub_8222CC48(ctx, base);
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,4
	ctx.r6.s64 = 4;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// rldicr r7,r7,35,28
	ctx.r7.u64 = rotl64(ctx.r7.u64, 35) & 0xFFFFFFF800000000;
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// li r4,111
	ctx.r4.s64 = 111;
	// bl 0x82238120
	ctx.lr = 0x8211BBEC;
	sub_82238120(ctx, base);
	// lwz r11,2932(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2932);
	// li r29,1
	ctx.r29.s64 = 1;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211bc24
	if (ctx.cr6.eq) goto loc_8211BC24;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1224(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1224);
	// rlwimi r8,r29,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r29.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1224(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1224, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,4096
	ctx.r6.u64 = ctx.r7.u64 | 268435456;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2932(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2932, ctx.r10.u32);
loc_8211BC24:
	// lwz r11,2948(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2948);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211bc58
	if (ctx.cr6.eq) goto loc_8211BC58;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1224(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1224);
	// rlwimi r8,r29,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r29.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1224(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1224, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,4096
	ctx.r6.u64 = ctx.r7.u64 | 268435456;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2948(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2948, ctx.r10.u32);
loc_8211BC58:
	// lwz r11,2996(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2996);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8211bc7c
	if (ctx.cr6.eq) goto loc_8211BC7C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8222c248
	ctx.lr = 0x8211BC74;
	sub_8222C248(ctx, base);
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,2996(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2996, ctx.r29.u32);
loc_8211BC7C:
	// lwz r11,3012(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3012);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8211bca0
	if (ctx.cr6.eq) goto loc_8211BCA0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8222c0a0
	ctx.lr = 0x8211BC98;
	sub_8222C0A0(ctx, base);
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,3012(r31)
	PPC_STORE_U32(ctx.r31.u32 + 3012, ctx.r29.u32);
loc_8211BCA0:
	// lwz r11,3028(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3028);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211bcd4
	if (ctx.cr6.eq) goto loc_8211BCD4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1236(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1236);
	// rlwimi r8,r29,24,7,8
	ctx.r8.u64 = (rotl32(ctx.r29.u32, 24) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1236(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1236, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,4096
	ctx.r6.u64 = ctx.r7.u64 | 268435456;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,3028(r31)
	PPC_STORE_U32(ctx.r31.u32 + 3028, ctx.r10.u32);
loc_8211BCD4:
	// lwz r11,2980(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2980);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x8211bd08
	if (ctx.cr6.eq) goto loc_8211BD08;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1244(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1244);
	// rlwimi r8,r29,0,30,31
	ctx.r8.u64 = (rotl32(ctx.r29.u32, 0) & 0x3) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r8,1244(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1244, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,4096
	ctx.r6.u64 = ctx.r7.u64 | 268435456;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2980(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2980, ctx.r10.u32);
loc_8211BD08:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25608(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25608);
	// bl 0x8211c5f0
	ctx.lr = 0x8211BD14;
	sub_8211C5F0(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x8211bda4
	if (ctx.cr6.eq) goto loc_8211BDA4;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r29,r27,-4
	ctx.r29.s64 = ctx.r27.s64 + -4;
	// addi r31,r28,8
	ctx.r31.s64 = ctx.r28.s64 + 8;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r27,r11,r10
	ctx.r27.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r11,1
	ctx.r11.s64 = 1;
	// rldicr r28,r11,35,63
	ctx.r28.u64 = rotl64(ctx.r11.u64, 35) & 0xFFFFFFFFFFFFFFFF;
loc_8211BD38:
	// lwzu r11,4(r29)
	ea = 4 + ctx.r29.u32;
	ctx.r11.u64 = PPC_LOAD_U32(ea);
	ctx.r29.u32 = ea;
	// li r3,3
	ctx.r3.s64 = 3;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82111400
	ctx.lr = 0x8211BD48;
	sub_82111400(ctx, base);
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// lfs f0,-8(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	ctx.f0.f64 = double(temp.f32);
	// mr r6,r27
	ctx.r6.u64 = ctx.r27.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// stfs f0,7856(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 7856, temp.u32);
	// lfs f13,-4(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + -4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,7860(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 7860, temp.u32);
	// lfs f12,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,7864(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 7864, temp.u32);
	// lfs f11,4(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,7868(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 7868, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// or r9,r10,r28
	ctx.r9.u64 = ctx.r10.u64 | ctx.r28.u64;
	// std r9,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r9.u64);
	// bl 0x8222dfc8
	ctx.lr = 0x8211BD8C;
	sub_8222DFC8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,257
	ctx.r3.s64 = 257;
	// bl 0x82113bc0
	ctx.lr = 0x8211BD98;
	sub_82113BC0(ctx, base);
	// addic. r30,r30,-1
	ctx.xer.ca = ctx.r30.u32 > 0;
	ctx.r30.s64 = ctx.r30.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// bne 0x8211bd38
	if (!ctx.cr0.eq) goto loc_8211BD38;
loc_8211BDA4:
	// mr r3,r24
	ctx.r3.u64 = ctx.r24.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x8211BDAC;
	sub_8222F0F8(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211BDB4"))) PPC_WEAK_FUNC(sub_8211BDB4);
PPC_FUNC_IMPL(__imp__sub_8211BDB4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211BDB8"))) PPC_WEAK_FUNC(sub_8211BDB8);
PPC_FUNC_IMPL(__imp__sub_8211BDB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e444
	ctx.lr = 0x8211BDC0;
	__restfpr_19(ctx, base);
	// stfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, ctx.f31.u64);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r20,-32178
	ctx.r20.s64 = -2108817408;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r23,16(r4)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// lwz r30,24(r4)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r21,28(r4)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// lwz r28,20(r4)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// lwz r11,25612(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 25612);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x8211BE08;
	sub_82238728(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,12
	ctx.r7.s64 = 12;
	// lwz r5,12(r25)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8211BE24;
	sub_8222CC48(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8211BE30;
	sub_821112B0(ctx, base);
	// lwz r6,4(r25)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// li r7,3
	ctx.r7.s64 = 3;
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// divwu r11,r6,r7
	ctx.r11.u32 = ctx.r6.u32 / ctx.r7.u32;
	// beq cr6,0x8211c004
	if (ctx.cr6.eq) goto loc_8211C004;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r30,r30,72
	ctx.r30.s64 = ctx.r30.s64 + 72;
	// add r26,r11,r10
	ctx.r26.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// li r22,1
	ctx.r22.s64 = 1;
	// lis r19,-32178
	ctx.r19.s64 = -2108817408;
	// addi r24,r11,28184
	ctx.r24.s64 = ctx.r11.s64 + 28184;
	// lfs f31,48(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
loc_8211BE70:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82113ab8
	ctx.lr = 0x8211BE78;
	sub_82113AB8(ctx, base);
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,5
	ctx.r6.s64 = 5;
	// rldicr r7,r7,35,28
	ctx.r7.u64 = rotl64(ctx.r7.u64, 35) & 0xFFFFFFF800000000;
	// addi r5,r30,-72
	ctx.r5.s64 = ctx.r30.s64 + -72;
	// li r4,110
	ctx.r4.s64 = 110;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238120
	ctx.lr = 0x8211BE94;
	sub_82238120(ctx, base);
	// lfs f0,-8(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,-4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -4);
	ctx.f13.f64 = double(temp.f32);
	// fadds f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// lfs f11,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fadds f9,f12,f11
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// fadds f8,f9,f10
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fcmpu cr6,f8,f31
	ctx.cr6.compare(ctx.f8.f64, ctx.f31.f64);
	// bne cr6,0x8211bec0
	if (!ctx.cr6.eq) goto loc_8211BEC0;
	// lwz r27,25600(r19)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r19.u32 + 25600);
	// b 0x8211bec4
	goto loc_8211BEC4;
loc_8211BEC0:
	// lwz r27,25612(r20)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r20.u32 + 25612);
loc_8211BEC4:
	// lwz r11,788(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 788);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8211bf18
	if (ctx.cr6.eq) goto loc_8211BF18;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// mr r9,r22
	ctx.r9.u64 = ctx.r22.u64;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,12808(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12808);
	// lwz r6,10548(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 10548);
	// subfic r5,r7,0
	ctx.xer.ca = ctx.r7.u32 <= 0;
	ctx.r5.s64 = 0 - ctx.r7.s64;
	// stw r22,12288(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12288, ctx.r22.u32);
	// subfe r3,r4,r4
	temp.u8 = (~ctx.r4.u32 + ctx.r4.u32 < ~ctx.r4.u32) | (~ctx.r4.u32 + ctx.r4.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r3.u64 = ~ctx.r4.u64 + ctx.r4.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r11,r3,r22
	ctx.r11.u64 = ctx.r3.u64 & ctx.r22.u64;
	// rlwimi r6,r11,0,31,31
	ctx.r6.u64 = (rotl32(ctx.r11.u32, 0) & 0x1) | (ctx.r6.u64 & 0xFFFFFFFFFFFFFFFE);
	// stw r6,10548(r8)
	PPC_STORE_U32(ctx.r8.u32 + 10548, ctx.r6.u32);
	// ld r10,16(r8)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r8.u32 + 16);
	// ori r7,r10,2048
	ctx.r7.u64 = ctx.r10.u64 | 2048;
	// oris r5,r7,2
	ctx.r5.u64 = ctx.r7.u64 | 131072;
	// std r7,16(r8)
	PPC_STORE_U64(ctx.r8.u32 + 16, ctx.r7.u64);
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// std r5,16(r8)
	PPC_STORE_U64(ctx.r8.u32 + 16, ctx.r5.u64);
	// stw r22,788(r24)
	PPC_STORE_U32(ctx.r24.u32 + 788, ctx.r22.u32);
loc_8211BF18:
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82111340
	ctx.lr = 0x8211BF24;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82111340
	ctx.lr = 0x8211BF30;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x8211BF3C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8211BF48;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8211BF54;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,368
	ctx.r3.s64 = 368;
	// bl 0x82111340
	ctx.lr = 0x8211BF60;
	sub_82111340(ctx, base);
	// li r4,3
	ctx.r4.s64 = 3;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x8211BF6C;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x8211BF78;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238380
	ctx.lr = 0x8211BF84;
	sub_82238380(ctx, base);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x8211BF98;
	sub_8222DFC8(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x8211c510
	ctx.lr = 0x8211BFA0;
	sub_8211C510(ctx, base);
	// lbzx r11,r29,r21
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + ctx.r21.u32);
	// rlwinm r10,r11,0,30,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211bfb8
	if (ctx.cr6.eq) goto loc_8211BFB8;
	// li r4,2
	ctx.r4.s64 = 2;
	// b 0x8211bfc8
	goto loc_8211BFC8;
loc_8211BFB8:
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x8211BFC4;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
loc_8211BFC8:
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x8211BFD0;
	sub_82111340(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x8211BFDC;
	sub_82238380(ctx, base);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x8211BFF0;
	sub_8222DFC8(ctx, base);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r28,r28,64
	ctx.r28.s64 = ctx.r28.s64 + 64;
	// addi r30,r30,80
	ctx.r30.s64 = ctx.r30.s64 + 80;
	// cmplw cr6,r29,r23
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r23.u32, ctx.xer);
	// blt cr6,0x8211be70
	if (ctx.cr6.lt) goto loc_8211BE70;
loc_8211C004:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x8211C010;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x8211C01C;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x8211C028;
	sub_82111340(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// lfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// b 0x8233e494
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211C034"))) PPC_WEAK_FUNC(sub_8211C034);
PPC_FUNC_IMPL(__imp__sub_8211C034) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211C038"))) PPC_WEAK_FUNC(sub_8211C038);
PPC_FUNC_IMPL(__imp__sub_8211C038) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e444
	ctx.lr = 0x8211C040;
	__restfpr_19(ctx, base);
	// stfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, ctx.f31.u64);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// lwz r23,16(r11)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r30,24(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// lwz r21,28(r11)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r11.u32 + 28);
	// lwz r28,20(r11)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// lwz r31,0(r25)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// bl 0x82111340
	ctx.lr = 0x8211C070;
	sub_82111340(ctx, base);
	// lis r20,-32178
	ctx.r20.s64 = -2108817408;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,25616(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 25616);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x8211C098;
	sub_82238728(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,12
	ctx.r7.s64 = 12;
	// lwz r5,16(r25)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r25.u32 + 16);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8211C0B4;
	sub_8222CC48(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8211C0C0;
	sub_821112B0(ctx, base);
	// lwz r6,8(r25)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	// li r7,3
	ctx.r7.s64 = 3;
	// li r29,0
	ctx.r29.s64 = 0;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// divwu r11,r6,r7
	ctx.r11.u32 = ctx.r6.u32 / ctx.r7.u32;
	// beq cr6,0x8211c28c
	if (ctx.cr6.eq) goto loc_8211C28C;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r30,r30,88
	ctx.r30.s64 = ctx.r30.s64 + 88;
	// add r26,r11,r10
	ctx.r26.u64 = ctx.r11.u64 + ctx.r10.u64;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// li r22,1
	ctx.r22.s64 = 1;
	// lis r19,-32178
	ctx.r19.s64 = -2108817408;
	// addi r24,r11,28184
	ctx.r24.s64 = ctx.r11.s64 + 28184;
	// lfs f31,48(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
loc_8211C100:
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82113ab8
	ctx.lr = 0x8211C108;
	sub_82113AB8(ctx, base);
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,6
	ctx.r6.s64 = 6;
	// rldicr r7,r7,35,28
	ctx.r7.u64 = rotl64(ctx.r7.u64, 35) & 0xFFFFFFF800000000;
	// addi r5,r30,-88
	ctx.r5.s64 = ctx.r30.s64 + -88;
	// li r4,110
	ctx.r4.s64 = 110;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238120
	ctx.lr = 0x8211C124;
	sub_82238120(ctx, base);
	// lfs f0,-8(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -8);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,-4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + -4);
	ctx.f13.f64 = double(temp.f32);
	// fadds f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// lfs f11,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fadds f9,f12,f11
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// fadds f8,f9,f10
	ctx.f8.f64 = double(float(ctx.f9.f64 + ctx.f10.f64));
	// fcmpu cr6,f8,f31
	ctx.cr6.compare(ctx.f8.f64, ctx.f31.f64);
	// bne cr6,0x8211c150
	if (!ctx.cr6.eq) goto loc_8211C150;
	// lwz r27,25604(r19)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r19.u32 + 25604);
	// b 0x8211c154
	goto loc_8211C154;
loc_8211C150:
	// lwz r27,25616(r20)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r20.u32 + 25616);
loc_8211C154:
	// lwz r11,788(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 788);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8211c1a8
	if (ctx.cr6.eq) goto loc_8211C1A8;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// mr r9,r22
	ctx.r9.u64 = ctx.r22.u64;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,12808(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12808);
	// lwz r6,10548(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 10548);
	// subfic r5,r7,0
	ctx.xer.ca = ctx.r7.u32 <= 0;
	ctx.r5.s64 = 0 - ctx.r7.s64;
	// stw r22,12288(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12288, ctx.r22.u32);
	// subfe r3,r4,r4
	temp.u8 = (~ctx.r4.u32 + ctx.r4.u32 < ~ctx.r4.u32) | (~ctx.r4.u32 + ctx.r4.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r3.u64 = ~ctx.r4.u64 + ctx.r4.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r11,r3,r22
	ctx.r11.u64 = ctx.r3.u64 & ctx.r22.u64;
	// rlwimi r6,r11,0,31,31
	ctx.r6.u64 = (rotl32(ctx.r11.u32, 0) & 0x1) | (ctx.r6.u64 & 0xFFFFFFFFFFFFFFFE);
	// stw r6,10548(r8)
	PPC_STORE_U32(ctx.r8.u32 + 10548, ctx.r6.u32);
	// ld r10,16(r8)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r8.u32 + 16);
	// ori r7,r10,2048
	ctx.r7.u64 = ctx.r10.u64 | 2048;
	// oris r5,r7,2
	ctx.r5.u64 = ctx.r7.u64 | 131072;
	// std r7,16(r8)
	PPC_STORE_U64(ctx.r8.u32 + 16, ctx.r7.u64);
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// std r5,16(r8)
	PPC_STORE_U64(ctx.r8.u32 + 16, ctx.r5.u64);
	// stw r22,788(r24)
	PPC_STORE_U32(ctx.r24.u32 + 788, ctx.r22.u32);
loc_8211C1A8:
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82111340
	ctx.lr = 0x8211C1B4;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82111340
	ctx.lr = 0x8211C1C0;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x8211C1CC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8211C1D8;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8211C1E4;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,368
	ctx.r3.s64 = 368;
	// bl 0x82111340
	ctx.lr = 0x8211C1F0;
	sub_82111340(ctx, base);
	// li r4,3
	ctx.r4.s64 = 3;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x8211C1FC;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x8211C208;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82238380
	ctx.lr = 0x8211C214;
	sub_82238380(ctx, base);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x8211C228;
	sub_8222DFC8(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x8211c510
	ctx.lr = 0x8211C230;
	sub_8211C510(ctx, base);
	// lbzx r11,r29,r21
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + ctx.r21.u32);
	// li r4,6
	ctx.r4.s64 = 6;
	// rlwinm r10,r11,0,30,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8211c250
	if (!ctx.cr6.eq) goto loc_8211C250;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x8211C24C;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
loc_8211C250:
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x8211C258;
	sub_82111340(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x8211C264;
	sub_82238380(ctx, base);
	// mr r6,r26
	ctx.r6.u64 = ctx.r26.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x8211C278;
	sub_8222DFC8(ctx, base);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r28,r28,64
	ctx.r28.s64 = ctx.r28.s64 + 64;
	// addi r30,r30,96
	ctx.r30.s64 = ctx.r30.s64 + 96;
	// cmplw cr6,r29,r23
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r23.u32, ctx.xer);
	// blt cr6,0x8211c100
	if (ctx.cr6.lt) goto loc_8211C100;
loc_8211C28C:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x8211C298;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x8211C2A4;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x8211C2B0;
	sub_82111340(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// lfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// b 0x8233e494
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211C2BC"))) PPC_WEAK_FUNC(sub_8211C2BC);
PPC_FUNC_IMPL(__imp__sub_8211C2BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211C2C0"))) PPC_WEAK_FUNC(sub_8211C2C0);
PPC_FUNC_IMPL(__imp__sub_8211C2C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x8211C2C8;
	__restfpr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8211c2f0
	if (!ctx.cr6.gt) goto loc_8211C2F0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82231210
	ctx.lr = 0x8211C2EC;
	sub_82231210(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_8211C2F0:
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// li r9,15
	ctx.r9.s64 = 15;
	// ori r8,r10,17920
	ctx.r8.u64 = ctx.r10.u64 | 17920;
	// li r4,1
	ctx.r4.s64 = 1;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// li r3,1
	ctx.r3.s64 = 1;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// lbz r7,11069(r31)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r31.u32 + 11069);
	// clrlwi r6,r7,24
	ctx.r6.u64 = ctx.r7.u32 & 0xFF;
	// rlwinm r6,r6,0,30,28
	ctx.r6.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// stb r6,11069(r31)
	PPC_STORE_U8(ctx.r31.u32 + 11069, ctx.r6.u8);
	// bl 0x821112b0
	ctx.lr = 0x8211C324;
	sub_821112B0(ctx, base);
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// addi r31,r11,276
	ctx.r31.s64 = ctx.r11.s64 + 276;
	// lwz r11,308(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 308);
	// clrlwi r30,r11,26
	ctx.r30.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r30,50
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 50, ctx.xer);
	// bne cr6,0x8211c348
	if (!ctx.cr6.eq) goto loc_8211C348;
	// li r10,3
	ctx.r10.s64 = 3;
	// rlwimi r11,r10,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r10.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_8211C348:
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r6,r10,31376
	ctx.r6.s64 = ctx.r10.s64 + 31376;
	// addi r29,r11,27648
	ctx.r29.s64 = ctx.r11.s64 + 27648;
	// lis r4,11264
	ctx.r4.s64 = 738197504;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// lfs f1,48(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// li r5,0
	ctx.r5.s64 = 0;
	// ori r4,r4,256
	ctx.r4.u64 = ctx.r4.u64 | 256;
	// bl 0x82227e30
	ctx.lr = 0x8211C380;
	sub_82227E30(ctx, base);
	// lwz r5,32(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// li r4,0
	ctx.r4.s64 = 0;
	// rlwimi r5,r30,0,26,31
	ctx.r5.u64 = (rotl32(ctx.r30.u32, 0) & 0x3F) | (ctx.r5.u64 & 0xFFFFFFFFFFFFFFC0);
	// li r3,360
	ctx.r3.s64 = 360;
	// stw r5,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r5.u32);
	// bl 0x82111340
	ctx.lr = 0x8211C398;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8211C3A4;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x8211C3B0;
	sub_82111340(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211c3e4
	if (ctx.cr6.eq) goto loc_8211C3E4;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x8211C3DC;
	sub_82237A38(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r11.u32);
loc_8211C3E4:
	// lwz r11,296(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 296);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211c40c
	if (ctx.cr6.eq) goto loc_8211C40C;
	// lis r6,16384
	ctx.r6.s64 = 1073741824;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82237a38
	ctx.lr = 0x8211C404;
	sub_82237A38(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,296(r31)
	PPC_STORE_U32(ctx.r31.u32 + 296, ctx.r11.u32);
loc_8211C40C:
	// lwz r11,300(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 300);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211c434
	if (ctx.cr6.eq) goto loc_8211C434;
	// lis r6,8192
	ctx.r6.s64 = 536870912;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x82237a38
	ctx.lr = 0x8211C42C;
	sub_82237A38(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,300(r31)
	PPC_STORE_U32(ctx.r31.u32 + 300, ctx.r11.u32);
loc_8211C434:
	// lwz r11,304(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 304);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211c45c
	if (ctx.cr6.eq) goto loc_8211C45C;
	// lis r6,4096
	ctx.r6.s64 = 268435456;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x82237a38
	ctx.lr = 0x8211C454;
	sub_82237A38(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,304(r31)
	PPC_STORE_U32(ctx.r31.u32 + 304, ctx.r11.u32);
loc_8211C45C:
	// lwz r11,40(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211c480
	if (ctx.cr6.eq) goto loc_8211C480;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r11,40(r29)
	PPC_STORE_U32(ctx.r29.u32 + 40, ctx.r11.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222cdf8
	ctx.lr = 0x8211C480;
	sub_8222CDF8(ctx, base);
loc_8211C480:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x8211C48C;
	sub_82113BC0(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8211C498;
	sub_82111340(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211C4A0"))) PPC_WEAK_FUNC(sub_8211C4A0);
PPC_FUNC_IMPL(__imp__sub_8211C4A0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x8211C4B8;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82111340
	ctx.lr = 0x8211C4C4;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82111340
	ctx.lr = 0x8211C4D0;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x8211C4DC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8211C4E8;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8211C4F4;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,368
	ctx.r3.s64 = 368;
	// bl 0x82111340
	ctx.lr = 0x8211C500;
	sub_82111340(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211C510"))) PPC_WEAK_FUNC(sub_8211C510);
PPC_FUNC_IMPL(__imp__sub_8211C510) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// ble cr6,0x8211c540
	if (!ctx.cr6.gt) goto loc_8211C540;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82231210
	ctx.lr = 0x8211C53C;
	sub_82231210(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_8211C540:
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// li r9,15
	ctx.r9.s64 = 15;
	// ori r8,r10,17920
	ctx.r8.u64 = ctx.r10.u64 | 17920;
	// li r7,1480
	ctx.r7.s64 = 1480;
	// stwu r8,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	ctx.r11.u32 = ea;
	// lis r6,2
	ctx.r6.s64 = 131072;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,108
	ctx.r3.s64 = 108;
	// stwu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r11.u32 = ea;
	// stwu r7,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	ctx.r11.u32 = ea;
	// stwu r6,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	ctx.r11.u32 = ea;
	// lbz r10,11069(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 11069);
	// lbz r5,11071(r31)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r31.u32 + 11071);
	// clrlwi r8,r10,24
	ctx.r8.u64 = ctx.r10.u32 & 0xFF;
	// rlwinm r9,r5,0,0,29
	ctx.r9.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r8,r8,0,30,28
	ctx.r8.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// stb r9,11071(r31)
	PPC_STORE_U8(ctx.r31.u32 + 11071, ctx.r9.u8);
	// stb r8,11069(r31)
	PPC_STORE_U8(ctx.r31.u32 + 11069, ctx.r8.u8);
	// bl 0x82111340
	ctx.lr = 0x8211C590;
	sub_82111340(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82111340
	ctx.lr = 0x8211C59C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82111340
	ctx.lr = 0x8211C5A8;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x8211C5B4;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8211C5C0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8211C5CC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,368
	ctx.r3.s64 = 368;
	// bl 0x82111340
	ctx.lr = 0x8211C5D8;
	sub_82111340(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211C5EC"))) PPC_WEAK_FUNC(sub_8211C5EC);
PPC_FUNC_IMPL(__imp__sub_8211C5EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211C5F0"))) PPC_WEAK_FUNC(sub_8211C5F0);
PPC_FUNC_IMPL(__imp__sub_8211C5F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// lwz r3,25592(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25592);
	// stw r11,12216(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12216, ctx.r11.u32);
	// ld r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// oris r9,r10,8
	ctx.r9.u64 = ctx.r10.u64 | 524288;
	// std r9,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r9.u64);
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x8211C62C;
	sub_82238728(ctx, base);
	// lwz r3,25592(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25592);
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x8211C638;
	sub_82238380(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211C650"))) PPC_WEAK_FUNC(sub_8211C650);
PPC_FUNC_IMPL(__imp__sub_8211C650) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32179
	ctx.r11.s64 = -2108882944;
	// lis r10,1
	ctx.r10.s64 = 65536;
	// addi r9,r11,20000
	ctx.r9.s64 = ctx.r11.s64 + 20000;
	// ori r8,r10,304
	ctx.r8.u64 = ctx.r10.u64 | 304;
	// lis r7,-32250
	ctx.r7.s64 = -2113536000;
	// addi r6,r7,31376
	ctx.r6.s64 = ctx.r7.s64 + 31376;
	// lwzx r11,r9,r8
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// rlwinm r5,r11,8,24,31
	ctx.r5.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 8) & 0xFF;
	// rlwinm r4,r11,16,24,31
	ctx.r4.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 16) & 0xFF;
	// lfs f0,244(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 244);
	ctx.f0.f64 = double(temp.f32);
	// rlwinm r10,r11,24,24,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0xFF;
	// std r5,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r5.u64);
	// lfd f13,-16(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// std r4,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r4.u64);
	// std r10,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r10.u64);
	// lfd f12,-8(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// lfd f11,-16(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// clrlwi r9,r11,24
	ctx.r9.u64 = ctx.r11.u32 & 0xFF;
	// fcfid f6,f13
	ctx.f6.f64 = double(ctx.f13.s64);
	// std r9,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, ctx.r9.u64);
	// lfd f10,-8(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// fcfid f8,f11
	ctx.f8.f64 = double(ctx.f11.s64);
	// fcfid f7,f12
	ctx.f7.f64 = double(ctx.f12.s64);
	// fcfid f9,f10
	ctx.f9.f64 = double(ctx.f10.s64);
	// frsp f5,f9
	ctx.f5.f64 = double(float(ctx.f9.f64));
	// frsp f4,f8
	ctx.f4.f64 = double(float(ctx.f8.f64));
	// frsp f3,f7
	ctx.f3.f64 = double(float(ctx.f7.f64));
	// frsp f2,f6
	ctx.f2.f64 = double(float(ctx.f6.f64));
	// fmuls f1,f5,f0
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f0.f64));
	// stfs f1,8(r3)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// fmuls f13,f4,f0
	ctx.f13.f64 = double(float(ctx.f4.f64 * ctx.f0.f64));
	// stfs f13,4(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// fmuls f12,f3,f0
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f0.f64));
	// stfs f12,0(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// fmuls f11,f2,f0
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f0.f64));
	// stfs f11,12(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211C6E4"))) PPC_WEAK_FUNC(sub_8211C6E4);
PPC_FUNC_IMPL(__imp__sub_8211C6E4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211C6E8"))) PPC_WEAK_FUNC(sub_8211C6E8);
PPC_FUNC_IMPL(__imp__sub_8211C6E8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-32183
	ctx.r30.s64 = -2109145088;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r31,r30,28184
	ctx.r31.s64 = ctx.r30.s64 + 28184;
	// li r5,64
	ctx.r5.s64 = 64;
	// addi r3,r31,36
	ctx.r3.s64 = ctx.r31.s64 + 36;
	// bl 0x8233e4e0
	ctx.lr = 0x8211C714;
	sub_8233E4E0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r4,r31,36
	ctx.r4.s64 = ctx.r31.s64 + 36;
	// bl 0x82257a50
	ctx.lr = 0x8211C720;
	sub_82257A50(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,4
	ctx.r6.s64 = 4;
	// lwz r3,28184(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28184);
	// rldicr r7,r7,63,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82238048
	ctx.lr = 0x8211C73C;
	sub_82238048(ctx, base);
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,4
	ctx.r6.s64 = 4;
	// rldicr r7,r7,62,1
	ctx.r7.u64 = rotl64(ctx.r7.u64, 62) & 0xC000000000000000;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,3
	ctx.r4.s64 = 3;
	// lwz r3,28184(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28184);
	// bl 0x82238120
	ctx.lr = 0x8211C758;
	sub_82238120(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211C770"))) PPC_WEAK_FUNC(sub_8211C770);
PPC_FUNC_IMPL(__imp__sub_8211C770) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x8211C778;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lhz r9,0(r4)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r4.u32 + 0);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r28,r6
	ctx.r28.u64 = ctx.r6.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// cmplwi cr6,r9,255
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 255, ctx.xer);
	// beq cr6,0x8211c7b0
	if (ctx.cr6.eq) goto loc_8211C7B0;
loc_8211C7A0:
	// lhzu r9,12(r10)
	ea = 12 + ctx.r10.u32;
	ctx.r9.u64 = PPC_LOAD_U16(ea);
	ctx.r10.u32 = ea;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// cmplwi cr6,r9,255
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 255, ctx.xer);
	// bne cr6,0x8211c7a0
	if (!ctx.cr6.eq) goto loc_8211C7A0;
loc_8211C7B0:
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r3,r11,56
	ctx.r3.s64 = ctx.r11.s64 + 56;
	// bl 0x82082c78
	ctx.lr = 0x8211C7C8;
	sub_82082C78(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211c7e0
	if (ctx.cr6.eq) goto loc_8211C7E0;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x822388f8
	ctx.lr = 0x8211C7E0;
	sub_822388F8(ctx, base);
loc_8211C7E0:
	// stw r31,4(r29)
	PPC_STORE_U32(ctx.r29.u32 + 4, ctx.r31.u32);
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82238638
	ctx.lr = 0x8211C7EC;
	sub_82238638(ctx, base);
	// stw r3,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r3.u32);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x8211c804
	if (ctx.cr6.eq) goto loc_8211C804;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82238290
	ctx.lr = 0x8211C800;
	sub_82238290(ctx, base);
	// stw r3,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r3.u32);
loc_8211C804:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211C810"))) PPC_WEAK_FUNC(sub_8211C810);
PPC_FUNC_IMPL(__imp__sub_8211C810) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,26
	ctx.r11.s64 = 1703936;
	// lis r9,42
	ctx.r9.s64 = 2752512;
	// ori r10,r11,9126
	ctx.r10.u64 = ctx.r11.u64 | 9126;
	// li r5,16
	ctx.r5.s64 = 16;
	// lis r6,44
	ctx.r6.s64 = 2883584;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// ori r11,r9,9145
	ctx.r11.u64 = ctx.r9.u64 | 9145;
	// sth r5,94(r1)
	PPC_STORE_U16(ctx.r1.u32 + 94, ctx.r5.u16);
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// li r31,0
	ctx.r31.s64 = 0;
	// li r7,5
	ctx.r7.s64 = 5;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// li r8,3
	ctx.r8.s64 = 3;
	// sth r31,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, ctx.r31.u16);
	// li r9,1
	ctx.r9.s64 = 1;
	// sth r31,82(r1)
	PPC_STORE_U16(ctx.r1.u32 + 82, ctx.r31.u16);
	// li r4,32
	ctx.r4.s64 = 32;
	// stb r31,90(r1)
	PPC_STORE_U8(ctx.r1.u32 + 90, ctx.r31.u8);
	// li r3,44
	ctx.r3.s64 = 44;
	// stb r31,88(r1)
	PPC_STORE_U8(ctx.r1.u32 + 88, ctx.r31.u8);
	// ori r6,r6,33700
	ctx.r6.u64 = ctx.r6.u64 | 33700;
	// stb r31,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, ctx.r31.u8);
	// li r5,255
	ctx.r5.s64 = 255;
	// sth r31,92(r1)
	PPC_STORE_U16(ctx.r1.u32 + 92, ctx.r31.u16);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stb r31,100(r1)
	PPC_STORE_U8(ctx.r1.u32 + 100, ctx.r31.u8);
	// li r30,56
	ctx.r30.s64 = 56;
	// stb r7,101(r1)
	PPC_STORE_U8(ctx.r1.u32 + 101, ctx.r7.u8);
	// stb r31,102(r1)
	PPC_STORE_U8(ctx.r1.u32 + 102, ctx.r31.u8);
	// sth r31,104(r1)
	PPC_STORE_U16(ctx.r1.u32 + 104, ctx.r31.u16);
	// sth r4,106(r1)
	PPC_STORE_U16(ctx.r1.u32 + 106, ctx.r4.u16);
	// stb r31,112(r1)
	PPC_STORE_U8(ctx.r1.u32 + 112, ctx.r31.u8);
	// stb r8,113(r1)
	PPC_STORE_U8(ctx.r1.u32 + 113, ctx.r8.u8);
	// stb r31,114(r1)
	PPC_STORE_U8(ctx.r1.u32 + 114, ctx.r31.u8);
	// sth r31,116(r1)
	PPC_STORE_U16(ctx.r1.u32 + 116, ctx.r31.u16);
	// sth r3,118(r1)
	PPC_STORE_U16(ctx.r1.u32 + 118, ctx.r3.u16);
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r11.u32);
	// stb r31,124(r1)
	PPC_STORE_U8(ctx.r1.u32 + 124, ctx.r31.u8);
	// stb r9,126(r1)
	PPC_STORE_U8(ctx.r1.u32 + 126, ctx.r9.u8);
	// stb r8,125(r1)
	PPC_STORE_U8(ctx.r1.u32 + 125, ctx.r8.u8);
	// sth r31,128(r1)
	PPC_STORE_U16(ctx.r1.u32 + 128, ctx.r31.u16);
	// sth r30,130(r1)
	PPC_STORE_U16(ctx.r1.u32 + 130, ctx.r30.u16);
	// stw r6,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r6.u32);
	// stb r31,136(r1)
	PPC_STORE_U8(ctx.r1.u32 + 136, ctx.r31.u8);
	// stb r7,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r7.u8);
	// stb r9,138(r1)
	PPC_STORE_U8(ctx.r1.u32 + 138, ctx.r9.u8);
	// sth r5,140(r1)
	PPC_STORE_U16(ctx.r1.u32 + 140, ctx.r5.u16);
	// sth r31,142(r1)
	PPC_STORE_U16(ctx.r1.u32 + 142, ctx.r31.u16);
	// stw r10,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r10.u32);
	// stb r31,148(r1)
	PPC_STORE_U8(ctx.r1.u32 + 148, ctx.r31.u8);
	// stb r31,149(r1)
	PPC_STORE_U8(ctx.r1.u32 + 149, ctx.r31.u8);
	// stb r31,150(r1)
	PPC_STORE_U8(ctx.r1.u32 + 150, ctx.r31.u8);
	// bl 0x82116360
	ctx.lr = 0x8211C8F8;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211c924
	if (ctx.cr6.eq) goto loc_8211C924;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r6,r11,21232
	ctx.r6.s64 = ctx.r11.s64 + 21232;
	// addi r5,r10,21536
	ctx.r5.s64 = ctx.r10.s64 + 21536;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211C918;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25620(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25620, ctx.r3.u32);
	// b 0x8211c930
	goto loc_8211C930;
loc_8211C924:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25620(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25620, ctx.r31.u32);
loc_8211C930:
	// bl 0x82116360
	ctx.lr = 0x8211C934;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211c960
	if (ctx.cr6.eq) goto loc_8211C960;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r6,r11,23184
	ctx.r6.s64 = ctx.r11.s64 + 23184;
	// addi r5,r10,24496
	ctx.r5.s64 = ctx.r10.s64 + 24496;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211C954;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25624(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25624, ctx.r3.u32);
	// b 0x8211c96c
	goto loc_8211C96C;
loc_8211C960:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25624(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25624, ctx.r31.u32);
loc_8211C96C:
	// bl 0x82116360
	ctx.lr = 0x8211C970;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211c99c
	if (ctx.cr6.eq) goto loc_8211C99C;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r6,r11,26368
	ctx.r6.s64 = ctx.r11.s64 + 26368;
	// addi r5,r10,27792
	ctx.r5.s64 = ctx.r10.s64 + 27792;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211C990;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25628(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25628, ctx.r3.u32);
	// b 0x8211c9a8
	goto loc_8211C9A8;
loc_8211C99C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25628(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25628, ctx.r31.u32);
loc_8211C9A8:
	// bl 0x82116360
	ctx.lr = 0x8211C9AC;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211c9d8
	if (ctx.cr6.eq) goto loc_8211C9D8;
	// lis r11,-32253
	ctx.r11.s64 = -2113732608;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// addi r6,r11,29712
	ctx.r6.s64 = ctx.r11.s64 + 29712;
	// addi r5,r10,31192
	ctx.r5.s64 = ctx.r10.s64 + 31192;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211C9CC;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25632(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25632, ctx.r3.u32);
	// b 0x8211c9e4
	goto loc_8211C9E4;
loc_8211C9D8:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25632(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25632, ctx.r31.u32);
loc_8211C9E4:
	// bl 0x82116360
	ctx.lr = 0x8211C9E8;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211ca14
	if (ctx.cr6.eq) goto loc_8211CA14;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,-32424
	ctx.r6.s64 = ctx.r11.s64 + -32424;
	// addi r5,r10,-31056
	ctx.r5.s64 = ctx.r10.s64 + -31056;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211CA08;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25636(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25636, ctx.r3.u32);
	// b 0x8211ca20
	goto loc_8211CA20;
loc_8211CA14:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25636(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25636, ctx.r31.u32);
loc_8211CA20:
	// bl 0x82116360
	ctx.lr = 0x8211CA24;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211ca50
	if (ctx.cr6.eq) goto loc_8211CA50;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,-29360
	ctx.r6.s64 = ctx.r11.s64 + -29360;
	// addi r5,r10,-28624
	ctx.r5.s64 = ctx.r10.s64 + -28624;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211CA44;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25640(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25640, ctx.r3.u32);
	// b 0x8211ca5c
	goto loc_8211CA5C;
loc_8211CA50:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25640(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25640, ctx.r31.u32);
loc_8211CA5C:
	// bl 0x82116360
	ctx.lr = 0x8211CA60;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211ca8c
	if (ctx.cr6.eq) goto loc_8211CA8C;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,-26936
	ctx.r6.s64 = ctx.r11.s64 + -26936;
	// addi r5,r10,-25392
	ctx.r5.s64 = ctx.r10.s64 + -25392;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211CA80;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25644(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25644, ctx.r3.u32);
	// b 0x8211ca98
	goto loc_8211CA98;
loc_8211CA8C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25644(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25644, ctx.r31.u32);
loc_8211CA98:
	// bl 0x82116360
	ctx.lr = 0x8211CA9C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cac8
	if (ctx.cr6.eq) goto loc_8211CAC8;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,-23480
	ctx.r6.s64 = ctx.r11.s64 + -23480;
	// addi r5,r10,-21808
	ctx.r5.s64 = ctx.r10.s64 + -21808;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211CABC;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25648(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25648, ctx.r3.u32);
	// b 0x8211cad4
	goto loc_8211CAD4;
loc_8211CAC8:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25648(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25648, ctx.r31.u32);
loc_8211CAD4:
	// bl 0x82116360
	ctx.lr = 0x8211CAD8;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cb04
	if (ctx.cr6.eq) goto loc_8211CB04;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,-19840
	ctx.r6.s64 = ctx.r11.s64 + -19840;
	// addi r5,r10,-18088
	ctx.r5.s64 = ctx.r10.s64 + -18088;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211CAF8;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25652(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25652, ctx.r3.u32);
	// b 0x8211cb10
	goto loc_8211CB10;
loc_8211CB04:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25652(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25652, ctx.r31.u32);
loc_8211CB10:
	// bl 0x82116360
	ctx.lr = 0x8211CB14;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cb40
	if (ctx.cr6.eq) goto loc_8211CB40;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,-16112
	ctx.r6.s64 = ctx.r11.s64 + -16112;
	// addi r5,r10,-14496
	ctx.r5.s64 = ctx.r10.s64 + -14496;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211CB34;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25656(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25656, ctx.r3.u32);
	// b 0x8211cb4c
	goto loc_8211CB4C;
loc_8211CB40:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25656(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25656, ctx.r31.u32);
loc_8211CB4C:
	// bl 0x82116360
	ctx.lr = 0x8211CB50;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cb7c
	if (ctx.cr6.eq) goto loc_8211CB7C;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,-12576
	ctx.r6.s64 = ctx.r11.s64 + -12576;
	// addi r5,r10,-11896
	ctx.r5.s64 = ctx.r10.s64 + -11896;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211CB70;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25660(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25660, ctx.r3.u32);
	// b 0x8211cb88
	goto loc_8211CB88;
loc_8211CB7C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25660(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25660, ctx.r31.u32);
loc_8211CB88:
	// bl 0x82116360
	ctx.lr = 0x8211CB8C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cbb8
	if (ctx.cr6.eq) goto loc_8211CBB8;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,-10216
	ctx.r6.s64 = ctx.r11.s64 + -10216;
	// addi r5,r10,-9672
	ctx.r5.s64 = ctx.r10.s64 + -9672;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211CBAC;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25664(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25664, ctx.r3.u32);
	// b 0x8211cbc4
	goto loc_8211CBC4;
loc_8211CBB8:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25664(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25664, ctx.r31.u32);
loc_8211CBC4:
	// bl 0x82116360
	ctx.lr = 0x8211CBC8;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cbf4
	if (ctx.cr6.eq) goto loc_8211CBF4;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,-7864
	ctx.r6.s64 = ctx.r11.s64 + -7864;
	// addi r5,r10,-7152
	ctx.r5.s64 = ctx.r10.s64 + -7152;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211CBE8;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25668(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25668, ctx.r3.u32);
	// b 0x8211cc00
	goto loc_8211CC00;
loc_8211CBF4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25668(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25668, ctx.r31.u32);
loc_8211CC00:
	// bl 0x82116360
	ctx.lr = 0x8211CC04;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cc30
	if (ctx.cr6.eq) goto loc_8211CC30;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,-5296
	ctx.r6.s64 = ctx.r11.s64 + -5296;
	// addi r5,r10,-4528
	ctx.r5.s64 = ctx.r10.s64 + -4528;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211CC24;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25672(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25672, ctx.r3.u32);
	// b 0x8211cc3c
	goto loc_8211CC3C;
loc_8211CC30:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25672(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25672, ctx.r31.u32);
loc_8211CC3C:
	// bl 0x82116360
	ctx.lr = 0x8211CC40;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cc6c
	if (ctx.cr6.eq) goto loc_8211CC6C;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,-2840
	ctx.r6.s64 = ctx.r11.s64 + -2840;
	// addi r5,r10,-2528
	ctx.r5.s64 = ctx.r10.s64 + -2528;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211CC60;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25676(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25676, ctx.r3.u32);
	// b 0x8211cc78
	goto loc_8211CC78;
loc_8211CC6C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,25676(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25676, ctx.r31.u32);
loc_8211CC78:
	// bl 0x82116360
	ctx.lr = 0x8211CC7C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cca8
	if (ctx.cr6.eq) goto loc_8211CCA8;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,-1136
	ctx.r6.s64 = ctx.r11.s64 + -1136;
	// addi r5,r10,-392
	ctx.r5.s64 = ctx.r10.s64 + -392;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8211CC9C;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25680(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25680, ctx.r3.u32);
	// b 0x8211ccb0
	goto loc_8211CCB0;
loc_8211CCA8:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// stw r31,25680(r11)
	PPC_STORE_U32(ctx.r11.u32 + 25680, ctx.r31.u32);
loc_8211CCB0:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211CCC8"))) PPC_WEAK_FUNC(sub_8211CCC8);
PPC_FUNC_IMPL(__imp__sub_8211CCC8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25620(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25620);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cce8
	if (ctx.cr6.eq) goto loc_8211CCE8;
	// bl 0x8211af20
	ctx.lr = 0x8211CCE8;
	sub_8211AF20(ctx, base);
loc_8211CCE8:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25624(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25624);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211ccfc
	if (ctx.cr6.eq) goto loc_8211CCFC;
	// bl 0x8211af20
	ctx.lr = 0x8211CCFC;
	sub_8211AF20(ctx, base);
loc_8211CCFC:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25628(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25628);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cd10
	if (ctx.cr6.eq) goto loc_8211CD10;
	// bl 0x8211af20
	ctx.lr = 0x8211CD10;
	sub_8211AF20(ctx, base);
loc_8211CD10:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25632(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25632);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cd24
	if (ctx.cr6.eq) goto loc_8211CD24;
	// bl 0x8211af20
	ctx.lr = 0x8211CD24;
	sub_8211AF20(ctx, base);
loc_8211CD24:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25636(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25636);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cd38
	if (ctx.cr6.eq) goto loc_8211CD38;
	// bl 0x8211af20
	ctx.lr = 0x8211CD38;
	sub_8211AF20(ctx, base);
loc_8211CD38:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25640(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25640);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cd4c
	if (ctx.cr6.eq) goto loc_8211CD4C;
	// bl 0x8211af20
	ctx.lr = 0x8211CD4C;
	sub_8211AF20(ctx, base);
loc_8211CD4C:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25644(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25644);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cd60
	if (ctx.cr6.eq) goto loc_8211CD60;
	// bl 0x8211af20
	ctx.lr = 0x8211CD60;
	sub_8211AF20(ctx, base);
loc_8211CD60:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25648(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25648);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cd74
	if (ctx.cr6.eq) goto loc_8211CD74;
	// bl 0x8211af20
	ctx.lr = 0x8211CD74;
	sub_8211AF20(ctx, base);
loc_8211CD74:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25652(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25652);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cd88
	if (ctx.cr6.eq) goto loc_8211CD88;
	// bl 0x8211af20
	ctx.lr = 0x8211CD88;
	sub_8211AF20(ctx, base);
loc_8211CD88:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25656(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25656);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cd9c
	if (ctx.cr6.eq) goto loc_8211CD9C;
	// bl 0x8211af20
	ctx.lr = 0x8211CD9C;
	sub_8211AF20(ctx, base);
loc_8211CD9C:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25660(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25660);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cdb0
	if (ctx.cr6.eq) goto loc_8211CDB0;
	// bl 0x8211af20
	ctx.lr = 0x8211CDB0;
	sub_8211AF20(ctx, base);
loc_8211CDB0:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25664(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25664);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cdc4
	if (ctx.cr6.eq) goto loc_8211CDC4;
	// bl 0x8211af20
	ctx.lr = 0x8211CDC4;
	sub_8211AF20(ctx, base);
loc_8211CDC4:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25668(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25668);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cdd8
	if (ctx.cr6.eq) goto loc_8211CDD8;
	// bl 0x8211af20
	ctx.lr = 0x8211CDD8;
	sub_8211AF20(ctx, base);
loc_8211CDD8:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25672(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25672);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211cdec
	if (ctx.cr6.eq) goto loc_8211CDEC;
	// bl 0x8211af20
	ctx.lr = 0x8211CDEC;
	sub_8211AF20(ctx, base);
loc_8211CDEC:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25676(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25676);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211ce00
	if (ctx.cr6.eq) goto loc_8211CE00;
	// bl 0x8211af20
	ctx.lr = 0x8211CE00;
	sub_8211AF20(ctx, base);
loc_8211CE00:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25680(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25680);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211ce14
	if (ctx.cr6.eq) goto loc_8211CE14;
	// bl 0x8211af20
	ctx.lr = 0x8211CE14;
	sub_8211AF20(ctx, base);
loc_8211CE14:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211CE24"))) PPC_WEAK_FUNC(sub_8211CE24);
PPC_FUNC_IMPL(__imp__sub_8211CE24) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211CE28"))) PPC_WEAK_FUNC(sub_8211CE28);
PPC_FUNC_IMPL(__imp__sub_8211CE28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e448
	ctx.lr = 0x8211CE30;
	__restfpr_20(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r26,0(r3)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x8211CE4C;
	sub_82111340(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,2020(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2020);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211ce88
	if (ctx.cr6.eq) goto loc_8211CE88;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1172(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// rlwinm r7,r8,0,0,29
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFC;
	// stw r7,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2020, ctx.r10.u32);
loc_8211CE88:
	// lbz r11,3369(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 3369);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211cfd4
	if (ctx.cr6.eq) goto loc_8211CFD4;
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// rlwinm r10,r11,0,5,5
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4000000;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211cf38
	if (ctx.cr6.eq) goto loc_8211CF38;
	// lwz r11,4(r20)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r20.u32 + 4);
	// li r3,3
	ctx.r3.s64 = 3;
	// addi r4,r11,276
	ctx.r4.s64 = ctx.r11.s64 + 276;
	// bl 0x82111400
	ctx.lr = 0x8211CEB4;
	sub_82111400(ctx, base);
	// lwz r11,2996(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2996);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211ced8
	if (ctx.cr6.eq) goto loc_8211CED8;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8222c248
	ctx.lr = 0x8211CED0;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2996(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2996, ctx.r11.u32);
loc_8211CED8:
	// lwz r11,3012(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3012);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211cefc
	if (ctx.cr6.eq) goto loc_8211CEFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8222c0a0
	ctx.lr = 0x8211CEF4;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,3012(r31)
	PPC_STORE_U32(ctx.r31.u32 + 3012, ctx.r11.u32);
loc_8211CEFC:
	// lwz r11,3028(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 3028);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211cfd4
	if (ctx.cr6.eq) goto loc_8211CFD4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r9,1
	ctx.r9.s64 = 1;
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1236(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1236);
	// rlwimi r7,r9,24,7,8
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 24) & 0x1800000) | (ctx.r7.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r7,1236(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1236, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,4096
	ctx.r5.u64 = ctx.r6.u64 | 268435456;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,3028(r31)
	PPC_STORE_U32(ctx.r31.u32 + 3028, ctx.r10.u32);
	// b 0x8211cfd4
	goto loc_8211CFD4;
loc_8211CF38:
	// lfs f0,3372(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 3372);
	ctx.f0.f64 = double(temp.f32);
	// li r12,1
	ctx.r12.s64 = 1;
	// stfs f0,6288(r26)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r26.u32 + 6288, temp.u32);
	// addi r11,r26,8
	ctx.r11.s64 = ctx.r26.s64 + 8;
	// lfs f13,3376(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 3376);
	ctx.f13.f64 = double(temp.f32);
	// rldicr r12,r12,59,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 59) & 0xFFFFFFFFFFFFFFFF;
	// stfs f13,6292(r26)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r26.u32 + 6292, temp.u32);
	// li r29,0
	ctx.r29.s64 = 0;
	// lfs f12,3380(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 3380);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,6296(r26)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r26.u32 + 6296, temp.u32);
	// lfs f11,3384(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 3384);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,6300(r26)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r26.u32 + 6300, temp.u32);
	// ld r11,8(r26)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r26.u32 + 8);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,8(r26)
	PPC_STORE_U64(ctx.r26.u32 + 8, ctx.r10.u64);
	// lwz r9,3460(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3460);
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// ble cr6,0x8211cfd4
	if (!ctx.cr6.gt) goto loc_8211CFD4;
	// li r11,1
	ctx.r11.s64 = 1;
	// addi r31,r30,3392
	ctx.r31.s64 = ctx.r30.s64 + 3392;
	// rldicr r28,r11,63,63
	ctx.r28.u64 = rotl64(ctx.r11.u64, 63) & 0xFFFFFFFFFFFFFFFF;
loc_8211CF8C:
	// lwz r4,-4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + -4);
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// rlwinm r10,r4,30,2,31
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// lwz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// add r11,r4,r6
	ctx.r11.u64 = ctx.r4.u64 + ctx.r6.u64;
	// addi r9,r11,-1
	ctx.r9.s64 = ctx.r11.s64 + -1;
	// rlwinm r8,r9,30,2,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
	// subf r7,r10,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r10.s64;
	// clrldi r11,r7,32
	ctx.r11.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// srad r9,r28,r11
	temp.u64 = ctx.r11.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r28.s64 < 0) & (((ctx.r28.s64 >> temp.u64) << temp.u64) != ctx.r28.s64);
	ctx.r9.s64 = ctx.r28.s64 >> temp.u64;
	// srd r7,r9,r10
	ctx.r7.u64 = ctx.r10.u8 & 0x40 ? 0 : (ctx.r9.u64 >> (ctx.r10.u8 & 0x7F));
	// bl 0x82238120
	ctx.lr = 0x8211CFC0;
	sub_82238120(ctx, base);
	// lwz r8,3460(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 3460);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r31,r31,12
	ctx.r31.s64 = ctx.r31.s64 + 12;
	// cmplw cr6,r29,r8
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r8.u32, ctx.xer);
	// blt cr6,0x8211cf8c
	if (ctx.cr6.lt) goto loc_8211CF8C;
loc_8211CFD4:
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// li r25,0
	ctx.r25.s64 = 0;
	// addi r9,r11,-27800
	ctx.r9.s64 = ctx.r11.s64 + -27800;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lwz r11,2120(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2120);
	// rlwinm r23,r11,30,31,31
	ctx.r23.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x1;
	// ble cr6,0x8211d100
	if (!ctx.cr6.gt) goto loc_8211D100;
	// li r29,3532
	ctx.r29.s64 = 3532;
	// addi r28,r30,96
	ctx.r28.s64 = ctx.r30.s64 + 96;
	// addi r22,r30,2816
	ctx.r22.s64 = ctx.r30.s64 + 2816;
	// addi r21,r30,-64
	ctx.r21.s64 = ctx.r30.s64 + -64;
	// subfic r24,r30,-96
	ctx.xer.ca = ctx.r30.u32 <= 4294967200;
	ctx.r24.s64 = -96 - ctx.r30.s64;
loc_8211D008:
	// lwz r11,-72(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + -72);
	// rlwinm r10,r11,0,20,20
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x800;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8211d0e4
	if (!ctx.cr6.eq) goto loc_8211D0E4;
	// lwz r31,12(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8211d034
	if (ctx.cr6.eq) goto loc_8211D034;
	// add r11,r31,r29
	ctx.r11.u64 = ctx.r31.u64 + ctx.r29.u64;
	// lwz r10,-32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8211d044
	if (!ctx.cr6.eq) goto loc_8211D044;
loc_8211D034:
	// add r11,r21,r29
	ctx.r11.u64 = ctx.r21.u64 + ctx.r29.u64;
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211d0e4
	if (ctx.cr6.eq) goto loc_8211D0E4;
loc_8211D044:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8211d05c
	if (ctx.cr6.eq) goto loc_8211D05C;
	// add r11,r31,r29
	ctx.r11.u64 = ctx.r31.u64 + ctx.r29.u64;
	// lwz r10,-64(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + -64);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x8211d068
	if (!ctx.cr6.eq) goto loc_8211D068;
loc_8211D05C:
	// lwzx r11,r21,r29
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + ctx.r29.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211d0e4
	if (ctx.cr6.eq) goto loc_8211D0E4;
loc_8211D068:
	// add r11,r25,r30
	ctx.r11.u64 = ctx.r25.u64 + ctx.r30.u64;
	// li r27,0
	ctx.r27.s64 = 0;
	// lbz r10,2744(r11)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r11.u32 + 2744);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211d080
	if (ctx.cr6.eq) goto loc_8211D080;
	// mr r27,r22
	ctx.r27.u64 = ctx.r22.u64;
loc_8211D080:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x8211d08c
	if (!ctx.cr6.eq) goto loc_8211D08C;
	// mr r31,r30
	ctx.r31.u64 = ctx.r30.u64;
loc_8211D08C:
	// li r7,15
	ctx.r7.s64 = 15;
	// li r6,15
	ctx.r6.s64 = 15;
	// rldicr r7,r7,33,30
	ctx.r7.u64 = rotl64(ctx.r7.u64, 33) & 0xFFFFFFFE00000000;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// li r4,108
	ctx.r4.s64 = 108;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82238048
	ctx.lr = 0x8211D0A8;
	sub_82238048(ctx, base);
	// add r7,r29,r31
	ctx.r7.u64 = ctx.r29.u64 + ctx.r31.u64;
	// add r11,r24,r28
	ctx.r11.u64 = ctx.r24.u64 + ctx.r28.u64;
	// add r5,r29,r31
	ctx.r5.u64 = ctx.r29.u64 + ctx.r31.u64;
	// add r11,r11,r31
	ctx.r11.u64 = ctx.r11.u64 + ctx.r31.u64;
	// mr r10,r23
	ctx.r10.u64 = ctx.r23.u64;
	// lwz r6,-64(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + -64);
	// addi r7,r11,24
	ctx.r7.s64 = ctx.r11.s64 + 24;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// mr r8,r27
	ctx.r8.u64 = ctx.r27.u64;
	// lwz r4,-32(r5)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r5.u32 + -32);
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// lbz r11,3368(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 3368);
	// lwzx r5,r29,r31
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r31.u32);
	// stb r11,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r11.u8);
	// bl 0x8211d130
	ctx.lr = 0x8211D0E4;
	sub_8211D130(ctx, base);
loc_8211D0E4:
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// addi r22,r22,64
	ctx.r22.s64 = ctx.r22.s64 + 64;
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// addi r28,r28,340
	ctx.r28.s64 = ctx.r28.s64 + 340;
	// cmplw cr6,r25,r11
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x8211d008
	if (ctx.cr6.lt) goto loc_8211D008;
loc_8211D100:
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x8211D10C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,3
	ctx.r3.s64 = 3;
	// bl 0x82111400
	ctx.lr = 0x8211D118;
	sub_82111400(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,4
	ctx.r3.s64 = 4;
	// bl 0x82111400
	ctx.lr = 0x8211D124;
	sub_82111400(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e498
	__restgprlr_20(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211D12C"))) PPC_WEAK_FUNC(sub_8211D12C);
PPC_FUNC_IMPL(__imp__sub_8211D12C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211D130"))) PPC_WEAK_FUNC(sub_8211D130);
PPC_FUNC_IMPL(__imp__sub_8211D130) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e454
	ctx.lr = 0x8211D138;
	__restfpr_23(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// mr r25,r5
	ctx.r25.u64 = ctx.r5.u64;
	// mr r23,r6
	ctx.r23.u64 = ctx.r6.u64;
	// mr r30,r7
	ctx.r30.u64 = ctx.r7.u64;
	// mr r28,r9
	ctx.r28.u64 = ctx.r9.u64;
	// mr r24,r10
	ctx.r24.u64 = ctx.r10.u64;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8211d178
	if (ctx.cr6.eq) goto loc_8211D178;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// li r5,64
	ctx.r5.s64 = 64;
	// mr r4,r8
	ctx.r4.u64 = ctx.r8.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x8211D174;
	sub_8233E4E0(ctx, base);
	// b 0x8211d1c8
	goto loc_8211D1C8;
loc_8211D178:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// lfs f0,48(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,36(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,136(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f0,132(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stfs f0,128(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f0,124(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f0,112(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f0,104(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f0,96(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f0,92(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f0,84(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f13,140(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// stfs f13,120(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
loc_8211D1C8:
	// lbz r26,311(r1)
	ctx.r26.u64 = PPC_LOAD_U8(ctx.r1.u32 + 311);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r6,20(r28)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r28.u32 + 20);
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// lfs f1,3360(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 3360);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8211d418
	ctx.lr = 0x8211D1E4;
	sub_8211D418(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,60
	ctx.r7.s64 = 60;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8211D200;
	sub_8222CC48(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cd68
	ctx.lr = 0x8211D20C;
	sub_8222CD68(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82113ab8
	ctx.lr = 0x8211D214;
	sub_82113AB8(ctx, base);
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x8211d284
	if (ctx.cr6.eq) goto loc_8211D284;
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f0,100(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,116(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 116);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,132(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 132);
	ctx.f12.f64 = double(temp.f32);
	// rldicr r12,r12,33,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 33) & 0xFFFFFFFFFFFFFFFF;
	// lfs f11,148(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 148);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,164(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 164);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,180(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 180);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,196(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 196);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,212(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 212);
	ctx.f7.f64 = double(temp.f32);
	// stfs f0,3888(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3888, temp.u32);
	// stfs f13,3892(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3892, temp.u32);
	// stfs f12,3896(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3896, temp.u32);
	// stfs f11,3900(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3900, temp.u32);
	// ld r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r10.u64);
	// li r12,1
	ctx.r12.s64 = 1;
	// stfs f10,3904(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3904, temp.u32);
	// stfs f9,3908(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3908, temp.u32);
	// rldicr r12,r12,32,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 32) & 0xFFFFFFFFFFFFFFFF;
	// stfs f8,3912(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3912, temp.u32);
	// stfs f7,3916(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3916, temp.u32);
	// ld r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r8,r9,r12
	ctx.r8.u64 = ctx.r9.u64 | ctx.r12.u64;
	// std r8,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r8.u64);
loc_8211D284:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211d2b8
	if (ctx.cr6.eq) goto loc_8211D2B8;
	// clrlwi r11,r24,24
	ctx.r11.u64 = ctx.r24.u32 & 0xFF;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r4,0
	ctx.r4.s64 = 0;
	// bne cr6,0x8211d2ac
	if (!ctx.cr6.eq) goto loc_8211D2AC;
	// lwz r4,316(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 316);
loc_8211D2AC:
	// bl 0x82113bc0
	ctx.lr = 0x8211D2B0;
	sub_82113BC0(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x8211d398
	goto loc_8211D398;
loc_8211D2B8:
	// lwz r30,316(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 316);
	// rlwinm r11,r11,0,26,26
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r3,100
	ctx.r3.s64 = 100;
	// addi r9,r10,28184
	ctx.r9.s64 = ctx.r10.s64 + 28184;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// beq cr6,0x8211d334
	if (ctx.cr6.eq) goto loc_8211D334;
	// li r11,4353
	ctx.r11.s64 = 4353;
	// stw r11,288(r9)
	PPC_STORE_U32(ctx.r9.u32 + 288, ctx.r11.u32);
	// bl 0x82111340
	ctx.lr = 0x8211D2E4;
	sub_82111340(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// li r3,96
	ctx.r3.s64 = 96;
	// li r4,1
	ctx.r4.s64 = 1;
	// bne cr6,0x8211d2f8
	if (!ctx.cr6.eq) goto loc_8211D2F8;
	// li r4,0
	ctx.r4.s64 = 0;
loc_8211D2F8:
	// bl 0x82111340
	ctx.lr = 0x8211D2FC;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x8211D308;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x8211D314;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x8211D320;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x8211D32C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x8211d38c
	goto loc_8211D38C;
loc_8211D334:
	// li r11,12545
	ctx.r11.s64 = 12545;
	// stw r11,288(r9)
	PPC_STORE_U32(ctx.r9.u32 + 288, ctx.r11.u32);
	// bl 0x82111340
	ctx.lr = 0x8211D340;
	sub_82111340(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// li r3,96
	ctx.r3.s64 = 96;
	// li r4,1
	ctx.r4.s64 = 1;
	// bne cr6,0x8211d354
	if (!ctx.cr6.eq) goto loc_8211D354;
	// li r4,0
	ctx.r4.s64 = 0;
loc_8211D354:
	// bl 0x82111340
	ctx.lr = 0x8211D358;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x8211D364;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x8211D370;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x8211D37C;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x8211D388;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
loc_8211D38C:
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x82111340
	ctx.lr = 0x8211D394;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
loc_8211D398:
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8211D3A0;
	sub_821112B0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x82111340
	ctx.lr = 0x8211D3AC;
	sub_82111340(ctx, base);
	// cmplwi cr6,r25,0
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, 0, ctx.xer);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,13
	ctx.r4.s64 = 13;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bne cr6,0x8211d3cc
	if (!ctx.cr6.eq) goto loc_8211D3CC;
	// rlwinm r6,r23,2,0,29
	ctx.r6.u64 = rotl64(ctx.r23.u32 | (ctx.r23.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8222dfc8
	ctx.lr = 0x8211D3C8;
	sub_8222DFC8(ctx, base);
	// b 0x8211d3d8
	goto loc_8211D3D8;
loc_8211D3CC:
	// rlwinm r7,r23,2,0,29
	ctx.r7.u64 = rotl64(ctx.r23.u32 | (ctx.r23.u64 << 32), 2) & 0xFFFFFFFC;
	// li r6,0
	ctx.r6.s64 = 0;
	// bl 0x8222e3e0
	ctx.lr = 0x8211D3D8;
	sub_8222E3E0(ctx, base);
loc_8211D3D8:
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x8211D3F4;
	sub_8222CC48(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cd68
	ctx.lr = 0x8211D400;
	sub_8222CD68(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8211D40C;
	sub_821112B0(ctx, base);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211D414"))) PPC_WEAK_FUNC(sub_8211D414);
PPC_FUNC_IMPL(__imp__sub_8211D414) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211D418"))) PPC_WEAK_FUNC(sub_8211D418);
PPC_FUNC_IMPL(__imp__sub_8211D418) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e44c
	ctx.lr = 0x8211D420;
	__restfpr_21(ctx, base);
	// stfd f29,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, ctx.f29.u64);
	// stfd f30,-112(r1)
	PPC_STORE_U64(ctx.r1.u32 + -112, ctx.f30.u64);
	// stfd f31,-104(r1)
	PPC_STORE_U64(ctx.r1.u32 + -104, ctx.f31.u64);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// lfs f0,312(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 312);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lwz r28,0(r3)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r9,r10,-27800
	ctx.r9.s64 = ctx.r10.s64 + -27800;
	// fmr f30,f1
	ctx.f30.f64 = ctx.f1.f64;
	// addi r29,r11,31376
	ctx.r29.s64 = ctx.r11.s64 + 31376;
	// mr r24,r6
	ctx.r24.u64 = ctx.r6.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// lwz r11,2120(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2120);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// lfs f31,48(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// li r22,1
	ctx.r22.s64 = 1;
	// addi r6,r11,-4
	ctx.r6.s64 = ctx.r11.s64 + -4;
	// lfs f29,36(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	ctx.f29.f64 = double(temp.f32);
	// rldicr r25,r8,36,63
	ctx.r25.u64 = rotl64(ctx.r8.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// cntlzw r5,r6
	ctx.r5.u64 = ctx.r6.u32 == 0 ? 32 : __builtin_clz(ctx.r6.u32);
	// li r23,0
	ctx.r23.s64 = 0;
	// li r21,0
	ctx.r21.s64 = 0;
	// addi r31,r10,28184
	ctx.r31.s64 = ctx.r10.s64 + 28184;
	// rlwinm r26,r5,27,31,31
	ctx.r26.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 27) & 0x1;
	// clrlwi r11,r7,24
	ctx.r11.u64 = ctx.r7.u32 & 0xFF;
	// bgt cr6,0x8211d534
	if (ctx.cr6.gt) goto loc_8211D534;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211d4a8
	if (ctx.cr6.eq) goto loc_8211D4A8;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r27,25676(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25676);
	// b 0x8211d700
	goto loc_8211D700;
loc_8211D4A8:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r10,r11,0,17,17
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211d528
	if (ctx.cr6.eq) goto loc_8211D528;
	// lwz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,44(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 44);
	// bne cr6,0x8211d4f8
	if (!ctx.cr6.eq) goto loc_8211D4F8;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211d4e4
	if (!ctx.cr6.eq) goto loc_8211D4E4;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// mr r23,r22
	ctx.r23.u64 = ctx.r22.u64;
	// li r21,2
	ctx.r21.s64 = 2;
	// lwz r27,25624(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25624);
	// b 0x8211d700
	goto loc_8211D700;
loc_8211D4E4:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// mr r23,r22
	ctx.r23.u64 = ctx.r22.u64;
	// li r21,2
	ctx.r21.s64 = 2;
	// lwz r27,25636(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25636);
	// b 0x8211d700
	goto loc_8211D700;
loc_8211D4F8:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211d514
	if (!ctx.cr6.eq) goto loc_8211D514;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// mr r23,r22
	ctx.r23.u64 = ctx.r22.u64;
	// li r21,2
	ctx.r21.s64 = 2;
	// lwz r27,25628(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25628);
	// b 0x8211d700
	goto loc_8211D700;
loc_8211D514:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// mr r23,r22
	ctx.r23.u64 = ctx.r22.u64;
	// li r21,2
	ctx.r21.s64 = 2;
	// lwz r27,25632(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25632);
	// b 0x8211d700
	goto loc_8211D700;
loc_8211D528:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r27,25620(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25620);
	// b 0x8211d700
	goto loc_8211D700;
loc_8211D534:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211d548
	if (ctx.cr6.eq) goto loc_8211D548;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r27,25680(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25680);
	// b 0x8211d5d0
	goto loc_8211D5D0;
loc_8211D548:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r10,r11,0,17,17
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211d5c8
	if (ctx.cr6.eq) goto loc_8211D5C8;
	// lwz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,44(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 44);
	// bne cr6,0x8211d598
	if (!ctx.cr6.eq) goto loc_8211D598;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211d584
	if (!ctx.cr6.eq) goto loc_8211D584;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// li r23,2
	ctx.r23.s64 = 2;
	// li r21,3
	ctx.r21.s64 = 3;
	// lwz r27,25644(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25644);
	// b 0x8211d5d0
	goto loc_8211D5D0;
loc_8211D584:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// li r23,2
	ctx.r23.s64 = 2;
	// li r21,3
	ctx.r21.s64 = 3;
	// lwz r27,25656(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25656);
	// b 0x8211d5d0
	goto loc_8211D5D0;
loc_8211D598:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211d5b4
	if (!ctx.cr6.eq) goto loc_8211D5B4;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// li r23,2
	ctx.r23.s64 = 2;
	// li r21,3
	ctx.r21.s64 = 3;
	// lwz r27,25648(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25648);
	// b 0x8211d5d0
	goto loc_8211D5D0;
loc_8211D5B4:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// li r23,2
	ctx.r23.s64 = 2;
	// li r21,3
	ctx.r21.s64 = 3;
	// lwz r27,25652(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25652);
	// b 0x8211d5d0
	goto loc_8211D5D0;
loc_8211D5C8:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r27,25640(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25640);
loc_8211D5D0:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lwz r11,4(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// rlwinm r9,r10,0,10,10
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200000;
	// addi r4,r11,16
	ctx.r4.s64 = ctx.r11.s64 + 16;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8211d5f0
	if (ctx.cr6.eq) goto loc_8211D5F0;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r4,25928(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25928);
loc_8211D5F0:
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111400
	ctx.lr = 0x8211D5F8;
	sub_82111400(ctx, base);
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211d61c
	if (ctx.cr6.eq) goto loc_8211D61C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x8211D614;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r11.u32);
loc_8211D61C:
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211d640
	if (ctx.cr6.eq) goto loc_8211D640;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x8211D638;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r11.u32);
loc_8211D640:
	// lwz r11,2388(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2388);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211d674
	if (ctx.cr6.eq) goto loc_8211D674;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r10,r11,24
	ctx.r10.s64 = ctx.r11.s64 + 24;
	// lwz r10,1188(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1188);
	// rlwinm r8,r10,0,9,6
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFE7FFFFF;
	// stw r8,1188(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1188, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r9,2388(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2388, ctx.r9.u32);
loc_8211D674:
	// lfs f0,312(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 312);
	ctx.f0.f64 = double(temp.f32);
	// stfs f31,7756(r28)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r28.u32 + 7756, temp.u32);
	// fdivs f13,f29,f0
	ctx.f13.f64 = double(float(ctx.f29.f64 / ctx.f0.f64));
	// stfs f30,7748(r28)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r28.u32 + 7748, temp.u32);
	// stfs f31,7752(r28)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r28.u32 + 7752, temp.u32);
	// stfs f13,7744(r28)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r28.u32 + 7744, temp.u32);
	// ld r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r28.u32 + 8);
	// or r10,r11,r25
	ctx.r10.u64 = ctx.r11.u64 | ctx.r25.u64;
	// std r10,8(r28)
	PPC_STORE_U64(ctx.r28.u32 + 8, ctx.r10.u64);
	// lwz r11,2292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2292);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211d6cc
	if (ctx.cr6.eq) goto loc_8211D6CC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r22,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r22.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2292, ctx.r10.u32);
loc_8211D6CC:
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211d700
	if (ctx.cr6.eq) goto loc_8211D700;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r8,r22,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r22.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,16384
	ctx.r6.u64 = ctx.r7.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r10.u32);
loc_8211D700:
	// clrlwi r26,r26,24
	ctx.r26.u64 = ctx.r26.u32 & 0xFF;
	// lfs f30,244(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 244);
	ctx.f30.f64 = double(temp.f32);
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// beq cr6,0x8211d768
	if (ctx.cr6.eq) goto loc_8211D768;
	// lwz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211d728
	if (!ctx.cr6.eq) goto loc_8211D728;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r27,25664(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25664);
	// b 0x8211d730
	goto loc_8211D730;
loc_8211D728:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r27,25668(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25668);
loc_8211D730:
	// lwz r10,316(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 316);
	// stfs f31,7772(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r28.u32 + 7772, temp.u32);
	// stfs f31,7764(r28)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r28.u32 + 7764, temp.u32);
	// stfs f31,7768(r28)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r28.u32 + 7768, temp.u32);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f0
	ctx.f13.f64 = double(ctx.f0.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// fmuls f11,f12,f30
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// stfs f11,7760(r28)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r28.u32 + 7760, temp.u32);
	// ld r9,8(r28)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r28.u32 + 8);
	// or r8,r9,r25
	ctx.r8.u64 = ctx.r9.u64 | ctx.r25.u64;
	// std r8,8(r28)
	PPC_STORE_U64(ctx.r28.u32 + 8, ctx.r8.u64);
	// b 0x8211d7bc
	goto loc_8211D7BC;
loc_8211D768:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r10,r11,0,17,17
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211d7bc
	if (ctx.cr6.eq) goto loc_8211D7BC;
	// rlwinm r11,r11,0,25,25
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211d7bc
	if (ctx.cr6.eq) goto loc_8211D7BC;
	// lfs f0,312(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 312);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// bne cr6,0x8211d7bc
	if (!ctx.cr6.eq) goto loc_8211D7BC;
	// rlwinm r11,r24,0,5,5
	ctx.r11.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0x4000000;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211d7bc
	if (ctx.cr6.eq) goto loc_8211D7BC;
	// lwz r11,44(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 44);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211d7b4
	if (!ctx.cr6.eq) goto loc_8211D7B4;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r27,25660(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25660);
	// b 0x8211d7bc
	goto loc_8211D7BC;
loc_8211D7B4:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r27,25672(r11)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25672);
loc_8211D7BC:
	// lwz r11,4(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r11,12216(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12216, ctx.r11.u32);
	// ld r10,16(r28)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r28.u32 + 16);
	// oris r9,r10,8
	ctx.r9.u64 = ctx.r10.u64 | 524288;
	// std r9,16(r28)
	PPC_STORE_U64(ctx.r28.u32 + 16, ctx.r9.u64);
	// lwz r4,8(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x8211D7DC;
	sub_82238728(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r4,0(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x8211D7E8;
	sub_82238380(ctx, base);
	// lwz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211d93c
	if (ctx.cr6.eq) goto loc_8211D93C;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82111400
	ctx.lr = 0x8211D800;
	sub_82111400(ctx, base);
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r10,r11,0,22,22
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x200;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211d878
	if (ctx.cr6.eq) goto loc_8211D878;
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211d844
	if (ctx.cr6.eq) goto loc_8211D844;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwinm r7,r8,0,22,18
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFE3FF;
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_8211D844:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211d8bc
	if (ctx.cr6.eq) goto loc_8211D8BC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwinm r7,r8,0,19,15
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFF1FFF;
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// b 0x8211d8b8
	goto loc_8211D8B8;
loc_8211D878:
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111390
	ctx.lr = 0x8211D888;
	sub_82111390(ctx, base);
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211d8bc
	if (ctx.cr6.eq) goto loc_8211D8BC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r22,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r22.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
loc_8211D8B8:
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_8211D8BC:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8211d8e0
	if (ctx.cr6.eq) goto loc_8211D8E0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8211D8D8;
	sub_8222C248(ctx, base);
	// mr r11,r22
	ctx.r11.u64 = ctx.r22.u64;
	// stw r22,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r22.u32);
loc_8211D8E0:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8211d904
	if (ctx.cr6.eq) goto loc_8211D904;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x8211D8FC;
	sub_8222C0A0(ctx, base);
	// mr r11,r22
	ctx.r11.u64 = ctx.r22.u64;
	// stw r22,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r22.u32);
loc_8211D904:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8211d944
	if (ctx.cr6.eq) goto loc_8211D944;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r22
	ctx.r10.u64 = ctx.r22.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1164(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r8,r22,23,7,8
	ctx.r8.u64 = (rotl32(ctx.r22.u32, 23) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r22,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r22.u32);
	// b 0x8211d944
	goto loc_8211D944;
loc_8211D93C:
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8211D944;
	sub_82111400(ctx, base);
loc_8211D944:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// rlwinm r10,r11,0,17,17
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211dab0
	if (ctx.cr6.eq) goto loc_8211DAB0;
	// lwz r11,40(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211d9bc
	if (ctx.cr6.eq) goto loc_8211D9BC;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82111400
	ctx.lr = 0x8211D96C;
	sub_82111400(ctx, base);
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// rlwinm r10,r11,0,22,22
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x200;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211d9a0
	if (ctx.cr6.eq) goto loc_8211D9A0;
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x82111390
	ctx.lr = 0x8211D98C;
	sub_82111390(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82111390
	ctx.lr = 0x8211D99C;
	sub_82111390(ctx, base);
	// b 0x8211d9c4
	goto loc_8211D9C4;
loc_8211D9A0:
	// li r5,2
	ctx.r5.s64 = 2;
	// bl 0x82111390
	ctx.lr = 0x8211D9A8;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// bl 0x82111390
	ctx.lr = 0x8211D9B8;
	sub_82111390(ctx, base);
	// b 0x8211d9c4
	goto loc_8211D9C4;
loc_8211D9BC:
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8211D9C4;
	sub_82111400(ctx, base);
loc_8211D9C4:
	// lwz r11,44(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 44);
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211da2c
	if (ctx.cr6.eq) goto loc_8211DA2C;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82111400
	ctx.lr = 0x8211D9DC;
	sub_82111400(ctx, base);
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// rlwinm r10,r11,0,22,22
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x200;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211da10
	if (ctx.cr6.eq) goto loc_8211DA10;
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x82111390
	ctx.lr = 0x8211D9FC;
	sub_82111390(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x82111390
	ctx.lr = 0x8211DA0C;
	sub_82111390(ctx, base);
	// b 0x8211da34
	goto loc_8211DA34;
loc_8211DA10:
	// li r5,2
	ctx.r5.s64 = 2;
	// bl 0x82111390
	ctx.lr = 0x8211DA18;
	sub_82111390(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x82111390
	ctx.lr = 0x8211DA28;
	sub_82111390(ctx, base);
	// b 0x8211da34
	goto loc_8211DA34;
loc_8211DA2C:
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x8211DA34;
	sub_82111400(ctx, base);
loc_8211DA34:
	// lwz r11,44(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 44);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211da48
	if (ctx.cr6.eq) goto loc_8211DA48;
	// fmr f0,f29
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f29.f64;
	// b 0x8211da4c
	goto loc_8211DA4C;
loc_8211DA48:
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64;
loc_8211DA4C:
	// lfs f13,48(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// cmplwi cr6,r26,0
	ctx.cr6.compare<uint32_t>(ctx.r26.u32, 0, ctx.xer);
	// lfs f12,52(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	ctx.f12.f64 = double(temp.f32);
	// beq cr6,0x8211da60
	if (ctx.cr6.eq) goto loc_8211DA60;
	// fmuls f0,f0,f30
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
loc_8211DA60:
	// stfs f0,6304(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + 6304, temp.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// stfs f12,6316(r28)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + 6316, temp.u32);
	// stfs f31,6308(r28)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r28.u32 + 6308, temp.u32);
	// rldicr r11,r11,59,63
	ctx.r11.u64 = rotl64(ctx.r11.u64, 59) & 0xFFFFFFFFFFFFFFFF;
	// stfs f13,6312(r28)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r28.u32 + 6312, temp.u32);
	// ld r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r28.u32 + 8);
	// or r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 | ctx.r11.u64;
	// std r9,8(r28)
	PPC_STORE_U64(ctx.r28.u32 + 8, ctx.r9.u64);
	// lfs f0,56(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6320(r28)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r28.u32 + 6320, temp.u32);
	// lfs f13,60(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,6324(r28)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r28.u32 + 6324, temp.u32);
	// lfs f12,64(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 64);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,6328(r28)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r28.u32 + 6328, temp.u32);
	// lfs f11,68(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 68);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,6332(r28)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r28.u32 + 6332, temp.u32);
	// ld r8,8(r28)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r28.u32 + 8);
	// or r7,r8,r11
	ctx.r7.u64 = ctx.r8.u64 | ctx.r11.u64;
	// std r7,8(r28)
	PPC_STORE_U64(ctx.r28.u32 + 8, ctx.r7.u64);
loc_8211DAB0:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// lfd f29,-120(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// lfd f30,-112(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// lfd f31,-104(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211DAC4"))) PPC_WEAK_FUNC(sub_8211DAC4);
PPC_FUNC_IMPL(__imp__sub_8211DAC4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211DAC8"))) PPC_WEAK_FUNC(sub_8211DAC8);
PPC_FUNC_IMPL(__imp__sub_8211DAC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8211DAD0;
	__restfpr_28(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,0
	ctx.r11.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// stb r11,118(r3)
	PPC_STORE_U8(ctx.r3.u32 + 118, ctx.r11.u8);
	// lis r11,1168
	ctx.r11.s64 = 76546048;
	// lwz r10,28(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// addi r30,r3,40
	ctx.r30.s64 = ctx.r3.s64 + 40;
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// li r28,3
	ctx.r28.s64 = 3;
	// lwz r9,32(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// ori r29,r11,2
	ctx.r29.u64 = ctx.r11.u64 | 2;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// lwz r8,608(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 608);
	// addic r7,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r7.s64 = ctx.r8.s64 + -1;
	// subfe r6,r7,r8
	temp.u8 = (~ctx.r7.u32 + ctx.r8.u32 < ~ctx.r7.u32) | (~ctx.r7.u32 + ctx.r8.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r6.u64 = ~ctx.r7.u64 + ctx.r8.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// stb r6,116(r3)
	PPC_STORE_U8(ctx.r3.u32 + 116, ctx.r6.u8);
loc_8211DB10:
	// li r10,3
	ctx.r10.s64 = 3;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x82237678
	ctx.lr = 0x8211DB34;
	sub_82237678(ctx, base);
	// stw r3,-20(r30)
	PPC_STORE_U32(ctx.r30.u32 + -20, ctx.r3.u32);
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// li r10,3
	ctx.r10.s64 = 3;
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// rlwinm r4,r7,31,1,31
	ctx.r4.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 31) & 0x7FFFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// rlwinm r3,r11,31,1,31
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x82237678
	ctx.lr = 0x8211DB64;
	sub_82237678(ctx, base);
	// stw r3,-8(r30)
	PPC_STORE_U32(ctx.r30.u32 + -8, ctx.r3.u32);
	// lwz r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// li r10,3
	ctx.r10.s64 = 3;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// rlwinm r3,r6,31,1,31
	ctx.r3.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r4,r5,31,1,31
	ctx.r4.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 31) & 0x7FFFFFFF;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x82237678
	ctx.lr = 0x8211DB94;
	sub_82237678(ctx, base);
	// stw r3,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r3.u32);
	// lbz r4,116(r31)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r31.u32 + 116);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x8211dc20
	if (ctx.cr6.eq) goto loc_8211DC20;
	// li r10,3
	ctx.r10.s64 = 3;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r8,r29
	ctx.r8.u64 = ctx.r29.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x82237678
	ctx.lr = 0x8211DBC8;
	sub_82237678(ctx, base);
	// stw r3,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r3.u32);
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// rotlwi r3,r3,0
	ctx.r3.u64 = rotl32(ctx.r3.u32, 0);
	// addi r9,r1,116
	ctx.r9.s64 = ctx.r1.s64 + 116;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82236c58
	ctx.lr = 0x8211DBF0;
	sub_82236C58(ctx, base);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mullw r5,r10,r11
	ctx.r5.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// bl 0x8233eaf0
	ctx.lr = 0x8211DC08;
	sub_8233EAF0(ctx, base);
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// lwz r9,48(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// lwz r8,32(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// rlwinm r5,r9,0,0,19
	ctx.r5.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFF000;
	// rlwinm r4,r8,0,0,19
	ctx.r4.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFF000;
	// bl 0x8222ee68
	ctx.lr = 0x8211DC20;
	sub_8222EE68(ctx, base);
loc_8211DC20:
	// addi r10,r1,120
	ctx.r10.s64 = ctx.r1.s64 + 120;
	// lwz r3,-20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + -20);
	// addi r9,r1,124
	ctx.r9.s64 = ctx.r1.s64 + 124;
	// addi r8,r1,92
	ctx.r8.s64 = ctx.r1.s64 + 92;
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82236c58
	ctx.lr = 0x8211DC44;
	sub_82236C58(ctx, base);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,88(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mullw r5,r10,r11
	ctx.r5.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r11.s32);
	// bl 0x8233eaf0
	ctx.lr = 0x8211DC5C;
	sub_8233EAF0(ctx, base);
	// lwz r3,-20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + -20);
	// lwz r9,48(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// lwz r8,32(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// rlwinm r5,r9,0,0,19
	ctx.r5.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFF000;
	// rlwinm r4,r8,0,0,19
	ctx.r4.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFF000;
	// bl 0x8222ee68
	ctx.lr = 0x8211DC74;
	sub_8222EE68(ctx, base);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// addi r9,r1,132
	ctx.r9.s64 = ctx.r1.s64 + 132;
	// lwz r3,-8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + -8);
	// addi r8,r1,100
	ctx.r8.s64 = ctx.r1.s64 + 100;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82236c58
	ctx.lr = 0x8211DC98;
	sub_82236C58(ctx, base);
	// lwz r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r6,100(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mullw r5,r6,r7
	ctx.r5.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r7.s32);
	// rlwinm r5,r5,31,1,31
	ctx.r5.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 31) & 0x7FFFFFFF;
	// bl 0x8233eaf0
	ctx.lr = 0x8211DCB4;
	sub_8233EAF0(ctx, base);
	// lwz r3,-8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + -8);
	// lwz r4,48(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// lwz r11,32(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// rlwinm r5,r4,0,0,19
	ctx.r5.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFF000;
	// rlwinm r4,r11,0,0,19
	ctx.r4.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFF000;
	// bl 0x8222ee68
	ctx.lr = 0x8211DCCC;
	sub_8222EE68(ctx, base);
	// addi r10,r1,136
	ctx.r10.s64 = ctx.r1.s64 + 136;
	// addi r9,r1,140
	ctx.r9.s64 = ctx.r1.s64 + 140;
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// addi r8,r1,108
	ctx.r8.s64 = ctx.r1.s64 + 108;
	// addi r7,r1,104
	ctx.r7.s64 = ctx.r1.s64 + 104;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82236c58
	ctx.lr = 0x8211DCF0;
	sub_82236C58(ctx, base);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// lwz r9,108(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,104(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// mullw r8,r9,r10
	ctx.r8.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// rlwinm r5,r8,31,1,31
	ctx.r5.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 31) & 0x7FFFFFFF;
	// bl 0x8233eaf0
	ctx.lr = 0x8211DD0C;
	sub_8233EAF0(ctx, base);
	// lwzu r3,4(r30)
	ea = 4 + ctx.r30.u32;
	ctx.r3.u64 = PPC_LOAD_U32(ea);
	ctx.r30.u32 = ea;
	// lwz r7,48(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// lwz r6,32(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// rlwinm r5,r7,0,0,19
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFF000;
	// rlwinm r4,r6,0,0,19
	ctx.r4.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFF000;
	// bl 0x8222ee68
	ctx.lr = 0x8211DD24;
	sub_8222EE68(ctx, base);
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// bne 0x8211db10
	if (!ctx.cr0.eq) goto loc_8211DB10;
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,117(r31)
	PPC_STORE_U8(ctx.r31.u32 + 117, ctx.r11.u8);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211DD3C"))) PPC_WEAK_FUNC(sub_8211DD3C);
PPC_FUNC_IMPL(__imp__sub_8211DD3C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211DD40"))) PPC_WEAK_FUNC(sub_8211DD40);
PPC_FUNC_IMPL(__imp__sub_8211DD40) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r9,-21846
	ctx.r9.s64 = -1431699456;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// ori r8,r9,43691
	ctx.r8.u64 = ctx.r9.u64 | 43691;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mulhwu r7,r11,r8
	ctx.r7.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r8.u32)) >> 32;
	// rlwinm r6,r7,31,1,31
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 31) & 0x7FFFFFFF;
	// addi r10,r1,88
	ctx.r10.s64 = ctx.r1.s64 + 88;
	// rlwinm r5,r6,1,0,30
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r1,92
	ctx.r9.s64 = ctx.r1.s64 + 92;
	// add r5,r6,r5
	ctx.r5.u64 = ctx.r6.u64 + ctx.r5.u64;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// subf r11,r5,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r5.s64;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r11.u32);
	// addi r3,r11,5
	ctx.r3.s64 = ctx.r11.s64 + 5;
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwzx r3,r11,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	// bl 0x82236c58
	ctx.lr = 0x8211DDB0;
	sub_82236C58(ctx, base);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r10,r1,92
	ctx.r10.s64 = ctx.r1.s64 + 92;
	// stw r5,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r5.u32);
	// addi r9,r1,88
	ctx.r9.s64 = ctx.r1.s64 + 88;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mullw r3,r4,r11
	ctx.r3.s64 = int64_t(ctx.r4.s32) * int64_t(ctx.r11.s32);
	// stw r3,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r3.u32);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// stw r11,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r11.u32);
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r11,r11,8
	ctx.r11.s64 = ctx.r11.s64 + 8;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwzx r3,r3,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r31.u32);
	// bl 0x82236c58
	ctx.lr = 0x8211DDFC;
	sub_82236C58(ctx, base);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r10,r1,92
	ctx.r10.s64 = ctx.r1.s64 + 92;
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r9,r1,88
	ctx.r9.s64 = ctx.r1.s64 + 88;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r5,12(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12, ctx.r5.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// rlwinm r3,r4,31,1,31
	ctx.r3.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 31) & 0x7FFFFFFF;
	// mullw r4,r3,r11
	ctx.r4.s64 = int64_t(ctx.r3.s32) * int64_t(ctx.r11.s32);
	// stw r11,20(r30)
	PPC_STORE_U32(ctx.r30.u32 + 20, ctx.r11.u32);
	// stw r4,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r4.u32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r3,r11,11
	ctx.r3.s64 = ctx.r11.s64 + 11;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwzx r3,r11,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	// bl 0x82236c58
	ctx.lr = 0x8211DE4C;
	sub_82236C58(ctx, base);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r10,24(r30)
	PPC_STORE_U32(ctx.r30.u32 + 24, ctx.r10.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// rlwinm r8,r9,31,1,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x7FFFFFFF;
	// mullw r7,r8,r11
	ctx.r7.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r11.s32);
	// stw r11,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r11.u32);
	// stw r7,28(r30)
	PPC_STORE_U32(ctx.r30.u32 + 28, ctx.r7.u32);
	// lbz r6,116(r31)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r31.u32 + 116);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// beq cr6,0x8211dec4
	if (ctx.cr6.eq) goto loc_8211DEC4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r10,r1,92
	ctx.r10.s64 = ctx.r1.s64 + 92;
	// addi r9,r1,88
	ctx.r9.s64 = ctx.r1.s64 + 88;
	// addi r11,r11,14
	ctx.r11.s64 = ctx.r11.s64 + 14;
	// addi r8,r1,84
	ctx.r8.s64 = ctx.r1.s64 + 84;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwzx r3,r3,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r31.u32);
	// bl 0x82236c58
	ctx.lr = 0x8211DEA8;
	sub_82236C58(ctx, base);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r10,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r10.u32);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// mullw r8,r9,r11
	ctx.r8.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r11.s32);
	// stw r8,40(r30)
	PPC_STORE_U32(ctx.r30.u32 + 40, ctx.r8.u32);
	// b 0x8211ded0
	goto loc_8211DED0;
loc_8211DEC4:
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r11.u32);
	// stw r11,40(r30)
	PPC_STORE_U32(ctx.r30.u32 + 40, ctx.r11.u32);
loc_8211DED0:
	// stw r11,44(r30)
	PPC_STORE_U32(ctx.r30.u32 + 44, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211DEEC"))) PPC_WEAK_FUNC(sub_8211DEEC);
PPC_FUNC_IMPL(__imp__sub_8211DEEC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211DEF0"))) PPC_WEAK_FUNC(sub_8211DEF0);
PPC_FUNC_IMPL(__imp__sub_8211DEF0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// addi r11,r11,5
	ctx.r11.s64 = ctx.r11.s64 + 5;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r10,r3
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// lwz r9,48(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// lwz r8,32(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// rlwinm r5,r9,0,0,19
	ctx.r5.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFF000;
	// rlwinm r4,r8,0,0,19
	ctx.r4.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFF000;
	// bl 0x8222ee68
	ctx.lr = 0x8211DF28;
	sub_8222EE68(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r7,r11,8
	ctx.r7.s64 = ctx.r11.s64 + 8;
	// rlwinm r6,r7,2,0,29
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r6,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r31.u32);
	// lwz r5,48(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// lwz r4,32(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// rlwinm r5,r5,0,0,19
	ctx.r5.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFFF000;
	// rlwinm r4,r4,0,0,19
	ctx.r4.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFF000;
	// bl 0x8222ee68
	ctx.lr = 0x8211DF4C;
	sub_8222EE68(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r3,r11,11
	ctx.r3.s64 = ctx.r11.s64 + 11;
	// rlwinm r11,r3,2,0,29
	ctx.r11.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r31.u32);
	// lwz r10,48(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// lwz r9,32(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// rlwinm r5,r10,0,0,19
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFF000;
	// rlwinm r4,r9,0,0,19
	ctx.r4.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFF000;
	// bl 0x8222ee68
	ctx.lr = 0x8211DF70;
	sub_8222EE68(ctx, base);
	// lbz r8,116(r31)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r31.u32 + 116);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8211dfbc
	if (ctx.cr6.eq) goto loc_8211DFBC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r11,r11,14
	ctx.r11.s64 = ctx.r11.s64 + 14;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r10,r31
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r31.u32);
	// lwz r9,48(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// lwz r8,32(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// rlwinm r5,r9,0,0,19
	ctx.r5.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFF000;
	// rlwinm r4,r8,0,0,19
	ctx.r4.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFF000;
	// bl 0x8222ee68
	ctx.lr = 0x8211DFA0;
	sub_8222EE68(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// stb r7,118(r31)
	PPC_STORE_U8(ctx.r31.u32 + 118, ctx.r7.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_8211DFBC:
	// li r11,1
	ctx.r11.s64 = 1;
	// stb r11,118(r31)
	PPC_STORE_U8(ctx.r31.u32 + 118, ctx.r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211DFD8"))) PPC_WEAK_FUNC(sub_8211DFD8);
PPC_FUNC_IMPL(__imp__sub_8211DFD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e44c
	ctx.lr = 0x8211DFE0;
	__restfpr_21(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lbz r10,118(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 118);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mr r21,r4
	ctx.r21.u64 = ctx.r4.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lwz r31,25776(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25776);
	// lwz r30,25772(r9)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25772);
	// beq cr6,0x8211e2c8
	if (ctx.cr6.eq) goto loc_8211E2C8;
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r11,r11,5
	ctx.r11.s64 = ctx.r11.s64 + 5;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r10,r24
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r24.u32);
	// bl 0x82111400
	ctx.lr = 0x8211E020;
	sub_82111400(ctx, base);
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r9,r11,8
	ctx.r9.s64 = ctx.r11.s64 + 8;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r8,r24
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r24.u32);
	// bl 0x82111400
	ctx.lr = 0x8211E038;
	sub_82111400(ctx, base);
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// li r3,2
	ctx.r3.s64 = 2;
	// addi r7,r11,11
	ctx.r7.s64 = ctx.r11.s64 + 11;
	// rlwinm r6,r7,2,0,29
	ctx.r6.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r6,r24
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r24.u32);
	// bl 0x82111400
	ctx.lr = 0x8211E050;
	sub_82111400(ctx, base);
	// lbz r5,116(r24)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r24.u32 + 116);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r27,r11,28184
	ctx.r27.s64 = ctx.r11.s64 + 28184;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x8211e0e0
	if (ctx.cr6.eq) goto loc_8211E0E0;
	// lwz r11,0(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 0);
	// li r3,3
	ctx.r3.s64 = 3;
	// addi r11,r11,14
	ctx.r11.s64 = ctx.r11.s64 + 14;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r10,r24
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r24.u32);
	// bl 0x82111400
	ctx.lr = 0x8211E07C;
	sub_82111400(ctx, base);
	// li r11,12545
	ctx.r11.s64 = 12545;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r11,288(r27)
	PPC_STORE_U32(ctx.r27.u32 + 288, ctx.r11.u32);
	// li r3,100
	ctx.r3.s64 = 100;
	// bl 0x82111340
	ctx.lr = 0x8211E090;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82111340
	ctx.lr = 0x8211E09C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x8211E0A8;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x8211E0B4;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x8211E0C0;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x8211E0CC;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x82111340
	ctx.lr = 0x8211E0D8;
	sub_82111340(ctx, base);
	// mr r22,r31
	ctx.r22.u64 = ctx.r31.u64;
	// b 0x8211e0f0
	goto loc_8211E0F0;
loc_8211E0E0:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x8211E0EC;
	sub_82113BC0(ctx, base);
	// mr r22,r30
	ctx.r22.u64 = ctx.r30.u64;
loc_8211E0F0:
	// lbz r11,116(r24)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r24.u32 + 116);
	// li r29,0
	ctx.r29.s64 = 0;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r9,r10,27,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r8,r9,1
	ctx.r8.u64 = ctx.r9.u64 ^ 1;
	// addic. r23,r8,3
	ctx.xer.ca = ctx.r8.u32 > 4294967292;
	ctx.r23.s64 = ctx.r8.s64 + 3;
	ctx.cr0.compare<int32_t>(ctx.r23.s32, 0, ctx.xer);
	// beq 0x8211e22c
	if (ctx.cr0.eq) goto loc_8211E22C;
	// li r11,1
	ctx.r11.s64 = 1;
	// li r30,1152
	ctx.r30.s64 = 1152;
	// addi r31,r27,1988
	ctx.r31.s64 = ctx.r27.s64 + 1988;
	// li r26,1
	ctx.r26.s64 = 1;
	// rldicr r28,r11,63,63
	ctx.r28.u64 = rotl64(ctx.r11.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// li r25,2
	ctx.r25.s64 = 2;
loc_8211E124:
	// lwz r11,-16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -16);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211e160
	if (ctx.cr6.eq) goto loc_8211E160;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r10,r29,32
	ctx.r10.s64 = ctx.r29.s64 + 32;
	// clrldi r8,r10,32
	ctx.r8.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// srd r6,r28,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r8.u8 & 0x7F));
	// lwzx r7,r30,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// rlwimi r7,r26,11,19,21
	ctx.r7.u64 = (rotl32(ctx.r26.u32, 11) & 0x1C00) | (ctx.r7.u64 & 0xFFFFFFFFFFFFE3FF);
	// stwx r7,r30,r11
	PPC_STORE_U32(ctx.r30.u32 + ctx.r11.u32, ctx.r7.u32);
	// ld r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 | ctx.r5.u64;
	// std r4,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r4.u64);
	// stw r25,-16(r31)
	PPC_STORE_U32(ctx.r31.u32 + -16, ctx.r25.u32);
loc_8211E160:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211e19c
	if (ctx.cr6.eq) goto loc_8211E19C;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r10,r29,32
	ctx.r10.s64 = ctx.r29.s64 + 32;
	// clrldi r8,r10,32
	ctx.r8.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// srd r6,r28,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r8.u8 & 0x7F));
	// lwzx r7,r30,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// rlwimi r7,r26,14,16,18
	ctx.r7.u64 = (rotl32(ctx.r26.u32, 14) & 0xE000) | (ctx.r7.u64 & 0xFFFFFFFFFFFF1FFF);
	// stwx r7,r30,r11
	PPC_STORE_U32(ctx.r30.u32 + ctx.r11.u32, ctx.r7.u32);
	// ld r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 | ctx.r5.u64;
	// std r4,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r4.u64);
	// stw r25,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r25.u32);
loc_8211E19C:
	// lwz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8211e1bc
	if (ctx.cr6.eq) goto loc_8211E1BC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x8222c248
	ctx.lr = 0x8211E1B8;
	sub_8222C248(ctx, base);
	// stw r26,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r26.u32);
loc_8211E1BC:
	// lwz r11,64(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8211e1dc
	if (ctx.cr6.eq) goto loc_8211E1DC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// bl 0x8222c0a0
	ctx.lr = 0x8211E1D8;
	sub_8222C0A0(ctx, base);
	// stw r26,64(r31)
	PPC_STORE_U32(ctx.r31.u32 + 64, ctx.r26.u32);
loc_8211E1DC:
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8211e218
	if (ctx.cr6.eq) goto loc_8211E218;
	// lwz r11,0(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 0);
	// addi r10,r29,32
	ctx.r10.s64 = ctx.r29.s64 + 32;
	// clrldi r8,r10,32
	ctx.r8.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// srd r6,r28,r8
	ctx.r6.u64 = ctx.r8.u8 & 0x40 ? 0 : (ctx.r28.u64 >> (ctx.r8.u8 & 0x7F));
	// lwzx r7,r30,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + ctx.r11.u32);
	// rlwimi r7,r26,17,13,15
	ctx.r7.u64 = (rotl32(ctx.r26.u32, 17) & 0x70000) | (ctx.r7.u64 & 0xFFFFFFFFFFF8FFFF);
	// stwx r7,r30,r11
	PPC_STORE_U32(ctx.r30.u32 + ctx.r11.u32, ctx.r7.u32);
	// ld r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// or r4,r6,r5
	ctx.r4.u64 = ctx.r6.u64 | ctx.r5.u64;
	// std r4,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r4.u64);
	// stw r25,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r25.u32);
loc_8211E218:
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// addi r30,r30,24
	ctx.r30.s64 = ctx.r30.s64 + 24;
	// addi r31,r31,320
	ctx.r31.s64 = ctx.r31.s64 + 320;
	// cmplw cr6,r29,r23
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r23.u32, ctx.xer);
	// blt cr6,0x8211e124
	if (ctx.cr6.lt) goto loc_8211E124;
loc_8211E22C:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x8211E238;
	sub_821112B0(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8211E244;
	sub_82111340(ctx, base);
	// lwz r11,4(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 4);
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// stw r11,12216(r21)
	PPC_STORE_U32(ctx.r21.u32 + 12216, ctx.r11.u32);
	// ld r10,16(r21)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r21.u32 + 16);
	// oris r9,r10,8
	ctx.r9.u64 = ctx.r10.u64 | 524288;
	// std r9,16(r21)
	PPC_STORE_U64(ctx.r21.u32 + 16, ctx.r9.u64);
	// lwz r4,8(r22)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r22.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x8211E264;
	sub_82238728(ctx, base);
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// lwz r4,0(r22)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r22.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x8211E270;
	sub_82238380(ctx, base);
	// lis r8,-32250
	ctx.r8.s64 = -2113536000;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r7,r8,31376
	ctx.r7.s64 = ctx.r8.s64 + 31376;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,15
	ctx.r3.s64 = 15;
	// lfs f1,48(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210afd8
	ctx.lr = 0x8211E28C;
	sub_8210AFD8(ctx, base);
	// li r6,16
	ctx.r6.s64 = 16;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x8222d600
	ctx.lr = 0x8211E2A0;
	sub_8222D600(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e2bc
	if (ctx.cr6.eq) goto loc_8211E2BC;
	// li r5,48
	ctx.r5.s64 = 48;
	// addi r4,r24,68
	ctx.r4.s64 = ctx.r24.s64 + 68;
	// bl 0x8233e4e0
	ctx.lr = 0x8211E2B4;
	sub_8233E4E0(ctx, base);
	// lwz r11,13828(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 13828);
	// stw r11,48(r21)
	PPC_STORE_U32(ctx.r21.u32 + 48, ctx.r11.u32);
loc_8211E2BC:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8211E2C8;
	sub_821112B0(ctx, base);
loc_8211E2C8:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211E2D0"))) PPC_WEAK_FUNC(sub_8211E2D0);
PPC_FUNC_IMPL(__imp__sub_8211E2D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// bge cr6,0x8211e318
	if (!ctx.cr6.lt) goto loc_8211E318;
	// fsubs f11,f2,f1
	ctx.f11.f64 = static_cast<float>(ctx.f2.f64 - ctx.f1.f64);
	// lfs f12,60(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,36(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,32(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,68(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 68, temp.u32);
	// stfs f13,84(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 84, temp.u32);
	// stfs f0,100(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 100, temp.u32);
	// fmuls f10,f11,f12
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fsubs f9,f0,f10
	ctx.f9.f64 = static_cast<float>(ctx.f0.f64 - ctx.f10.f64);
	// stfs f9,72(r3)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r3.u32 + 72, temp.u32);
	// fsubs f8,f10,f0
	ctx.f8.f64 = static_cast<float>(ctx.f10.f64 - ctx.f0.f64);
	// stfs f8,88(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 88, temp.u32);
	// stfs f9,104(r3)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r3.u32 + 104, temp.u32);
	// blr 
	return;
loc_8211E318:
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// ble cr6,0x8211e358
	if (!ctx.cr6.gt) goto loc_8211E358;
	// fsubs f11,f1,f2
	ctx.f11.f64 = static_cast<float>(ctx.f1.f64 - ctx.f2.f64);
	// lfs f12,60(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,36(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,32(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,72(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 72, temp.u32);
	// stfs f13,88(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 88, temp.u32);
	// stfs f0,104(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 104, temp.u32);
	// fmuls f10,f11,f12
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fsubs f9,f10,f0
	ctx.f9.f64 = static_cast<float>(ctx.f10.f64 - ctx.f0.f64);
	// stfs f9,68(r3)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r3.u32 + 68, temp.u32);
	// fsubs f8,f0,f10
	ctx.f8.f64 = static_cast<float>(ctx.f0.f64 - ctx.f10.f64);
	// stfs f9,84(r3)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r3.u32 + 84, temp.u32);
	// stfs f8,100(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 100, temp.u32);
	// blr 
	return;
loc_8211E358:
	// lfs f0,32(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,36(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,68(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 68, temp.u32);
	// stfs f13,72(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 72, temp.u32);
	// stfs f0,84(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 84, temp.u32);
	// stfs f0,88(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 88, temp.u32);
	// stfs f13,100(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 100, temp.u32);
	// stfs f13,104(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 104, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211E37C"))) PPC_WEAK_FUNC(sub_8211E37C);
PPC_FUNC_IMPL(__imp__sub_8211E37C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211E380"))) PPC_WEAK_FUNC(sub_8211E380);
PPC_FUNC_IMPL(__imp__sub_8211E380) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e454
	ctx.lr = 0x8211E388;
	__restfpr_23(ctx, base);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// bl 0x821237a8
	ctx.lr = 0x8211E394;
	sub_821237A8(ctx, base);
	// bl 0x8211c810
	ctx.lr = 0x8211E398;
	sub_8211C810(ctx, base);
	// lis r11,42
	ctx.r11.s64 = 2752512;
	// li r29,0
	ctx.r29.s64 = 0;
	// ori r30,r11,9145
	ctx.r30.u64 = ctx.r11.u64 | 9145;
	// li r31,3
	ctx.r31.s64 = 3;
	// stb r29,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r29.u8);
	// stw r30,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r30.u32);
	// li r4,3
	ctx.r4.s64 = 3;
	// stw r30,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r30.u32);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stb r31,149(r1)
	PPC_STORE_U8(ctx.r1.u32 + 149, ctx.r31.u8);
	// bl 0x821160a8
	ctx.lr = 0x8211E3C4;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211E3C8;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e3f4
	if (ctx.cr6.eq) goto loc_8211E3F4;
	// lis r11,-32251
	ctx.r11.s64 = -2113601536;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r6,r11,-32024
	ctx.r6.s64 = ctx.r11.s64 + -32024;
	// addi r5,r10,-31744
	ctx.r5.s64 = ctx.r10.s64 + -31744;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E3E8;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25932(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25932, ctx.r3.u32);
	// b 0x8211e400
	goto loc_8211E400;
loc_8211E3F4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25932(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25932, ctx.r29.u32);
loc_8211E400:
	// bl 0x82122a58
	ctx.lr = 0x8211E404;
	sub_82122A58(ctx, base);
	// bl 0x82135918
	ctx.lr = 0x8211E408;
	sub_82135918(ctx, base);
	// bl 0x821270e8
	ctx.lr = 0x8211E40C;
	sub_821270E8(ctx, base);
	// bl 0x82128640
	ctx.lr = 0x8211E410;
	sub_82128640(ctx, base);
	// stw r30,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r30.u32);
	// stb r29,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r29.u8);
	// li r4,4
	ctx.r4.s64 = 4;
	// stw r30,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r30.u32);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stb r31,149(r1)
	PPC_STORE_U8(ctx.r1.u32 + 149, ctx.r31.u8);
	// stw r30,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r30.u32);
	// stb r31,161(r1)
	PPC_STORE_U8(ctx.r1.u32 + 161, ctx.r31.u8);
	// bl 0x821160a8
	ctx.lr = 0x8211E434;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211E438;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e464
	if (ctx.cr6.eq) goto loc_8211E464;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// addi r6,r11,29296
	ctx.r6.s64 = ctx.r11.s64 + 29296;
	// addi r5,r10,28792
	ctx.r5.s64 = ctx.r10.s64 + 28792;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E458;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25872(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25872, ctx.r3.u32);
	// b 0x8211e470
	goto loc_8211E470;
loc_8211E464:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25872(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25872, ctx.r29.u32);
loc_8211E470:
	// bl 0x8211af88
	ctx.lr = 0x8211E474;
	sub_8211AF88(ctx, base);
	// lis r11,44
	ctx.r11.s64 = 2883584;
	// li r25,5
	ctx.r25.s64 = 5;
	// stb r29,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r29.u8);
	// ori r31,r11,9125
	ctx.r31.u64 = ctx.r11.u64 | 9125;
	// stb r25,149(r1)
	PPC_STORE_U8(ctx.r1.u32 + 149, ctx.r25.u8);
	// li r4,3
	ctx.r4.s64 = 3;
	// stw r31,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r31.u32);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stw r31,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r31.u32);
	// bl 0x821160a8
	ctx.lr = 0x8211E49C;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211E4A0;
	sub_82116360(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r24,r11,8368
	ctx.r24.s64 = ctx.r11.s64 + 8368;
	// addi r23,r10,8064
	ctx.r23.s64 = ctx.r10.s64 + 8064;
	// beq cr6,0x8211e4d4
	if (ctx.cr6.eq) goto loc_8211E4D4;
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E4C8;
	sub_8211C770(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// stw r3,26088(r11)
	PPC_STORE_U32(ctx.r11.u32 + 26088, ctx.r3.u32);
	// b 0x8211e4e0
	goto loc_8211E4E0;
loc_8211E4D4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,26088(r10)
	PPC_STORE_U32(ctx.r10.u32 + 26088, ctx.r29.u32);
loc_8211E4E0:
	// lis r11,-32179
	ctx.r11.s64 = -2108882944;
	// lis r10,0
	ctx.r10.s64 = 0;
	// addi r9,r11,20000
	ctx.r9.s64 = ctx.r11.s64 + 20000;
	// ori r8,r10,65512
	ctx.r8.u64 = ctx.r10.u64 | 65512;
	// lis r7,-32178
	ctx.r7.s64 = -2108817408;
	// lwzx r11,r9,r8
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// stw r11,26076(r7)
	PPC_STORE_U32(ctx.r7.u32 + 26076, ctx.r11.u32);
	// bl 0x8212c608
	ctx.lr = 0x8211E500;
	sub_8212C608(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x821344d8
	ctx.lr = 0x8211E508;
	sub_821344D8(ctx, base);
	// lis r6,-32250
	ctx.r6.s64 = -2113536000;
	// lis r5,-32182
	ctx.r5.s64 = -2109079552;
	// addi r4,r6,31376
	ctx.r4.s64 = ctx.r6.s64 + 31376;
	// addi r3,r5,-27848
	ctx.r3.s64 = ctx.r5.s64 + -27848;
	// lfs f0,36(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,48(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,32(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,-27848(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + -27848, temp.u32);
	// stfs f0,4(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// stfs f13,8(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// stfs f13,12(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
	// stfs f0,16(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 16, temp.u32);
	// stfs f0,20(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 20, temp.u32);
	// stfs f0,24(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 24, temp.u32);
	// stfs f13,28(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 28, temp.u32);
	// stfs f12,32(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 32, temp.u32);
	// stfs f12,36(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 36, temp.u32);
	// stfs f13,40(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 40, temp.u32);
	// stfs f0,44(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 44, temp.u32);
	// bl 0x8211f498
	ctx.lr = 0x8211E558;
	sub_8211F498(ctx, base);
	// stw r31,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r31.u32);
	// stb r29,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r29.u8);
	// li r4,3
	ctx.r4.s64 = 3;
	// stw r31,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r31.u32);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stb r25,149(r1)
	PPC_STORE_U8(ctx.r1.u32 + 149, ctx.r25.u8);
	// bl 0x821160a8
	ctx.lr = 0x8211E574;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211E578;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e5a4
	if (ctx.cr6.eq) goto loc_8211E5A4;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,1040
	ctx.r6.s64 = ctx.r11.s64 + 1040;
	// addi r5,r10,1808
	ctx.r5.s64 = ctx.r10.s64 + 1808;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E598;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25772(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25772, ctx.r3.u32);
	// b 0x8211e5b0
	goto loc_8211E5B0;
loc_8211E5A4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25772(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25772, ctx.r29.u32);
loc_8211E5B0:
	// bl 0x82116360
	ctx.lr = 0x8211E5B4;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e5e0
	if (ctx.cr6.eq) goto loc_8211E5E0;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,2128
	ctx.r6.s64 = ctx.r11.s64 + 2128;
	// addi r5,r10,2944
	ctx.r5.s64 = ctx.r10.s64 + 2944;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E5D4;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25776(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25776, ctx.r3.u32);
	// b 0x8211e5ec
	goto loc_8211E5EC;
loc_8211E5E0:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25776(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25776, ctx.r29.u32);
loc_8211E5EC:
	// lis r11,24
	ctx.r11.s64 = 1572864;
	// stw r30,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r30.u32);
	// li r28,10
	ctx.r28.s64 = 10;
	// stb r29,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r29.u8);
	// ori r27,r11,10374
	ctx.r27.u64 = ctx.r11.u64 | 10374;
	// stb r28,149(r1)
	PPC_STORE_U8(ctx.r1.u32 + 149, ctx.r28.u8);
	// li r4,3
	ctx.r4.s64 = 3;
	// stw r27,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r27.u32);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x821160a8
	ctx.lr = 0x8211E614;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211E618;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e644
	if (ctx.cr6.eq) goto loc_8211E644;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,3264
	ctx.r6.s64 = ctx.r11.s64 + 3264;
	// addi r5,r10,3496
	ctx.r5.s64 = ctx.r10.s64 + 3496;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E638;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25752(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25752, ctx.r3.u32);
	// b 0x8211e650
	goto loc_8211E650;
loc_8211E644:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25752(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25752, ctx.r29.u32);
loc_8211E650:
	// lis r11,26
	ctx.r11.s64 = 1703936;
	// stw r30,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r30.u32);
	// stb r29,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r29.u8);
	// li r4,3
	ctx.r4.s64 = 3;
	// ori r26,r11,9126
	ctx.r26.u64 = ctx.r11.u64 | 9126;
	// stb r28,149(r1)
	PPC_STORE_U8(ctx.r1.u32 + 149, ctx.r28.u8);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stw r26,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r26.u32);
	// bl 0x821160a8
	ctx.lr = 0x8211E674;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211E678;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e6a4
	if (ctx.cr6.eq) goto loc_8211E6A4;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,4000
	ctx.r6.s64 = ctx.r11.s64 + 4000;
	// addi r5,r10,4232
	ctx.r5.s64 = ctx.r10.s64 + 4232;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E698;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25760(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25760, ctx.r3.u32);
	// b 0x8211e6b0
	goto loc_8211E6B0;
loc_8211E6A4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25760(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25760, ctx.r29.u32);
loc_8211E6B0:
	// stw r30,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r30.u32);
	// li r4,3
	ctx.r4.s64 = 3;
	// stb r29,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r29.u8);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stw r31,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r31.u32);
	// stb r25,149(r1)
	PPC_STORE_U8(ctx.r1.u32 + 149, ctx.r25.u8);
	// bl 0x821160a8
	ctx.lr = 0x8211E6CC;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211E6D0;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e6fc
	if (ctx.cr6.eq) goto loc_8211E6FC;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,4744
	ctx.r6.s64 = ctx.r11.s64 + 4744;
	// addi r5,r10,5096
	ctx.r5.s64 = ctx.r10.s64 + 5096;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E6F0;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25788(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25788, ctx.r3.u32);
	// b 0x8211e708
	goto loc_8211E708;
loc_8211E6FC:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25788(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25788, ctx.r29.u32);
loc_8211E708:
	// bl 0x82116360
	ctx.lr = 0x8211E70C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e738
	if (ctx.cr6.eq) goto loc_8211E738;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,5608
	ctx.r6.s64 = ctx.r11.s64 + 5608;
	// addi r5,r10,5880
	ctx.r5.s64 = ctx.r10.s64 + 5880;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E72C;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25792(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25792, ctx.r3.u32);
	// b 0x8211e744
	goto loc_8211E744;
loc_8211E738:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25792(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25792, ctx.r29.u32);
loc_8211E744:
	// stw r30,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r30.u32);
	// li r4,4
	ctx.r4.s64 = 4;
	// stb r29,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r29.u8);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stw r27,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r27.u32);
	// stb r28,149(r1)
	PPC_STORE_U8(ctx.r1.u32 + 149, ctx.r28.u8);
	// stw r31,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r31.u32);
	// stb r25,161(r1)
	PPC_STORE_U8(ctx.r1.u32 + 161, ctx.r25.u8);
	// bl 0x821160a8
	ctx.lr = 0x8211E768;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211E76C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e798
	if (ctx.cr6.eq) goto loc_8211E798;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,6352
	ctx.r6.s64 = ctx.r11.s64 + 6352;
	// addi r5,r10,6656
	ctx.r5.s64 = ctx.r10.s64 + 6656;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E78C;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25768(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25768, ctx.r3.u32);
	// b 0x8211e7a4
	goto loc_8211E7A4;
loc_8211E798:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25768(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25768, ctx.r29.u32);
loc_8211E7A4:
	// stw r30,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r30.u32);
	// li r4,4
	ctx.r4.s64 = 4;
	// stb r29,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r29.u8);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stw r26,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r26.u32);
	// stb r28,149(r1)
	PPC_STORE_U8(ctx.r1.u32 + 149, ctx.r28.u8);
	// stw r31,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r31.u32);
	// stb r25,161(r1)
	PPC_STORE_U8(ctx.r1.u32 + 161, ctx.r25.u8);
	// bl 0x821160a8
	ctx.lr = 0x8211E7C8;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211E7CC;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e7f8
	if (ctx.cr6.eq) goto loc_8211E7F8;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,7200
	ctx.r6.s64 = ctx.r11.s64 + 7200;
	// addi r5,r10,7512
	ctx.r5.s64 = ctx.r10.s64 + 7512;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E7EC;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25764(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25764, ctx.r3.u32);
	// b 0x8211e804
	goto loc_8211E804;
loc_8211E7F8:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25764(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25764, ctx.r29.u32);
loc_8211E804:
	// stw r31,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r31.u32);
	// li r4,3
	ctx.r4.s64 = 3;
	// stb r29,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r29.u8);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stw r31,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r31.u32);
	// stb r25,149(r1)
	PPC_STORE_U8(ctx.r1.u32 + 149, ctx.r25.u8);
	// bl 0x821160a8
	ctx.lr = 0x8211E820;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211E824;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e848
	if (ctx.cr6.eq) goto loc_8211E848;
	// mr r6,r23
	ctx.r6.u64 = ctx.r23.u64;
	// mr r5,r24
	ctx.r5.u64 = ctx.r24.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E83C;
	sub_8211C770(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// stw r3,25756(r11)
	PPC_STORE_U32(ctx.r11.u32 + 25756, ctx.r3.u32);
	// b 0x8211e854
	goto loc_8211E854;
loc_8211E848:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25756(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25756, ctx.r29.u32);
loc_8211E854:
	// stw r26,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r26.u32);
	// li r4,2
	ctx.r4.s64 = 2;
	// stb r29,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r29.u8);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x821160a8
	ctx.lr = 0x8211E868;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8211E86C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e898
	if (ctx.cr6.eq) goto loc_8211E898;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,8680
	ctx.r6.s64 = ctx.r11.s64 + 8680;
	// addi r5,r10,9192
	ctx.r5.s64 = ctx.r10.s64 + 9192;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c770
	ctx.lr = 0x8211E88C;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25784(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25784, ctx.r3.u32);
	// b 0x8211e8a4
	goto loc_8211E8A4;
loc_8211E898:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25784(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25784, ctx.r29.u32);
loc_8211E8A4:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x82082030
	ctx.lr = 0x8211E8B8;
	sub_82082030(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211e8e0
	if (ctx.cr6.eq) goto loc_8211E8E0;
	// li r5,52
	ctx.r5.s64 = 52;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8233eaf0
	ctx.lr = 0x8211E8D0;
	sub_8233EAF0(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// addi r31,r11,25796
	ctx.r31.s64 = ctx.r11.s64 + 25796;
	// stw r30,25796(r11)
	PPC_STORE_U32(ctx.r11.u32 + 25796, ctx.r30.u32);
	// b 0x8211e8f0
	goto loc_8211E8F0;
loc_8211E8E0:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// addi r31,r10,25796
	ctx.r31.s64 = ctx.r10.s64 + 25796;
	// stw r29,25796(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25796, ctx.r29.u32);
loc_8211E8F0:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,4096
	ctx.r4.s64 = 4096;
	// li r3,4
	ctx.r3.s64 = 4;
	// bl 0x82082030
	ctx.lr = 0x8211E904;
	sub_82082030(ctx, base);
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// lis r7,6184
	ctx.r7.s64 = 405274624;
	// stw r6,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r6.u32);
	// stw r5,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r5.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r3,25800(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25800, ctx.r3.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// ori r7,r7,390
	ctx.r7.u64 = ctx.r7.u64 | 390;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82298418
	ctx.lr = 0x8211E950;
	sub_82298418(ctx, base);
	// lwz r4,25800(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25800);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x822986a8
	ctx.lr = 0x8211E95C;
	sub_822986A8(ctx, base);
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x8233e4a4
	__restgprlr_23(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211E964"))) PPC_WEAK_FUNC(sub_8211E964);
PPC_FUNC_IMPL(__imp__sub_8211E964) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211E968"))) PPC_WEAK_FUNC(sub_8211E968);
PPC_FUNC_IMPL(__imp__sub_8211E968) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x8211E970;
	__restfpr_14(ctx, base);
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, ctx.f31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,0(r4)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// stw r4,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r4.u32);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// stw r30,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r30.u32);
	// beq cr6,0x8211f13c
	if (ctx.cr6.eq) goto loc_8211F13C;
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r14,2048
	ctx.r14.s64 = 2048;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// li r15,8192
	ctx.r15.s64 = 8192;
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r11.u32);
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// li r22,1
	ctx.r22.s64 = 1;
	// lfs f31,36(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// li r16,64
	ctx.r16.s64 = 64;
	// li r23,128
	ctx.r23.s64 = 128;
	// li r26,1536
	ctx.r26.s64 = 1536;
	// li r17,3
	ctx.r17.s64 = 3;
	// li r20,512
	ctx.r20.s64 = 512;
	// li r18,2
	ctx.r18.s64 = 2;
	// li r19,8
	ctx.r19.s64 = 8;
	// addi r27,r11,-27800
	ctx.r27.s64 = ctx.r11.s64 + -27800;
	// li r21,256
	ctx.r21.s64 = 256;
	// li r24,4
	ctx.r24.s64 = 4;
	// addi r25,r10,27648
	ctx.r25.s64 = ctx.r10.s64 + 27648;
loc_8211E9E8:
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,69
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 69, ctx.xer);
	// bgt cr6,0x8211f124
	if (ctx.cr6.gt) goto loc_8211F124;
	// lis r12,-32238
	ctx.r12.s64 = -2112749568;
	// rlwinm r0,r11,2,0,29
	ctx.r0.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r12,r12,-5620
	ctx.r12.s64 = ctx.r12.s64 + -5620;
	// lwzx r0,r12,r0
	ctx.r0.u64 = PPC_LOAD_U32(ctx.r12.u32 + ctx.r0.u32);
	// mtctr r0
	ctx.ctr.u64 = ctx.r0.u64;
	// bctr 
	switch (ctx.r11.u64) {
	case 0:
		goto loc_8211EB24;
	case 1:
		goto loc_8211EB44;
	case 2:
		goto loc_8211F124;
	case 3:
		goto loc_8211EE9C;
	case 4:
		goto loc_8211EB64;
	case 5:
		goto loc_8211F084;
	case 6:
		goto loc_8211EE08;
	case 7:
		goto loc_8211EB34;
	case 8:
		goto loc_8211EB80;
	case 9:
		goto loc_8211F124;
	case 10:
		goto loc_8211F124;
	case 11:
		goto loc_8211EBD0;
	case 12:
		goto loc_8211F124;
	case 13:
		goto loc_8211F124;
	case 14:
		goto loc_8211F124;
	case 15:
		goto loc_8211F124;
	case 16:
		goto loc_8211EC58;
	case 17:
		goto loc_8211EBE0;
	case 18:
		goto loc_8211EB90;
	case 19:
		goto loc_8211EC74;
	case 20:
		goto loc_8211F124;
	case 21:
		goto loc_8211F124;
	case 22:
		goto loc_8211F124;
	case 23:
		goto loc_8211F124;
	case 24:
		goto loc_8211F124;
	case 25:
		goto loc_8211EC88;
	case 26:
		goto loc_8211EC98;
	case 27:
		goto loc_8211EF8C;
	case 28:
		goto loc_8211EF9C;
	case 29:
		goto loc_8211EFAC;
	case 30:
		goto loc_8211EE8C;
	case 31:
		goto loc_8211EF6C;
	case 32:
		goto loc_8211EFBC;
	case 33:
		goto loc_8211EE58;
	case 34:
		goto loc_8211EE6C;
	case 35:
		goto loc_8211ED1C;
	case 36:
		goto loc_8211ED38;
	case 37:
		goto loc_8211EFCC;
	case 38:
		goto loc_8211F06C;
	case 39:
		goto loc_8211EE40;
	case 40:
		goto loc_8211ED54;
	case 41:
		goto loc_8211ED64;
	case 42:
		goto loc_8211ECA8;
	case 43:
		goto loc_8211F124;
	case 44:
		goto loc_8211F124;
	case 45:
		goto loc_8211EF7C;
	case 46:
		goto loc_8211F0D8;
	case 47:
		goto loc_8211EE7C;
	case 48:
		goto loc_8211F124;
	case 49:
		goto loc_8211EE2C;
	case 50:
		goto loc_8211F124;
	case 51:
		goto loc_8211F124;
	case 52:
		goto loc_8211F124;
	case 53:
		goto loc_8211ECB8;
	case 54:
		goto loc_8211EB70;
	case 55:
		goto loc_8211EFE8;
	case 56:
		goto loc_8211EFF4;
	case 57:
		goto loc_8211F008;
	case 58:
		goto loc_8211F060;
	case 59:
		goto loc_8211EDFC;
	case 60:
		goto loc_8211EE18;
	case 61:
		goto loc_8211F124;
	case 62:
		goto loc_8211F124;
	case 63:
		goto loc_8211F124;
	case 64:
		goto loc_8211F100;
	case 65:
		goto loc_8211F124;
	case 66:
		goto loc_8211EBC0;
	case 67:
		goto loc_8211EB54;
	case 68:
		goto loc_8211F124;
	case 69:
		goto loc_8211EBA4;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-5340(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5340);
	// lwz r16,-5308(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5308);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-4452(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4452);
	// lwz r16,-5276(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5276);
	// lwz r16,-3964(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3964);
	// lwz r16,-4600(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4600);
	// lwz r16,-5324(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5324);
	// lwz r16,-5248(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5248);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-5168(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5168);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-5032(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5032);
	// lwz r16,-5152(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5152);
	// lwz r16,-5232(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5232);
	// lwz r16,-5004(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5004);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-4984(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4984);
	// lwz r16,-4968(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4968);
	// lwz r16,-4212(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4212);
	// lwz r16,-4196(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4196);
	// lwz r16,-4180(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4180);
	// lwz r16,-4468(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4468);
	// lwz r16,-4244(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4244);
	// lwz r16,-4164(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4164);
	// lwz r16,-4520(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4520);
	// lwz r16,-4500(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4500);
	// lwz r16,-4836(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4836);
	// lwz r16,-4808(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4808);
	// lwz r16,-4148(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4148);
	// lwz r16,-3988(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3988);
	// lwz r16,-4544(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4544);
	// lwz r16,-4780(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4780);
	// lwz r16,-4764(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4764);
	// lwz r16,-4952(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4952);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-4228(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4228);
	// lwz r16,-3880(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3880);
	// lwz r16,-4484(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4484);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-4564(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4564);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-4936(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4936);
	// lwz r16,-5264(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5264);
	// lwz r16,-4120(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4120);
	// lwz r16,-4108(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4108);
	// lwz r16,-4088(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4088);
	// lwz r16,-4000(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4000);
	// lwz r16,-4612(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4612);
	// lwz r16,-4584(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -4584);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-3840(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3840);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-5184(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5184);
	// lwz r16,-5292(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5292);
	// lwz r16,-3804(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -3804);
	// lwz r16,-5212(r17)
	ctx.r16.u64 = PPC_LOAD_U32(ctx.r17.u32 + -5212);
loc_8211EB24:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82120340
	ctx.lr = 0x8211EB30;
	sub_82120340(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EB34:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8211f670
	ctx.lr = 0x8211EB40;
	sub_8211F670(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EB44:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821205d0
	ctx.lr = 0x8211EB50;
	sub_821205D0(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EB54:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8211faf8
	ctx.lr = 0x8211EB60;
	sub_8211FAF8(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EB64:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82120260
	ctx.lr = 0x8211EB6C;
	sub_82120260(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EB70:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82120028
	ctx.lr = 0x8211EB7C;
	sub_82120028(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EB80:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x8212a698
	ctx.lr = 0x8211EB8C;
	sub_8212A698(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EB90:
	// stw r14,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r14.u32);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,20
	ctx.r3.s64 = ctx.r31.s64 + 20;
	// bl 0x821265c0
	ctx.lr = 0x8211EBA0;
	sub_821265C0(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EBA4:
	// lwz r29,2120(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2120);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// stw r15,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r15.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82122380
	ctx.lr = 0x8211EBB8;
	sub_82122380(ctx, base);
	// stw r29,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r29.u32);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EBC0:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8211ce28
	ctx.lr = 0x8211EBCC;
	sub_8211CE28(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EBD0:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x8212c278
	ctx.lr = 0x8211EBDC;
	sub_8212C278(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EBE0:
	// addi r30,r30,12
	ctx.r30.s64 = ctx.r30.s64 + 12;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211ec00
	if (!ctx.cr6.eq) goto loc_8211EC00;
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// mr r11,r22
	ctx.r11.u64 = ctx.r22.u64;
	// beq cr6,0x8211ec04
	if (ctx.cr6.eq) goto loc_8211EC04;
loc_8211EC00:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8211EC04:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211f124
	if (!ctx.cr6.eq) goto loc_8211F124;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// stw r4,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r4.u32);
	// beq cr6,0x8211f124
	if (ctx.cr6.eq) goto loc_8211F124;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// addi r29,r31,24
	ctx.r29.s64 = ctx.r31.s64 + 24;
	// stw r11,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r11.u32);
loc_8211EC2C:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8212bb70
	ctx.lr = 0x8211EC34;
	sub_8212BB70(ctx, base);
	// lwz r11,8(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211ec48
	if (ctx.cr6.eq) goto loc_8211EC48;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r10.u32);
loc_8211EC48:
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211ec2c
	if (!ctx.cr6.eq) goto loc_8211EC2C;
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EC58:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8211EC64;
	sub_821112B0(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,24
	ctx.r3.s64 = ctx.r31.s64 + 24;
	// bl 0x8212bb70
	ctx.lr = 0x8211EC70;
	sub_8212BB70(ctx, base);
	// b 0x8211f118
	goto loc_8211F118;
loc_8211EC74:
	// stw r16,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r16.u32);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,8
	ctx.r3.s64 = ctx.r31.s64 + 8;
	// bl 0x82129290
	ctx.lr = 0x8211EC84;
	sub_82129290(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EC88:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82120e10
	ctx.lr = 0x8211EC94;
	sub_82120E10(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EC98:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821216e0
	ctx.lr = 0x8211ECA4;
	sub_821216E0(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211ECA8:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,8
	ctx.r3.s64 = ctx.r31.s64 + 8;
	// bl 0x82129148
	ctx.lr = 0x8211ECB4;
	sub_82129148(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211ECB8:
	// addi r30,r30,12
	ctx.r30.s64 = ctx.r30.s64 + 12;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211ecd8
	if (!ctx.cr6.eq) goto loc_8211ECD8;
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// mr r11,r22
	ctx.r11.u64 = ctx.r22.u64;
	// beq cr6,0x8211ecdc
	if (ctx.cr6.eq) goto loc_8211ECDC;
loc_8211ECD8:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8211ECDC:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211f124
	if (!ctx.cr6.eq) goto loc_8211F124;
	// lwz r11,2120(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2120);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// ori r10,r11,4096
	ctx.r10.u64 = ctx.r11.u64 | 4096;
	// stw r10,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r10.u32);
	// bl 0x8211e968
	ctx.lr = 0x8211ED00;
	sub_8211E968(ctx, base);
	// lwz r9,2120(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2120);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// rlwinm r8,r9,0,20,18
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFFEFFF;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r8,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r8.u32);
	// bl 0x8211e968
	ctx.lr = 0x8211ED18;
	sub_8211E968(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211ED1C:
	// lwz r29,2120(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2120);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// stw r22,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r22.u32);
	// addi r3,r31,1824
	ctx.r3.s64 = ctx.r31.s64 + 1824;
	// bl 0x821347d0
	ctx.lr = 0x8211ED30;
	sub_821347D0(ctx, base);
	// stw r29,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r29.u32);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211ED38:
	// lwz r29,2120(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2120);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// stw r23,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r23.u32);
	// addi r3,r31,1824
	ctx.r3.s64 = ctx.r31.s64 + 1824;
	// bl 0x82134b50
	ctx.lr = 0x8211ED4C;
	sub_82134B50(ctx, base);
	// stw r29,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r29.u32);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211ED54:
	// stw r26,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r26.u32);
	// addi r3,r31,32
	ctx.r3.s64 = ctx.r31.s64 + 32;
	// bl 0x8212efb0
	ctx.lr = 0x8211ED60;
	sub_8212EFB0(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211ED64:
	// lwz r11,1712(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1712);
	// addi r28,r31,32
	ctx.r28.s64 = ctx.r31.s64 + 32;
	// addi r30,r11,1108
	ctx.r30.s64 = ctx.r11.s64 + 1108;
	// lwz r11,1140(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1140);
	// clrlwi r29,r11,26
	ctx.r29.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r29,50
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 50, ctx.xer);
	// bne cr6,0x8211ed88
	if (!ctx.cr6.eq) goto loc_8211ED88;
	// rlwimi r11,r17,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r17.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r11.u32);
loc_8211ED88:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,188(r25)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r25.u32 + 188);
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82227e30
	ctx.lr = 0x8211EDAC;
	sub_82227E30(ctx, base);
	// lwz r11,32(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// rlwimi r29,r11,0,0,25
	ctx.r29.u64 = (rotl32(ctx.r11.u32, 0) & 0xFFFFFFC0) | (ctx.r29.u64 & 0xFFFFFFFF0000003F);
	// stw r29,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r29.u32);
	// lwz r10,1680(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 1680);
	// addi r5,r10,1932
	ctx.r5.s64 = ctx.r10.s64 + 1932;
	// lwz r11,36(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8211eddc
	if (ctx.cr6.eq) goto loc_8211EDDC;
	// stw r5,36(r25)
	PPC_STORE_U32(ctx.r25.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r25)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r25.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8211EDDC;
	sub_8222CDF8(ctx, base);
loc_8211EDDC:
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8211EDE8;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x8211EDF4;
	sub_82113BC0(ctx, base);
	// lwz r28,80(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EDFC:
	// stw r20,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r20.u32);
	// addi r3,r31,32
	ctx.r3.s64 = ctx.r31.s64 + 32;
	// bl 0x8212f108
	ctx.lr = 0x8211EE08;
	sub_8212F108(ctx, base);
loc_8211EE08:
	// addi r4,r30,12
	ctx.r4.s64 = ctx.r30.s64 + 12;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8211e968
	ctx.lr = 0x8211EE14;
	sub_8211E968(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EE18:
	// addi r4,r30,12
	ctx.r4.s64 = ctx.r30.s64 + 12;
	// addi r3,r31,32
	ctx.r3.s64 = ctx.r31.s64 + 32;
	// bl 0x8212f998
	ctx.lr = 0x8211EE24;
	sub_8212F998(ctx, base);
	// stw r26,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r26.u32);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EE2C:
	// stw r26,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r26.u32);
	// addi r4,r30,12
	ctx.r4.s64 = ctx.r30.s64 + 12;
	// addi r3,r31,32
	ctx.r3.s64 = ctx.r31.s64 + 32;
	// bl 0x8212e870
	ctx.lr = 0x8211EE3C;
	sub_8212E870(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EE40:
	// stw r26,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r26.u32);
	// addi r4,r30,12
	ctx.r4.s64 = ctx.r30.s64 + 12;
	// addi r3,r31,32
	ctx.r3.s64 = ctx.r31.s64 + 32;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x8212d4b0
	ctx.lr = 0x8211EE54;
	sub_8212D4B0(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EE58:
	// stw r18,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r18.u32);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,1728
	ctx.r3.s64 = ctx.r31.s64 + 1728;
	// bl 0x82135a50
	ctx.lr = 0x8211EE68;
	sub_82135A50(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EE6C:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,1728
	ctx.r3.s64 = ctx.r31.s64 + 1728;
	// bl 0x82135c20
	ctx.lr = 0x8211EE78;
	sub_82135C20(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EE7C:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,1756
	ctx.r3.s64 = ctx.r31.s64 + 1756;
	// bl 0x821355c8
	ctx.lr = 0x8211EE88;
	sub_821355C8(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EE8C:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,1720
	ctx.r3.s64 = ctx.r31.s64 + 1720;
	// bl 0x82122cd0
	ctx.lr = 0x8211EE98;
	sub_82122CD0(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EE9C:
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// addi r29,r30,12
	ctx.r29.s64 = ctx.r30.s64 + 12;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211eebc
	if (!ctx.cr6.eq) goto loc_8211EEBC;
	// lwz r11,4(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// mr r11,r22
	ctx.r11.u64 = ctx.r22.u64;
	// beq cr6,0x8211eec0
	if (ctx.cr6.eq) goto loc_8211EEC0;
loc_8211EEBC:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8211EEC0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211ef18
	if (!ctx.cr6.eq) goto loc_8211EF18;
	// lwz r11,24(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// ble cr6,0x8211ef18
	if (!ctx.cr6.gt) goto loc_8211EF18;
	// lwz r4,0(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// stw r4,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r4.u32);
	// beq cr6,0x8211ef18
	if (ctx.cr6.eq) goto loc_8211EF18;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
loc_8211EEF0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x821221e0
	ctx.lr = 0x8211EEF8;
	sub_821221E0(ctx, base);
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211ef0c
	if (ctx.cr6.eq) goto loc_8211EF0C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r10.u32);
loc_8211EF0C:
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211eef0
	if (!ctx.cr6.eq) goto loc_8211EEF0;
loc_8211EF18:
	// lwz r11,2140(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2140);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211f124
	if (ctx.cr6.eq) goto loc_8211F124;
	// lbz r10,432(r25)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r25.u32 + 432);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211f124
	if (ctx.cr6.eq) goto loc_8211F124;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82122758
	ctx.lr = 0x8211EF38;
	sub_82122758(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,2128(r27)
	PPC_STORE_U32(ctx.r27.u32 + 2128, ctx.r11.u32);
	// stw r10,2124(r27)
	PPC_STORE_U32(ctx.r27.u32 + 2124, ctx.r10.u32);
	// stw r9,1712(r27)
	PPC_STORE_U32(ctx.r27.u32 + 1712, ctx.r9.u32);
	// stw r11,1720(r27)
	PPC_STORE_U32(ctx.r27.u32 + 1720, ctx.r11.u32);
	// stw r10,1796(r27)
	PPC_STORE_U32(ctx.r27.u32 + 1796, ctx.r10.u32);
	// stw r9,1728(r27)
	PPC_STORE_U32(ctx.r27.u32 + 1728, ctx.r9.u32);
	// stw r11,1764(r27)
	PPC_STORE_U32(ctx.r27.u32 + 1764, ctx.r11.u32);
	// stw r10,4(r27)
	PPC_STORE_U32(ctx.r27.u32 + 4, ctx.r10.u32);
	// stw r9,2140(r27)
	PPC_STORE_U32(ctx.r27.u32 + 2140, ctx.r9.u32);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EF6C:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,1760
	ctx.r3.s64 = ctx.r31.s64 + 1760;
	// bl 0x82127b60
	ctx.lr = 0x8211EF78;
	sub_82127B60(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EF7C:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,1768
	ctx.r3.s64 = ctx.r31.s64 + 1768;
	// bl 0x82126d80
	ctx.lr = 0x8211EF88;
	sub_82126D80(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EF8C:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82121810
	ctx.lr = 0x8211EF98;
	sub_82121810(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EF9C:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82121b98
	ctx.lr = 0x8211EFA8;
	sub_82121B98(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EFAC:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82121f00
	ctx.lr = 0x8211EFB8;
	sub_82121F00(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EFBC:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// addi r3,r31,20
	ctx.r3.s64 = ctx.r31.s64 + 20;
	// bl 0x82126710
	ctx.lr = 0x8211EFC8;
	sub_82126710(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EFCC:
	// lwz r29,2120(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2120);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// stw r23,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r23.u32);
	// addi r3,r31,1824
	ctx.r3.s64 = ctx.r31.s64 + 1824;
	// bl 0x82134fa0
	ctx.lr = 0x8211EFE0;
	sub_82134FA0(ctx, base);
	// stw r29,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r29.u32);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EFE8:
	// addi r3,r31,1776
	ctx.r3.s64 = ctx.r31.s64 + 1776;
	// bl 0x8211b1f0
	ctx.lr = 0x8211EFF0;
	sub_8211B1F0(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211EFF4:
	// stw r19,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r19.u32);
	// addi r3,r31,1776
	ctx.r3.s64 = ctx.r31.s64 + 1776;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x8211b2e8
	ctx.lr = 0x8211F004;
	sub_8211B2E8(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211F008:
	// lbz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 12);
	// addi r3,r31,1776
	ctx.r3.s64 = ctx.r31.s64 + 1776;
	// addi r11,r11,-1
	ctx.r11.s64 = ctx.r11.s64 + -1;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bgt cr6,0x8211f124
	if (ctx.cr6.gt) goto loc_8211F124;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bdzf 4*cr6+eq,0x8211f048
	--ctx.ctr.u64;
	if (ctx.ctr.u32 == 0 && !ctx.cr6.eq) goto loc_8211F048;
	// bdzf 4*cr6+eq,0x8211f054
	--ctx.ctr.u64;
	if (ctx.ctr.u32 == 0 && !ctx.cr6.eq) goto loc_8211F054;
	// bne cr6,0x8211f03c
	if (!ctx.cr6.eq) goto loc_8211F03C;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x8211b9b0
	ctx.lr = 0x8211F038;
	sub_8211B9B0(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211F03C:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x8211bb10
	ctx.lr = 0x8211F044;
	sub_8211BB10(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211F048:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x8211bdb8
	ctx.lr = 0x8211F050;
	sub_8211BDB8(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211F054:
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x8211c038
	ctx.lr = 0x8211F05C;
	sub_8211C038(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211F060:
	// addi r3,r31,1776
	ctx.r3.s64 = ctx.r31.s64 + 1776;
	// bl 0x8211c2c0
	ctx.lr = 0x8211F068;
	sub_8211C2C0(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211F06C:
	// stw r26,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r26.u32);
	// addi r3,r31,32
	ctx.r3.s64 = ctx.r31.s64 + 32;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82132e30
	ctx.lr = 0x8211F07C;
	sub_82132E30(ctx, base);
	// stw r21,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r21.u32);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211F084:
	// stw r24,2120(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2120, ctx.r24.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// addi r4,r11,12
	ctx.r4.s64 = ctx.r11.s64 + 12;
	// bl 0x8211e968
	ctx.lr = 0x8211F098;
	sub_8211E968(ctx, base);
	// lwz r11,16(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,12
	ctx.r4.s64 = ctx.r11.s64 + 12;
	// bl 0x8211e968
	ctx.lr = 0x8211F0A8;
	sub_8211E968(ctx, base);
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,12
	ctx.r4.s64 = ctx.r11.s64 + 12;
	// bl 0x8211e968
	ctx.lr = 0x8211F0B8;
	sub_8211E968(ctx, base);
	// lwz r11,24(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r4,r11,12
	ctx.r4.s64 = ctx.r11.s64 + 12;
	// bl 0x8211e968
	ctx.lr = 0x8211F0C8;
	sub_8211E968(ctx, base);
	// addi r3,r31,1720
	ctx.r3.s64 = ctx.r31.s64 + 1720;
	// lwz r4,28(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// bl 0x82122cd0
	ctx.lr = 0x8211F0D4;
	sub_82122CD0(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211F0D8:
	// lbz r11,12(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 12);
	// addi r29,r31,1828
	ctx.r29.s64 = ctx.r31.s64 + 1828;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211f124
	if (ctx.cr6.eq) goto loc_8211F124;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82128710
	ctx.lr = 0x8211F0F0;
	sub_82128710(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// bl 0x82128ea8
	ctx.lr = 0x8211F0FC;
	sub_82128EA8(ctx, base);
	// b 0x8211f124
	goto loc_8211F124;
loc_8211F100:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8211F10C;
	sub_821112B0(ctx, base);
	// addi r4,r30,12
	ctx.r4.s64 = ctx.r30.s64 + 12;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8211e968
	ctx.lr = 0x8211F118;
	sub_8211E968(ctx, base);
loc_8211F118:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8211F124;
	sub_821112B0(ctx, base);
loc_8211F124:
	// lwz r30,8(r28)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x8211f13c
	if (ctx.cr6.eq) goto loc_8211F13C;
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// stw r11,8(r28)
	PPC_STORE_U32(ctx.r28.u32 + 8, ctx.r11.u32);
	// bne cr6,0x8211e9e8
	if (!ctx.cr6.eq) goto loc_8211E9E8;
loc_8211F13C:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211F148"))) PPC_WEAK_FUNC(sub_8211F148);
PPC_FUNC_IMPL(__imp__sub_8211F148) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8211F150;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x821239f0
	ctx.lr = 0x8211F158;
	sub_821239F0(ctx, base);
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// lwz r3,25932(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25932);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f16c
	if (ctx.cr6.eq) goto loc_8211F16C;
	// bl 0x8211af20
	ctx.lr = 0x8211F16C;
	sub_8211AF20(ctx, base);
loc_8211F16C:
	// li r28,0
	ctx.r28.s64 = 0;
	// stw r28,25932(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25932, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// bl 0x8211ccc8
	ctx.lr = 0x8211F17C;
	sub_8211CCC8(ctx, base);
	// lis r31,-32182
	ctx.r31.s64 = -2109079552;
	// lwz r3,-25536(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -25536);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f190
	if (ctx.cr6.eq) goto loc_8211F190;
	// bl 0x8211af20
	ctx.lr = 0x8211F190;
	sub_8211AF20(ctx, base);
loc_8211F190:
	// lis r30,-32182
	ctx.r30.s64 = -2109079552;
	// stw r28,-25536(r31)
	PPC_STORE_U32(ctx.r31.u32 + -25536, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lwz r3,-25540(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + -25540);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f1ac
	if (ctx.cr6.eq) goto loc_8211F1AC;
	// bl 0x8211af20
	ctx.lr = 0x8211F1AC;
	sub_8211AF20(ctx, base);
loc_8211F1AC:
	// lis r31,-32182
	ctx.r31.s64 = -2109079552;
	// stw r28,-25540(r30)
	PPC_STORE_U32(ctx.r30.u32 + -25540, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lwz r3,-25544(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -25544);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f1c8
	if (ctx.cr6.eq) goto loc_8211F1C8;
	// bl 0x8211af20
	ctx.lr = 0x8211F1C8;
	sub_8211AF20(ctx, base);
loc_8211F1C8:
	// stw r28,-25544(r31)
	PPC_STORE_U32(ctx.r31.u32 + -25544, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// bl 0x8212cf28
	ctx.lr = 0x8211F1D4;
	sub_8212CF28(ctx, base);
	// bl 0x82127490
	ctx.lr = 0x8211F1D8;
	sub_82127490(ctx, base);
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// lwz r3,25872(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25872);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f1ec
	if (ctx.cr6.eq) goto loc_8211F1EC;
	// bl 0x8211af20
	ctx.lr = 0x8211F1EC;
	sub_8211AF20(ctx, base);
loc_8211F1EC:
	// stw r28,25872(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25872, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// bl 0x8211ae18
	ctx.lr = 0x8211F1F8;
	sub_8211AE18(ctx, base);
	// bl 0x82134700
	ctx.lr = 0x8211F1FC;
	sub_82134700(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25924(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25924);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f210
	if (ctx.cr6.eq) goto loc_8211F210;
	// bl 0x8211af20
	ctx.lr = 0x8211F210;
	sub_8211AF20(ctx, base);
loc_8211F210:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25920(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25920);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f224
	if (ctx.cr6.eq) goto loc_8211F224;
	// bl 0x8211af20
	ctx.lr = 0x8211F224;
	sub_8211AF20(ctx, base);
loc_8211F224:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r31,2
	ctx.r31.s64 = 2;
	// addi r11,r11,28172
	ctx.r11.s64 = ctx.r11.s64 + 28172;
	// addi r30,r11,-4
	ctx.r30.s64 = ctx.r11.s64 + -4;
loc_8211F234:
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// bl 0x8222f0f8
	ctx.lr = 0x8211F23C;
	sub_8222F0F8(ctx, base);
	// addic. r31,r31,-1
	ctx.xer.ca = ctx.r31.u32 > 0;
	ctx.r31.s64 = ctx.r31.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// stwu r28,4(r30)
	ea = 4 + ctx.r30.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r30.u32 = ea;
	// bne 0x8211f234
	if (!ctx.cr0.eq) goto loc_8211F234;
	// lis r29,-32178
	ctx.r29.s64 = -2108817408;
	// lwz r31,25752(r29)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25752);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8211f290
	if (ctx.cr6.eq) goto loc_8211F290;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f268
	if (ctx.cr6.eq) goto loc_8211F268;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F268;
	sub_8222F0F8(ctx, base);
loc_8211F268:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f278
	if (ctx.cr6.eq) goto loc_8211F278;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F278;
	sub_8222F0F8(ctx, base);
loc_8211F278:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f288
	if (ctx.cr6.eq) goto loc_8211F288;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F288;
	sub_8222F0F8(ctx, base);
loc_8211F288:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82116248
	ctx.lr = 0x8211F290;
	sub_82116248(ctx, base);
loc_8211F290:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// stw r28,25752(r29)
	PPC_STORE_U32(ctx.r29.u32 + 25752, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lwz r31,25784(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25784);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8211f2e0
	if (ctx.cr6.eq) goto loc_8211F2E0;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f2b8
	if (ctx.cr6.eq) goto loc_8211F2B8;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F2B8;
	sub_8222F0F8(ctx, base);
loc_8211F2B8:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f2c8
	if (ctx.cr6.eq) goto loc_8211F2C8;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F2C8;
	sub_8222F0F8(ctx, base);
loc_8211F2C8:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f2d8
	if (ctx.cr6.eq) goto loc_8211F2D8;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F2D8;
	sub_8222F0F8(ctx, base);
loc_8211F2D8:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82116248
	ctx.lr = 0x8211F2E0;
	sub_82116248(ctx, base);
loc_8211F2E0:
	// lis r29,-32178
	ctx.r29.s64 = -2108817408;
	// stw r28,25784(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25784, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lwz r31,25772(r29)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25772);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8211f330
	if (ctx.cr6.eq) goto loc_8211F330;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f308
	if (ctx.cr6.eq) goto loc_8211F308;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F308;
	sub_8222F0F8(ctx, base);
loc_8211F308:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f318
	if (ctx.cr6.eq) goto loc_8211F318;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F318;
	sub_8222F0F8(ctx, base);
loc_8211F318:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f328
	if (ctx.cr6.eq) goto loc_8211F328;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F328;
	sub_8222F0F8(ctx, base);
loc_8211F328:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82116248
	ctx.lr = 0x8211F330;
	sub_82116248(ctx, base);
loc_8211F330:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// stw r28,25772(r29)
	PPC_STORE_U32(ctx.r29.u32 + 25772, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lwz r31,25776(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25776);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8211f380
	if (ctx.cr6.eq) goto loc_8211F380;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f358
	if (ctx.cr6.eq) goto loc_8211F358;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F358;
	sub_8222F0F8(ctx, base);
loc_8211F358:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f368
	if (ctx.cr6.eq) goto loc_8211F368;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F368;
	sub_8222F0F8(ctx, base);
loc_8211F368:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f378
	if (ctx.cr6.eq) goto loc_8211F378;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F378;
	sub_8222F0F8(ctx, base);
loc_8211F378:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82116248
	ctx.lr = 0x8211F380;
	sub_82116248(ctx, base);
loc_8211F380:
	// lis r29,-32178
	ctx.r29.s64 = -2108817408;
	// stw r28,25776(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25776, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lwz r31,25788(r29)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25788);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8211f3d0
	if (ctx.cr6.eq) goto loc_8211F3D0;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f3a8
	if (ctx.cr6.eq) goto loc_8211F3A8;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F3A8;
	sub_8222F0F8(ctx, base);
loc_8211F3A8:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f3b8
	if (ctx.cr6.eq) goto loc_8211F3B8;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F3B8;
	sub_8222F0F8(ctx, base);
loc_8211F3B8:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f3c8
	if (ctx.cr6.eq) goto loc_8211F3C8;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F3C8;
	sub_8222F0F8(ctx, base);
loc_8211F3C8:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82116248
	ctx.lr = 0x8211F3D0;
	sub_82116248(ctx, base);
loc_8211F3D0:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// stw r28,25788(r29)
	PPC_STORE_U32(ctx.r29.u32 + 25788, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lwz r31,25792(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25792);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x8211f420
	if (ctx.cr6.eq) goto loc_8211F420;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f3f8
	if (ctx.cr6.eq) goto loc_8211F3F8;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F3F8;
	sub_8222F0F8(ctx, base);
loc_8211F3F8:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f408
	if (ctx.cr6.eq) goto loc_8211F408;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F408;
	sub_8222F0F8(ctx, base);
loc_8211F408:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f418
	if (ctx.cr6.eq) goto loc_8211F418;
	// bl 0x8222f0f8
	ctx.lr = 0x8211F418;
	sub_8222F0F8(ctx, base);
loc_8211F418:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82116248
	ctx.lr = 0x8211F420;
	sub_82116248(ctx, base);
loc_8211F420:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// stw r28,25792(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25792, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lwz r11,25796(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25796);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211f444
	if (ctx.cr6.eq) goto loc_8211F444;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8211F444;
	sub_82080000(ctx, base);
loc_8211F444:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// stw r28,25796(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25796, ctx.r28.u32);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lwz r11,25800(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25800);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211f468
	if (ctx.cr6.eq) goto loc_8211F468;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8211F468;
	sub_82080000(ctx, base);
loc_8211F468:
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// stw r28,25800(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25800, ctx.r28.u32);
	// mr r31,r28
	ctx.r31.u64 = ctx.r28.u64;
loc_8211F474:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82120d60
	ctx.lr = 0x8211F47C;
	sub_82120D60(ctx, base);
	// addi r31,r31,1
	ctx.r31.s64 = ctx.r31.s64 + 1;
	// cmplwi cr6,r31,16
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 16, ctx.xer);
	// blt cr6,0x8211f474
	if (ctx.cr6.lt) goto loc_8211F474;
	// bl 0x82116800
	ctx.lr = 0x8211F48C;
	sub_82116800(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211F494"))) PPC_WEAK_FUNC(sub_8211F494);
PPC_FUNC_IMPL(__imp__sub_8211F494) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211F498"))) PPC_WEAK_FUNC(sub_8211F498);
PPC_FUNC_IMPL(__imp__sub_8211F498) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e44c
	ctx.lr = 0x8211F4A0;
	__restfpr_21(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r25,0
	ctx.r25.s64 = 0;
	// lis r9,8208
	ctx.r9.s64 = 537919488;
	// lis r11,-32198
	ctx.r11.s64 = -2110128128;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// mr r30,r25
	ctx.r30.u64 = ctx.r25.u64;
	// ori r23,r9,2
	ctx.r23.u64 = ctx.r9.u64 | 2;
	// li r21,1
	ctx.r21.s64 = 1;
	// lis r22,-1
	ctx.r22.s64 = -65536;
	// lis r26,-32178
	ctx.r26.s64 = -2108817408;
	// addi r24,r11,-16080
	ctx.r24.s64 = ctx.r11.s64 + -16080;
	// addi r27,r10,28172
	ctx.r27.s64 = ctx.r10.s64 + 28172;
loc_8211F4D0:
	// lwz r11,25076(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 25076);
	// addi r10,r30,3
	ctx.r10.s64 = ctx.r30.s64 + 3;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// li r5,-1
	ctx.r5.s64 = -1;
	// stw r11,25076(r26)
	PPC_STORE_U32(ctx.r26.u32 + 25076, ctx.r11.u32);
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,32
	ctx.r3.s64 = 32;
	// rlwinm r28,r30,2,0,29
	ctx.r28.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r29,r10,12,0,19
	ctx.r29.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFFFF000;
	// bl 0x82082030
	ctx.lr = 0x8211F4FC;
	sub_82082030(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// bl 0x8233eaf0
	ctx.lr = 0x8211F50C;
	sub_8233EAF0(ctx, base);
	// lwz r5,8(r24)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r24.u32 + 8);
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x8211f534
	if (ctx.cr6.eq) goto loc_8211F534;
	// li r4,32
	ctx.r4.s64 = 32;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x822472e0
	ctx.lr = 0x8211F524;
	sub_822472E0(ctx, base);
	// addi r11,r31,-16
	ctx.r11.s64 = ctx.r31.s64 + -16;
	// lwz r11,-4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -4);
	// oris r10,r11,16384
	ctx.r10.u64 = ctx.r11.u64 | 1073741824;
	// stw r10,-4(r31)
	PPC_STORE_U32(ctx.r31.u32 + -4, ctx.r10.u32);
loc_8211F534:
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// bne cr6,0x8211f544
	if (!ctx.cr6.eq) goto loc_8211F544;
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// b 0x8211f5a8
	goto loc_8211F5A8;
loc_8211F544:
	// lis r4,-19840
	ctx.r4.s64 = -1300234240;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82082c78
	ctx.lr = 0x8211F550;
	sub_82082C78(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x8211f590
	if (!ctx.cr6.eq) goto loc_8211F590;
	// lwz r11,-4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + -4);
	// addi r29,r31,-16
	ctx.r29.s64 = ctx.r31.s64 + -16;
	// rlwinm r10,r11,0,1,1
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x40000000;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8211f57c
	if (ctx.cr6.eq) goto loc_8211F57C;
	// li r5,4
	ctx.r5.s64 = 4;
	// clrlwi r4,r11,2
	ctx.r4.u64 = ctx.r11.u32 & 0x3FFFFFFF;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x822472e0
	ctx.lr = 0x8211F57C;
	sub_822472E0(ctx, base);
loc_8211F57C:
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,8(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// bl 0x82080000
	ctx.lr = 0x8211F588;
	sub_82080000(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// b 0x8211f5a8
	goto loc_8211F5A8;
loc_8211F590:
	// stw r29,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r29.u32);
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r3,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r3.u32);
	// stw r23,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r23.u32);
	// stw r21,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r21.u32);
	// stw r22,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r22.u32);
loc_8211F5A8:
	// rotlwi r3,r11,0
	ctx.r3.u64 = rotl32(ctx.r11.u32, 0);
	// stwx r11,r28,r27
	PPC_STORE_U32(ctx.r28.u32 + ctx.r27.u32, ctx.r11.u32);
	// li r10,4098
	ctx.r10.s64 = 4098;
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r25.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,12
	ctx.r4.s64 = 12;
	// lwz r9,28(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// lwz r6,24(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mr r8,r6
	ctx.r8.u64 = ctx.r6.u64;
	// bl 0x8222eb50
	ctx.lr = 0x8211F5D4;
	sub_8222EB50(ctx, base);
	// li r9,1024
	ctx.r9.s64 = 1024;
	// addi r11,r3,-2
	ctx.r11.s64 = ctx.r3.s64 + -2;
	// mr r10,r25
	ctx.r10.u64 = ctx.r25.u64;
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// addi r7,r30,2
	ctx.r7.s64 = ctx.r30.s64 + 2;
loc_8211F5E8:
	// cmpwi cr6,r7,0
	ctx.cr6.compare<int32_t>(ctx.r7.s32, 0, ctx.xer);
	// ble cr6,0x8211f628
	if (!ctx.cr6.gt) goto loc_8211F628;
	// mr r9,r25
	ctx.r9.u64 = ctx.r25.u64;
loc_8211F5F4:
	// clrlwi r8,r10,16
	ctx.r8.u64 = ctx.r10.u32 & 0xFFFF;
	// sth r10,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r10.u16);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// add r10,r8,r30
	ctx.r10.u64 = ctx.r8.u64 + ctx.r30.u64;
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// addi r6,r10,2
	ctx.r6.s64 = ctx.r10.s64 + 2;
	// addi r5,r8,1
	ctx.r5.s64 = ctx.r8.s64 + 1;
	// clrlwi r4,r6,16
	ctx.r4.u64 = ctx.r6.u32 & 0xFFFF;
	// clrlwi r10,r5,16
	ctx.r10.u64 = ctx.r5.u32 & 0xFFFF;
	// sth r4,4(r11)
	PPC_STORE_U16(ctx.r11.u32 + 4, ctx.r4.u16);
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// cmpw cr6,r9,r7
	ctx.cr6.compare<int32_t>(ctx.r9.s32, ctx.r7.s32, ctx.xer);
	// blt cr6,0x8211f5f4
	if (ctx.cr6.lt) goto loc_8211F5F4;
loc_8211F628:
	// clrlwi r9,r10,16
	ctx.r9.u64 = ctx.r10.u32 & 0xFFFF;
	// add r9,r9,r30
	ctx.r9.u64 = ctx.r9.u64 + ctx.r30.u64;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// clrlwi r8,r9,16
	ctx.r8.u64 = ctx.r9.u32 & 0xFFFF;
	// sth r8,2(r11)
	PPC_STORE_U16(ctx.r11.u32 + 2, ctx.r8.u16);
	// sthu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U16(ea, ctx.r10.u16);
	ctx.r11.u32 = ea;
	// bdnz 0x8211f5e8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8211F5E8;
	// lwzx r3,r28,r27
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + ctx.r27.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,24(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// bl 0x8222ee68
	ctx.lr = 0x8211F654;
	sub_8222EE68(ctx, base);
	// addi r11,r30,1
	ctx.r11.s64 = ctx.r30.s64 + 1;
	// clrlwi r30,r11,16
	ctx.r30.u64 = ctx.r11.u32 & 0xFFFF;
	// cmplwi cr6,r30,2
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 2, ctx.xer);
	// blt cr6,0x8211f4d0
	if (ctx.cr6.lt) goto loc_8211F4D0;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211F66C"))) PPC_WEAK_FUNC(sub_8211F66C);
PPC_FUNC_IMPL(__imp__sub_8211F66C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211F670"))) PPC_WEAK_FUNC(sub_8211F670);
PPC_FUNC_IMPL(__imp__sub_8211F670) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	PPCVRegister vTemp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x8211F678;
	__restfpr_29(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r8,r11,27648
	ctx.r8.s64 = ctx.r11.s64 + 27648;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// lwz r3,36(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 36);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8211f754
	if (ctx.cr6.eq) goto loc_8211F754;
	// bl 0x8222f080
	ctx.lr = 0x8211F69C;
	sub_8222F080(ctx, base);
	// lbz r11,18(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 18);
	// li r30,0
	ctx.r30.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211f6cc
	if (ctx.cr6.eq) goto loc_8211F6CC;
	// lwz r5,364(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 364);
	// lwz r11,36(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8211f6cc
	if (ctx.cr6.eq) goto loc_8211F6CC;
	// stw r5,36(r8)
	PPC_STORE_U32(ctx.r8.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8211F6CC;
	sub_8222CDF8(ctx, base);
loc_8211F6CC:
	// lbz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 16);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211f6dc
	if (ctx.cr6.eq) goto loc_8211F6DC;
	// li r30,16
	ctx.r30.s64 = 16;
loc_8211F6DC:
	// lbz r11,17(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 17);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8211f6f4
	if (ctx.cr6.eq) goto loc_8211F6F4;
	// lwz r11,12(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// ori r30,r30,15
	ctx.r30.u64 = ctx.r30.u64 | 15;
	// b 0x8211f6f8
	goto loc_8211F6F8;
loc_8211F6F4:
	// li r11,0
	ctx.r11.s64 = 0;
loc_8211F6F8:
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// addi r11,r1,80
	ctx.r11.s64 = ctx.r1.s64 + 80;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lwz r3,2004(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2004);
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r7,r10,-21808
	ctx.r7.s64 = ctx.r10.s64 + -21808;
	// addi r6,r9,-21824
	ctx.r6.s64 = ctx.r9.s64 + -21824;
	// lvlx128 v63,r0,r11
	temp.u32 = ctx.r0.u32 + ctx.r11.u32;
	simd::store_shuffled(ctx.v63,
		simde_mm_shuffle_epi8(
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(base + ((temp).u32 & ~0xF))),
			simde_mm_load_si128(reinterpret_cast<const simde__m128i*>(&VectorMaskL[((temp).u32 & 0xF) * 16]))
		));
	// vsldoi128 v62,v63,v63,4
	simd::store_i8(ctx.v62.u8, simd::shift_left_insert_bytes(simd::load_i8(ctx.v63.u8), simd::load_i8(ctx.v63.u8), 12));
	// vupkd3d128 v12,v62,0
	vTemp.u32[0] = ctx.v62.u8[3] | 0x3F800000;
	vTemp.u32[1] = ctx.v62.u8[0] | 0x3F800000;
	vTemp.u32[2] = ctx.v62.u8[1] | 0x3F800000;
	vTemp.u32[3] = ctx.v62.u8[2] | 0x3F800000;
	ctx.v12 = vTemp;
	// lvx128 v13,r0,r6
	simd::store_shuffled(ctx.v13, simd::load_and_shuffle(base + ((ctx.r6.u32) & ~0xF), VectorMaskL));
	// lvx128 v0,r0,r7
	simd::store_shuffled(ctx.v0, simd::load_and_shuffle(base + ((ctx.r7.u32) & ~0xF), VectorMaskL));
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r8,0
	ctx.r8.s64 = 0;
	// vmaddfp v0,v0,v12,v13
	ctx.fpscr.enableFlushMode();
	simd::store_f32_aligned(ctx.v0.f32, simd::add_f32(simd::mul_f32(simd::load_f32_aligned(ctx.v0.f32), simd::load_f32_aligned(ctx.v12.f32)), simd::load_f32_aligned(ctx.v13.f32)));
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lfs f1,48(r9)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// stvx128 v0,r0,r11
	ea = (ctx.r11.u32) & ~0xF;
	simd::store_shuffled(base + ea, simd::to_vec128i(ctx.v0), &VectorMaskL[(ea & 0xF) * 16]);
	// bl 0x82229fb8
	ctx.lr = 0x8211F754;
	sub_82229FB8(ctx, base);
loc_8211F754:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211F75C"))) PPC_WEAK_FUNC(sub_8211F75C);
PPC_FUNC_IMPL(__imp__sub_8211F75C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211F760"))) PPC_WEAK_FUNC(sub_8211F760);
PPC_FUNC_IMPL(__imp__sub_8211F760) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8211F768;
	__restfpr_28(ctx, base);
	// addi r8,r3,2020
	ctx.r8.s64 = ctx.r3.s64 + 2020;
	// stw r5,2016(r3)
	PPC_STORE_U32(ctx.r3.u32 + 2016, ctx.r5.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmpwi cr6,r5,4
	ctx.cr6.compare<int32_t>(ctx.r5.s32, 4, ctx.xer);
	// blt cr6,0x8211f81c
	if (ctx.cr6.lt) goto loc_8211F81C;
	// addi r7,r5,-3
	ctx.r7.s64 = ctx.r5.s64 + -3;
	// addi r10,r4,-4
	ctx.r10.s64 = ctx.r4.s64 + -4;
	// addi r11,r8,4
	ctx.r11.s64 = ctx.r8.s64 + 4;
	// subf r6,r8,r4
	ctx.r6.s64 = ctx.r4.s64 - ctx.r8.s64;
loc_8211F78C:
	// lfs f0,4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// stfs f0,-4(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + -4, temp.u32);
	// lfsx f13,r6,r11
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + ctx.r11.u32);
	ctx.f13.f64 = double(temp.f32);
	// cmplw cr6,r9,r7
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, ctx.xer);
	// stfs f13,0(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// lfs f12,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,4(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 4, temp.u32);
	// lfs f11,16(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,8(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r11.u32 + 8, temp.u32);
	// lfs f10,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,12(r11)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r11.u32 + 12, temp.u32);
	// lfs f9,24(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,16(r11)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r11.u32 + 16, temp.u32);
	// lfs f8,28(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,20(r11)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r11.u32 + 20, temp.u32);
	// lfs f7,32(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 32);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,24(r11)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r11.u32 + 24, temp.u32);
	// lfs f6,36(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,28(r11)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r11.u32 + 28, temp.u32);
	// lfs f5,40(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,32(r11)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r11.u32 + 32, temp.u32);
	// lfs f4,44(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 44);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,36(r11)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r11.u32 + 36, temp.u32);
	// lfs f3,48(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,40(r11)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r11.u32 + 40, temp.u32);
	// lfs f2,52(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 52);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,44(r11)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r11.u32 + 44, temp.u32);
	// lfs f1,56(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,48(r11)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r11.u32 + 48, temp.u32);
	// lfs f0,60(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,52(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 52, temp.u32);
	// lfsu f0,64(r10)
	ea = 64 + ctx.r10.u32;
	temp.u32 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,56(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 56, temp.u32);
	// addi r11,r11,64
	ctx.r11.s64 = ctx.r11.s64 + 64;
	// blt cr6,0x8211f78c
	if (ctx.cr6.lt) goto loc_8211F78C;
loc_8211F81C:
	// cmplw cr6,r9,r5
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r5.u32, ctx.xer);
	// bge cr6,0x8211f86c
	if (!ctx.cr6.lt) goto loc_8211F86C;
	// rlwinm r11,r9,4,0,27
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// subf r7,r9,r5
	ctx.r7.s64 = ctx.r5.s64 - ctx.r9.s64;
	// add r10,r11,r4
	ctx.r10.u64 = ctx.r11.u64 + ctx.r4.u64;
	// add r11,r11,r8
	ctx.r11.u64 = ctx.r11.u64 + ctx.r8.u64;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// addi r11,r11,4
	ctx.r11.s64 = ctx.r11.s64 + 4;
	// subf r9,r8,r4
	ctx.r9.s64 = ctx.r4.s64 - ctx.r8.s64;
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
loc_8211F844:
	// lfs f0,4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,-4(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + -4, temp.u32);
	// lfsx f13,r9,r11
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r11.u32);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,0(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// lfs f12,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,4(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r11.u32 + 4, temp.u32);
	// lfsu f0,16(r10)
	ea = 16 + ctx.r10.u32;
	temp.u32 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,8(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 8, temp.u32);
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// bdnz 0x8211f844
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8211F844;
loc_8211F86C:
	// lwz r8,2016(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2016);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8211f8f0
	if (ctx.cr6.eq) goto loc_8211F8F0;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r11,10272
	ctx.r11.s64 = 10272;
	// addi r4,r3,-8252
	ctx.r4.s64 = ctx.r3.s64 + -8252;
	// rldicr r31,r10,63,63
	ctx.r31.u64 = rotl64(ctx.r10.u64, 63) & 0xFFFFFFFFFFFFFFFF;
loc_8211F894:
	// lwz r9,2004(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2004);
	// add r30,r4,r11
	ctx.r30.u64 = ctx.r4.u64 + ctx.r11.u64;
	// lwzx r10,r4,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r11.u32);
	// addi r29,r7,9
	ctx.r29.s64 = ctx.r7.s64 + 9;
	// stwx r10,r11,r9
	PPC_STORE_U32(ctx.r11.u32 + ctx.r9.u32, ctx.r10.u32);
	// add r10,r11,r9
	ctx.r10.u64 = ctx.r11.u64 + ctx.r9.u64;
	// clrldi r29,r29,32
	ctx.r29.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// or r5,r6,r5
	ctx.r5.u64 = ctx.r6.u64 | ctx.r5.u64;
	// srd r29,r31,r29
	ctx.r29.u64 = ctx.r29.u8 & 0x40 ? 0 : (ctx.r31.u64 >> (ctx.r29.u8 & 0x7F));
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// lwz r28,4(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// rotlwi r6,r6,1
	ctx.r6.u64 = rotl32(ctx.r6.u32, 1);
	// stw r28,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r28.u32);
	// lwz r28,8(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stw r28,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r28.u32);
	// lwz r30,12(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// stw r30,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r30.u32);
	// ld r10,32(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 32);
	// or r10,r29,r10
	ctx.r10.u64 = ctx.r29.u64 | ctx.r10.u64;
	// std r10,32(r9)
	PPC_STORE_U64(ctx.r9.u32 + 32, ctx.r10.u64);
	// bne 0x8211f894
	if (!ctx.cr0.eq) goto loc_8211F894;
loc_8211F8F0:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r11,r11,28184
	ctx.r11.s64 = ctx.r11.s64 + 28184;
	// lwz r10,1044(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1044);
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x8211f954
	if (ctx.cr6.eq) goto loc_8211F954;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// subfic r9,r5,0
	ctx.xer.ca = ctx.r5.u32 <= 0;
	ctx.r9.s64 = 0 - ctx.r5.s64;
	// li r7,4096
	ctx.r7.s64 = 4096;
	// subfe r4,r8,r8
	temp.u8 = (~ctx.r8.u32 + ctx.r8.u32 < ~ctx.r8.u32) | (~ctx.r8.u32 + ctx.r8.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r4.u64 = ~ctx.r8.u64 + ctx.r8.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// li r12,1
	ctx.r12.s64 = 1;
	// and r9,r4,r7
	ctx.r9.u64 = ctx.r4.u64 & ctx.r7.u64;
	// lwz r3,10564(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 10564);
	// mr r6,r10
	ctx.r6.u64 = ctx.r10.u64;
	// stw r9,10420(r10)
	PPC_STORE_U32(ctx.r10.u32 + 10420, ctx.r9.u32);
	// rldicr r12,r12,44,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 44) & 0xFFFFFFFFFFFFFFFF;
	// rlwinm r8,r3,0,0,25
	ctx.r8.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFC0;
	// or r7,r8,r5
	ctx.r7.u64 = ctx.r8.u64 | ctx.r5.u64;
	// stw r7,10564(r10)
	PPC_STORE_U32(ctx.r10.u32 + 10564, ctx.r7.u32);
	// ld r4,16(r10)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r10.u32 + 16);
	// ori r3,r4,128
	ctx.r3.u64 = ctx.r4.u64 | 128;
	// or r9,r3,r12
	ctx.r9.u64 = ctx.r3.u64 | ctx.r12.u64;
	// std r3,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, ctx.r3.u64);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// std r9,16(r6)
	PPC_STORE_U64(ctx.r6.u32 + 16, ctx.r9.u64);
	// stw r5,1044(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1044, ctx.r5.u32);
loc_8211F954:
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211F958"))) PPC_WEAK_FUNC(sub_8211F958);
PPC_FUNC_IMPL(__imp__sub_8211F958) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x8211F960;
	__restfpr_28(ctx, base);
	// lwz r8,2016(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2016);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x8211f9e4
	if (ctx.cr6.eq) goto loc_8211F9E4;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r11,10272
	ctx.r11.s64 = 10272;
	// addi r4,r3,-8252
	ctx.r4.s64 = ctx.r3.s64 + -8252;
	// rldicr r31,r10,63,63
	ctx.r31.u64 = rotl64(ctx.r10.u64, 63) & 0xFFFFFFFFFFFFFFFF;
loc_8211F988:
	// lwz r9,2004(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2004);
	// add r30,r4,r11
	ctx.r30.u64 = ctx.r4.u64 + ctx.r11.u64;
	// lwzx r10,r4,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r11.u32);
	// addi r29,r7,9
	ctx.r29.s64 = ctx.r7.s64 + 9;
	// stwx r10,r11,r9
	PPC_STORE_U32(ctx.r11.u32 + ctx.r9.u32, ctx.r10.u32);
	// add r10,r11,r9
	ctx.r10.u64 = ctx.r11.u64 + ctx.r9.u64;
	// clrldi r29,r29,32
	ctx.r29.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// or r5,r6,r5
	ctx.r5.u64 = ctx.r6.u64 | ctx.r5.u64;
	// srd r29,r31,r29
	ctx.r29.u64 = ctx.r29.u8 & 0x40 ? 0 : (ctx.r31.u64 >> (ctx.r29.u8 & 0x7F));
	// addic. r8,r8,-1
	ctx.xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r8.s32, 0, ctx.xer);
	// lwz r28,4(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r11,r11,16
	ctx.r11.s64 = ctx.r11.s64 + 16;
	// rotlwi r6,r6,1
	ctx.r6.u64 = rotl32(ctx.r6.u32, 1);
	// stw r28,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r28.u32);
	// lwz r28,8(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// stw r28,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r28.u32);
	// lwz r30,12(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// stw r30,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r30.u32);
	// ld r10,32(r9)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r9.u32 + 32);
	// or r10,r29,r10
	ctx.r10.u64 = ctx.r29.u64 | ctx.r10.u64;
	// std r10,32(r9)
	PPC_STORE_U64(ctx.r9.u32 + 32, ctx.r10.u64);
	// bne 0x8211f988
	if (!ctx.cr0.eq) goto loc_8211F988;
loc_8211F9E4:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r11,r11,28184
	ctx.r11.s64 = ctx.r11.s64 + 28184;
	// lwz r10,1044(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1044);
	// cmplw cr6,r10,r5
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, ctx.xer);
	// beq cr6,0x8211fa48
	if (ctx.cr6.eq) goto loc_8211FA48;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// subfic r9,r5,0
	ctx.xer.ca = ctx.r5.u32 <= 0;
	ctx.r9.s64 = 0 - ctx.r5.s64;
	// li r7,4096
	ctx.r7.s64 = 4096;
	// subfe r4,r8,r8
	temp.u8 = (~ctx.r8.u32 + ctx.r8.u32 < ~ctx.r8.u32) | (~ctx.r8.u32 + ctx.r8.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r4.u64 = ~ctx.r8.u64 + ctx.r8.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// li r12,1
	ctx.r12.s64 = 1;
	// and r9,r4,r7
	ctx.r9.u64 = ctx.r4.u64 & ctx.r7.u64;
	// lwz r3,10564(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 10564);
	// mr r6,r10
	ctx.r6.u64 = ctx.r10.u64;
	// stw r9,10420(r10)
	PPC_STORE_U32(ctx.r10.u32 + 10420, ctx.r9.u32);
	// rldicr r12,r12,44,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 44) & 0xFFFFFFFFFFFFFFFF;
	// rlwinm r8,r3,0,0,25
	ctx.r8.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFC0;
	// or r7,r8,r5
	ctx.r7.u64 = ctx.r8.u64 | ctx.r5.u64;
	// stw r7,10564(r10)
	PPC_STORE_U32(ctx.r10.u32 + 10564, ctx.r7.u32);
	// ld r4,16(r10)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r10.u32 + 16);
	// ori r3,r4,128
	ctx.r3.u64 = ctx.r4.u64 | 128;
	// or r9,r3,r12
	ctx.r9.u64 = ctx.r3.u64 | ctx.r12.u64;
	// std r3,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, ctx.r3.u64);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// std r9,16(r6)
	PPC_STORE_U64(ctx.r6.u32 + 16, ctx.r9.u64);
	// stw r5,1044(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1044, ctx.r5.u32);
loc_8211FA48:
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211FA4C"))) PPC_WEAK_FUNC(sub_8211FA4C);
PPC_FUNC_IMPL(__imp__sub_8211FA4C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211FA50"))) PPC_WEAK_FUNC(sub_8211FA50);
PPC_FUNC_IMPL(__imp__sub_8211FA50) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x8211fabc
	if (ctx.cr6.eq) goto loc_8211FABC;
	// stw r4,2124(r3)
	PPC_STORE_U32(ctx.r3.u32 + 2124, ctx.r4.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r11,620(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 620);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// bl 0x82113e88
	ctx.lr = 0x8211FA80;
	sub_82113E88(ctx, base);
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r11,r10,-30232
	ctx.r11.s64 = ctx.r10.s64 + -30232;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r11,2352
	ctx.r4.s64 = ctx.r11.s64 + 2352;
	// bl 0x820f6340
	ctx.lr = 0x8211FA98;
	sub_820F6340(ctx, base);
	// lwz r11,88(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8211fab4
	if (!ctx.cr6.eq) goto loc_8211FAB4;
	// lis r10,-13569
	ctx.r10.s64 = -889257984;
	// lis r9,-32249
	ctx.r9.s64 = -2113470464;
	// addi r8,r9,-30280
	ctx.r8.s64 = ctx.r9.s64 + -30280;
	// stw r8,-13570(r10)
	PPC_STORE_U32(ctx.r10.u32 + -13570, ctx.r8.u32);
loc_8211FAB4:
	// lwz r11,12(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r11,2128(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2128, ctx.r11.u32);
loc_8211FABC:
	// lwz r11,2128(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2128);
	// stw r11,1712(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1712, ctx.r11.u32);
	// stw r11,1720(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1720, ctx.r11.u32);
	// stw r11,1796(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1796, ctx.r11.u32);
	// stw r11,1728(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1728, ctx.r11.u32);
	// stw r11,1764(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1764, ctx.r11.u32);
	// stw r11,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r11.u32);
	// stw r11,1832(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1832, ctx.r11.u32);
	// stw r11,2140(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2140, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8211FAF4"))) PPC_WEAK_FUNC(sub_8211FAF4);
PPC_FUNC_IMPL(__imp__sub_8211FAF4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211FAF8"))) PPC_WEAK_FUNC(sub_8211FAF8);
PPC_FUNC_IMPL(__imp__sub_8211FAF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x8211FB00;
	__restfpr_25(ctx, base);
	// stfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, ctx.f31.u64);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r26,24(r4)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// lwz r5,32(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// lwz r31,2004(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2004);
	// lwz r4,28(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// bl 0x8211f760
	ctx.lr = 0x8211FB24;
	sub_8211F760(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,744(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 744);
	// bl 0x8211fa50
	ctx.lr = 0x8211FB30;
	sub_8211FA50(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// clrlwi r10,r26,31
	ctx.r10.u64 = ctx.r26.u32 & 0x1;
	// addi r25,r11,31376
	ctx.r25.s64 = ctx.r11.s64 + 31376;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lfs f31,48(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// lwz r29,2124(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2124);
	// lfs f0,380(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 380);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,376(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 376);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,1520(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r30.u32 + 1520, temp.u32);
	// stfs f0,1524(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 1524, temp.u32);
	// beq cr6,0x8211fc44
	if (ctx.cr6.eq) goto loc_8211FC44;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,2140(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2140);
	// li r9,4
	ctx.r9.s64 = 4;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,2076
	ctx.r5.s64 = ctx.r10.s64 + 2076;
	// stw r9,2120(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2120, ctx.r9.u32);
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8211fb90
	if (ctx.cr6.eq) goto loc_8211FB90;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8211FB90;
	sub_8222CDF8(ctx, base);
loc_8211FB90:
	// lwz r11,2140(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2140);
	// addi r3,r11,1980
	ctx.r3.s64 = ctx.r11.s64 + 1980;
	// bl 0x8210b080
	ctx.lr = 0x8211FB9C;
	sub_8210B080(ctx, base);
	// li r6,255
	ctx.r6.s64 = 255;
	// li r4,0
	ctx.r4.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r3,177
	ctx.r3.s64 = 177;
	// bl 0x8210afd8
	ctx.lr = 0x8211FBB0;
	sub_8210AFD8(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x8211FBBC;
	sub_82113BC0(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8211FBC8;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,372
	ctx.r3.s64 = 372;
	// bl 0x82111340
	ctx.lr = 0x8211FBD4;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8211FBE0;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,364
	ctx.r3.s64 = 364;
	// bl 0x82111340
	ctx.lr = 0x8211FBEC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,368
	ctx.r3.s64 = 368;
	// bl 0x82111340
	ctx.lr = 0x8211FBF8;
	sub_82111340(ctx, base);
	// li r4,255
	ctx.r4.s64 = 255;
	// li r3,132
	ctx.r3.s64 = 132;
	// bl 0x82111340
	ctx.lr = 0x8211FC04;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x8211FC10;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82111340
	ctx.lr = 0x8211FC1C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,124
	ctx.r3.s64 = 124;
	// bl 0x82111340
	ctx.lr = 0x8211FC28;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,120
	ctx.r3.s64 = 120;
	// bl 0x82111340
	ctx.lr = 0x8211FC34;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,116
	ctx.r3.s64 = 116;
	// bl 0x82111340
	ctx.lr = 0x8211FC40;
	sub_82111340(ctx, base);
	// b 0x8211fcac
	goto loc_8211FCAC;
loc_8211FC44:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,360
	ctx.r3.s64 = 360;
	// bl 0x82111340
	ctx.lr = 0x8211FC50;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,108
	ctx.r3.s64 = 108;
	// bl 0x82111340
	ctx.lr = 0x8211FC5C;
	sub_82111340(ctx, base);
	// rlwinm r11,r26,0,30,30
	ctx.r11.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,16
	ctx.r11.s64 = 16;
	// bne cr6,0x8211fc70
	if (!ctx.cr6.eq) goto loc_8211FC70;
	// li r11,32
	ctx.r11.s64 = 32;
loc_8211FC70:
	// stw r11,2120(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2120, ctx.r11.u32);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,2140(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2140);
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// addi r5,r10,1932
	ctx.r5.s64 = ctx.r10.s64 + 1932;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x8211fca0
	if (ctx.cr6.eq) goto loc_8211FCA0;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8211FCA0;
	sub_8222CDF8(ctx, base);
loc_8211FCA0:
	// lwz r11,2140(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2140);
	// addi r3,r11,1980
	ctx.r3.s64 = ctx.r11.s64 + 1980;
	// bl 0x8210b080
	ctx.lr = 0x8211FCAC;
	sub_8210B080(ctx, base);
loc_8211FCAC:
	// lwz r11,8(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 8);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lwz r9,12(r29)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r8,16(r29)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// addi r7,r29,8
	ctx.r7.s64 = ctx.r29.s64 + 8;
	// lwz r6,20(r29)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r11.u32);
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r8,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r8.u32);
	// stw r6,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r6.u32);
	// stfs f31,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f31,80(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// bl 0x82113910
	ctx.lr = 0x8211FCE4;
	sub_82113910(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8211FCF0;
	sub_821112B0(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x8211FCFC;
	sub_82111340(ctx, base);
	// addi r28,r29,24
	ctx.r28.s64 = ctx.r29.s64 + 24;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// addi r29,r29,88
	ctx.r29.s64 = ctx.r29.s64 + 88;
	// bl 0x82257cb8
	ctx.lr = 0x8211FD14;
	sub_82257CB8(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x821139a8
	ctx.lr = 0x8211FD20;
	sub_821139A8(ctx, base);
	// addi r3,r28,48
	ctx.r3.s64 = ctx.r28.s64 + 48;
	// bl 0x821229c0
	ctx.lr = 0x8211FD28;
	sub_821229C0(ctx, base);
	// clrlwi r5,r26,30
	ctx.r5.u64 = ctx.r26.u32 & 0x3;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// bne cr6,0x8211fd40
	if (!ctx.cr6.eq) goto loc_8211FD40;
	// addi r4,r27,36
	ctx.r4.s64 = ctx.r27.s64 + 36;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8211fe60
	ctx.lr = 0x8211FD40;
	sub_8211FE60(ctx, base);
loc_8211FD40:
	// lis r9,-32171
	ctx.r9.s64 = -2108358656;
	// lfs f0,36(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32171
	ctx.r11.s64 = -2108358656;
	// addi r11,r11,10536
	ctx.r11.s64 = ctx.r11.s64 + 10536;
	// lwz r10,10552(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 10552);
	// clrlwi r8,r10,31
	ctx.r8.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x8211fd80
	if (!ctx.cr6.eq) goto loc_8211FD80;
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stfs f0,0(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 0, temp.u32);
	// stfs f0,4(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 4, temp.u32);
	// fmr f13,f0
	ctx.f13.f64 = ctx.f0.f64;
	// stfs f0,8(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 8, temp.u32);
	// stw r10,10552(r9)
	PPC_STORE_U32(ctx.r9.u32 + 10552, ctx.r10.u32);
	// stfs f31,12(r11)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 12, temp.u32);
	// b 0x8211fd84
	goto loc_8211FD84;
loc_8211FD80:
	// lfs f13,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
loc_8211FD84:
	// stfs f13,2160(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2160, temp.u32);
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stfs f13,2164(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2164, temp.u32);
	// rldicr r12,r12,60,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 60) & 0xFFFFFFFFFFFFFFFF;
	// lfs f13,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// rldicr r9,r10,49,63
	ctx.r9.u64 = rotl64(ctx.r10.u64, 49) & 0xFFFFFFFFFFFFFFFF;
	// stfs f13,2168(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2168, temp.u32);
	// li r8,1
	ctx.r8.s64 = 1;
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,2172(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 2172, temp.u32);
	// rldicr r10,r8,47,63
	ctx.r10.u64 = rotl64(ctx.r8.u64, 47) & 0xFFFFFFFFFFFFFFFF;
	// ld r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// or r6,r7,r12
	ctx.r6.u64 = ctx.r7.u64 | ctx.r12.u64;
	// std r6,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r6.u64);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,6928(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6928, temp.u32);
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,6932(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6932, temp.u32);
	// lfs f13,8(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,6936(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6936, temp.u32);
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,6940(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6940, temp.u32);
	// ld r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r4,r5,r9
	ctx.r4.u64 = ctx.r5.u64 | ctx.r9.u64;
	// std r4,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r4.u64);
	// lfs f13,56(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,40(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// stfs f13,7048(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7048, temp.u32);
	// lfs f13,32(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,7040(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7040, temp.u32);
	// stfs f13,7044(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7044, temp.u32);
	// stfs f12,7052(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7052, temp.u32);
	// ld r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r11,r3,r10
	ctx.r11.u64 = ctx.r3.u64 | ctx.r10.u64;
	// std r11,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r11.u64);
	// stfs f31,7072(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7072, temp.u32);
	// stfs f31,7076(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7076, temp.u32);
	// stfs f31,7080(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7080, temp.u32);
	// stfs f31,7084(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7084, temp.u32);
	// ld r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r7,r8,r10
	ctx.r7.u64 = ctx.r8.u64 | ctx.r10.u64;
	// std r7,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r7.u64);
	// stfs f0,6944(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6944, temp.u32);
	// stfs f0,6948(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6948, temp.u32);
	// stfs f0,6952(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6952, temp.u32);
	// stfs f0,6956(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6956, temp.u32);
	// ld r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r5,r6,r9
	ctx.r5.u64 = ctx.r6.u64 | ctx.r9.u64;
	// std r5,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r5.u64);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// lfd f31,-72(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8211FE5C"))) PPC_WEAK_FUNC(sub_8211FE5C);
PPC_FUNC_IMPL(__imp__sub_8211FE5C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_8211FE60"))) PPC_WEAK_FUNC(sub_8211FE60);
PPC_FUNC_IMPL(__imp__sub_8211FE60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r7,31
	ctx.r7.s64 = 31;
	// lwz r3,2004(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2004);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// addi r5,r4,160
	ctx.r5.s64 = ctx.r4.s64 + 160;
	// li r6,16
	ctx.r6.s64 = 16;
	// rldicr r7,r7,54,9
	ctx.r7.u64 = rotl64(ctx.r7.u64, 54) & 0xFFC0000000000000;
	// li r4,21
	ctx.r4.s64 = 21;
	// bl 0x82238048
	ctx.lr = 0x8211FE90;
	sub_82238048(ctx, base);
	// li r12,1
	ctx.r12.s64 = 1;
	// li r11,1
	ctx.r11.s64 = 1;
	// rldicr r12,r12,46,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 46) & 0xFFFFFFFFFFFFFFFF;
	// li r10,4
	ctx.r10.s64 = 4;
	// rldicr r11,r11,45,63
	ctx.r11.u64 = rotl64(ctx.r11.u64, 45) & 0xFFFFFFFFFFFFFFFF;
	// addi r9,r31,124
	ctx.r9.s64 = ctx.r31.s64 + 124;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// li r11,0
	ctx.r11.s64 = 0;
	// li r7,1
	ctx.r7.s64 = 1;
	// lfs f0,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,7152(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7152, temp.u32);
	// lfs f13,20(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,7156(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7156, temp.u32);
	// lfs f12,24(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,7160(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7160, temp.u32);
	// lfs f11,28(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,7164(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7164, temp.u32);
	// ld r5,8(r3)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// or r4,r5,r12
	ctx.r4.u64 = ctx.r5.u64 | ctx.r12.u64;
	// std r4,8(r3)
	PPC_STORE_U64(ctx.r3.u32 + 8, ctx.r4.u64);
	// lfs f10,0(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,7200(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7200, temp.u32);
	// lfs f9,4(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,7204(r3)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7204, temp.u32);
	// lfs f8,8(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,7208(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7208, temp.u32);
	// lfs f7,12(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,7212(r3)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7212, temp.u32);
	// ld r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// or r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 | ctx.r8.u64;
	// std r8,8(r3)
	PPC_STORE_U64(ctx.r3.u32 + 8, ctx.r8.u64);
	// lfs f6,96(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,7168(r3)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7168, temp.u32);
	// lfs f5,100(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 100);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,7172(r3)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7172, temp.u32);
	// lfs f4,104(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 104);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,7176(r3)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7176, temp.u32);
	// lfs f3,108(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,7180(r3)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7180, temp.u32);
	// ld r5,8(r3)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// or r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 | ctx.r6.u64;
	// std r4,8(r3)
	PPC_STORE_U64(ctx.r3.u32 + 8, ctx.r4.u64);
	// lfs f2,112(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 112);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,7184(r3)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7184, temp.u32);
	// lfs f1,116(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 116);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,7188(r3)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7188, temp.u32);
	// lfs f0,120(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 120);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,7192(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7192, temp.u32);
	// lfs f13,124(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 124);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,7196(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 7196, temp.u32);
	// ld r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// or r8,r10,r6
	ctx.r8.u64 = ctx.r10.u64 | ctx.r6.u64;
	// std r8,8(r3)
	PPC_STORE_U64(ctx.r3.u32 + 8, ctx.r8.u64);
loc_8211FF70:
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// lwzu r8,4(r9)
	ea = 4 + ctx.r9.u32;
	ctx.r8.u64 = PPC_LOAD_U32(ea);
	ctx.r9.u32 = ea;
	// clrlwi r6,r11,27
	ctx.r6.u64 = ctx.r11.u32 & 0x1F;
	// addi r5,r10,2532
	ctx.r5.s64 = ctx.r10.s64 + 2532;
	// clrlwi r4,r8,31
	ctx.r4.u64 = ctx.r8.u32 & 0x1;
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r8,r7,r6
	ctx.r8.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r6.u8 & 0x3F));
	// lwzx r5,r10,r3
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// slw r4,r4,r6
	ctx.r4.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r4.u32 << (ctx.r6.u8 & 0x3F));
	// andc r8,r5,r8
	ctx.r8.u64 = ctx.r5.u64 & ~ctx.r8.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// or r6,r8,r4
	ctx.r6.u64 = ctx.r8.u64 | ctx.r4.u64;
	// stwx r6,r10,r3
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, ctx.r6.u32);
	// bdnz 0x8211ff70
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8211FF70;
	// li r11,1
	ctx.r11.s64 = 1;
	// ld r8,32(r3)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// li r10,4
	ctx.r10.s64 = 4;
	// rldicr r6,r11,56,63
	ctx.r6.u64 = rotl64(ctx.r11.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// addi r9,r31,140
	ctx.r9.s64 = ctx.r31.s64 + 140;
	// or r5,r8,r6
	ctx.r5.u64 = ctx.r8.u64 | ctx.r6.u64;
	// li r11,4
	ctx.r11.s64 = 4;
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// std r5,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, ctx.r5.u64);
loc_8211FFCC:
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x7FFFFFF;
	// lwzu r8,4(r9)
	ea = 4 + ctx.r9.u32;
	ctx.r8.u64 = PPC_LOAD_U32(ea);
	ctx.r9.u32 = ea;
	// clrlwi r5,r11,27
	ctx.r5.u64 = ctx.r11.u32 & 0x1F;
	// addi r4,r10,2532
	ctx.r4.s64 = ctx.r10.s64 + 2532;
	// clrlwi r8,r8,31
	ctx.r8.u64 = ctx.r8.u32 & 0x1;
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r4,r7,r5
	ctx.r4.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r5.u8 & 0x3F));
	// lwzx r31,r10,r3
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// slw r8,r8,r5
	ctx.r8.u64 = ctx.r5.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r5.u8 & 0x3F));
	// andc r5,r31,r4
	ctx.r5.u64 = ctx.r31.u64 & ~ctx.r4.u64;
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// or r4,r5,r8
	ctx.r4.u64 = ctx.r5.u64 | ctx.r8.u64;
	// stwx r4,r10,r3
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, ctx.r4.u32);
	// bdnz 0x8211ffcc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_8211FFCC;
	// ld r11,32(r3)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// or r10,r11,r6
	ctx.r10.u64 = ctx.r11.u64 | ctx.r6.u64;
	// std r10,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, ctx.r10.u64);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82120024"))) PPC_WEAK_FUNC(sub_82120024);
PPC_FUNC_IMPL(__imp__sub_82120024) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82120028"))) PPC_WEAK_FUNC(sub_82120028);
PPC_FUNC_IMPL(__imp__sub_82120028) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x82120030;
	__restfpr_24(ctx, base);
	// stfd f31,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, ctx.f31.u64);
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r6,12(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// lwz r9,2128(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2128);
	// lis r8,-32250
	ctx.r8.s64 = -2113536000;
	// clrlwi r4,r6,31
	ctx.r4.u64 = ctx.r6.u32 & 0x1;
	// addi r5,r8,31376
	ctx.r5.s64 = ctx.r8.s64 + 31376;
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// lwz r3,0(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// lwz r8,4(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// lwz r6,8(r9)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lfs f0,48(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// lwz r4,12(r9)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// lfs f31,36(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// addi r24,r10,27648
	ctx.r24.s64 = ctx.r10.s64 + 27648;
	// stw r3,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r3.u32);
	// stw r8,4(r7)
	PPC_STORE_U32(ctx.r7.u32 + 4, ctx.r8.u32);
	// stw r6,8(r7)
	PPC_STORE_U32(ctx.r7.u32 + 8, ctx.r6.u32);
	// stw r4,12(r7)
	PPC_STORE_U32(ctx.r7.u32 + 12, ctx.r4.u32);
	// stfs f0,148(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f0,144(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// beq cr6,0x821201a4
	if (ctx.cr6.eq) goto loc_821201A4;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// lwz r9,440(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 440);
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// cntlzw r8,r9
	ctx.r8.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// rlwinm r7,r8,27,31,31
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 27) & 0x1;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x821201a4
	if (ctx.cr6.eq) goto loc_821201A4;
	// lwz r30,1020(r10)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1020);
	// lfs f0,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fctidz f12,f0
	ctx.f12.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// fctidz f11,f13
	ctx.f11.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// li r4,0
	ctx.r4.s64 = 0;
	// stfd f12,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.f12.u64);
	// stfd f11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.f11.u64);
	// lwz r26,20(r11)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r11.u32 + 20);
	// lwz r29,4(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// lwz r28,116(r1)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r27,132(r1)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// bl 0x82298e30
	ctx.lr = 0x821200F0;
	sub_82298E30(ctx, base);
	// lwz r11,164(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	// cmplw cr6,r28,r11
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82120108
	if (!ctx.cr6.eq) goto loc_82120108;
	// lwz r11,168(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82120200
	if (ctx.cr6.eq) goto loc_82120200;
loc_82120108:
	// li r31,0
	ctx.r31.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r31.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r31.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82299680
	ctx.lr = 0x82120140;
	sub_82299680(ctx, base);
	// lis r7,6184
	ctx.r7.s64 = 405274624;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r31.u32);
	// ori r7,r7,438
	ctx.r7.u64 = ctx.r7.u64 | 438;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82298418
	ctx.lr = 0x82120178;
	sub_82298418(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r4,112(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// bl 0x822986a8
	ctx.lr = 0x82120184;
	sub_822986A8(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r29,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r29.u32);
	// stw r28,12(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12, ctx.r28.u32);
	// stw r27,16(r30)
	PPC_STORE_U32(ctx.r30.u32 + 16, ctx.r27.u32);
	// stw r11,20(r30)
	PPC_STORE_U32(ctx.r30.u32 + 20, ctx.r11.u32);
	// stw r31,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r31.u32);
	// stw r31,96(r30)
	PPC_STORE_U32(ctx.r30.u32 + 96, ctx.r31.u32);
	// b 0x82120200
	goto loc_82120200;
loc_821201A4:
	// lwz r11,2140(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 2140);
	// li r26,11
	ctx.r26.s64 = 11;
	// addi r31,r11,16
	ctx.r31.s64 = ctx.r11.s64 + 16;
	// addi r29,r11,120
	ctx.r29.s64 = ctx.r11.s64 + 120;
	// lwz r11,48(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	// clrlwi r30,r11,26
	ctx.r30.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r30,50
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 50, ctx.xer);
	// bne cr6,0x821201d0
	if (!ctx.cr6.eq) goto loc_821201D0;
	// li r10,3
	ctx.r10.s64 = 3;
	// rlwimi r11,r10,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r10.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_821201D0:
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,188(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 188);
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,20
	ctx.r4.s64 = 20;
	// bl 0x82227e30
	ctx.lr = 0x821201F4;
	sub_82227E30(ctx, base);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// rlwimi r11,r30,0,26,31
	ctx.r11.u64 = (rotl32(ctx.r30.u32, 0) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_82120200:
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8211c650
	ctx.lr = 0x82120208;
	sub_8211C650(ctx, base);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// rlwinm r3,r26,26,0,5
	ctx.r3.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 26) & 0xFC000000;
	// bl 0x8210af50
	ctx.lr = 0x82120228;
	sub_8210AF50(ctx, base);
	// lwz r10,2140(r25)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r25.u32 + 2140);
	// lwz r11,36(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 36);
	// addi r5,r10,1932
	ctx.r5.s64 = ctx.r10.s64 + 1932;
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212024c
	if (ctx.cr6.eq) goto loc_8212024C;
	// stw r5,36(r24)
	PPC_STORE_U32(ctx.r24.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212024C;
	sub_8222CDF8(ctx, base);
loc_8212024C:
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82113910
	ctx.lr = 0x82120254;
	sub_82113910(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// lfd f31,-80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82120260"))) PPC_WEAK_FUNC(sub_82120260);
PPC_FUNC_IMPL(__imp__sub_82120260) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82120268;
	__restfpr_27(ctx, base);
	// stfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,2140(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2140);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// li r27,3
	ctx.r27.s64 = 3;
	// addi r31,r11,16
	ctx.r31.s64 = ctx.r11.s64 + 16;
	// lwz r11,48(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 48);
	// clrlwi r30,r11,26
	ctx.r30.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r30,50
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 50, ctx.xer);
	// bne cr6,0x82120298
	if (!ctx.cr6.eq) goto loc_82120298;
	// rlwimi r11,r27,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r27.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_82120298:
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r5,r10,31376
	ctx.r5.s64 = ctx.r10.s64 + 31376;
	// addi r29,r11,27648
	ctx.r29.s64 = ctx.r11.s64 + 27648;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lfs f31,36(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// li r4,20
	ctx.r4.s64 = 20;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// bl 0x82227e30
	ctx.lr = 0x821202D0;
	sub_82227E30(ctx, base);
	// lwz r4,32(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rlwimi r30,r4,0,0,25
	ctx.r30.u64 = (rotl32(ctx.r4.u32, 0) & 0xFFFFFFC0) | (ctx.r30.u64 & 0xFFFFFFFF0000003F);
	// stw r30,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r30.u32);
	// bl 0x8211c650
	ctx.lr = 0x821202E4;
	sub_8211C650(ctx, base);
	// lwz r11,2140(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2140);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// addi r31,r11,120
	ctx.r31.s64 = ctx.r11.s64 + 120;
	// lwz r11,152(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 152);
	// clrlwi r30,r11,26
	ctx.r30.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r30,50
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 50, ctx.xer);
	// bne cr6,0x82120308
	if (!ctx.cr6.eq) goto loc_82120308;
	// rlwimi r11,r27,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r27.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
loc_82120308:
	// li r8,0
	ctx.r8.s64 = 0;
	// lwz r3,188(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 188);
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lis r4,11264
	ctx.r4.s64 = 738197504;
	// bl 0x82227e30
	ctx.lr = 0x82120328;
	sub_82227E30(ctx, base);
	// lwz r11,32(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	// rlwimi r11,r30,0,26,31
	ctx.r11.u64 = (rotl32(ctx.r30.u32, 0) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r31)
	PPC_STORE_U32(ctx.r31.u32 + 32, ctx.r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-56(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82120340"))) PPC_WEAK_FUNC(sub_82120340);
PPC_FUNC_IMPL(__imp__sub_82120340) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82120348;
	__restfpr_26(ctx, base);
	// stfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, ctx.f30.u64);
	// stfd f31,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f31.u64);
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lwz r10,12(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// addi r9,r11,31376
	ctx.r9.s64 = ctx.r11.s64 + 31376;
	// clrlwi r8,r10,31
	ctx.r8.u64 = ctx.r10.u32 & 0x1;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// stb r8,2132(r28)
	PPC_STORE_U8(ctx.r28.u32 + 2132, ctx.r8.u8);
	// lfs f31,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// lwz r31,2004(r28)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r28.u32 + 2004);
	// lfs f30,36(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// stfs f31,168(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// stfs f31,164(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stfs f31,160(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// stfs f31,156(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// stfs f31,148(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f31,144(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f31,140(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// stfs f31,136(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f31,128(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f31,124(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stfs f31,120(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// stfs f31,116(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f30,172(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// stfs f30,152(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// stfs f30,132(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stfs f30,112(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// bl 0x82113ab8
	ctx.lr = 0x821203C4;
	sub_82113AB8(ctx, base);
	// lwz r7,16(r27)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// li r4,2
	ctx.r4.s64 = 2;
	// stw r7,2012(r28)
	PPC_STORE_U32(ctx.r28.u32 + 2012, ctx.r7.u32);
	// lwz r6,12(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// clrlwi r5,r6,31
	ctx.r5.u64 = ctx.r6.u32 & 0x1;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// bne cr6,0x821203e8
	if (!ctx.cr6.eq) goto loc_821203E8;
	// li r4,0
	ctx.r4.s64 = 0;
loc_821203E8:
	// bl 0x822324a0
	ctx.lr = 0x821203EC;
	sub_822324A0(ctx, base);
	// li r6,96
	ctx.r6.s64 = 96;
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x822389e8
	ctx.lr = 0x82120400;
	sub_822389E8(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stfs f30,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// li r7,1
	ctx.r7.s64 = 1;
	// stfs f31,84(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stw r11,2116(r28)
	PPC_STORE_U32(ctx.r28.u32 + 2116, ctx.r11.u32);
	// stfs f31,88(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// rldicr r7,r7,38,63
	ctx.r7.u64 = rotl64(ctx.r7.u64, 38) & 0xFFFFFFFFFFFFFFFF;
	// stfs f31,92(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// li r6,2
	ctx.r6.s64 = 2;
	// stfs f31,96(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stfs f30,100(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// li r4,101
	ctx.r4.s64 = 101;
	// stfs f31,104(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stfs f31,108(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// bl 0x82238120
	ctx.lr = 0x82120444;
	sub_82238120(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// lis r9,-30584
	ctx.r9.s64 = -2004353024;
	// addi r8,r10,22200
	ctx.r8.s64 = ctx.r10.s64 + 22200;
	// ori r7,r9,34953
	ctx.r7.u64 = ctx.r9.u64 | 34953;
	// lwz r11,984(r8)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 984);
	// mulhwu r6,r11,r7
	ctx.r6.u64 = (uint64_t(ctx.r11.u32) * uint64_t(ctx.r7.u32)) >> 32;
	// rlwinm r5,r6,28,4,31
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 28) & 0xFFFFFFF;
	// mulli r4,r5,30
	ctx.r4.s64 = ctx.r5.s64 * 30;
	// subf. r3,r4,r11
	ctx.r3.s64 = ctx.r11.s64 - ctx.r4.s64;
	ctx.cr0.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne 0x82120558
	if (!ctx.cr0.eq) goto loc_82120558;
	// bl 0x8233c830
	ctx.lr = 0x82120470;
	sub_8233C830(ctx, base);
	// rlwinm r10,r3,16,16,31
	ctx.r10.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 16) & 0xFFFF;
	// lis r11,-32640
	ctx.r11.s64 = -2139095040;
	// xor r9,r10,r3
	ctx.r9.u64 = ctx.r10.u64 ^ ctx.r3.u64;
	// ori r31,r11,32897
	ctx.r31.u64 = ctx.r11.u64 | 32897;
	// rlwinm r8,r9,24,8,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xFFFFFF;
	// li r11,127
	ctx.r11.s64 = 127;
	// xor r6,r8,r9
	ctx.r6.u64 = ctx.r8.u64 ^ ctx.r9.u64;
	// rlwinm r7,r11,1,31,31
	ctx.r7.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0x1;
	// mulhwu r5,r6,r31
	ctx.r5.u64 = (uint64_t(ctx.r6.u32) * uint64_t(ctx.r31.u32)) >> 32;
	// rlwinm r4,r5,25,7,31
	ctx.r4.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 25) & 0x1FFFFFF;
	// li r30,255
	ctx.r30.s64 = 255;
	// rlwinm r3,r4,8,0,23
	ctx.r3.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 8) & 0xFFFFFF00;
	// subf r10,r4,r3
	ctx.r10.s64 = ctx.r3.s64 - ctx.r4.s64;
	// subf r9,r10,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r10.s64;
	// subfc r8,r9,r11
	ctx.xer.ca = ctx.r11.u32 >= ctx.r9.u32;
	ctx.r8.s64 = ctx.r11.s64 - ctx.r9.s64;
	// rlwinm r6,r9,1,31,31
	ctx.r6.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x1;
	// subfe r5,r7,r6
	temp.u8 = (~ctx.r7.u32 + ctx.r6.u32 < ~ctx.r7.u32) | (~ctx.r7.u32 + ctx.r6.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r5.u64 = ~ctx.r7.u64 + ctx.r6.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r29,r5,r30
	ctx.r29.u64 = ctx.r5.u64 & ctx.r30.u64;
	// bl 0x8233c830
	ctx.lr = 0x821204BC;
	sub_8233C830(ctx, base);
	// rlwinm r4,r3,16,16,31
	ctx.r4.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 16) & 0xFFFF;
	// li r11,127
	ctx.r11.s64 = 127;
	// xor r9,r4,r3
	ctx.r9.u64 = ctx.r4.u64 ^ ctx.r3.u64;
	// rlwinm r10,r11,1,31,31
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0x1;
	// rlwinm r8,r9,24,8,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xFFFFFF;
	// xor r7,r8,r9
	ctx.r7.u64 = ctx.r8.u64 ^ ctx.r9.u64;
	// mulhwu r6,r7,r31
	ctx.r6.u64 = (uint64_t(ctx.r7.u32) * uint64_t(ctx.r31.u32)) >> 32;
	// rlwinm r5,r6,25,7,31
	ctx.r5.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 25) & 0x1FFFFFF;
	// rlwinm r4,r5,8,0,23
	ctx.r4.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 8) & 0xFFFFFF00;
	// subf r3,r5,r4
	ctx.r3.s64 = ctx.r4.s64 - ctx.r5.s64;
	// subf r9,r3,r7
	ctx.r9.s64 = ctx.r7.s64 - ctx.r3.s64;
	// subfc r8,r9,r11
	ctx.xer.ca = ctx.r11.u32 >= ctx.r9.u32;
	ctx.r8.s64 = ctx.r11.s64 - ctx.r9.s64;
	// rlwinm r7,r9,1,31,31
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x1;
	// subfe r6,r10,r7
	temp.u8 = (~ctx.r10.u32 + ctx.r7.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r7.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r6.u64 = ~ctx.r10.u64 + ctx.r7.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r26,r6,r30
	ctx.r26.u64 = ctx.r6.u64 & ctx.r30.u64;
	// bl 0x8233c830
	ctx.lr = 0x821204FC;
	sub_8233C830(ctx, base);
	// rlwinm r5,r3,16,16,31
	ctx.r5.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 16) & 0xFFFF;
	// lis r6,-32178
	ctx.r6.s64 = -2108817408;
	// xor r3,r5,r3
	ctx.r3.u64 = ctx.r5.u64 ^ ctx.r3.u64;
	// lis r4,-1
	ctx.r4.s64 = -65536;
	// rlwinm r8,r3,24,8,31
	ctx.r8.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 24) & 0xFFFFFF;
	// rlwimi r4,r29,8,16,23
	ctx.r4.u64 = (rotl32(ctx.r29.u32, 8) & 0xFF00) | (ctx.r4.u64 & 0xFFFFFFFFFFFF00FF);
	// xor r7,r8,r3
	ctx.r7.u64 = ctx.r8.u64 ^ ctx.r3.u64;
	// lwz r10,25800(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 25800);
	// or r8,r4,r26
	ctx.r8.u64 = ctx.r4.u64 | ctx.r26.u64;
	// mulhwu r5,r7,r31
	ctx.r5.u64 = (uint64_t(ctx.r7.u32) * uint64_t(ctx.r31.u32)) >> 32;
	// rlwinm r3,r5,25,7,31
	ctx.r3.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 25) & 0x1FFFFFF;
	// li r11,127
	ctx.r11.s64 = 127;
	// rlwinm r6,r3,8,0,23
	ctx.r6.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 8) & 0xFFFFFF00;
	// rlwinm r9,r11,1,31,31
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0x1;
	// subf r4,r3,r6
	ctx.r4.s64 = ctx.r6.s64 - ctx.r3.s64;
	// rlwinm r5,r8,8,0,23
	ctx.r5.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 8) & 0xFFFFFF00;
	// subf r3,r4,r7
	ctx.r3.s64 = ctx.r7.s64 - ctx.r4.s64;
	// subfc r11,r3,r11
	ctx.xer.ca = ctx.r11.u32 >= ctx.r3.u32;
	ctx.r11.s64 = ctx.r11.s64 - ctx.r3.s64;
	// rlwinm r8,r3,1,31,31
	ctx.r8.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0x1;
	// subfe r7,r9,r8
	temp.u8 = (~ctx.r9.u32 + ctx.r8.u32 < ~ctx.r9.u32) | (~ctx.r9.u32 + ctx.r8.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r7.u64 = ~ctx.r9.u64 + ctx.r8.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// and r6,r7,r30
	ctx.r6.u64 = ctx.r7.u64 & ctx.r30.u64;
	// or r5,r5,r6
	ctx.r5.u64 = ctx.r5.u64 | ctx.r6.u64;
	// stw r5,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r5.u32);
loc_82120558:
	// lwz r30,20(r27)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// lwz r31,0(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x821205b4
	if (ctx.cr6.eq) goto loc_821205B4;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// lis r11,-32249
	ctx.r11.s64 = -2113470464;
	// addi r29,r11,-32448
	ctx.r29.s64 = ctx.r11.s64 + -32448;
loc_82120578:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x8212058C;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r29,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r29.u32);
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x8212059C;
	sub_82080000(ctx, base);
	// lwz r31,0(r30)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x821205b4
	if (ctx.cr6.eq) goto loc_821205B4;
	// lwz r11,4(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r11,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r11.u32);
	// bne cr6,0x82120578
	if (!ctx.cr6.eq) goto loc_82120578;
loc_821205B4:
	// lwz r11,668(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 668);
	// stw r11,2144(r28)
	PPC_STORE_U32(ctx.r28.u32 + 2144, ctx.r11.u32);
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// lfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821205CC"))) PPC_WEAK_FUNC(sub_821205CC);
PPC_FUNC_IMPL(__imp__sub_821205CC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821205D0"))) PPC_WEAK_FUNC(sub_821205D0);
PPC_FUNC_IMPL(__imp__sub_821205D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e44c
	ctx.lr = 0x821205D8;
	__restfpr_21(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r31,2004(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2004);
	// mr r21,r3
	ctx.r21.u64 = ctx.r3.u64;
	// addi r30,r11,27648
	ctx.r30.s64 = ctx.r11.s64 + 27648;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// lwz r5,364(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 364);
	// lwz r11,36(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82120610
	if (ctx.cr6.eq) goto loc_82120610;
	// stw r5,36(r30)
	PPC_STORE_U32(ctx.r30.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82120610;
	sub_8222CDF8(ctx, base);
loc_82120610:
	// lwz r29,368(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 368);
	// lwz r11,52(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212063c
	if (ctx.cr6.eq) goto loc_8212063C;
	// stw r29,52(r30)
	PPC_STORE_U32(ctx.r30.u32 + 52, ctx.r29.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// bl 0x8222d188
	ctx.lr = 0x82120630;
	sub_8222D188(ctx, base);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8212063c
	if (ctx.cr6.eq) goto loc_8212063C;
	// bl 0x82113790
	ctx.lr = 0x8212063C;
	sub_82113790(ctx, base);
loc_8212063C:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x822389e8
	ctx.lr = 0x82120650;
	sub_822389E8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82234570
	ctx.lr = 0x8212065C;
	sub_82234570(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r29,360(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 360);
	// bl 0x8211c650
	ctx.lr = 0x82120668;
	sub_8211C650(ctx, base);
	// lwz r11,32(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 32);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// clrlwi r28,r11,26
	ctx.r28.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r28,50
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 50, ctx.xer);
	// bne cr6,0x82120688
	if (!ctx.cr6.eq) goto loc_82120688;
	// li r10,3
	ctx.r10.s64 = 3;
	// rlwimi r11,r10,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r10.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r29)
	PPC_STORE_U32(ctx.r29.u32 + 32, ctx.r11.u32);
loc_82120688:
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lwz r3,188(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 188);
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r4,r10,31376
	ctx.r4.s64 = ctx.r10.s64 + 31376;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r29
	ctx.r6.u64 = ctx.r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lfs f1,48(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// li r4,768
	ctx.r4.s64 = 768;
	// bl 0x82227e30
	ctx.lr = 0x821206B0;
	sub_82227E30(ctx, base);
	// lwz r3,32(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 32);
	// rlwimi r3,r28,0,26,31
	ctx.r3.u64 = (rotl32(ctx.r28.u32, 0) & 0x3F) | (ctx.r3.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r3,32(r29)
	PPC_STORE_U32(ctx.r29.u32 + 32, ctx.r3.u32);
	// lwz r11,52(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821206cc
	if (ctx.cr6.eq) goto loc_821206CC;
	// bl 0x82113790
	ctx.lr = 0x821206CC;
	sub_82113790(ctx, base);
loc_821206CC:
	// lbz r11,12(r27)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r27.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821206e4
	if (ctx.cr6.eq) goto loc_821206E4;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x821208a0
	ctx.lr = 0x821206E4;
	sub_821208A0(ctx, base);
loc_821206E4:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,360(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 360);
	// bl 0x822352a0
	ctx.lr = 0x821206F0;
	sub_822352A0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r26,0
	ctx.r26.s64 = 0;
	// addi r28,r11,28184
	ctx.r28.s64 = ctx.r11.s64 + 28184;
	// li r11,1
	ctx.r11.s64 = 1;
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
	// addi r29,r28,292
	ctx.r29.s64 = ctx.r28.s64 + 292;
	// rldicr r27,r11,63,63
	ctx.r27.u64 = rotl64(ctx.r11.u64, 63) & 0xFFFFFFFFFFFFFFFF;
loc_8212070C:
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82120738
	if (ctx.cr6.eq) goto loc_82120738;
	// addi r11,r30,32
	ctx.r11.s64 = ctx.r30.s64 + 32;
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// clrldi r10,r11,32
	ctx.r10.u64 = ctx.r11.u64 & 0xFFFFFFFF;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// srd r6,r27,r10
	ctx.r6.u64 = ctx.r10.u8 & 0x40 ? 0 : (ctx.r27.u64 >> (ctx.r10.u8 & 0x7F));
	// bl 0x82237a38
	ctx.lr = 0x82120734;
	sub_82237A38(ctx, base);
	// stw r26,0(r29)
	PPC_STORE_U32(ctx.r29.u32 + 0, ctx.r26.u32);
loc_82120738:
	// addi r29,r29,4
	ctx.r29.s64 = ctx.r29.s64 + 4;
	// addi r11,r28,356
	ctx.r11.s64 = ctx.r28.s64 + 356;
	// addi r30,r30,1
	ctx.r30.s64 = ctx.r30.s64 + 1;
	// cmpw cr6,r29,r11
	ctx.cr6.compare<int32_t>(ctx.r29.s32, ctx.r11.s32, ctx.xer);
	// blt cr6,0x8212070c
	if (ctx.cr6.lt) goto loc_8212070C;
	// lwz r24,80(r1)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r28,r26
	ctx.r28.u64 = ctx.r26.u64;
	// addi r22,r31,12880
	ctx.r22.s64 = ctx.r31.s64 + 12880;
	// addi r25,r31,12808
	ctx.r25.s64 = ctx.r31.s64 + 12808;
	// lis r27,16384
	ctx.r27.s64 = 1073741824;
	// li r23,-1
	ctx.r23.s64 = -1;
loc_82120764:
	// lwz r29,4(r25)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x8212085c
	if (ctx.cr6.eq) goto loc_8212085C;
	// lwz r11,11036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82120784
	if (ctx.cr6.eq) goto loc_82120784;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// b 0x8212085c
	goto loc_8212085C;
loc_82120784:
	// lwz r11,11040(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11040);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// and r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 & ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x8212085c
	if (ctx.cr6.eq) goto loc_8212085C;
	// lwz r11,13912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13912);
	// lwz r10,13916(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13916);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x8212083c
	if (ctx.cr6.lt) goto loc_8212083C;
	// li r5,128
	ctx.r5.s64 = 128;
	// lwz r30,13908(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13908);
	// li r4,502
	ctx.r4.s64 = 502;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82230228
	ctx.lr = 0x821207BC;
	sub_82230228(ctx, base);
	// lbz r11,11069(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 11069);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821207d8
	if (ctx.cr6.eq) goto loc_821207D8;
	// lwz r8,17120(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 17120);
	// b 0x8212082c
	goto loc_8212082C;
loc_821207D8:
	// rlwinm r11,r8,12,20,31
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 12) & 0xFFF;
	// stw r8,13908(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13908, ctx.r8.u32);
	// clrlwi r10,r8,3
	ctx.r10.u64 = ctx.r8.u32 & 0x1FFFFFFF;
	// stw r26,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r26.u32);
	// addi r11,r11,512
	ctx.r11.s64 = ctx.r11.s64 + 512;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// subf r3,r27,r10
	ctx.r3.s64 = ctx.r10.s64 - ctx.r27.s64;
	// bne cr6,0x8212080c
	if (!ctx.cr6.eq) goto loc_8212080C;
	// lwz r11,13904(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13904);
	// stw r3,112(r11)
	PPC_STORE_U32(ctx.r11.u32 + 112, ctx.r3.u32);
	// b 0x82120824
	goto loc_82120824;
loc_8212080C:
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// lwz r11,13912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13912);
	// subf r11,r30,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r30.s64;
	// addi r10,r11,-8
	ctx.r10.s64 = ctx.r11.s64 + -8;
	// srawi r9,r10,3
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 3;
	// stw r9,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r9.u32);
loc_82120824:
	// addi r4,r3,2008
	ctx.r4.s64 = ctx.r3.s64 + 2008;
	// bl 0x8223b9b8
	ctx.lr = 0x8212082C;
	sub_8223B9B8(ctx, base);
loc_8212082C:
	// addi r11,r8,8
	ctx.r11.s64 = ctx.r8.s64 + 8;
	// addi r10,r8,2008
	ctx.r10.s64 = ctx.r8.s64 + 2008;
	// stw r11,13912(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13912, ctx.r11.u32);
	// stw r10,13916(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13916, ctx.r10.u32);
loc_8212083C:
	// rlwimi r24,r29,30,2,31
	ctx.r24.u64 = (rotl32(ctx.r29.u32, 30) & 0x3FFFFFFF) | (ctx.r24.u64 & 0xFFFFFFFFC0000000);
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r23.u32);
	// addi r10,r11,8
	ctx.r10.s64 = ctx.r11.s64 + 8;
	// rlwinm r24,r24,0,2,0
	ctx.r24.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r24,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r24.u32);
	// ld r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r9,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r9.u64);
	// stw r10,13912(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13912, ctx.r10.u32);
loc_8212085C:
	// stwu r26,4(r25)
	ea = 4 + ctx.r25.u32;
	PPC_STORE_U32(ea, ctx.r26.u32);
	ctx.r25.u32 = ea;
	// stbx r26,r22,r28
	PPC_STORE_U8(ctx.r22.u32 + ctx.r28.u32, ctx.r26.u8);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// cmpwi cr6,r28,4
	ctx.cr6.compare<int32_t>(ctx.r28.s32, 4, ctx.xer);
	// blt cr6,0x82120764
	if (ctx.cr6.lt) goto loc_82120764;
	// stw r26,2128(r21)
	PPC_STORE_U32(ctx.r21.u32 + 2128, ctx.r26.u32);
	// stw r26,2124(r21)
	PPC_STORE_U32(ctx.r21.u32 + 2124, ctx.r26.u32);
	// stw r26,1712(r21)
	PPC_STORE_U32(ctx.r21.u32 + 1712, ctx.r26.u32);
	// stw r26,1720(r21)
	PPC_STORE_U32(ctx.r21.u32 + 1720, ctx.r26.u32);
	// stw r26,1796(r21)
	PPC_STORE_U32(ctx.r21.u32 + 1796, ctx.r26.u32);
	// stw r26,1728(r21)
	PPC_STORE_U32(ctx.r21.u32 + 1728, ctx.r26.u32);
	// stw r26,1764(r21)
	PPC_STORE_U32(ctx.r21.u32 + 1764, ctx.r26.u32);
	// stw r26,4(r21)
	PPC_STORE_U32(ctx.r21.u32 + 4, ctx.r26.u32);
	// stw r26,2140(r21)
	PPC_STORE_U32(ctx.r21.u32 + 2140, ctx.r26.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212089C"))) PPC_WEAK_FUNC(sub_8212089C);
PPC_FUNC_IMPL(__imp__sub_8212089C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821208A0"))) PPC_WEAK_FUNC(sub_821208A0);
PPC_FUNC_IMPL(__imp__sub_821208A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e438
	ctx.lr = 0x821208A8;
	__restfpr_16(ctx, base);
	// stfd f31,-144(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -144, ctx.f31.u64);
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32179
	ctx.r10.s64 = -2108882944;
	// lhz r11,280(r4)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r4.u32 + 280);
	// lis r9,0
	ctx.r9.s64 = 0;
	// lwz r17,2004(r3)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2004);
	// lis r8,0
	ctx.r8.s64 = 0;
	// addi r7,r10,20000
	ctx.r7.s64 = ctx.r10.s64 + 20000;
	// ori r6,r9,65512
	ctx.r6.u64 = ctx.r9.u64 | 65512;
	// ori r5,r8,65516
	ctx.r5.u64 = ctx.r8.u64 | 65516;
	// mr r16,r4
	ctx.r16.u64 = ctx.r4.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwzx r27,r7,r6
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r6.u32);
	// lwzx r29,r7,r5
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r5.u32);
	// beq cr6,0x821208f0
	if (ctx.cr6.eq) goto loc_821208F0;
	// lhz r10,282(r4)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r4.u32 + 282);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x821208f4
	if (!ctx.cr6.eq) goto loc_821208F4;
loc_821208F0:
	// clrlwi r11,r27,16
	ctx.r11.u64 = ctx.r27.u32 & 0xFFFF;
loc_821208F4:
	// clrlwi r10,r11,16
	ctx.r10.u64 = ctx.r11.u32 & 0xFFFF;
	// divwu r11,r27,r10
	ctx.r11.u32 = ctx.r27.u32 / ctx.r10.u32;
	// twllei r10,0
	if (ctx.r10.u32 <= 0) __builtin_debugtrap();
	// clrlwi r11,r11,31
	ctx.r11.u64 = ctx.r11.u32 & 0x1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bgt cr6,0x82120910
	if (ctx.cr6.gt) goto loc_82120910;
	// li r11,1
	ctx.r11.s64 = 1;
loc_82120910:
	// clrlwi r11,r11,16
	ctx.r11.u64 = ctx.r11.u32 & 0xFFFF;
	// li r31,0
	ctx.r31.s64 = 0;
	// mr r18,r11
	ctx.r18.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// bgt cr6,0x82120930
	if (ctx.cr6.gt) goto loc_82120930;
	// cmplw cr6,r27,r10
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r10.u32, ctx.xer);
	// mr r10,r31
	ctx.r10.u64 = ctx.r31.u64;
	// ble cr6,0x82120934
	if (!ctx.cr6.gt) goto loc_82120934;
loc_82120930:
	// li r10,1
	ctx.r10.s64 = 1;
loc_82120934:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// stw r31,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r31.u32);
	// lis r25,-32178
	ctx.r25.s64 = -2108817408;
	// stw r31,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r31.u32);
	// addi r24,r11,27648
	ctx.r24.s64 = ctx.r11.s64 + 27648;
	// stw r31,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r31.u32);
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// stw r31,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r31.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// clrlwi r28,r10,24
	ctx.r28.u64 = ctx.r10.u32 & 0xFF;
	// lwz r23,25684(r25)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r25.u32 + 25684);
	// lwz r22,360(r24)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r24.u32 + 360);
	// mr r3,r22
	ctx.r3.u64 = ctx.r22.u64;
	// bl 0x822365d8
	ctx.lr = 0x8212096C;
	sub_822365D8(ctx, base);
	// lis r11,10280
	ctx.r11.s64 = 673710080;
	// addi r7,r1,128
	ctx.r7.s64 = ctx.r1.s64 + 128;
	// ori r21,r11,390
	ctx.r21.u64 = ctx.r11.u64 | 390;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r21
	ctx.r5.u64 = ctx.r21.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82237798
	ctx.lr = 0x8212098C;
	sub_82237798(ctx, base);
	// lwz r11,36(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 36);
	// mr r20,r3
	ctx.r20.u64 = ctx.r3.u64;
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x821209b0
	if (ctx.cr6.eq) goto loc_821209B0;
	// stw r3,36(r24)
	PPC_STORE_U32(ctx.r24.u32 + 36, ctx.r3.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x821209B0;
	sub_8222CDF8(ctx, base);
loc_821209B0:
	// lwz r11,52(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 52);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821209d0
	if (ctx.cr6.eq) goto loc_821209D0;
	// stw r31,52(r24)
	PPC_STORE_U32(ctx.r24.u32 + 52, ctx.r31.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 188);
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// bl 0x8222d188
	ctx.lr = 0x821209D0;
	sub_8222D188(ctx, base);
loc_821209D0:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r30,r11,28184
	ctx.r30.s64 = ctx.r11.s64 + 28184;
	// lwz r11,292(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 292);
	// cmplw cr6,r11,r22
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r22.u32, ctx.xer);
	// beq cr6,0x82120a00
	if (ctx.cr6.eq) goto loc_82120A00;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r5,r22
	ctx.r5.u64 = ctx.r22.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x821209FC;
	sub_82237A38(ctx, base);
	// stw r22,292(r30)
	PPC_STORE_U32(ctx.r30.u32 + 292, ctx.r22.u32);
loc_82120A00:
	// clrlwi r19,r28,24
	ctx.r19.u64 = ctx.r28.u32 & 0xFF;
	// lwz r11,2052(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// stw r31,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r31.u32);
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x82120aa4
	if (ctx.cr6.eq) goto loc_82120AA4;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82120a34
	if (ctx.cr6.eq) goto loc_82120A34;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82120A2C;
	sub_8222C0A0(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r11.u32);
loc_82120A34:
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82120a58
	if (ctx.cr6.eq) goto loc_82120A58;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82120A50;
	sub_8222C248(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r11.u32);
loc_82120A58:
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r3,25684(r25)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r25.u32 + 25684);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r31.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,116
	ctx.r4.s64 = ctx.r1.s64 + 116;
	// bl 0x82299680
	ctx.lr = 0x82120A88;
	sub_82299680(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x82082030
	ctx.lr = 0x82120A9C;
	sub_82082030(ctx, base);
	// mr r23,r3
	ctx.r23.u64 = ctx.r3.u64;
	// b 0x82120ae8
	goto loc_82120AE8;
loc_82120AA4:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82120ac4
	if (ctx.cr6.eq) goto loc_82120AC4;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82120ABC;
	sub_8222C0A0(ctx, base);
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r31.u32);
loc_82120AC4:
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82120ae8
	if (ctx.cr6.eq) goto loc_82120AE8;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82120AE0;
	sub_8222C248(ctx, base);
	// mr r11,r31
	ctx.r11.u64 = ctx.r31.u64;
	// stw r31,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r31.u32);
loc_82120AE8:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x82120AF4;
	sub_82113BC0(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x82120B00;
	sub_82111340(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25780(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25780);
	// bl 0x8211c5f0
	ctx.lr = 0x82120B0C;
	sub_8211C5F0(ctx, base);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// stw r31,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, ctx.r31.u32);
	// stw r31,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r31.u32);
	// mr r30,r27
	ctx.r30.u64 = ctx.r27.u64;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// stw r31,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r31.u32);
	// stw r29,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r29.u32);
	// mr r26,r29
	ctx.r26.u64 = ctx.r29.u64;
	// stw r27,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r27.u32);
	// mr r28,r31
	ctx.r28.u64 = ctx.r31.u64;
	// stw r27,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r27.u32);
	// cmplwi cr6,r18,0
	ctx.cr6.compare<uint32_t>(ctx.r18.u32, 0, ctx.xer);
	// stw r29,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r29.u32);
	// lfs f31,48(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// stw r31,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r31.u32);
	// stfs f31,176(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// stfs f31,180(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lwz r25,25684(r25)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r25.u32 + 25684);
	// beq cr6,0x82120c28
	if (ctx.cr6.eq) goto loc_82120C28;
loc_82120B58:
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x82120b98
	if (ctx.cr6.eq) goto loc_82120B98;
	// srawi r27,r27,1
	ctx.xer.ca = (ctx.r27.s32 < 0) & ((ctx.r27.u32 & 0x1) != 0);
	ctx.r27.s64 = ctx.r27.s32 >> 1;
	// rlwinm r30,r30,31,1,31
	ctx.r30.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r29,r29,31,1,31
	ctx.r29.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 31) & 0x7FFFFFFF;
	// stw r27,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r27.u32);
	// srawi r26,r26,1
	ctx.xer.ca = (ctx.r26.s32 < 0) & ((ctx.r26.u32 & 0x1) != 0);
	ctx.r26.s64 = ctx.r26.s32 >> 1;
	// stw r30,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, ctx.r30.u32);
	// stw r29,172(r1)
	PPC_STORE_U32(ctx.r1.u32 + 172, ctx.r29.u32);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// stw r26,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r26.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r4,r22
	ctx.r4.u64 = ctx.r22.u64;
	// beq cr6,0x82120b94
	if (ctx.cr6.eq) goto loc_82120B94;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
loc_82120B94:
	// bl 0x82111400
	ctx.lr = 0x82120B98;
	sub_82111400(ctx, base);
loc_82120B98:
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x8222cbc8
	ctx.lr = 0x82120BA4;
	sub_8222CBC8(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x82120BA8;
	sub_8210B0D8(ctx, base);
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x82120bf4
	if (ctx.cr6.eq) goto loc_82120BF4;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r23,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r23.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r31.u32);
	// mr r7,r21
	ctx.r7.u64 = ctx.r21.u64;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82298418
	ctx.lr = 0x82120BE4;
	sub_82298418(ctx, base);
	// mr r3,r23
	ctx.r3.u64 = ctx.r23.u64;
	// lwz r4,116(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// bl 0x822986a8
	ctx.lr = 0x82120BF0;
	sub_822986A8(ctx, base);
	// mr r25,r23
	ctx.r25.u64 = ctx.r23.u64;
loc_82120BF4:
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x8211c650
	ctx.lr = 0x82120BFC;
	sub_8211C650(ctx, base);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// li r3,256
	ctx.r3.s64 = 256;
	// bl 0x8210af50
	ctx.lr = 0x82120C1C;
	sub_8210AF50(ctx, base);
	// addi r28,r28,1
	ctx.r28.s64 = ctx.r28.s64 + 1;
	// cmplw cr6,r28,r18
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, ctx.r18.u32, ctx.xer);
	// blt cr6,0x82120b58
	if (ctx.cr6.lt) goto loc_82120B58;
loc_82120C28:
	// lwz r5,364(r24)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r24.u32 + 364);
	// lwz r11,36(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82120c48
	if (ctx.cr6.eq) goto loc_82120C48;
	// stw r5,36(r24)
	PPC_STORE_U32(ctx.r24.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82120C48;
	sub_8222CDF8(ctx, base);
loc_82120C48:
	// lwz r3,368(r24)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r24.u32 + 368);
	// bl 0x8210b080
	ctx.lr = 0x82120C50;
	sub_8210B080(ctx, base);
	// mr r3,r20
	ctx.r3.u64 = ctx.r20.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x82120C58;
	sub_8222F0F8(ctx, base);
	// lwz r11,276(r16)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r16.u32 + 276);
	// cmpwi cr6,r11,6
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 6, ctx.xer);
	// bne cr6,0x82120d50
	if (!ctx.cr6.eq) goto loc_82120D50;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,284(r16)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r16.u32 + 284);
	// li r6,264
	ctx.r6.s64 = 264;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82085870
	ctx.lr = 0x82120C7C;
	sub_82085870(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82120cac
	if (!ctx.cr6.eq) goto loc_82120CAC;
loc_82120C84:
	// cmplwi cr6,r19,0
	ctx.cr6.compare<uint32_t>(ctx.r19.u32, 0, ctx.xer);
	// beq cr6,0x82120d50
	if (ctx.cr6.eq) goto loc_82120D50;
	// cmplwi cr6,r23,0
	ctx.cr6.compare<uint32_t>(ctx.r23.u32, 0, ctx.xer);
	// beq cr6,0x82120d50
	if (ctx.cr6.eq) goto loc_82120D50;
	// addi r4,r23,-16
	ctx.r4.s64 = ctx.r23.s64 + -16;
	// lwz r3,-8(r23)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r23.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82120CA0;
	sub_82080000(ctx, base);
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// lfd f31,-144(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -144);
	// b 0x8233e488
	__restgprlr_16(ctx, base);
	return;
loc_82120CAC:
	// lwz r31,20(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82120c84
	if (ctx.cr6.eq) goto loc_82120C84;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r25
	ctx.r5.u64 = ctx.r25.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8225ac18
	ctx.lr = 0x82120CCC;
	sub_8225AC18(ctx, base);
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r11,0(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	// mtctr r10
	ctx.ctr.u64 = ctx.r10.u64;
	// bctrl 
	ctx.lr = 0x82120CE0;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// bl 0x82082030
	ctx.lr = 0x82120CF4;
	sub_82082030(ctx, base);
	// lwz r11,112(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r8,12(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// mtctr r8
	ctx.ctr.u64 = ctx.r8.u64;
	// bctrl 
	ctx.lr = 0x82120D10;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x8233e4e0
	ctx.lr = 0x82120D20;
	sub_8233E4E0(ctx, base);
	// lwz r3,112(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r7,0(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r6,8(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// mtctr r6
	ctx.ctr.u64 = ctx.r6.u64;
	// bctrl 
	ctx.lr = 0x82120D34;
	PPC_CALL_INDIRECT_FUNC(ctx.ctr.u32);
	// stw r30,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r30.u32);
	// li r6,8
	ctx.r6.s64 = 8;
	// stw r29,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r29.u32);
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// li r4,137
	ctx.r4.s64 = 137;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x820da698
	ctx.lr = 0x82120D50;
	sub_820DA698(ctx, base);
loc_82120D50:
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// lfd f31,-144(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -144);
	// b 0x8233e488
	__restgprlr_16(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82120D5C"))) PPC_WEAK_FUNC(sub_82120D5C);
PPC_FUNC_IMPL(__imp__sub_82120D5C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82120D60"))) PPC_WEAK_FUNC(sub_82120D60);
PPC_FUNC_IMPL(__imp__sub_82120D60) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82120D68;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// mulli r10,r3,120
	ctx.r10.s64 = ctx.r3.s64 * 120;
	// addi r11,r11,3480
	ctx.r11.s64 = ctx.r11.s64 + 3480;
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// addi r9,r11,117
	ctx.r9.s64 = ctx.r11.s64 + 117;
	// lbzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r9.u32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82120e00
	if (ctx.cr6.eq) goto loc_82120E00;
	// add r29,r10,r11
	ctx.r29.u64 = ctx.r10.u64 + ctx.r11.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// li r28,3
	ctx.r28.s64 = 3;
	// addi r31,r29,32
	ctx.r31.s64 = ctx.r29.s64 + 32;
	// stb r30,117(r29)
	PPC_STORE_U8(ctx.r29.u32 + 117, ctx.r30.u8);
loc_82120DA0:
	// lwz r3,-12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -12);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82120db4
	if (ctx.cr6.eq) goto loc_82120DB4;
	// bl 0x8222f0f8
	ctx.lr = 0x82120DB0;
	sub_8222F0F8(ctx, base);
	// stw r30,-12(r31)
	PPC_STORE_U32(ctx.r31.u32 + -12, ctx.r30.u32);
loc_82120DB4:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82120dc8
	if (ctx.cr6.eq) goto loc_82120DC8;
	// bl 0x8222f0f8
	ctx.lr = 0x82120DC4;
	sub_8222F0F8(ctx, base);
	// stw r30,0(r31)
	PPC_STORE_U32(ctx.r31.u32 + 0, ctx.r30.u32);
loc_82120DC8:
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82120ddc
	if (ctx.cr6.eq) goto loc_82120DDC;
	// bl 0x8222f0f8
	ctx.lr = 0x82120DD8;
	sub_8222F0F8(ctx, base);
	// stw r30,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r30.u32);
loc_82120DDC:
	// stb r30,116(r29)
	PPC_STORE_U8(ctx.r29.u32 + 116, ctx.r30.u8);
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82120df4
	if (ctx.cr6.eq) goto loc_82120DF4;
	// bl 0x8222f0f8
	ctx.lr = 0x82120DF0;
	sub_8222F0F8(ctx, base);
	// stw r30,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r30.u32);
loc_82120DF4:
	// addic. r28,r28,-1
	ctx.xer.ca = ctx.r28.u32 > 0;
	ctx.r28.s64 = ctx.r28.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r28.s32, 0, ctx.xer);
	// addi r31,r31,4
	ctx.r31.s64 = ctx.r31.s64 + 4;
	// bne 0x82120da0
	if (!ctx.cr0.eq) goto loc_82120DA0;
loc_82120E00:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x82121608
	ctx.lr = 0x82120E08;
	sub_82121608(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82120E10"))) PPC_WEAK_FUNC(sub_82120E10);
PPC_FUNC_IMPL(__imp__sub_82120E10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e450
	ctx.lr = 0x82120E18;
	__restfpr_22(ctx, base);
	// stfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -104, ctx.f30.u64);
	// stfd f31,-96(r1)
	PPC_STORE_U64(ctx.r1.u32 + -96, ctx.f31.u64);
	// stwu r1,-1072(r1)
	ea = -1072 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,20(r4)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 20);
	// mr r22,r3
	ctx.r22.u64 = ctx.r3.u64;
	// lwz r26,28(r4)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82120e44
	if (ctx.cr6.eq) goto loc_82120E44;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// bl 0x82120d60
	ctx.lr = 0x82120E44;
	sub_82120D60(ctx, base);
loc_82120E44:
	// lwz r28,16(r27)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// cmplwi cr6,r28,0
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 0, ctx.xer);
	// beq cr6,0x82121308
	if (ctx.cr6.eq) goto loc_82121308;
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// mulli r10,r26,120
	ctx.r10.s64 = ctx.r26.s64 * 120;
	// addi r11,r11,3480
	ctx.r11.s64 = ctx.r11.s64 + 3480;
	// lis r9,-32250
	ctx.r9.s64 = -2113536000;
	// add r25,r10,r11
	ctx.r25.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r29,r9,31376
	ctx.r29.s64 = ctx.r9.s64 + 31376;
	// li r24,0
	ctx.r24.s64 = 0;
	// lbz r10,117(r25)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r25.u32 + 117);
	// lfs f31,48(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// bne cr6,0x82120f48
	if (!ctx.cr6.eq) goto loc_82120F48;
	// lis r11,-32197
	ctx.r11.s64 = -2110062592;
	// addi r4,r1,320
	ctx.r4.s64 = ctx.r1.s64 + 320;
	// addi r5,r11,-23448
	ctx.r5.s64 = ctx.r11.s64 + -23448;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x82316b80
	ctx.lr = 0x82120E90;
	sub_82316B80(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// beq cr6,0x82121308
	if (ctx.cr6.eq) goto loc_82121308;
	// lwz r11,348(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121308
	if (ctx.cr6.eq) goto loc_82121308;
	// lwz r11,352(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121308
	if (ctx.cr6.eq) goto loc_82121308;
	// addi r4,r1,320
	ctx.r4.s64 = ctx.r1.s64 + 320;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x8211dac8
	ctx.lr = 0x82120EBC;
	sub_8211DAC8(ctx, base);
	// lwz r11,24(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82120f38
	if (!ctx.cr6.eq) goto loc_82120F38;
	// lis r11,-32179
	ctx.r11.s64 = -2108882944;
	// lfs f13,204(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 204);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,0
	ctx.r10.s64 = 0;
	// addi r9,r11,20000
	ctx.r9.s64 = ctx.r11.s64 + 20000;
	// ori r8,r10,65520
	ctx.r8.u64 = ctx.r10.u64 | 65520;
	// li r11,1
	ctx.r11.s64 = 1;
	// lfsx f0,r9,r8
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// bge cr6,0x82120ef0
	if (!ctx.cr6.lt) goto loc_82120EF0;
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
loc_82120EF0:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82120f04
	if (ctx.cr6.eq) goto loc_82120F04;
	// lfs f1,468(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 468);
	ctx.f1.f64 = double(temp.f32);
	// b 0x82120f08
	goto loc_82120F08;
loc_82120F04:
	// lfs f1,184(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 184);
	ctx.f1.f64 = double(temp.f32);
loc_82120F08:
	// lwz r9,352(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	// lwz r8,348(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f12,f13
	ctx.f12.f64 = double(ctx.f13.s64);
	// fcfid f11,f0
	ctx.f11.f64 = double(ctx.f0.s64);
	// frsp f10,f12
	ctx.f10.f64 = double(float(ctx.f12.f64));
	// frsp f9,f11
	ctx.f9.f64 = double(float(ctx.f11.f64));
	// fdivs f2,f10,f9
	ctx.f2.f64 = double(float(ctx.f10.f64 / ctx.f9.f64));
	// b 0x82120f40
	goto loc_82120F40;
loc_82120F38:
	// fmr f2,f31
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = ctx.f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
loc_82120F40:
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x8211e2d0
	ctx.lr = 0x82120F48;
	sub_8211E2D0(ctx, base);
loc_82120F48:
	// lwz r11,28(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 28);
	// li r23,-1
	ctx.r23.s64 = -1;
	// cmpwi cr6,r11,16
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 16, ctx.xer);
	// bge cr6,0x82120f78
	if (!ctx.cr6.lt) goto loc_82120F78;
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,26328(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 26328);
	// lwzx r30,r9,r10
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82120f78
	if (ctx.cr6.eq) goto loc_82120F78;
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// bne cr6,0x82120f80
	if (!ctx.cr6.eq) goto loc_82120F80;
loc_82120F78:
	// mr r30,r24
	ctx.r30.u64 = ctx.r24.u64;
	// b 0x82121040
	goto loc_82121040;
loc_82120F80:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82083998
	ctx.lr = 0x82120F88;
	sub_82083998(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121040
	if (ctx.cr6.eq) goto loc_82121040;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x8211dd40
	ctx.lr = 0x82120FA0;
	sub_8211DD40(ctx, base);
	// addi r31,r30,540
	ctx.r31.s64 = ctx.r30.s64 + 540;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x823052d8
	ctx.lr = 0x82120FB0;
	sub_823052D8(ctx, base);
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x823194d0
	ctx.lr = 0x82120FC4;
	sub_823194D0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x823051a8
	ctx.lr = 0x82120FCC;
	sub_823051A8(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x8211def0
	ctx.lr = 0x82120FD4;
	sub_8211DEF0(ctx, base);
	// ld r3,192(r1)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// bl 0x823413b0
	ctx.lr = 0x82120FDC;
	sub_823413B0(ctx, base);
	// ld r3,200(r1)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// frsp f30,f1
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = double(float(ctx.f1.f64));
	// bl 0x823413b0
	ctx.lr = 0x82120FE8;
	sub_823413B0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f1.f64));
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// fdivs f30,f30,f0
	ctx.f30.f64 = double(float(ctx.f30.f64 / ctx.f0.f64));
	// bl 0x82083910
	ctx.lr = 0x82120FF8;
	sub_82083910(ctx, base);
	// fsubs f13,f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = static_cast<float>(ctx.f1.f64 - ctx.f30.f64);
	// lfs f0,88(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 88);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	ctx.cr6.compare(ctx.f13.f64, ctx.f0.f64);
	// ble cr6,0x82121040
	if (!ctx.cr6.gt) goto loc_82121040;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82083998
	ctx.lr = 0x82121010;
	sub_82083998(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121040
	if (ctx.cr6.eq) goto loc_82121040;
	// mr r4,r23
	ctx.r4.u64 = ctx.r23.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x823052d8
	ctx.lr = 0x82121028;
	sub_823052D8(ctx, base);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x823159b0
	ctx.lr = 0x82121038;
	sub_823159B0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x823051a8
	ctx.lr = 0x82121040;
	sub_823051A8(ctx, base);
loc_82121040:
	// lwz r31,24(r27)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r27.u32 + 24);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82121180
	if (ctx.cr6.eq) goto loc_82121180;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// rlwinm r10,r26,2,0,29
	ctx.r10.u64 = rotl64(ctx.r26.u32 | (ctx.r26.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r11,25688
	ctx.r9.s64 = ctx.r11.s64 + 25688;
	// lwzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82121078
	if (!ctx.cr6.eq) goto loc_82121078;
	// lwz r11,220(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 220);
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// rlwinm r5,r11,30,31,31
	ctx.r5.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 30) & 0x1;
	// bl 0x82121318
	ctx.lr = 0x82121078;
	sub_82121318(ctx, base);
loc_82121078:
	// lwz r3,96(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212108c
	if (ctx.cr6.eq) goto loc_8212108C;
	// bl 0x820b91d0
	ctx.lr = 0x82121088;
	sub_820B91D0(ctx, base);
	// b 0x821210a8
	goto loc_821210A8;
loc_8212108C:
	// lwz r11,88(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821210a0
	if (ctx.cr6.eq) goto loc_821210A0;
	// lwz r30,88(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 88);
	// b 0x821210ac
	goto loc_821210AC;
loc_821210A0:
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x820b90a0
	ctx.lr = 0x821210A8;
	sub_820B90A0(ctx, base);
loc_821210A8:
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_821210AC:
	// stw r24,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r24.u32);
	// lis r5,6184
	ctx.r5.s64 = 405274624;
	// stw r24,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r24.u32);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// stw r24,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r24.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r24,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r24.u32);
	// ori r5,r5,32646
	ctx.r5.u64 = ctx.r5.u64 | 32646;
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// lwz r3,12(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// bl 0x82237798
	ctx.lr = 0x821210D8;
	sub_82237798(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r3,r11
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82121104
	if (ctx.cr6.eq) goto loc_82121104;
	// stw r3,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r3.u32);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82121104;
	sub_8222CDF8(ctx, base);
loc_82121104:
	// lwz r11,52(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121124
	if (ctx.cr6.eq) goto loc_82121124;
	// stw r24,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r24.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// bl 0x8222d188
	ctx.lr = 0x82121124;
	sub_8222D188(ctx, base);
loc_82121124:
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r4,2004(r22)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r22.u32 + 2004);
	// bl 0x8211dfd8
	ctx.lr = 0x82121130;
	sub_8211DFD8(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,4(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// li r6,0
	ctx.r6.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = ctx.f31.f64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210af50
	ctx.lr = 0x82121150;
	sub_8210AF50(ctx, base);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121174
	if (ctx.cr6.eq) goto loc_82121174;
	// stw r24,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r24.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// mr r11,r24
	ctx.r11.u64 = ctx.r24.u64;
	// bl 0x8222cdf8
	ctx.lr = 0x82121174;
	sub_8222CDF8(ctx, base);
loc_82121174:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x8212117C;
	sub_8222F0F8(ctx, base);
	// b 0x821211b4
	goto loc_821211B4;
loc_82121180:
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// lwz r5,364(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 364);
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 36);
	// cmplw cr6,r5,r10
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x821211a8
	if (ctx.cr6.eq) goto loc_821211A8;
	// stw r5,36(r11)
	PPC_STORE_U32(ctx.r11.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x821211A8;
	sub_8222CDF8(ctx, base);
loc_821211A8:
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r4,2004(r22)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r22.u32 + 2004);
	// bl 0x8211dfd8
	ctx.lr = 0x821211B4;
	sub_8211DFD8(ctx, base);
loc_821211B4:
	// lwz r31,2004(r22)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r22.u32 + 2004);
	// lwz r29,13048(r31)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13048);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x821212b4
	if (ctx.cr6.eq) goto loc_821212B4;
	// lwz r11,11036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821211d8
	if (ctx.cr6.eq) goto loc_821211D8;
	// stw r11,8(r29)
	PPC_STORE_U32(ctx.r29.u32 + 8, ctx.r11.u32);
	// b 0x821212b4
	goto loc_821212B4;
loc_821211D8:
	// lwz r11,11040(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 11040);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// and r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 & ctx.r10.u64;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x821212b4
	if (ctx.cr6.eq) goto loc_821212B4;
	// lwz r11,13912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13912);
	// lwz r10,13916(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13916);
	// cmplw cr6,r11,r10
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r10.u32, ctx.xer);
	// blt cr6,0x82121290
	if (ctx.cr6.lt) goto loc_82121290;
	// li r5,128
	ctx.r5.s64 = 128;
	// lwz r30,13908(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13908);
	// li r4,502
	ctx.r4.s64 = 502;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82230228
	ctx.lr = 0x82121210;
	sub_82230228(ctx, base);
	// lbz r11,11069(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 11069);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// rlwinm r10,r11,0,26,26
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212122c
	if (ctx.cr6.eq) goto loc_8212122C;
	// lwz r8,17120(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 17120);
	// b 0x82121280
	goto loc_82121280;
loc_8212122C:
	// rlwinm r11,r8,12,20,31
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 12) & 0xFFF;
	// stw r8,13908(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13908, ctx.r8.u32);
	// clrlwi r10,r8,3
	ctx.r10.u64 = ctx.r8.u32 & 0x1FFFFFFF;
	// stw r24,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r24.u32);
	// addi r11,r11,512
	ctx.r11.s64 = ctx.r11.s64 + 512;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// rlwinm r11,r11,0,19,19
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x1000;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addis r3,r10,-16384
	ctx.r3.s64 = ctx.r10.s64 + -1073741824;
	// bne cr6,0x82121260
	if (!ctx.cr6.eq) goto loc_82121260;
	// lwz r11,13904(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13904);
	// stw r3,112(r11)
	PPC_STORE_U32(ctx.r11.u32 + 112, ctx.r3.u32);
	// b 0x82121278
	goto loc_82121278;
loc_82121260:
	// stw r3,0(r30)
	PPC_STORE_U32(ctx.r30.u32 + 0, ctx.r3.u32);
	// lwz r11,13912(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13912);
	// subf r11,r30,r11
	ctx.r11.s64 = ctx.r11.s64 - ctx.r30.s64;
	// addi r10,r11,-8
	ctx.r10.s64 = ctx.r11.s64 + -8;
	// srawi r9,r10,3
	ctx.xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7) != 0);
	ctx.r9.s64 = ctx.r10.s32 >> 3;
	// stw r9,4(r30)
	PPC_STORE_U32(ctx.r30.u32 + 4, ctx.r9.u32);
loc_82121278:
	// addi r4,r3,2008
	ctx.r4.s64 = ctx.r3.s64 + 2008;
	// bl 0x8223b9b8
	ctx.lr = 0x82121280;
	sub_8223B9B8(ctx, base);
loc_82121280:
	// addi r11,r8,8
	ctx.r11.s64 = ctx.r8.s64 + 8;
	// addi r10,r8,2008
	ctx.r10.s64 = ctx.r8.s64 + 2008;
	// stw r11,13912(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13912, ctx.r11.u32);
	// stw r10,13916(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13916, ctx.r10.u32);
loc_82121290:
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r10,r11,8
	ctx.r10.s64 = ctx.r11.s64 + 8;
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r23.u32);
	// rlwimi r9,r29,30,2,31
	ctx.r9.u64 = (rotl32(ctx.r29.u32, 30) & 0x3FFFFFFF) | (ctx.r9.u64 & 0xFFFFFFFFC0000000);
	// rlwinm r8,r9,0,2,0
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r8,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r8.u32);
	// ld r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r7,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r7.u64);
	// stw r10,13912(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13912, ctx.r10.u32);
loc_821212B4:
	// lbz r11,11070(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 11070);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r24,13048(r31)
	PPC_STORE_U32(ctx.r31.u32 + 13048, ctx.r24.u32);
	// clrlwi r10,r11,25
	ctx.r10.u64 = ctx.r11.u32 & 0x7F;
	// stb r10,11070(r31)
	PPC_STORE_U8(ctx.r31.u32 + 11070, ctx.r10.u8);
	// lwz r3,2004(r22)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r22.u32 + 2004);
	// bl 0x82238380
	ctx.lr = 0x821212D0;
	sub_82238380(ctx, base);
	// lwz r9,2004(r22)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r22.u32 + 2004);
	// stw r24,12216(r9)
	PPC_STORE_U32(ctx.r9.u32 + 12216, ctx.r24.u32);
	// li r4,7
	ctx.r4.s64 = 7;
	// ld r8,16(r9)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r9.u32 + 16);
	// oris r7,r8,8
	ctx.r7.u64 = ctx.r8.u64 | 524288;
	// std r7,16(r9)
	PPC_STORE_U64(ctx.r9.u32 + 16, ctx.r7.u64);
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x821212F0;
	sub_82111340(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x821212FC;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82121308;
	sub_821112B0(ctx, base);
loc_82121308:
	// addi r1,r1,1072
	ctx.r1.s64 = ctx.r1.s64 + 1072;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x8233e4a0
	__restgprlr_22(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82121318"))) PPC_WEAK_FUNC(sub_82121318);
PPC_FUNC_IMPL(__imp__sub_82121318) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e44c
	ctx.lr = 0x82121320;
	__restfpr_21(ctx, base);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// rlwinm r8,r3,2,0,29
	ctx.r8.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r7,r11,25688
	ctx.r7.s64 = ctx.r11.s64 + 25688;
	// mr r24,r3
	ctx.r24.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r22,r5
	ctx.r22.u64 = ctx.r5.u64;
	// addi r6,r4,48
	ctx.r6.s64 = ctx.r4.s64 + 48;
	// stwx r4,r8,r7
	PPC_STORE_U32(ctx.r8.u32 + ctx.r7.u32, ctx.r4.u32);
loc_82121344:
	// mfmsr r9
	ctx.r9.u64 = ctx.msr;
	// mtmsrd r13,1
	ctx.msr = (ctx.r13.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// lwarx r10,0,r6
	ctx.reserved.u32 = *(uint32_t*)(base + ctx.r6.u32);
	ctx.r10.u64 = __builtin_bswap32(ctx.reserved.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stwcx. r10,0,r6
	ctx.cr0.lt = 0;
	ctx.cr0.gt = 0;
	ctx.cr0.eq = __sync_bool_compare_and_swap(reinterpret_cast<uint32_t*>(base + ctx.r6.u32), ctx.reserved.s32, __builtin_bswap32(ctx.r10.s32));
	ctx.cr0.so = ctx.xer.so;
	// mtmsrd r9,1
	ctx.msr = (ctx.r9.u32 & 0x8020) | (ctx.msr & ~0x8020);
	// bne 0x82121344
	if (!ctx.cr0.eq) goto loc_82121344;
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82121378
	if (ctx.cr6.eq) goto loc_82121378;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82177f68
	ctx.lr = 0x82121378;
	sub_82177F68(ctx, base);
loc_82121378:
	// lwz r3,96(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 96);
	// li r31,0
	ctx.r31.s64 = 0;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// stw r31,88(r30)
	PPC_STORE_U32(ctx.r30.u32 + 88, ctx.r31.u32);
	// beq cr6,0x82121394
	if (ctx.cr6.eq) goto loc_82121394;
	// bl 0x820b91d0
	ctx.lr = 0x82121390;
	sub_820B91D0(ctx, base);
	// b 0x821213b0
	goto loc_821213B0;
loc_82121394:
	// lwz r11,88(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821213a8
	if (ctx.cr6.eq) goto loc_821213A8;
	// lwz r27,88(r30)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// b 0x821213b4
	goto loc_821213B4;
loc_821213A8:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x820b90a0
	ctx.lr = 0x821213B0;
	sub_820B90A0(ctx, base);
loc_821213B0:
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
loc_821213B4:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r29,12(r27)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// li r5,-1
	ctx.r5.s64 = -1;
	// lwz r28,16(r27)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,100
	ctx.r3.s64 = 100;
	// bl 0x82082030
	ctx.lr = 0x821213D0;
	sub_82082030(ctx, base);
	// li r21,1
	ctx.r21.s64 = 1;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82121414
	if (ctx.cr6.eq) goto loc_82121414;
	// li r11,3
	ctx.r11.s64 = 3;
	// stb r31,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, ctx.r31.u8);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r31,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r31.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r11.u32);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// stb r21,52(r3)
	PPC_STORE_U8(ctx.r3.u32 + 52, ctx.r21.u8);
	// stb r31,53(r3)
	PPC_STORE_U8(ctx.r3.u32 + 53, ctx.r31.u8);
	// stw r31,72(r3)
	PPC_STORE_U32(ctx.r3.u32 + 72, ctx.r31.u32);
	// stw r31,76(r3)
	PPC_STORE_U32(ctx.r3.u32 + 76, ctx.r31.u32);
	// stw r31,80(r3)
	PPC_STORE_U32(ctx.r3.u32 + 80, ctx.r31.u32);
	// stw r31,96(r3)
	PPC_STORE_U32(ctx.r3.u32 + 96, ctx.r31.u32);
	// stw r10,84(r3)
	PPC_STORE_U32(ctx.r3.u32 + 84, ctx.r10.u32);
	// b 0x82121418
	goto loc_82121418;
loc_82121414:
	// mr r25,r31
	ctx.r25.u64 = ctx.r31.u64;
loc_82121418:
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// rlwinm r23,r24,3,0,28
	ctx.r23.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r24,r11,5400
	ctx.r24.s64 = ctx.r11.s64 + 5400;
	// lis r11,6688
	ctx.r11.s64 = 438304768;
	// clrlwi r10,r22,24
	ctx.r10.u64 = ctx.r22.u32 & 0xFF;
	// ori r26,r11,32690
	ctx.r26.u64 = ctx.r11.u64 | 32690;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stwx r25,r23,r24
	PPC_STORE_U32(ctx.r23.u32 + ctx.r24.u32, ctx.r25.u32);
	// stw r25,88(r30)
	PPC_STORE_U32(ctx.r30.u32 + 88, ctx.r25.u32);
	// beq cr6,0x821215c0
	if (ctx.cr6.eq) goto loc_821215C0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,16
	ctx.r4.s64 = 16;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x82082030
	ctx.lr = 0x82121454;
	sub_82082030(ctx, base);
	// addi r8,r1,112
	ctx.r8.s64 = ctx.r1.s64 + 112;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// stw r3,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r3.u32);
	// addi r11,r1,116
	ctx.r11.s64 = ctx.r1.s64 + 116;
	// stw r8,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r8.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82298418
	ctx.lr = 0x82121494;
	sub_82298418(ctx, base);
	// lwz r7,80(r27)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r27.u32 + 80);
	// cmpw cr6,r3,r7
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r7.s32, ctx.xer);
	// ble cr6,0x82121518
	if (!ctx.cr6.gt) goto loc_82121518;
loc_821214A0:
	// clrlwi r11,r29,31
	ctx.r11.u64 = ctx.r29.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821215ac
	if (!ctx.cr6.eq) goto loc_821215AC;
	// clrlwi r11,r28,31
	ctx.r11.u64 = ctx.r28.u32 & 0x1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821215ac
	if (!ctx.cr6.eq) goto loc_821215AC;
	// cmplwi cr6,r29,8
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 8, ctx.xer);
	// blt cr6,0x821215ac
	if (ctx.cr6.lt) goto loc_821215AC;
	// cmplwi cr6,r28,8
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 8, ctx.xer);
	// blt cr6,0x821215ac
	if (ctx.cr6.lt) goto loc_821215AC;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r30.u32);
	// rlwinm r29,r29,31,1,31
	ctx.r29.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 31) & 0x7FFFFFFF;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// rlwinm r28,r28,31,1,31
	ctx.r28.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 31) & 0x7FFFFFFF;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// addi r11,r1,116
	ctx.r11.s64 = ctx.r1.s64 + 116;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r11.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82298418
	ctx.lr = 0x8212150C;
	sub_82298418(ctx, base);
	// lwz r9,80(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 80);
	// cmpw cr6,r3,r9
	ctx.cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, ctx.xer);
	// bgt cr6,0x821214a0
	if (ctx.cr6.gt) goto loc_821214A0;
loc_82121518:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x821215c0
	if (ctx.cr6.eq) goto loc_821215C0;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r31.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x82299680
	ctx.lr = 0x82121550;
	sub_82299680(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,112(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// bl 0x822986a8
	ctx.lr = 0x8212155C;
	sub_822986A8(ctx, base);
	// lwz r11,4(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r31.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// mr r7,r26
	ctx.r7.u64 = ctx.r26.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r11.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82298418
	ctx.lr = 0x82121594;
	sub_82298418(ctx, base);
	// lwz r4,112(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// bl 0x822986a8
	ctx.lr = 0x821215A0;
	sub_822986A8(ctx, base);
	// addi r10,r24,4
	ctx.r10.s64 = ctx.r24.s64 + 4;
	// stwx r30,r23,r10
	PPC_STORE_U32(ctx.r23.u32 + ctx.r10.u32, ctx.r30.u32);
	// b 0x821215e8
	goto loc_821215E8;
loc_821215AC:
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x821215c0
	if (ctx.cr6.eq) goto loc_821215C0;
	// addi r4,r30,-16
	ctx.r4.s64 = ctx.r30.s64 + -16;
	// lwz r3,-8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821215C0;
	sub_82080000(ctx, base);
loc_821215C0:
	// li r10,3
	ctx.r10.s64 = 3;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r26
	ctx.r8.u64 = ctx.r26.u64;
	// li r7,4
	ctx.r7.s64 = 4;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82237678
	ctx.lr = 0x821215E4;
	sub_82237678(ctx, base);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_821215E8:
	// stw r30,4(r25)
	PPC_STORE_U32(ctx.r25.u32 + 4, ctx.r30.u32);
	// stw r29,12(r25)
	PPC_STORE_U32(ctx.r25.u32 + 12, ctx.r29.u32);
	// stw r28,16(r25)
	PPC_STORE_U32(ctx.r25.u32 + 16, ctx.r28.u32);
	// stw r21,20(r25)
	PPC_STORE_U32(ctx.r25.u32 + 20, ctx.r21.u32);
	// stw r31,8(r25)
	PPC_STORE_U32(ctx.r25.u32 + 8, ctx.r31.u32);
	// stw r31,96(r25)
	PPC_STORE_U32(ctx.r25.u32 + 96, ctx.r31.u32);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82121608"))) PPC_WEAK_FUNC(sub_82121608);
PPC_FUNC_IMPL(__imp__sub_82121608) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82121610;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// rlwinm r31,r3,2,0,29
	ctx.r31.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r29,r11,25688
	ctx.r29.s64 = ctx.r11.s64 + 25688;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// li r30,0
	ctx.r30.s64 = 0;
	// lwzx r11,r31,r29
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r29.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121650
	if (ctx.cr6.eq) goto loc_82121650;
	// stw r30,88(r11)
	PPC_STORE_U32(ctx.r11.u32 + 88, ctx.r30.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwzx r3,r31,r29
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r29.u32);
	// bl 0x82178200
	ctx.lr = 0x82121644;
	sub_82178200(ctx, base);
	// lwzx r3,r31,r29
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + ctx.r29.u32);
	// bl 0x82172d60
	ctx.lr = 0x8212164C;
	sub_82172D60(ctx, base);
	// stwx r30,r31,r29
	PPC_STORE_U32(ctx.r31.u32 + ctx.r29.u32, ctx.r30.u32);
loc_82121650:
	// lis r11,-32176
	ctx.r11.s64 = -2108686336;
	// rlwinm r29,r28,3,0,28
	ctx.r29.u64 = rotl64(ctx.r28.u32 | (ctx.r28.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r28,r11,5400
	ctx.r28.s64 = ctx.r11.s64 + 5400;
	// lwzx r31,r29,r28
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r28.u32);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x821216d4
	if (ctx.cr6.eq) goto loc_821216D4;
	// lwz r27,4(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r30,4(r31)
	PPC_STORE_U32(ctx.r31.u32 + 4, ctx.r30.u32);
	// stw r30,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r30.u32);
	// stw r30,16(r31)
	PPC_STORE_U32(ctx.r31.u32 + 16, ctx.r30.u32);
	// stw r30,20(r31)
	PPC_STORE_U32(ctx.r31.u32 + 20, ctx.r30.u32);
	// stw r30,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r30.u32);
	// stw r30,96(r31)
	PPC_STORE_U32(ctx.r31.u32 + 96, ctx.r30.u32);
	// bl 0x8211a4e0
	ctx.lr = 0x8212168C;
	sub_8211A4E0(ctx, base);
	// addi r4,r31,-16
	ctx.r4.s64 = ctx.r31.s64 + -16;
	// lwz r3,-8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x82121698;
	sub_82080000(ctx, base);
	// addi r31,r28,4
	ctx.r31.s64 = ctx.r28.s64 + 4;
	// stwx r30,r29,r28
	PPC_STORE_U32(ctx.r29.u32 + ctx.r28.u32, ctx.r30.u32);
	// lwzx r11,r29,r31
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + ctx.r31.u32);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821216c4
	if (ctx.cr6.eq) goto loc_821216C4;
	// addi r4,r11,-16
	ctx.r4.s64 = ctx.r11.s64 + -16;
	// lwz r3,-8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -8);
	// bl 0x82080000
	ctx.lr = 0x821216B8;
	sub_82080000(ctx, base);
	// stwx r30,r29,r31
	PPC_STORE_U32(ctx.r29.u32 + ctx.r31.u32, ctx.r30.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
loc_821216C4:
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x821216d4
	if (ctx.cr6.eq) goto loc_821216D4;
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8222f0f8
	ctx.lr = 0x821216D4;
	sub_8222F0F8(ctx, base);
loc_821216D4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821216DC"))) PPC_WEAK_FUNC(sub_821216DC);
PPC_FUNC_IMPL(__imp__sub_821216DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821216E0"))) PPC_WEAK_FUNC(sub_821216E0);
PPC_FUNC_IMPL(__imp__sub_821216E0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x821216E8;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addic. r31,r4,12
	ctx.xer.ca = ctx.r4.u32 > 4294967283;
	ctx.r31.s64 = ctx.r4.s64 + 12;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// beq 0x82121808
	if (ctx.cr0.eq) goto loc_82121808;
	// lwz r29,2004(r3)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2004);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82121708;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82121714;
	sub_821112B0(ctx, base);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// li r11,12545
	ctx.r11.s64 = 12545;
	// addi r9,r10,28184
	ctx.r9.s64 = ctx.r10.s64 + 28184;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,100
	ctx.r3.s64 = 100;
	// stw r11,288(r9)
	PPC_STORE_U32(ctx.r9.u32 + 288, ctx.r11.u32);
	// bl 0x82111340
	ctx.lr = 0x82121730;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82111340
	ctx.lr = 0x8212173C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x82121748;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x82121754;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x82121760;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x8212176C;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x82111340
	ctx.lr = 0x82121778;
	sub_82111340(ctx, base);
	// lis r28,-32178
	ctx.r28.s64 = -2108817408;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r11,25752(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 25752);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r8,12216(r29)
	PPC_STORE_U32(ctx.r29.u32 + 12216, ctx.r8.u32);
	// ld r7,16(r29)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r29.u32 + 16);
	// oris r6,r7,8
	ctx.r6.u64 = ctx.r7.u64 | 524288;
	// std r6,16(r29)
	PPC_STORE_U64(ctx.r29.u32 + 16, ctx.r6.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x821217A0;
	sub_82238728(ctx, base);
	// lwz r11,25752(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 25752);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x821217B0;
	sub_82238380(ctx, base);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// beq cr6,0x821217c8
	if (ctx.cr6.eq) goto loc_821217C8;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_821217C8:
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821217fc
	if (ctx.cr6.eq) goto loc_821217FC;
loc_821217D4:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82121810
	ctx.lr = 0x821217DC;
	sub_82121810(ctx, base);
	// lwz r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821217f0
	if (ctx.cr6.eq) goto loc_821217F0;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r10.u32);
loc_821217F0:
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821217d4
	if (!ctx.cr6.eq) goto loc_821217D4;
loc_821217FC:
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82121808;
	sub_82111340(ctx, base);
loc_82121808:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82121810"))) PPC_WEAK_FUNC(sub_82121810);
PPC_FUNC_IMPL(__imp__sub_82121810) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82121818;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,16(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121b90
	if (ctx.cr6.eq) goto loc_82121B90;
	// lwz r31,2004(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2004);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x8212183C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82121848;
	sub_821112B0(ctx, base);
	// lwz r11,28(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// li r4,1
	ctx.r4.s64 = 1;
	// rlwinm r10,r11,0,30,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0x2;
	// li r3,100
	ctx.r3.s64 = 100;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// addi r30,r10,28184
	ctx.r30.s64 = ctx.r10.s64 + 28184;
	// beq cr6,0x821218b8
	if (ctx.cr6.eq) goto loc_821218B8;
	// li r11,4353
	ctx.r11.s64 = 4353;
	// stw r11,288(r30)
	PPC_STORE_U32(ctx.r30.u32 + 288, ctx.r11.u32);
	// bl 0x82111340
	ctx.lr = 0x82121874;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82111340
	ctx.lr = 0x82121880;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x8212188C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x82121898;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x821218A4;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x821218B0;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x82121904
	goto loc_82121904;
loc_821218B8:
	// li r11,12545
	ctx.r11.s64 = 12545;
	// stw r11,288(r30)
	PPC_STORE_U32(ctx.r30.u32 + 288, ctx.r11.u32);
	// bl 0x82111340
	ctx.lr = 0x821218C4;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82111340
	ctx.lr = 0x821218D0;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x821218DC;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x821218E8;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x821218F4;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x82121900;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
loc_82121904:
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x82111340
	ctx.lr = 0x8212190C;
	sub_82111340(ctx, base);
	// lwz r3,32(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 32);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82121a64
	if (ctx.cr6.eq) goto loc_82121A64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82172e00
	ctx.lr = 0x82121924;
	sub_82172E00(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121a64
	if (ctx.cr6.eq) goto loc_82121A64;
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82121954
	if (ctx.cr6.eq) goto loc_82121954;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8212194C;
	sub_8222C248(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r11.u32);
loc_82121954:
	// lwz r11,2052(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82121978
	if (ctx.cr6.eq) goto loc_82121978;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82121970;
	sub_8222C0A0(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r11.u32);
loc_82121978:
	// lwz r11,1972(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1972);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821219ac
	if (ctx.cr6.eq) goto loc_821219AC;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwinm r7,r8,0,22,18
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFE3FF;
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r28,1972(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1972, ctx.r28.u32);
loc_821219AC:
	// lwz r11,1988(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1988);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821219e0
	if (ctx.cr6.eq) goto loc_821219E0;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwinm r7,r8,0,19,15
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFF1FFF;
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r28,1988(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1988, ctx.r28.u32);
loc_821219E0:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,25764(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25764);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82121A08;
	sub_82238728(ctx, base);
	// lwz r11,25764(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25764);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82121A18;
	sub_82238380(ctx, base);
	// lwz r11,32(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 32);
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82121a38
	if (ctx.cr6.eq) goto loc_82121A38;
	// bl 0x820b91d0
	ctx.lr = 0x82121A2C;
	sub_820B91D0(ctx, base);
	// lwz r4,4(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// b 0x82121aa0
	goto loc_82121AA0;
loc_82121A38:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82121a50
	if (ctx.cr6.eq) goto loc_82121A50;
	// lwz r11,88(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// b 0x82121aa0
	goto loc_82121AA0;
loc_82121A50:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x82121A58;
	sub_820B90A0(ctx, base);
	// lwz r4,4(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// b 0x82121aa0
	goto loc_82121AA0;
loc_82121A64:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,25760(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25760);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82121A8C;
	sub_82238728(ctx, base);
	// lwz r11,25760(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25760);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82121A9C;
	sub_82238380(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
loc_82121AA0:
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x82121AA8;
	sub_82111400(ctx, base);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r11,16(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r3,r11,2,0,29
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8210b178
	ctx.lr = 0x82121ACC;
	sub_8210B178(ctx, base);
	// lwz r11,16(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// lwz r4,12(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 12);
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8233e4e0
	ctx.lr = 0x82121AE4;
	sub_8233E4E0(ctx, base);
	// lwz r11,16(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r3,r9,2,0,29
	ctx.r3.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8210b488
	ctx.lr = 0x82121AF8;
	sub_8210B488(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,36
	ctx.r7.s64 = 36;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x82121B14;
	sub_8222CC48(ctx, base);
	// lwz r11,20(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// lis r8,-32182
	ctx.r8.s64 = -2109079552;
	// addi r7,r11,-2
	ctx.r7.s64 = ctx.r11.s64 + -2;
	// addi r6,r8,-25532
	ctx.r6.s64 = ctx.r8.s64 + -25532;
	// rlwinm r5,r7,2,0,29
	ctx.r5.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwzx r4,r5,r6
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r6.u32);
	// bl 0x8222cd68
	ctx.lr = 0x82121B34;
	sub_8222CD68(ctx, base);
	// lwz r11,24(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,6
	ctx.r4.s64 = 6;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// addi r7,r11,2
	ctx.r7.s64 = ctx.r11.s64 + 2;
	// bl 0x8222e3e0
	ctx.lr = 0x82121B50;
	sub_8222E3E0(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x82121B6C;
	sub_8222CC48(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cd68
	ctx.lr = 0x82121B78;
	sub_8222CD68(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82121B84;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82121B90;
	sub_821112B0(ctx, base);
loc_82121B90:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82121B98"))) PPC_WEAK_FUNC(sub_82121B98);
PPC_FUNC_IMPL(__imp__sub_82121B98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82121BA0;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,20(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121ef4
	if (ctx.cr6.eq) goto loc_82121EF4;
	// lwz r11,24(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121ef4
	if (ctx.cr6.eq) goto loc_82121EF4;
	// lwz r31,2004(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2004);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82121BD0;
	sub_821112B0(ctx, base);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// li r11,12545
	ctx.r11.s64 = 12545;
	// addi r29,r10,28184
	ctx.r29.s64 = ctx.r10.s64 + 28184;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,100
	ctx.r3.s64 = 100;
	// stw r11,288(r29)
	PPC_STORE_U32(ctx.r29.u32 + 288, ctx.r11.u32);
	// bl 0x82111340
	ctx.lr = 0x82121BEC;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82111340
	ctx.lr = 0x82121BF8;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x82121C04;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x82121C10;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x82121C1C;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x82121C28;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x82111340
	ctx.lr = 0x82121C34;
	sub_82111340(ctx, base);
	// lwz r3,44(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 44);
	// li r28,0
	ctx.r28.s64 = 0;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82121d8c
	if (ctx.cr6.eq) goto loc_82121D8C;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82172e00
	ctx.lr = 0x82121C4C;
	sub_82172E00(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121d8c
	if (ctx.cr6.eq) goto loc_82121D8C;
	// lwz r11,2036(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82121c7c
	if (ctx.cr6.eq) goto loc_82121C7C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82121C74;
	sub_8222C248(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,2036(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2036, ctx.r11.u32);
loc_82121C7C:
	// lwz r11,2052(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82121ca0
	if (ctx.cr6.eq) goto loc_82121CA0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82121C98;
	sub_8222C0A0(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,2052(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2052, ctx.r11.u32);
loc_82121CA0:
	// lwz r11,1972(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1972);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121cd4
	if (ctx.cr6.eq) goto loc_82121CD4;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwinm r7,r8,0,22,18
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFE3FF;
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r28,1972(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1972, ctx.r28.u32);
loc_82121CD4:
	// lwz r11,1988(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1988);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82121d08
	if (ctx.cr6.eq) goto loc_82121D08;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwinm r7,r8,0,19,15
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFF1FFF;
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r28,1988(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1988, ctx.r28.u32);
loc_82121D08:
	// lis r29,-32178
	ctx.r29.s64 = -2108817408;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,25788(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25788);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82121D30;
	sub_82238728(ctx, base);
	// lwz r11,25788(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25788);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82121D40;
	sub_82238380(ctx, base);
	// lwz r11,44(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 44);
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82121d60
	if (ctx.cr6.eq) goto loc_82121D60;
	// bl 0x820b91d0
	ctx.lr = 0x82121D54;
	sub_820B91D0(ctx, base);
	// lwz r4,4(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// b 0x82121dc8
	goto loc_82121DC8;
loc_82121D60:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82121d78
	if (ctx.cr6.eq) goto loc_82121D78;
	// lwz r11,88(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// b 0x82121dc8
	goto loc_82121DC8;
loc_82121D78:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x82121D80;
	sub_820B90A0(ctx, base);
	// lwz r4,4(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// b 0x82121dc8
	goto loc_82121DC8;
loc_82121D8C:
	// lis r29,-32178
	ctx.r29.s64 = -2108817408;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,25792(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25792);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82121DB4;
	sub_82238728(ctx, base);
	// lwz r11,25792(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25792);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82121DC4;
	sub_82238380(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
loc_82121DC8:
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x82121DD0;
	sub_82111400(ctx, base);
	// lfs f0,28(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,7744(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7744, temp.u32);
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f13,32(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// stfs f13,7748(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7748, temp.u32);
	// rldicr r12,r12,36,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// lfs f12,36(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	ctx.f12.f64 = double(temp.f32);
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// stfs f12,7752(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7752, temp.u32);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lfs f11,40(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	ctx.f11.f64 = double(temp.f32);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// stfs f11,7756(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7756, temp.u32);
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r11,r10
	ctx.r9.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r3,r9,2,0,29
	ctx.r3.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8210b178
	ctx.lr = 0x82121E28;
	sub_8210B178(ctx, base);
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// lwz r4,12(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r11,r10
	ctx.r8.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r5,r8,2,0,29
	ctx.r5.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8233e4e0
	ctx.lr = 0x82121E40;
	sub_8233E4E0(ctx, base);
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r11,r10
	ctx.r7.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r3,r7,2,0,29
	ctx.r3.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8210b488
	ctx.lr = 0x82121E54;
	sub_8210B488(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,20
	ctx.r7.s64 = 20;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x82121E70;
	sub_8222CC48(ctx, base);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// lwz r6,24(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// rlwinm r3,r6,1,0,30
	ctx.r3.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// bl 0x8210b4d0
	ctx.lr = 0x82121E88;
	sub_8210B4D0(ctx, base);
	// lwz r5,24(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// rlwinm r5,r5,1,0,30
	ctx.r5.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 1) & 0xFFFFFFFE;
	// bl 0x8233e4e0
	ctx.lr = 0x82121E98;
	sub_8233E4E0(ctx, base);
	// lwz r4,24(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// rlwinm r3,r4,1,0,30
	ctx.r3.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 1) & 0xFFFFFFFE;
	// bl 0x8210b7b8
	ctx.lr = 0x82121EA4;
	sub_8210B7B8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x8222cd68
	ctx.lr = 0x82121EB0;
	sub_8222CD68(ctx, base);
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r7,24(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// rlwinm r6,r3,31,1,31
	ctx.r6.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 31) & 0x7FFFFFFF;
	// li r4,6
	ctx.r4.s64 = 6;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222e3e0
	ctx.lr = 0x82121ECC;
	sub_8222E3E0(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x82121EE8;
	sub_8222CC48(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cd68
	ctx.lr = 0x82121EF4;
	sub_8222CD68(ctx, base);
loc_82121EF4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82121EFC"))) PPC_WEAK_FUNC(sub_82121EFC);
PPC_FUNC_IMPL(__imp__sub_82121EFC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82121F00"))) PPC_WEAK_FUNC(sub_82121F00);
PPC_FUNC_IMPL(__imp__sub_82121F00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82121F08;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// lwz r3,24(r4)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821221d4
	if (ctx.cr6.eq) goto loc_821221D4;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82172e00
	ctx.lr = 0x82121F28;
	sub_82172E00(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821221d4
	if (ctx.cr6.eq) goto loc_821221D4;
	// li r30,0
	ctx.r30.s64 = 0;
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r29,2004(r29)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2004);
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r30.u32);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r30.u32);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r3,r11,3,0,28
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x8210b178
	ctx.lr = 0x82121F60;
	sub_8210B178(ctx, base);
	// lwz r11,16(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r11,r10
	ctx.r10.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r5,r10,3,0,28
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x8233e4e0
	ctx.lr = 0x82121F78;
	sub_8233E4E0(ctx, base);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// lis r9,-32183
	ctx.r9.s64 = -2109145088;
	// rlwinm r7,r10,1,0,30
	ctx.r7.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r11,r9,27648
	ctx.r11.s64 = ctx.r9.s64 + 27648;
	// add r8,r10,r7
	ctx.r8.u64 = ctx.r10.u64 + ctx.r7.u64;
	// mr r9,r30
	ctx.r9.u64 = ctx.r30.u64;
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r7,r11,200
	ctx.r7.s64 = ctx.r11.s64 + 200;
	// stb r30,264(r11)
	PPC_STORE_U8(ctx.r11.u32 + 264, ctx.r30.u8);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r8,272(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	// lwz r9,268(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r4,r9,2,0,29
	ctx.r4.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,31
	ctx.r6.s64 = ctx.r10.s64 + 31;
	// rlwinm r10,r6,0,0,26
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFE0;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// lwzx r3,r4,r7
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + ctx.r7.u32);
	// lwz r11,24(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r4,r11,0,0,29
	ctx.r4.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFC;
	// bl 0x8222ee68
	ctx.lr = 0x82121FCC;
	sub_8222EE68(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82121FD8;
	sub_821112B0(ctx, base);
	// lbz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r31.u32 + 20);
	// li r4,1
	ctx.r4.s64 = 1;
	// subfic r9,r10,0
	ctx.xer.ca = ctx.r10.u32 <= 0;
	ctx.r9.s64 = 0 - ctx.r10.s64;
	// subfe r8,r9,r9
	temp.u8 = (~ctx.r9.u32 + ctx.r9.u32 < ~ctx.r9.u32) | (~ctx.r9.u32 + ctx.r9.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r8.u64 = ~ctx.r9.u64 + ctx.r9.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// rlwinm r11,r8,0,0,18
	ctx.r11.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFE000;
	// addi r3,r11,12545
	ctx.r3.s64 = ctx.r11.s64 + 12545;
	// bl 0x82113bc0
	ctx.lr = 0x82121FF4;
	sub_82113BC0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r28,1
	ctx.r28.s64 = 1;
	// addi r30,r11,28184
	ctx.r30.s64 = ctx.r11.s64 + 28184;
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82122024
	if (ctx.cr6.eq) goto loc_82122024;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x8212201C;
	sub_8222C248(ctx, base);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// stw r28,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r28.u32);
loc_82122024:
	// lwz r11,2052(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82122048
	if (ctx.cr6.eq) goto loc_82122048;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82122040;
	sub_8222C0A0(ctx, base);
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// stw r28,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r28.u32);
loc_82122048:
	// lwz r11,1972(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212207c
	if (ctx.cr6.eq) goto loc_8212207C;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r28,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r28.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1972, ctx.r10.u32);
loc_8212207C:
	// lwz r11,1988(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821220b0
	if (ctx.cr6.eq) goto loc_821220B0;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r28,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r28.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1988, ctx.r10.u32);
loc_821220B0:
	// lis r4,14119
	ctx.r4.s64 = 925302784;
	// li r3,208
	ctx.r3.s64 = 208;
	// ori r4,r4,50604
	ctx.r4.u64 = ctx.r4.u64 | 50604;
	// bl 0x82111340
	ctx.lr = 0x821220C0;
	sub_82111340(ctx, base);
	// lis r4,16384
	ctx.r4.s64 = 1073741824;
	// li r3,204
	ctx.r3.s64 = 204;
	// bl 0x82111340
	ctx.lr = 0x821220CC;
	sub_82111340(ctx, base);
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r11,25768(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25768);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r29)
	PPC_STORE_U32(ctx.r29.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r29.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r29)
	PPC_STORE_U64(ctx.r29.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x821220F4;
	sub_82238728(ctx, base);
	// lwz r11,25768(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25768);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82122104;
	sub_82238380(ctx, base);
	// lwz r11,24(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212211c
	if (ctx.cr6.eq) goto loc_8212211C;
	// bl 0x820b91d0
	ctx.lr = 0x82122118;
	sub_820B91D0(ctx, base);
	// b 0x82122138
	goto loc_82122138;
loc_8212211C:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82122130
	if (ctx.cr6.eq) goto loc_82122130;
	// lwz r11,88(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x8212213c
	goto loc_8212213C;
loc_82122130:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x82122138;
	sub_820B90A0(ctx, base);
loc_82122138:
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_8212213C:
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82111400
	ctx.lr = 0x82122148;
	sub_82111400(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,24
	ctx.r7.s64 = 24;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8222cc48
	ctx.lr = 0x82122164;
	sub_8222CC48(ctx, base);
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	// li r11,3
	ctx.r11.s64 = 3;
	// li r5,0
	ctx.r5.s64 = 0;
	// divwu r11,r10,r11
	ctx.r11.u32 = ctx.r10.u32 / ctx.r11.u32;
	// li r4,4
	ctx.r4.s64 = 4;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// add r6,r11,r10
	ctx.r6.u64 = ctx.r11.u64 + ctx.r10.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x82122188;
	sub_8222DFC8(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82122194;
	sub_821112B0(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x821221A0;
	sub_82113BC0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,208
	ctx.r3.s64 = 208;
	// bl 0x82111340
	ctx.lr = 0x821221AC;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,204
	ctx.r3.s64 = 204;
	// bl 0x82111340
	ctx.lr = 0x821221B8;
	sub_82111340(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8222cc48
	ctx.lr = 0x821221D4;
	sub_8222CC48(ctx, base);
loc_821221D4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821221DC"))) PPC_WEAK_FUNC(sub_821221DC);
PPC_FUNC_IMPL(__imp__sub_821221DC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821221E0"))) PPC_WEAK_FUNC(sub_821221E0);
PPC_FUNC_IMPL(__imp__sub_821221E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x821221E8;
	__restfpr_27(ctx, base);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r28,2004(r3)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2004);
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// lwz r11,2140(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2140);
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// addi r5,r11,1836
	ctx.r5.s64 = ctx.r11.s64 + 1836;
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82122224
	if (ctx.cr6.eq) goto loc_82122224;
	// stw r5,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82122224;
	sub_8222CDF8(ctx, base);
loc_82122224:
	// lwz r10,2140(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2140);
	// lwz r11,52(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// addi r29,r10,1884
	ctx.r29.s64 = ctx.r10.s64 + 1884;
	// cmplw cr6,r29,r11
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82122254
	if (ctx.cr6.eq) goto loc_82122254;
	// stw r29,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r29.u32);
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222d188
	ctx.lr = 0x82122248;
	sub_8222D188(ctx, base);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82122254
	if (ctx.cr6.eq) goto loc_82122254;
	// bl 0x82113790
	ctx.lr = 0x82122254;
	sub_82113790(ctx, base);
loc_82122254:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r31,25980(r11)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25980);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 4);
	// stw r10,12216(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r28)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r28.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r28)
	PPC_STORE_U64(ctx.r28.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x8212227C;
	sub_82238728(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82122288;
	sub_82238380(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82122294;
	sub_821112B0(ctx, base);
	// lwz r7,16(r27)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r27.u32 + 16);
	// lwz r6,440(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 440);
	// cntlzw r5,r6
	ctx.r5.u64 = ctx.r6.u32 == 0 ? 32 : __builtin_clz(ctx.r6.u32);
	// rlwinm r4,r5,27,31,31
	ctx.r4.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 27) & 0x1;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x821222bc
	if (ctx.cr6.eq) goto loc_821222BC;
	// lwz r11,2140(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2140);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r4,r11,68
	ctx.r4.s64 = ctx.r11.s64 + 68;
	// bl 0x82111400
	ctx.lr = 0x821222BC;
	sub_82111400(ctx, base);
loc_821222BC:
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// lwz r9,24(r27)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r27.u32 + 24);
	// lis r8,-32250
	ctx.r8.s64 = -2113536000;
	// lwz r7,28(r27)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r27.u32 + 28);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lwz r6,32(r27)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r27.u32 + 32);
	// addi r5,r8,31376
	ctx.r5.s64 = ctx.r8.s64 + 31376;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r11.u32);
	// addi r11,r27,20
	ctx.r11.s64 = ctx.r27.s64 + 20;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// stw r6,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r6.u32);
	// lfs f0,124(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f8.f64 = double(temp.f32);
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fctidz f9,f13
	ctx.f9.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// stfd f9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.f9.u64);
	// lwz r8,100(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// fctidz f10,f0
	ctx.f10.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// fctidz f11,f12
	ctx.f11.s64 = (ctx.f12.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f12.f64);
	// stfd f11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f11.u64);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f7,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.f7.u64);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lfs f0,36(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// lwz r9,92(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lfs f13,48(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// lwz r7,100(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stfs f0,128(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f13,132(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stw r8,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r8.u32);
	// stw r10,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r10.u32);
	// stw r9,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r9.u32);
	// stw r7,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r7.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x82122358;
	sub_8222CBC8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,12(r27)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r27.u32 + 12);
	// bl 0x82113bc0
	ctx.lr = 0x82122364;
	sub_82113BC0(ctx, base);
	// bl 0x8210b0d8
	ctx.lr = 0x82122368;
	sub_8210B0D8(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82122374;
	sub_821112B0(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212237C"))) PPC_WEAK_FUNC(sub_8212237C);
PPC_FUNC_IMPL(__imp__sub_8212237C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82122380"))) PPC_WEAK_FUNC(sub_82122380);
PPC_FUNC_IMPL(__imp__sub_82122380) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e444
	ctx.lr = 0x82122388;
	__restfpr_19(ctx, base);
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x8233fa38
	ctx.lr = 0x82122390;
	sub_8233FA38(ctx, base);
	// stwu r1,-448(r1)
	ea = -448 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r30,2004(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2004);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,212
	ctx.r3.s64 = 212;
	// lwz r19,1204(r31)
	ctx.r19.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1204);
	// bl 0x82111340
	ctx.lr = 0x821223B8;
	sub_82111340(ctx, base);
	// li r4,254
	ctx.r4.s64 = 254;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x821223C4;
	sub_82113BC0(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r12,1
	ctx.r12.s64 = 1;
	// addi r28,r11,31376
	ctx.r28.s64 = ctx.r11.s64 + 31376;
	// rldicr r12,r12,44,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 44) & 0xFFFFFFFFFFFFFFFF;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f31,48(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// lfs f0,1480(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 1480);
	ctx.f0.f64 = double(temp.f32);
	// stfs f31,7232(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7232, temp.u32);
	// stfs f0,7236(r30)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7236, temp.u32);
	// stfs f31,7240(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7240, temp.u32);
	// stfs f31,7244(r30)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r30.u32 + 7244, temp.u32);
	// ld r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r30.u32 + 8);
	// or r9,r10,r12
	ctx.r9.u64 = ctx.r10.u64 | ctx.r12.u64;
	// std r9,8(r30)
	PPC_STORE_U64(ctx.r30.u32 + 8, ctx.r9.u64);
	// bl 0x821112b0
	ctx.lr = 0x82122404;
	sub_821112B0(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x82122410;
	sub_82111340(ctx, base);
	// lbz r8,12(r29)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r29.u32 + 12);
	// lfs f28,36(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 36);
	ctx.f28.f64 = double(temp.f32);
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// beq cr6,0x82122434
	if (ctx.cr6.eq) goto loc_82122434;
	// li r6,0
	ctx.r6.s64 = 0;
	// fmr f1,f28
	ctx.f1.f64 = ctx.f28.f64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,16
	ctx.r3.s64 = 16;
	// bl 0x8210afd8
	ctx.lr = 0x82122434;
	sub_8210AFD8(ctx, base);
loc_82122434:
	// lwz r11,272(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 272);
	// addi r4,r31,100
	ctx.r4.s64 = ctx.r31.s64 + 100;
	// lwz r10,276(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 276);
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// lwz r9,280(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 280);
	// li r5,64
	ctx.r5.s64 = 64;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// stw r9,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r9.u32);
	// bl 0x8233e4e0
	ctx.lr = 0x8212245C;
	sub_8233E4E0(ctx, base);
	// addi r4,r31,164
	ctx.r4.s64 = ctx.r31.s64 + 164;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// li r5,64
	ctx.r5.s64 = 64;
	// bl 0x8233e4e0
	ctx.lr = 0x8212246C;
	sub_8233E4E0(ctx, base);
	// lfs f0,13004(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 13004);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,13008(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 13008);
	ctx.f13.f64 = double(temp.f32);
	// fctidz f12,f0
	ctx.f12.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// lfs f11,13012(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 13012);
	ctx.f11.f64 = double(temp.f32);
	// fctidz f10,f13
	ctx.f10.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// lfs f8,13000(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 13000);
	ctx.f8.f64 = double(temp.f32);
	// fctidz f9,f11
	ctx.f9.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// stfd f12,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f12.u64);
	// lwz r22,84(r1)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// lwz r21,92(r1)
	ctx.r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f9.u64);
	// stfd f7,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f7.u64);
	// lwz r20,84(r1)
	ctx.r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r23,92(r1)
	ctx.r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// li r11,6
	ctx.r11.s64 = 6;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// stw r22,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r22.u32);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// lfs f30,13016(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 13016);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,13020(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 13020);
	ctx.f29.f64 = double(temp.f32);
	// addi r8,r10,-4
	ctx.r8.s64 = ctx.r10.s64 + -4;
	// stfs f30,128(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// addi r10,r9,-4
	ctx.r10.s64 = ctx.r9.s64 + -4;
	// stfs f29,132(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// stw r23,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r23.u32);
	// stw r21,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r21.u32);
	// stw r20,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r20.u32);
loc_821224E4:
	// lwzu r11,4(r10)
	ea = 4 + ctx.r10.u32;
	ctx.r11.u64 = PPC_LOAD_U32(ea);
	ctx.r10.u32 = ea;
	// stwu r11,4(r8)
	ea = 4 + ctx.r8.u32;
	PPC_STORE_U32(ea, ctx.r11.u32);
	ctx.r8.u32 = ea;
	// bdnz 0x821224e4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_821224E4;
	// lbz r11,12(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 12);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82122500
	if (!ctx.cr6.eq) goto loc_82122500;
	// fmr f31,f28
	ctx.fpscr.disableFlushMode();
	ctx.f31.f64 = ctx.f28.f64;
loc_82122500:
	// stfs f31,164(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// stfs f31,160(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8222cbc8
	ctx.lr = 0x82122514;
	sub_8222CBC8(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,124
	ctx.r3.s64 = 124;
	// lwz r24,852(r31)
	ctx.r24.u64 = PPC_LOAD_U32(ctx.r31.u32 + 852);
	// bl 0x82111340
	ctx.lr = 0x82122524;
	sub_82111340(ctx, base);
	// lwz r11,16(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// li r25,0
	ctx.r25.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x821225f4
	if (!ctx.cr6.gt) goto loc_821225F4;
	// li r26,0
	ctx.r26.s64 = 0;
	// li r28,0
	ctx.r28.s64 = 0;
loc_8212253C:
	// lwz r11,24(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// add r11,r11,r28
	ctx.r11.u64 = ctx.r11.u64 + ctx.r28.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// stw r4,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r4.u32);
	// beq cr6,0x821225dc
	if (ctx.cr6.eq) goto loc_821225DC;
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// stw r10,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r10.u32);
loc_8212255C:
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r11,r11,-20
	ctx.r11.s64 = ctx.r11.s64 + -20;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bgt cr6,0x821225b4
	if (ctx.cr6.gt) goto loc_821225B4;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bdzf 4*cr6+eq,0x8212258c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 == 0 && !ctx.cr6.eq) goto loc_8212258C;
	// bdzf 4*cr6+eq,0x821225ac
	--ctx.ctr.u64;
	if (ctx.ctr.u32 == 0 && !ctx.cr6.eq) goto loc_821225AC;
	// bne cr6,0x82122598
	if (!ctx.cr6.eq) goto loc_82122598;
	// addi r3,r27,20
	ctx.r3.s64 = ctx.r27.s64 + 20;
	// bl 0x82123ba8
	ctx.lr = 0x82122588;
	sub_82123BA8(ctx, base);
	// b 0x821225b4
	goto loc_821225B4;
loc_8212258C:
	// addi r3,r27,20
	ctx.r3.s64 = ctx.r27.s64 + 20;
	// bl 0x82123d78
	ctx.lr = 0x82122594;
	sub_82123D78(ctx, base);
	// b 0x821225b4
	goto loc_821225B4;
loc_82122598:
	// lwz r11,20(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// addi r3,r27,20
	ctx.r3.s64 = ctx.r27.s64 + 20;
	// lwzx r5,r11,r26
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r26.u32);
	// bl 0x82124718
	ctx.lr = 0x821225A8;
	sub_82124718(ctx, base);
	// b 0x821225b4
	goto loc_821225B4;
loc_821225AC:
	// addi r3,r27,20
	ctx.r3.s64 = ctx.r27.s64 + 20;
	// bl 0x82124a88
	ctx.lr = 0x821225B4;
	sub_82124A88(ctx, base);
loc_821225B4:
	// lwz r11,24(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 24);
	// add r10,r11,r28
	ctx.r10.u64 = ctx.r11.u64 + ctx.r28.u64;
	// lwz r11,8(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821225d0
	if (ctx.cr6.eq) goto loc_821225D0;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r9,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r9.u32);
loc_821225D0:
	// mr r4,r11
	ctx.r4.u64 = ctx.r11.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212255c
	if (!ctx.cr6.eq) goto loc_8212255C;
loc_821225DC:
	// lwz r11,16(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 16);
	// addi r25,r25,1
	ctx.r25.s64 = ctx.r25.s64 + 1;
	// addi r28,r28,12
	ctx.r28.s64 = ctx.r28.s64 + 12;
	// addi r26,r26,4
	ctx.r26.s64 = ctx.r26.s64 + 4;
	// cmplw cr6,r25,r11
	ctx.cr6.compare<uint32_t>(ctx.r25.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x8212253c
	if (ctx.cr6.lt) goto loc_8212253C;
loc_821225F4:
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lfs f13,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,276(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 276, temp.u32);
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lfs f13,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// rldicr r12,r12,59,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 59) & 0xFFFFFFFFFFFFFFFF;
	// stfs f0,272(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 272, temp.u32);
	// clrldi r10,r21,32
	ctx.r10.u64 = ctx.r21.u64 & 0xFFFFFFFF;
	// stfs f13,280(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 280, temp.u32);
	// clrldi r8,r22,32
	ctx.r8.u64 = ctx.r22.u64 & 0xFFFFFFFF;
	// stfs f0,2208(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2208, temp.u32);
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfs f0,276(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 276);
	ctx.f0.f64 = double(temp.f32);
	// clrldi r7,r23,32
	ctx.r7.u64 = ctx.r23.u64 & 0xFFFFFFFF;
	// stfs f0,2212(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2212, temp.u32);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfs f0,280(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 280);
	ctx.f0.f64 = double(temp.f32);
	// std r7,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r7.u64);
	// stfs f0,2216(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2216, temp.u32);
	// clrldi r6,r20,32
	ctx.r6.u64 = ctx.r20.u64 & 0xFFFFFFFF;
	// lfs f0,284(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 284);
	ctx.f0.f64 = double(temp.f32);
	// std r6,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r6.u64);
	// stfs f0,2220(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2220, temp.u32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// ld r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// or r4,r5,r12
	ctx.r4.u64 = ctx.r5.u64 | ctx.r12.u64;
	// std r4,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r4.u64);
	// lfs f0,272(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 272);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// stfs f0,6256(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6256, temp.u32);
	// lfs f0,276(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 276);
	ctx.f0.f64 = double(temp.f32);
	// li r12,1
	ctx.r12.s64 = 1;
	// stfs f0,6260(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6260, temp.u32);
	// fmr f6,f29
	ctx.f6.f64 = ctx.f29.f64;
	// lfs f0,280(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 280);
	ctx.f0.f64 = double(temp.f32);
	// rldicr r12,r12,60,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 60) & 0xFFFFFFFFFFFFFFFF;
	// stfs f0,6264(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6264, temp.u32);
	// fmr f5,f30
	ctx.f5.f64 = ctx.f30.f64;
	// lfs f0,284(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 284);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6268(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6268, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// or r9,r10,r12
	ctx.r9.u64 = ctx.r10.u64 | ctx.r12.u64;
	// lfd f0,88(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f12,f0
	ctx.f12.f64 = double(ctx.f0.s64);
	// std r9,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r9.u64);
	// lfd f11,136(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// lfd f10,96(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f9,f13
	ctx.f9.f64 = double(ctx.f13.s64);
	// fcfid f8,f10
	ctx.f8.f64 = double(ctx.f10.s64);
	// fcfid f7,f11
	ctx.f7.f64 = double(ctx.f11.s64);
	// frsp f3,f12
	ctx.f3.f64 = double(float(ctx.f12.f64));
	// frsp f2,f9
	ctx.f2.f64 = double(float(ctx.f9.f64));
	// frsp f4,f8
	ctx.f4.f64 = double(float(ctx.f8.f64));
	// frsp f1,f7
	ctx.f1.f64 = double(float(ctx.f7.f64));
	// bl 0x8222a560
	ctx.lr = 0x821226DC;
	sub_8222A560(ctx, base);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// bl 0x821139a8
	ctx.lr = 0x821226E8;
	sub_821139A8(ctx, base);
	// lwz r11,852(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 852);
	// cmplw cr6,r11,r24
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r24.u32, ctx.xer);
	// beq cr6,0x82122718
	if (ctx.cr6.eq) goto loc_82122718;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// lwz r9,10548(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 10548);
	// rlwimi r9,r24,14,15,17
	ctx.r9.u64 = (rotl32(ctx.r24.u32, 14) & 0x1C000) | (ctx.r9.u64 & 0xFFFFFFFFFFFE3FFF);
	// stw r9,10548(r11)
	PPC_STORE_U32(ctx.r11.u32 + 10548, ctx.r9.u32);
	// ld r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// ori r7,r8,2048
	ctx.r7.u64 = ctx.r8.u64 | 2048;
	// std r7,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r7.u64);
	// stw r24,852(r31)
	PPC_STORE_U32(ctx.r31.u32 + 852, ctx.r24.u32);
loc_82122718:
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x82122724;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82122730;
	sub_821112B0(ctx, base);
	// mr r4,r19
	ctx.r4.u64 = ctx.r19.u64;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212273C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82232270
	ctx.lr = 0x82122748;
	sub_82232270(ctx, base);
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// addi r12,r1,-112
	ctx.r12.s64 = ctx.r1.s64 + -112;
	// bl 0x8233fa84
	ctx.lr = 0x82122754;
	__savefpr_28(ctx, base);
	// b 0x8233e494
	__restgprlr_19(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82122758"))) PPC_WEAK_FUNC(sub_82122758);
PPC_FUNC_IMPL(__imp__sub_82122758) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82122760;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,2140(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2140);
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
	// lwz r29,2004(r3)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2004);
	// addi r30,r11,68
	ctx.r30.s64 = ctx.r11.s64 + 68;
	// lwz r11,100(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 100);
	// clrlwi r28,r11,26
	ctx.r28.u64 = ctx.r11.u32 & 0x3F;
	// cmplwi cr6,r28,50
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 50, ctx.xer);
	// bne cr6,0x82122790
	if (!ctx.cr6.eq) goto loc_82122790;
	// li r10,3
	ctx.r10.s64 = 3;
	// rlwimi r11,r10,1,26,31
	ctx.r11.u64 = (rotl32(ctx.r10.u32, 1) & 0x3F) | (ctx.r11.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r11,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r11.u32);
loc_82122790:
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r5,r10,31376
	ctx.r5.s64 = ctx.r10.s64 + 31376;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lfs f1,36(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82227e30
	ctx.lr = 0x821227C4;
	sub_82227E30(ctx, base);
	// lwz r4,32(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	// rlwimi r4,r28,0,26,31
	ctx.r4.u64 = (rotl32(ctx.r28.u32, 0) & 0x3F) | (ctx.r4.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r4,32(r30)
	PPC_STORE_U32(ctx.r30.u32 + 32, ctx.r4.u32);
	// lwz r5,364(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 364);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x821227f0
	if (ctx.cr6.eq) goto loc_821227F0;
	// stw r5,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x821227F0;
	sub_8222CDF8(ctx, base);
loc_821227F0:
	// lwz r30,368(r31)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r31.u32 + 368);
	// lwz r11,52(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212281c
	if (ctx.cr6.eq) goto loc_8212281C;
	// stw r30,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r30.u32);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222d188
	ctx.lr = 0x82122810;
	sub_8222D188(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x8212281c
	if (ctx.cr6.eq) goto loc_8212281C;
	// bl 0x82113790
	ctx.lr = 0x8212281C;
	sub_82113790(ctx, base);
loc_8212281C:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82122828;
	sub_821112B0(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x82122834;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x82122840;
	sub_82113BC0(ctx, base);
	// li r4,15
	ctx.r4.s64 = 15;
	// li r3,212
	ctx.r3.s64 = 212;
	// bl 0x82111340
	ctx.lr = 0x8212284C;
	sub_82111340(ctx, base);
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r11,25756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25756);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r29)
	PPC_STORE_U32(ctx.r29.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r29)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r29.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r29)
	PPC_STORE_U64(ctx.r29.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82122874;
	sub_82238728(ctx, base);
	// lwz r11,25756(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25756);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82122884;
	sub_82238380(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,2140(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 2140);
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// addi r30,r10,68
	ctx.r30.s64 = ctx.r10.s64 + 68;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x821228bc
	if (ctx.cr6.eq) goto loc_821228BC;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x821228B8;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_821228BC:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// li r30,1
	ctx.r30.s64 = 1;
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821228e4
	if (ctx.cr6.eq) goto loc_821228E4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x821228DC;
	sub_8222C248(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r30.u32);
loc_821228E4:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82122908
	if (ctx.cr6.eq) goto loc_82122908;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82122900;
	sub_8222C0A0(ctx, base);
	// mr r11,r30
	ctx.r11.u64 = ctx.r30.u64;
	// stw r30,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r30.u32);
loc_82122908:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x8212293c
	if (ctx.cr6.eq) goto loc_8212293C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1164(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r8,r30,24,7,8
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 24) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r10.u32);
loc_8212293C:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82122970
	if (ctx.cr6.eq) goto loc_82122970;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82122970:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821229a4
	if (ctx.cr6.eq) goto loc_821229A4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r30,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r30.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_821229A4:
	// bl 0x8210b0d8
	ctx.lr = 0x821229A8;
	sub_8210B0D8(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x821229B4;
	sub_82111340(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821229BC"))) PPC_WEAK_FUNC(sub_821229BC);
PPC_FUNC_IMPL(__imp__sub_821229BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821229C0"))) PPC_WEAK_FUNC(sub_821229C0);
PPC_FUNC_IMPL(__imp__sub_821229C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// li r12,1
	ctx.r12.s64 = 1;
	// addi r9,r10,28184
	ctx.r9.s64 = ctx.r10.s64 + 28184;
	// rldicr r12,r12,59,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 59) & 0xFFFFFFFFFFFFFFFF;
	// lwz r11,28184(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28184);
	// stfs f0,272(r9)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 272, temp.u32);
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,276(r9)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + 276, temp.u32);
	// lfs f13,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,280(r9)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + 280, temp.u32);
	// stfs f0,2208(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2208, temp.u32);
	// lfs f0,276(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 276);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,2212(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2212, temp.u32);
	// lfs f0,280(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 280);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,2216(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2216, temp.u32);
	// lfs f0,284(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 284);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,2220(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 2220, temp.u32);
	// ld r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// or r6,r7,r12
	ctx.r6.u64 = ctx.r7.u64 | ctx.r12.u64;
	// li r12,1
	ctx.r12.s64 = 1;
	// std r6,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r6.u64);
	// lfs f0,272(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 272);
	ctx.f0.f64 = double(temp.f32);
	// lwz r11,28184(r10)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28184);
	// stfs f0,6256(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6256, temp.u32);
	// lfs f0,276(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 276);
	ctx.f0.f64 = double(temp.f32);
	// rldicr r12,r12,60,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 60) & 0xFFFFFFFFFFFFFFFF;
	// stfs f0,6260(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6260, temp.u32);
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// lfs f0,280(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 280);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6264(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6264, temp.u32);
	// lfs f0,284(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 284);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6268(r11)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r11.u32 + 6268, temp.u32);
	// ld r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r11.u32 + 8);
	// or r3,r4,r12
	ctx.r3.u64 = ctx.r4.u64 | ctx.r12.u64;
	// std r3,8(r11)
	PPC_STORE_U64(ctx.r11.u32 + 8, ctx.r3.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82122A58"))) PPC_WEAK_FUNC(sub_82122A58);
PPC_FUNC_IMPL(__imp__sub_82122A58) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r9,42
	ctx.r9.s64 = 2752512;
	// lis r8,24
	ctx.r8.s64 = 1572864;
	// lis r10,42
	ctx.r10.s64 = 2752512;
	// lis r7,44
	ctx.r7.s64 = 2883584;
	// ori r4,r9,8592
	ctx.r4.u64 = ctx.r9.u64 | 8592;
	// lis r6,26
	ctx.r6.s64 = 1703936;
	// ori r9,r8,10374
	ctx.r9.u64 = ctx.r8.u64 | 10374;
	// stw r4,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r4.u32);
	// ori r5,r10,9145
	ctx.r5.u64 = ctx.r10.u64 | 9145;
	// ori r8,r7,9049
	ctx.r8.u64 = ctx.r7.u64 | 9049;
	// stw r9,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r9.u32);
	// li r11,10
	ctx.r11.s64 = 10;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// li r3,3
	ctx.r3.s64 = 3;
	// stw r8,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r8.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r11,113(r1)
	PPC_STORE_U8(ctx.r1.u32 + 113, ctx.r11.u8);
	// li r7,5
	ctx.r7.s64 = 5;
	// stb r3,101(r1)
	PPC_STORE_U8(ctx.r1.u32 + 101, ctx.r3.u8);
	// ori r6,r6,8326
	ctx.r6.u64 = ctx.r6.u64 | 8326;
	// stb r10,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, ctx.r10.u8);
	// stb r7,125(r1)
	PPC_STORE_U8(ctx.r1.u32 + 125, ctx.r7.u8);
	// li r4,6
	ctx.r4.s64 = 6;
	// stw r6,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r6.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stb r11,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, ctx.r11.u8);
	// bl 0x821160a8
	ctx.lr = 0x82122AD8;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x82122ADC;
	sub_82116360(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r30,r11,9480
	ctx.r30.s64 = ctx.r11.s64 + 9480;
	// beq cr6,0x82122b0c
	if (ctx.cr6.eq) goto loc_82122B0C;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// addi r5,r11,10800
	ctx.r5.s64 = ctx.r11.s64 + 10800;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x82122B00;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25808(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25808, ctx.r3.u32);
	// b 0x82122b18
	goto loc_82122B18;
loc_82122B0C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25808(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25808, ctx.r11.u32);
loc_82122B18:
	// bl 0x82116360
	ctx.lr = 0x82122B1C;
	sub_82116360(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r31,r11,12168
	ctx.r31.s64 = ctx.r11.s64 + 12168;
	// beq cr6,0x82122b4c
	if (ctx.cr6.eq) goto loc_82122B4C;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// addi r5,r11,12472
	ctx.r5.s64 = ctx.r11.s64 + 12472;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x82122B40;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25812(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25812, ctx.r3.u32);
	// b 0x82122b58
	goto loc_82122B58;
loc_82122B4C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25812(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25812, ctx.r11.u32);
loc_82122B58:
	// bl 0x82116360
	ctx.lr = 0x82122B5C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82122b84
	if (ctx.cr6.eq) goto loc_82122B84;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// addi r5,r11,13392
	ctx.r5.s64 = ctx.r11.s64 + 13392;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x82122B78;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25816(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25816, ctx.r3.u32);
	// b 0x82122b90
	goto loc_82122B90;
loc_82122B84:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25816(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25816, ctx.r11.u32);
loc_82122B90:
	// bl 0x82116360
	ctx.lr = 0x82122B94;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82122bbc
	if (ctx.cr6.eq) goto loc_82122BBC;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// addi r5,r11,14824
	ctx.r5.s64 = ctx.r11.s64 + 14824;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x82122BB0;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25820(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25820, ctx.r3.u32);
	// b 0x82122bc8
	goto loc_82122BC8;
loc_82122BBC:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25820(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25820, ctx.r11.u32);
loc_82122BC8:
	// bl 0x82116360
	ctx.lr = 0x82122BCC;
	sub_82116360(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r30,r11,15784
	ctx.r30.s64 = ctx.r11.s64 + 15784;
	// beq cr6,0x82122bfc
	if (ctx.cr6.eq) goto loc_82122BFC;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// addi r5,r11,16216
	ctx.r5.s64 = ctx.r11.s64 + 16216;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x82122BF0;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25824(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25824, ctx.r3.u32);
	// b 0x82122c08
	goto loc_82122C08;
loc_82122BFC:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25824(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25824, ctx.r11.u32);
loc_82122C08:
	// bl 0x82116360
	ctx.lr = 0x82122C0C;
	sub_82116360(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r31,r11,17312
	ctx.r31.s64 = ctx.r11.s64 + 17312;
	// beq cr6,0x82122c3c
	if (ctx.cr6.eq) goto loc_82122C3C;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// addi r5,r11,17896
	ctx.r5.s64 = ctx.r11.s64 + 17896;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x82122C30;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25828(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25828, ctx.r3.u32);
	// b 0x82122c48
	goto loc_82122C48;
loc_82122C3C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25828(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25828, ctx.r11.u32);
loc_82122C48:
	// bl 0x82116360
	ctx.lr = 0x82122C4C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82122c74
	if (ctx.cr6.eq) goto loc_82122C74;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// addi r5,r11,18864
	ctx.r5.s64 = ctx.r11.s64 + 18864;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x82122C68;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25832(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25832, ctx.r3.u32);
	// b 0x82122c80
	goto loc_82122C80;
loc_82122C74:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25832(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25832, ctx.r11.u32);
loc_82122C80:
	// bl 0x82116360
	ctx.lr = 0x82122C84;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82122cac
	if (ctx.cr6.eq) goto loc_82122CAC;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r6,r31
	ctx.r6.u64 = ctx.r31.u64;
	// addi r5,r11,20016
	ctx.r5.s64 = ctx.r11.s64 + 20016;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x82122CA0;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25836(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25836, ctx.r3.u32);
	// b 0x82122cb8
	goto loc_82122CB8;
loc_82122CAC:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25836(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25836, ctx.r11.u32);
loc_82122CB8:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82122CD0"))) PPC_WEAK_FUNC(sub_82122CD0);
PPC_FUNC_IMPL(__imp__sub_82122CD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e45c
	ctx.lr = 0x82122CD8;
	__restfpr_25(ctx, base);
	// stfd f29,-88(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -88, ctx.f29.u64);
	// stfd f30,-80(r1)
	PPC_STORE_U64(ctx.r1.u32 + -80, ctx.f30.u64);
	// stfd f31,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, ctx.f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,32(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// mr r26,r4
	ctx.r26.u64 = ctx.r4.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82122d08
	if (!ctx.cr6.eq) goto loc_82122D08;
	// lwz r11,24(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821230e8
	if (ctx.cr6.eq) goto loc_821230E8;
loc_82122D08:
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r31,4(r25)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82122D18;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82122D24;
	sub_821112B0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// li r29,1
	ctx.r29.s64 = 1;
	// addi r30,r11,28184
	ctx.r30.s64 = ctx.r11.s64 + 28184;
	// lwz r11,1972(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1972);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82122d64
	if (ctx.cr6.eq) goto loc_82122D64;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r29,11,19,21
	ctx.r8.u64 = (rotl32(ctx.r29.u32, 11) & 0x1C00) | (ctx.r8.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1972(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1972, ctx.r10.u32);
loc_82122D64:
	// lwz r11,1988(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82122d98
	if (ctx.cr6.eq) goto loc_82122D98;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r29,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r29.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r30)
	PPC_STORE_U32(ctx.r30.u32 + 1988, ctx.r10.u32);
loc_82122D98:
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82122dbc
	if (ctx.cr6.eq) goto loc_82122DBC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82122DB4;
	sub_8222C248(ctx, base);
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r29.u32);
loc_82122DBC:
	// lwz r11,2052(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82122de0
	if (ctx.cr6.eq) goto loc_82122DE0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82122DD8;
	sub_8222C0A0(ctx, base);
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r29.u32);
loc_82122DE0:
	// lwz r11,2068(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2068);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82122e14
	if (ctx.cr6.eq) goto loc_82122E14;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1164(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r8,r29,23,7,8
	ctx.r8.u64 = (rotl32(ctx.r29.u32, 23) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r29,2068(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2068, ctx.r29.u32);
loc_82122E14:
	// lwz r11,2292(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2292);
	// li r9,3
	ctx.r9.s64 = 3;
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82122e4c
	if (ctx.cr6.eq) goto loc_82122E4C;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1176(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r7,r9,11,19,21
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 11) & 0x1C00) | (ctx.r7.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r7,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,16384
	ctx.r5.u64 = ctx.r6.u64 | 1073741824;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2292(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2292, ctx.r10.u32);
loc_82122E4C:
	// lwz r11,2308(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2308);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82122e80
	if (ctx.cr6.eq) goto loc_82122E80;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1176(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r7,r9,14,16,18
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 14) & 0xE000) | (ctx.r7.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r7,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,16384
	ctx.r5.u64 = ctx.r6.u64 | 1073741824;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2308(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2308, ctx.r10.u32);
loc_82122E80:
	// lwz r11,2356(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2356);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82122ea4
	if (ctx.cr6.eq) goto loc_82122EA4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82122E9C;
	sub_8222C248(ctx, base);
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,2356(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2356, ctx.r29.u32);
loc_82122EA4:
	// lwz r11,2372(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2372);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82122ec8
	if (ctx.cr6.eq) goto loc_82122EC8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x82122EC0;
	sub_8222C0A0(ctx, base);
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,2372(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2372, ctx.r29.u32);
loc_82122EC8:
	// lwz r11,2388(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2388);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82122efc
	if (ctx.cr6.eq) goto loc_82122EFC;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// mr r10,r29
	ctx.r10.u64 = ctx.r29.u64;
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// lwz r9,1164(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r9,r29,23,7,8
	ctx.r9.u64 = (rotl32(ctx.r29.u32, 23) & 0x1800000) | (ctx.r9.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r9,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r9.u32);
	// ld r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// oris r7,r8,16384
	ctx.r7.u64 = ctx.r8.u64 | 1073741824;
	// std r7,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r7.u64);
	// stw r29,2388(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2388, ctx.r29.u32);
loc_82122EFC:
	// lwz r11,2340(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2340);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x82122f30
	if (ctx.cr6.eq) goto loc_82122F30;
	// lwz r11,0(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r10,-1
	ctx.r10.s64 = -1;
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// lwz r9,1172(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// rlwimi r9,r29,0,30,31
	ctx.r9.u64 = (rotl32(ctx.r29.u32, 0) & 0x3) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r9,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r9.u32);
	// ld r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// oris r7,r8,16384
	ctx.r7.u64 = ctx.r8.u64 | 1073741824;
	// std r7,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r7.u64);
	// stw r10,2340(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2340, ctx.r10.u32);
loc_82122F30:
	// lwz r11,24(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 24);
	// li r10,1
	ctx.r10.s64 = 1;
	// li r27,0
	ctx.r27.s64 = 0;
	// rldicr r28,r10,36,63
	ctx.r28.u64 = rotl64(ctx.r10.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82123000
	if (!ctx.cr6.gt) goto loc_82123000;
	// lfs f31,92(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f31.f64 = double(temp.f32);
	// li r29,0
	ctx.r29.s64 = 0;
	// lfs f30,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f29.f64 = double(temp.f32);
loc_82122F58:
	// lwz r11,20(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// add r30,r11,r29
	ctx.r30.u64 = ctx.r11.u64 + ctx.r29.u64;
	// lwz r11,120(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 120);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82122fec
	if (ctx.cr6.eq) goto loc_82122FEC;
	// lfs f0,92(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// addi r7,r30,20
	ctx.r7.s64 = ctx.r30.s64 + 20;
	// stfs f0,3968(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3968, temp.u32);
	// addi r5,r30,4
	ctx.r5.s64 = ctx.r30.s64 + 4;
	// lfs f13,96(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// stfs f13,3972(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3972, temp.u32);
	// lfs f12,100(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 100);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,3976(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3976, temp.u32);
	// lfs f11,104(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,3980(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3980, temp.u32);
	// ld r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// oris r10,r11,32768
	ctx.r10.u64 = ctx.r11.u64 | 2147483648;
	// std r10,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r10.u64);
	// lwz r9,120(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 120);
	// lfs f10,36(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,7744(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7744, temp.u32);
	// stfs f29,7748(r31)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7748, temp.u32);
	// stfs f30,7752(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7752, temp.u32);
	// stfs f31,7756(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7756, temp.u32);
	// ld r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r6,r8,r28
	ctx.r6.u64 = ctx.r8.u64 | ctx.r28.u64;
	// std r6,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r6.u64);
	// lwz r6,108(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 108);
	// lwz r4,16(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	// bl 0x82123100
	ctx.lr = 0x82122FD4;
	sub_82123100(ctx, base);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r5,120(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 120);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// lwz r4,16(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82123308
	ctx.lr = 0x82122FEC;
	sub_82123308(ctx, base);
loc_82122FEC:
	// lwz r11,24(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 24);
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// addi r29,r29,124
	ctx.r29.s64 = ctx.r29.s64 + 124;
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82122f58
	if (ctx.cr6.lt) goto loc_82122F58;
loc_82123000:
	// lwz r11,32(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 32);
	// li r27,0
	ctx.r27.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x821230dc
	if (!ctx.cr6.gt) goto loc_821230DC;
	// lfs f31,92(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f31.f64 = double(temp.f32);
	// li r29,0
	ctx.r29.s64 = 0;
	// lfs f30,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f30.f64 = double(temp.f32);
	// lfs f29,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f29.f64 = double(temp.f32);
loc_82123020:
	// lwz r11,28(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 28);
	// add r30,r29,r11
	ctx.r30.u64 = ctx.r29.u64 + ctx.r11.u64;
	// lwz r11,120(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 120);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821230c8
	if (ctx.cr6.eq) goto loc_821230C8;
	// lfs f0,92(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 92);
	ctx.f0.f64 = double(temp.f32);
	// addi r7,r30,20
	ctx.r7.s64 = ctx.r30.s64 + 20;
	// stfs f0,3968(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3968, temp.u32);
	// addi r5,r30,4
	ctx.r5.s64 = ctx.r30.s64 + 4;
	// lfs f13,96(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// stfs f13,3972(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3972, temp.u32);
	// lfs f12,100(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 100);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,3976(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3976, temp.u32);
	// lfs f11,104(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,3980(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 3980, temp.u32);
	// ld r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 0);
	// oris r10,r11,32768
	ctx.r10.u64 = ctx.r11.u64 | 2147483648;
	// std r10,0(r31)
	PPC_STORE_U64(ctx.r31.u32 + 0, ctx.r10.u64);
	// lwz r9,120(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 120);
	// lwz r8,80(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 80);
	// lfs f10,36(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 36);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,7744(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7744, temp.u32);
	// stfs f29,7748(r31)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7748, temp.u32);
	// stfs f31,7756(r31)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7756, temp.u32);
	// stfs f30,7752(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7752, temp.u32);
	// ld r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r4,r6,r28
	ctx.r4.u64 = ctx.r6.u64 | ctx.r28.u64;
	// std r4,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r4.u64);
	// lwz r6,108(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 108);
	// lwz r4,16(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	// bl 0x82123100
	ctx.lr = 0x821230A0;
	sub_82123100(ctx, base);
	// lwz r11,120(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 120);
	// addi r3,r11,16
	ctx.r3.s64 = ctx.r11.s64 + 16;
	// bl 0x82113ab8
	ctx.lr = 0x821230AC;
	sub_82113AB8(ctx, base);
	// lwz r11,120(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 120);
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r4,16(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	// mr r6,r30
	ctx.r6.u64 = ctx.r30.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r5,80(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 80);
	// bl 0x82123308
	ctx.lr = 0x821230C8;
	sub_82123308(ctx, base);
loc_821230C8:
	// lwz r11,32(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 32);
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// addi r29,r29,124
	ctx.r29.s64 = ctx.r29.s64 + 124;
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x82123020
	if (ctx.cr6.lt) goto loc_82123020;
loc_821230DC:
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x821230E8;
	sub_82111340(ctx, base);
loc_821230E8:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f29,-88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// lfd f30,-80(r1)
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// lfd f31,-72(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x8233e4ac
	__restgprlr_25(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821230FC"))) PPC_WEAK_FUNC(sub_821230FC);
PPC_FUNC_IMPL(__imp__sub_821230FC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82123100"))) PPC_WEAK_FUNC(sub_82123100);
PPC_FUNC_IMPL(__imp__sub_82123100) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82123108;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r10,r4,0,5,5
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x4000000;
	// lwz r31,4(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82123274
	if (ctx.cr6.eq) goto loc_82123274;
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// addi r9,r10,-27800
	ctx.r9.s64 = ctx.r10.s64 + -27800;
	// lwz r10,2120(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2120);
	// rlwinm r8,r10,30,31,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x1;
	// cmplwi cr6,r8,0
	ctx.cr6.compare<uint32_t>(ctx.r8.u32, 0, ctx.xer);
	// bne cr6,0x82123300
	if (!ctx.cr6.eq) goto loc_82123300;
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// li r12,1
	ctx.r12.s64 = 1;
	// stfs f0,6288(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6288, temp.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f13,4(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// rldicr r12,r12,59,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 59) & 0xFFFFFFFFFFFFFFFF;
	// stfs f13,6292(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6292, temp.u32);
	// lfs f12,8(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,6296(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6296, temp.u32);
	// lfs f11,12(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,6300(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6300, temp.u32);
	// ld r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r9,r10,r12
	ctx.r9.u64 = ctx.r10.u64 | ctx.r12.u64;
	// std r9,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r9.u64);
	// lwz r11,0(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r4,r11,276
	ctx.r4.s64 = ctx.r11.s64 + 276;
	// bl 0x82111400
	ctx.lr = 0x8212317C;
	sub_82111400(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// lwz r11,2292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2292);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821231b8
	if (ctx.cr6.eq) goto loc_821231B8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwinm r7,r8,0,22,18
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFFE3FF;
	// stw r7,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,16384
	ctx.r5.u64 = ctx.r6.u64 | 1073741824;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2292, ctx.r10.u32);
loc_821231B8:
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821231ec
	if (ctx.cr6.eq) goto loc_821231EC;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1176(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwinm r7,r8,0,19,15
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFFFFFFF1FFF;
	// stw r7,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,16384
	ctx.r5.u64 = ctx.r6.u64 | 1073741824;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r10.u32);
loc_821231EC:
	// lwz r11,2388(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2388);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82123224
	if (ctx.cr6.eq) goto loc_82123224;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r9,2
	ctx.r9.s64 = 2;
	// addi r10,r11,24
	ctx.r10.s64 = ctx.r11.s64 + 24;
	// lwz r7,1188(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1188);
	// rlwimi r7,r8,24,7,8
	ctx.r7.u64 = (rotl32(ctx.r8.u32, 24) & 0x1800000) | (ctx.r7.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r7,1188(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1188, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,16384
	ctx.r5.u64 = ctx.r6.u64 | 1073741824;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r9,2388(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2388, ctx.r9.u32);
loc_82123224:
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82123248
	if (ctx.cr6.eq) goto loc_82123248;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x82123240;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r11.u32);
loc_82123248:
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82123300
	if (ctx.cr6.eq) goto loc_82123300;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82123264;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
loc_82123274:
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// li r12,1
	ctx.r12.s64 = 1;
	// stfs f0,6288(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6288, temp.u32);
	// cmplwi cr6,r6,0
	ctx.cr6.compare<uint32_t>(ctx.r6.u32, 0, ctx.xer);
	// rldicr r12,r12,59,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 59) & 0xFFFFFFFFFFFFFFFF;
	// lfs f13,4(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,6292(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6292, temp.u32);
	// lfs f12,8(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,6296(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6296, temp.u32);
	// lfs f11,12(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,6300(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6300, temp.u32);
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// beq cr6,0x82123300
	if (ctx.cr6.eq) goto loc_82123300;
	// li r11,1
	ctx.r11.s64 = 1;
	// addi r30,r7,4
	ctx.r30.s64 = ctx.r7.s64 + 4;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// rldicr r28,r11,63,63
	ctx.r28.u64 = rotl64(ctx.r11.u64, 63) & 0xFFFFFFFFFFFFFFFF;
loc_821232C0:
	// lwz r4,-4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + -4);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r6,4(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// rlwinm r10,r4,30,2,31
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r11,r4,r6
	ctx.r11.u64 = ctx.r4.u64 + ctx.r6.u64;
	// addi r9,r11,-1
	ctx.r9.s64 = ctx.r11.s64 + -1;
	// rlwinm r8,r9,30,2,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
	// subf r7,r10,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r10.s64;
	// clrldi r11,r7,32
	ctx.r11.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// srad r9,r28,r11
	temp.u64 = ctx.r11.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r28.s64 < 0) & (((ctx.r28.s64 >> temp.u64) << temp.u64) != ctx.r28.s64);
	ctx.r9.s64 = ctx.r28.s64 >> temp.u64;
	// srd r7,r9,r10
	ctx.r7.u64 = ctx.r10.u8 & 0x40 ? 0 : (ctx.r9.u64 >> (ctx.r10.u8 & 0x7F));
	// bl 0x82238120
	ctx.lr = 0x821232F4;
	sub_82238120(ctx, base);
	// addic. r29,r29,-1
	ctx.xer.ca = ctx.r29.u32 > 0;
	ctx.r29.s64 = ctx.r29.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r29.s32, 0, ctx.xer);
	// addi r30,r30,12
	ctx.r30.s64 = ctx.r30.s64 + 12;
	// bne 0x821232c0
	if (!ctx.cr0.eq) goto loc_821232C0;
loc_82123300:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82123308"))) PPC_WEAK_FUNC(sub_82123308);
PPC_FUNC_IMPL(__imp__sub_82123308) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e458
	ctx.lr = 0x82123310;
	__restfpr_24(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,40(r5)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 40);
	// mr r25,r3
	ctx.r25.u64 = ctx.r3.u64;
	// mr r24,r4
	ctx.r24.u64 = ctx.r4.u64;
	// mr r27,r5
	ctx.r27.u64 = ctx.r5.u64;
	// mr r26,r6
	ctx.r26.u64 = ctx.r6.u64;
	// mr r29,r7
	ctx.r29.u64 = ctx.r7.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82123670
	if (ctx.cr6.eq) goto loc_82123670;
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// lwz r31,4(r25)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	// addi r9,r10,-27800
	ctx.r9.s64 = ctx.r10.s64 + -27800;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// lwz r10,2120(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2120);
	// addi r8,r10,-4
	ctx.r8.s64 = ctx.r10.s64 + -4;
	// cntlzw r7,r8
	ctx.r7.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// rlwinm r30,r7,27,31,31
	ctx.r30.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x1;
	// beq cr6,0x82123364
	if (ctx.cr6.eq) goto loc_82123364;
	// bl 0x820b91d0
	ctx.lr = 0x82123360;
	sub_820B91D0(ctx, base);
	// b 0x82123380
	goto loc_82123380;
loc_82123364:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82123378
	if (ctx.cr6.eq) goto loc_82123378;
	// lwz r11,88(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x82123384
	goto loc_82123384;
loc_82123378:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x82123380;
	sub_820B90A0(ctx, base);
loc_82123380:
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82123384:
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82111400
	ctx.lr = 0x82123390;
	sub_82111400(ctx, base);
	// rlwinm r11,r24,0,3,5
	ctx.r11.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0x1C000000;
	// rlwinm r11,r11,0,5,3
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 0) & 0xFFFFFFFFF7FFFFFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821233b0
	if (!ctx.cr6.eq) goto loc_821233B0;
	// lwz r11,0(r25)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r4,r11,172
	ctx.r4.s64 = ctx.r11.s64 + 172;
	// bl 0x82111400
	ctx.lr = 0x821233B0;
	sub_82111400(ctx, base);
loc_821233B0:
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r4,32(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 32);
	// bl 0x82113bc0
	ctx.lr = 0x821233BC;
	sub_82113BC0(ctx, base);
	// lbz r11,116(r26)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r26.u32 + 116);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821233d8
	if (ctx.cr6.eq) goto loc_821233D8;
	// lwz r11,220(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 220);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r11,1
	ctx.r11.s64 = 1;
	// bne cr6,0x821233dc
	if (!ctx.cr6.eq) goto loc_821233DC;
loc_821233D8:
	// li r11,0
	ctx.r11.s64 = 0;
loc_821233DC:
	// lwz r10,24(r27)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r27.u32 + 24);
	// clrlwi r28,r11,24
	ctx.r28.u64 = ctx.r11.u32 & 0xFF;
	// rlwinm r9,r10,31,31,31
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// beq cr6,0x82123548
	if (ctx.cr6.eq) goto loc_82123548;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,328
	ctx.r3.s64 = 328;
	// bl 0x82111340
	ctx.lr = 0x821233FC;
	sub_82111340(ctx, base);
	// rlwinm r11,r24,0,5,5
	ctx.r11.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0x4000000;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82123458
	if (ctx.cr6.eq) goto loc_82123458;
	// clrlwi r11,r30,24
	ctx.r11.u64 = ctx.r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// clrlwi r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	// beq cr6,0x82123438
	if (ctx.cr6.eq) goto loc_82123438;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212342c
	if (ctx.cr6.eq) goto loc_8212342C;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25832(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25832);
	// b 0x821234e4
	goto loc_821234E4;
loc_8212342C:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25824(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25824);
	// b 0x821234e4
	goto loc_821234E4;
loc_82123438:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212344c
	if (ctx.cr6.eq) goto loc_8212344C;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25836(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25836);
	// b 0x821234e4
	goto loc_821234E4;
loc_8212344C:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25828(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25828);
	// b 0x821234e4
	goto loc_821234E4;
loc_82123458:
	// clrlwi r29,r29,24
	ctx.r29.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82123470
	if (ctx.cr6.eq) goto loc_82123470;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25820(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25820);
	// b 0x82123478
	goto loc_82123478;
loc_82123470:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25812(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25812);
loc_82123478:
	// rlwinm r11,r24,0,3,3
	ctx.r11.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0x10000000;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x821234e4
	if (!ctx.cr6.eq) goto loc_821234E4;
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r11.u32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r9,r10,8
	ctx.r9.u64 = ctx.r10.u64 | 524288;
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x821234A4;
	sub_82238728(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x821234B0;
	sub_82238380(ctx, base);
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// lwz r6,112(r26)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r26.u32 + 112);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r5,0(r26)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// bl 0x82123678
	ctx.lr = 0x821234C8;
	sub_82123678(ctx, base);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x821234dc
	if (ctx.cr6.eq) goto loc_821234DC;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25816(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25816);
	// b 0x821234e4
	goto loc_821234E4;
loc_821234DC:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25808(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25808);
loc_821234E4:
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r11.u32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r9,r10,8
	ctx.r9.u64 = ctx.r10.u64 | 524288;
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82123504;
	sub_82238728(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82123510;
	sub_82238380(ctx, base);
	// mr r7,r28
	ctx.r7.u64 = ctx.r28.u64;
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// lwz r6,112(r26)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r26.u32 + 112);
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r5,0(r26)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// bl 0x82123678
	ctx.lr = 0x82123528;
	sub_82123678(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,328
	ctx.r3.s64 = 328;
	// bl 0x82111340
	ctx.lr = 0x82123534;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cd68
	ctx.lr = 0x82123540;
	sub_8222CD68(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
loc_82123548:
	// rlwinm r11,r24,0,5,5
	ctx.r11.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0x4000000;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821235a4
	if (ctx.cr6.eq) goto loc_821235A4;
	// clrlwi r11,r30,24
	ctx.r11.u64 = ctx.r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// clrlwi r11,r29,24
	ctx.r11.u64 = ctx.r29.u32 & 0xFF;
	// beq cr6,0x82123584
	if (ctx.cr6.eq) goto loc_82123584;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82123578
	if (ctx.cr6.eq) goto loc_82123578;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25832(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25832);
	// b 0x82123628
	goto loc_82123628;
loc_82123578:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25824(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25824);
	// b 0x82123628
	goto loc_82123628;
loc_82123584:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82123598
	if (ctx.cr6.eq) goto loc_82123598;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25836(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25836);
	// b 0x82123628
	goto loc_82123628;
loc_82123598:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25828(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25828);
	// b 0x82123628
	goto loc_82123628;
loc_821235A4:
	// clrlwi r29,r29,24
	ctx.r29.u64 = ctx.r29.u32 & 0xFF;
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x821235bc
	if (ctx.cr6.eq) goto loc_821235BC;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25820(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25820);
	// b 0x821235c4
	goto loc_821235C4;
loc_821235BC:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25812(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25812);
loc_821235C4:
	// rlwinm r11,r24,0,3,3
	ctx.r11.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 0) & 0x10000000;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82123628
	if (!ctx.cr6.eq) goto loc_82123628;
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r11.u32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r9,r10,8
	ctx.r9.u64 = ctx.r10.u64 | 524288;
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x821235F0;
	sub_82238728(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x821235FC;
	sub_82238380(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r5,0(r26)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// bl 0x82123740
	ctx.lr = 0x8212360C;
	sub_82123740(ctx, base);
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82123620
	if (ctx.cr6.eq) goto loc_82123620;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25816(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25816);
	// b 0x82123628
	goto loc_82123628;
loc_82123620:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r30,25808(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25808);
loc_82123628:
	// lwz r11,4(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// stw r11,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r11.u32);
	// ld r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r9,r10,8
	ctx.r9.u64 = ctx.r10.u64 | 524288;
	// std r9,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r9.u64);
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82123648;
	sub_82238728(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82123654;
	sub_82238380(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r5,0(r26)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// bl 0x82123740
	ctx.lr = 0x82123664;
	sub_82123740(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cd68
	ctx.lr = 0x82123670;
	sub_8222CD68(ctx, base);
loc_82123670:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4a8
	__restgprlr_24(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82123678"))) PPC_WEAK_FUNC(sub_82123678);
PPC_FUNC_IMPL(__imp__sub_82123678) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x82123680;
	__restfpr_26(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r28,4(r3)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi r11,r7,24
	ctx.r11.u64 = ctx.r7.u32 & 0xFF;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r29,r6
	ctx.r29.u64 = ctx.r6.u64;
	// mr r30,r5
	ctx.r30.u64 = ctx.r5.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,28
	ctx.r7.s64 = 28;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// beq cr6,0x8212371c
	if (ctx.cr6.eq) goto loc_8212371C;
	// addi r5,r31,144
	ctx.r5.s64 = ctx.r31.s64 + 144;
	// bl 0x8222cc48
	ctx.lr = 0x821236BC;
	sub_8222CC48(ctx, base);
	// addi r4,r31,176
	ctx.r4.s64 = ctx.r31.s64 + 176;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8222cd68
	ctx.lr = 0x821236C8;
	sub_8222CD68(ctx, base);
	// lwz r11,220(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 220);
	// li r29,0
	ctx.r29.s64 = 0;
	// lwz r26,228(r31)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r31.u32 + 228);
	// lwz r27,224(r31)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r31.u32 + 224);
	// mullw r31,r11,r30
	ctx.r31.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r30.s32);
loc_821236DC:
	// cmplw cr6,r31,r26
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, ctx.r26.u32, ctx.xer);
	// mr r30,r31
	ctx.r30.u64 = ctx.r31.u64;
	// blt cr6,0x821236ec
	if (ctx.cr6.lt) goto loc_821236EC;
	// mr r30,r26
	ctx.r30.u64 = ctx.r26.u64;
loc_821236EC:
	// rlwinm r11,r30,1,0,30
	ctx.r11.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 1) & 0xFFFFFFFE;
	// li r6,0
	ctx.r6.s64 = 0;
	// add r7,r30,r11
	ctx.r7.u64 = ctx.r30.u64 + ctx.r11.u64;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8222e3e0
	ctx.lr = 0x82123708;
	sub_8222E3E0(ctx, base);
	// subf. r31,r30,r31
	ctx.r31.s64 = ctx.r31.s64 - ctx.r30.s64;
	ctx.cr0.compare<int32_t>(ctx.r31.s32, 0, ctx.xer);
	// add r29,r29,r27
	ctx.r29.u64 = ctx.r29.u64 + ctx.r27.u64;
	// bne 0x821236dc
	if (!ctx.cr0.eq) goto loc_821236DC;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_8212371C:
	// addi r5,r31,112
	ctx.r5.s64 = ctx.r31.s64 + 112;
	// bl 0x8222cc48
	ctx.lr = 0x82123724;
	sub_8222CC48(ctx, base);
	// rlwinm r6,r29,2,0,29
	ctx.r6.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,13
	ctx.r4.s64 = 13;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x82123738;
	sub_8222DFC8(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82123740"))) PPC_WEAK_FUNC(sub_82123740);
PPC_FUNC_IMPL(__imp__sub_82123740) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,4(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// addi r5,r4,112
	ctx.r5.s64 = ctx.r4.s64 + 112;
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// li r7,28
	ctx.r7.s64 = 28;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222cc48
	ctx.lr = 0x82123778;
	sub_8222CC48(ctx, base);
	// rlwinm r11,r31,1,0,30
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 1) & 0xFFFFFFFE;
	// li r5,0
	ctx.r5.s64 = 0;
	// add r6,r31,r11
	ctx.r6.u64 = ctx.r31.u64 + ctx.r11.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x82123790;
	sub_8222DFC8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821237A8"))) PPC_WEAK_FUNC(sub_821237A8);
PPC_FUNC_IMPL(__imp__sub_821237A8) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x821237B0;
	__restfpr_26(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,44
	ctx.r11.s64 = 2883584;
	// lis r10,24
	ctx.r10.s64 = 1572864;
	// ori r31,r11,9125
	ctx.r31.u64 = ctx.r11.u64 | 9125;
	// ori r30,r10,10374
	ctx.r30.u64 = ctx.r10.u64 | 10374;
	// li r27,0
	ctx.r27.s64 = 0;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// li r26,10
	ctx.r26.s64 = 10;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// stb r27,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, ctx.r27.u8);
	// li r4,3
	ctx.r4.s64 = 3;
	// stb r26,101(r1)
	PPC_STORE_U8(ctx.r1.u32 + 101, ctx.r26.u8);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x821160a8
	ctx.lr = 0x821237E8;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x821237EC;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82123818
	if (ctx.cr6.eq) goto loc_82123818;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,21048
	ctx.r6.s64 = ctx.r11.s64 + 21048;
	// addi r5,r10,21288
	ctx.r5.s64 = ctx.r10.s64 + 21288;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212380C;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25840(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25840, ctx.r3.u32);
	// b 0x82123824
	goto loc_82123824;
loc_82123818:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,25840(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25840, ctx.r27.u32);
loc_82123824:
	// li r28,5
	ctx.r28.s64 = 5;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// stb r27,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, ctx.r27.u8);
	// li r4,5
	ctx.r4.s64 = 5;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stb r26,101(r1)
	PPC_STORE_U8(ctx.r1.u32 + 101, ctx.r26.u8);
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r31.u32);
	// stb r28,113(r1)
	PPC_STORE_U8(ctx.r1.u32 + 113, ctx.r28.u8);
	// stw r31,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r31.u32);
	// stb r28,125(r1)
	PPC_STORE_U8(ctx.r1.u32 + 125, ctx.r28.u8);
	// bl 0x821160a8
	ctx.lr = 0x82123854;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x82123858;
	sub_82116360(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r29,r11,21912
	ctx.r29.s64 = ctx.r11.s64 + 21912;
	// beq cr6,0x82123888
	if (ctx.cr6.eq) goto loc_82123888;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r6,r11,21608
	ctx.r6.s64 = ctx.r11.s64 + 21608;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212387C;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25844(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25844, ctx.r3.u32);
	// b 0x82123894
	goto loc_82123894;
loc_82123888:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,25844(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25844, ctx.r27.u32);
loc_82123894:
	// bl 0x82116360
	ctx.lr = 0x82123898;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821238c0
	if (ctx.cr6.eq) goto loc_821238C0;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r6,r11,22256
	ctx.r6.s64 = ctx.r11.s64 + 22256;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x821238B4;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25856(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25856, ctx.r3.u32);
	// b 0x821238cc
	goto loc_821238CC;
loc_821238C0:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,25856(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25856, ctx.r27.u32);
loc_821238CC:
	// bl 0x82116360
	ctx.lr = 0x821238D0;
	sub_82116360(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r29,r11,23168
	ctx.r29.s64 = ctx.r11.s64 + 23168;
	// beq cr6,0x82123900
	if (ctx.cr6.eq) goto loc_82123900;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r6,r11,22792
	ctx.r6.s64 = ctx.r11.s64 + 22792;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x821238F4;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25852(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25852, ctx.r3.u32);
	// b 0x8212390c
	goto loc_8212390C;
loc_82123900:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,25852(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25852, ctx.r27.u32);
loc_8212390C:
	// bl 0x82116360
	ctx.lr = 0x82123910;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82123938
	if (ctx.cr6.eq) goto loc_82123938;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// addi r6,r11,23560
	ctx.r6.s64 = ctx.r11.s64 + 23560;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x8212392C;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25868(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25868, ctx.r3.u32);
	// b 0x82123944
	goto loc_82123944;
loc_82123938:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,25868(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25868, ctx.r27.u32);
loc_82123944:
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r31.u32);
	// li r4,4
	ctx.r4.s64 = 4;
	// stb r27,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, ctx.r27.u8);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r30.u32);
	// stb r26,101(r1)
	PPC_STORE_U8(ctx.r1.u32 + 101, ctx.r26.u8);
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r31.u32);
	// stb r28,113(r1)
	PPC_STORE_U8(ctx.r1.u32 + 113, ctx.r28.u8);
	// bl 0x821160a8
	ctx.lr = 0x82123968;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8212396C;
	sub_82116360(ctx, base);
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// addi r31,r11,24504
	ctx.r31.s64 = ctx.r11.s64 + 24504;
	// beq cr6,0x8212399c
	if (ctx.cr6.eq) goto loc_8212399C;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r6,r11,24136
	ctx.r6.s64 = ctx.r11.s64 + 24136;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x82123990;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25848(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25848, ctx.r3.u32);
	// b 0x821239a8
	goto loc_821239A8;
loc_8212399C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,25848(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25848, ctx.r27.u32);
loc_821239A8:
	// bl 0x82116360
	ctx.lr = 0x821239AC;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821239d8
	if (ctx.cr6.eq) goto loc_821239D8;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// mr r5,r31
	ctx.r5.u64 = ctx.r31.u64;
	// addi r6,r11,24848
	ctx.r6.s64 = ctx.r11.s64 + 24848;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x821239C8;
	sub_8211C770(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// stw r3,25864(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25864, ctx.r3.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
loc_821239D8:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r27
	ctx.r11.u64 = ctx.r27.u64;
	// stw r27,25864(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25864, ctx.r27.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821239EC"))) PPC_WEAK_FUNC(sub_821239EC);
PPC_FUNC_IMPL(__imp__sub_821239EC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821239F0"))) PPC_WEAK_FUNC(sub_821239F0);
PPC_FUNC_IMPL(__imp__sub_821239F0) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, ctx.r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// lwz r3,25840(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25840);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82123a18
	if (ctx.cr6.eq) goto loc_82123A18;
	// bl 0x8211af20
	ctx.lr = 0x82123A18;
	sub_8211AF20(ctx, base);
loc_82123A18:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25840(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25840, ctx.r11.u32);
	// lwz r3,25844(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25844);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82123a34
	if (ctx.cr6.eq) goto loc_82123A34;
	// bl 0x8211af20
	ctx.lr = 0x82123A34;
	sub_8211AF20(ctx, base);
loc_82123A34:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25844(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25844, ctx.r11.u32);
	// lwz r3,25852(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25852);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82123a50
	if (ctx.cr6.eq) goto loc_82123A50;
	// bl 0x8211af20
	ctx.lr = 0x82123A50;
	sub_8211AF20(ctx, base);
loc_82123A50:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25852(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25852, ctx.r11.u32);
	// lwz r3,25848(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25848);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82123a6c
	if (ctx.cr6.eq) goto loc_82123A6C;
	// bl 0x8211af20
	ctx.lr = 0x82123A6C;
	sub_8211AF20(ctx, base);
loc_82123A6C:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25848(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25848, ctx.r11.u32);
	// lwz r3,25856(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25856);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82123a88
	if (ctx.cr6.eq) goto loc_82123A88;
	// bl 0x8211af20
	ctx.lr = 0x82123A88;
	sub_8211AF20(ctx, base);
loc_82123A88:
	// lis r30,-32178
	ctx.r30.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25856(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25856, ctx.r11.u32);
	// lwz r3,25860(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 25860);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82123aa4
	if (ctx.cr6.eq) goto loc_82123AA4;
	// bl 0x8211af20
	ctx.lr = 0x82123AA4;
	sub_8211AF20(ctx, base);
loc_82123AA4:
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25860(r30)
	PPC_STORE_U32(ctx.r30.u32 + 25860, ctx.r11.u32);
	// lwz r3,25864(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25864);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82123ac0
	if (ctx.cr6.eq) goto loc_82123AC0;
	// bl 0x8211af20
	ctx.lr = 0x82123AC0;
	sub_8211AF20(ctx, base);
loc_82123AC0:
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,25864(r31)
	PPC_STORE_U32(ctx.r31.u32 + 25864, ctx.r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// ld r30,-24(r1)
	ctx.r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	ctx.r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82123AE0"))) PPC_WEAK_FUNC(sub_82123AE0);
PPC_FUNC_IMPL(__imp__sub_82123AE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r10,44(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 44);
	// mr r11,r4
	ctx.r11.u64 = ctx.r4.u64;
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82123b90
	if (ctx.cr6.eq) goto loc_82123B90;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lfs f12,20(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// lfs f13,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f12,f13
	ctx.cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// beq cr6,0x82123b90
	if (ctx.cr6.eq) goto loc_82123B90;
	// lfs f0,24(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	ctx.cr6.compare(ctx.f0.f64, ctx.f13.f64);
	// beq cr6,0x82123b90
	if (ctx.cr6.eq) goto loc_82123B90;
	// lfs f13,12(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lfs f11,16(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// fadds f12,f13,f12
	ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// fadds f9,f11,f0
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// fctiwz f10,f13
	ctx.f10.u64 = uint64_t(int32_t(std::trunc(ctx.f13.f64)));
	// stfd f10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f10.u64);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// fctiwz f8,f11
	ctx.f8.u64 = uint64_t(int32_t(std::trunc(ctx.f11.f64)));
	// stfd f8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f8.u64);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// fctiwz f7,f12
	ctx.f7.u64 = uint64_t(int32_t(std::trunc(ctx.f12.f64)));
	// stfd f7,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f7.u64);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// fctiwz f6,f9
	ctx.f6.u64 = uint64_t(int32_t(std::trunc(ctx.f9.f64)));
	// stfd f6,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f6.u64);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// stw r9,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r9.u32);
	// stw r8,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r8.u32);
	// bl 0x8222cad0
	ctx.lr = 0x82123B7C;
	sub_8222CAD0(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
loc_82123B90:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82123BA4"))) PPC_WEAK_FUNC(sub_82123BA4);
PPC_FUNC_IMPL(__imp__sub_82123BA4) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82123BA8"))) PPC_WEAK_FUNC(sub_82123BA8);
PPC_FUNC_IMPL(__imp__sub_82123BA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x82123BB0;
	__restfpr_29(ctx, base);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// bl 0x82123ae0
	ctx.lr = 0x82123BC0;
	sub_82123AE0(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82123bd8
	if (!ctx.cr6.eq) goto loc_82123BD8;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
loc_82123BD8:
	// lbz r11,48(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 48);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82123d68
	if (ctx.cr6.eq) goto loc_82123D68;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// lwz r10,52(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// lfs f0,28(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 28);
	ctx.f0.f64 = double(temp.f32);
	// addi r29,r11,-27800
	ctx.r29.s64 = ctx.r11.s64 + -27800;
	// lwz r8,60(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	// lwz r7,64(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	// lfs f13,32(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,36(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	ctx.f12.f64 = double(temp.f32);
	// lwz r30,0(r30)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// lfs f11,40(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	ctx.f11.f64 = double(temp.f32);
	// fadds f10,f12,f0
	ctx.f10.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fadds f9,f11,f13
	ctx.f9.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lwz r11,2120(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2120);
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stw r9,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r9.u32);
	// stfs f10,92(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stw r8,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r8.u32);
	// stfs f10,104(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stw r7,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r7.u32);
	// stfs f9,108(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// cmpwi cr6,r11,8192
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 8192, ctx.xer);
	// stfs f9,120(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// beq cr6,0x82123cc4
	if (ctx.cr6.eq) goto loc_82123CC4;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82123C60;
	sub_821112B0(ctx, base);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// li r11,12545
	ctx.r11.s64 = 12545;
	// addi r9,r10,28184
	ctx.r9.s64 = ctx.r10.s64 + 28184;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,100
	ctx.r3.s64 = 100;
	// stw r11,288(r9)
	PPC_STORE_U32(ctx.r9.u32 + 288, ctx.r11.u32);
	// bl 0x82111340
	ctx.lr = 0x82123C7C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82111340
	ctx.lr = 0x82123C88;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x82123C94;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x82123CA0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x82123CAC;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x82123CB8;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x82111340
	ctx.lr = 0x82123CC4;
	sub_82111340(ctx, base);
loc_82123CC4:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82123CD0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x82123CDC;
	sub_82111400(ctx, base);
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r11,25840(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25840);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r30)
	PPC_STORE_U32(ctx.r30.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r30)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r30.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r30)
	PPC_STORE_U64(ctx.r30.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82123D04;
	sub_82238728(ctx, base);
	// lwz r11,25840(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25840);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82123D14;
	sub_82238380(ctx, base);
	// li r6,12
	ctx.r6.s64 = 12;
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,13
	ctx.r4.s64 = 13;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8222d600
	ctx.lr = 0x82123D28;
	sub_8222D600(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82123d44
	if (ctx.cr6.eq) goto loc_82123D44;
	// li r5,48
	ctx.r5.s64 = 48;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8233e4e0
	ctx.lr = 0x82123D3C;
	sub_8233E4E0(ctx, base);
	// lwz r11,13828(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 13828);
	// stw r11,48(r30)
	PPC_STORE_U32(ctx.r30.u32 + 48, ctx.r11.u32);
loc_82123D44:
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82123D50;
	sub_82111340(ctx, base);
	// lwz r11,2120(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2120);
	// cmpwi cr6,r11,8192
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 8192, ctx.xer);
	// beq cr6,0x82123d68
	if (ctx.cr6.eq) goto loc_82123D68;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82123D68;
	sub_821112B0(ctx, base);
loc_82123D68:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82123D74"))) PPC_WEAK_FUNC(sub_82123D74);
PPC_FUNC_IMPL(__imp__sub_82123D74) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82123D78"))) PPC_WEAK_FUNC(sub_82123D78);
PPC_FUNC_IMPL(__imp__sub_82123D78) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e44c
	ctx.lr = 0x82123D80;
	__restfpr_21(ctx, base);
	// stfd f30,-112(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -112, ctx.f30.u64);
	// stfd f31,-104(r1)
	PPC_STORE_U64(ctx.r1.u32 + -104, ctx.f31.u64);
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// bl 0x82123ae0
	ctx.lr = 0x82123D98;
	sub_82123AE0(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82123db8
	if (!ctx.cr6.eq) goto loc_82123DB8;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// lfd f30,-112(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// lfd f31,-104(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
loc_82123DB8:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lbz r10,160(r30)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r30.u32 + 160);
	// lfs f13,32(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// li r9,2
	ctx.r9.s64 = 2;
	// addi r8,r11,31376
	ctx.r8.s64 = ctx.r11.s64 + 31376;
	// lfs f12,40(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// addic r7,r10,-1
	ctx.xer.ca = ctx.r10.u32 > 0;
	ctx.r7.s64 = ctx.r10.s64 + -1;
	// lfs f0,28(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	ctx.f0.f64 = double(temp.f32);
	// lfs f10,36(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	ctx.f10.f64 = double(temp.f32);
	// fadds f11,f12,f13
	ctx.f11.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f13,92(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// subfe r5,r6,r6
	temp.u8 = (~ctx.r6.u32 + ctx.r6.u32 < ~ctx.r6.u32) | (~ctx.r6.u32 + ctx.r6.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r5.u64 = ~ctx.r6.u64 + ctx.r6.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f12,f10,f0
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f0.f64));
	// lfs f1,156(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 156);
	ctx.f1.f64 = double(temp.f32);
	// lwz r28,0(r31)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// lfs f13,48(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// and r27,r5,r9
	ctx.r27.u64 = ctx.r5.u64 & ctx.r9.u64;
	// stfs f0,88(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fcmpu cr6,f1,f13
	ctx.cr6.compare(ctx.f1.f64, ctx.f13.f64);
	// stfs f0,112(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f12,96(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f12,104(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f11,108(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f11,116(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// beq cr6,0x82123ea0
	if (ctx.cr6.eq) goto loc_82123EA0;
	// lfs f0,148(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 148);
	ctx.f0.f64 = double(temp.f32);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lfs f13,152(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 152);
	ctx.f13.f64 = double(temp.f32);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r11,r30,148
	ctx.r11.s64 = ctx.r30.s64 + 148;
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// bl 0x82183938
	ctx.lr = 0x82123E40;
	sub_82183938(ctx, base);
	// lfs f12,148(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 148);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,152(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 152);
	ctx.f11.f64 = double(temp.f32);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stfs f11,84(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f1,156(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 156);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82183938
	ctx.lr = 0x82123E60;
	sub_82183938(ctx, base);
	// lfs f10,148(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 148);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,152(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 152);
	ctx.f9.f64 = double(temp.f32);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stfs f10,80(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// stfs f9,84(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f1,156(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 156);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82183938
	ctx.lr = 0x82123E80;
	sub_82183938(ctx, base);
	// lfs f8,148(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 148);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,152(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 152);
	ctx.f7.f64 = double(temp.f32);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stfs f8,80(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// stfs f7,84(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f1,156(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 156);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82183938
	ctx.lr = 0x82123EA0;
	sub_82183938(ctx, base);
loc_82123EA0:
	// lwz r9,84(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 84);
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// lwz r8,88(r30)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// lwz r7,92(r30)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r30.u32 + 92);
	// lfs f0,52(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	ctx.f0.f64 = double(temp.f32);
	// lwz r6,96(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 96);
	// lfs f13,56(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// lwz r3,48(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// lfs f12,60(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,64(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 64);
	ctx.f11.f64 = double(temp.f32);
	// li r25,1
	ctx.r25.s64 = 1;
	// lfs f10,68(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 68);
	ctx.f10.f64 = double(temp.f32);
	// lis r23,-32178
	ctx.r23.s64 = -2108817408;
	// lfs f9,72(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 72);
	ctx.f9.f64 = double(temp.f32);
	// lis r26,-32178
	ctx.r26.s64 = -2108817408;
	// lfs f8,76(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 76);
	ctx.f8.f64 = double(temp.f32);
	// lis r21,-32178
	ctx.r21.s64 = -2108817408;
	// lfs f7,80(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 80);
	ctx.f7.f64 = double(temp.f32);
	// lis r22,-32178
	ctx.r22.s64 = -2108817408;
	// lfs f6,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f6.f64 = double(temp.f32);
	// stw r9,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r9.u32);
	// lfs f5,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f5.f64 = double(temp.f32);
	// stw r8,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r8.u32);
	// lfs f4,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f4.f64 = double(temp.f32);
	// stw r7,192(r1)
	PPC_STORE_U32(ctx.r1.u32 + 192, ctx.r7.u32);
	// lfs f3,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f3.f64 = double(temp.f32);
	// stw r6,220(r1)
	PPC_STORE_U32(ctx.r1.u32 + 220, ctx.r6.u32);
	// lfs f2,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f2.f64 = double(temp.f32);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// lfs f1,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f1.f64 = double(temp.f32);
	// addi r24,r11,-27800
	ctx.r24.s64 = ctx.r11.s64 + -27800;
	// lfs f31,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f31.f64 = double(temp.f32);
	// addi r31,r10,28184
	ctx.r31.s64 = ctx.r10.s64 + 28184;
	// lfs f30,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f30.f64 = double(temp.f32);
	// stfs f0,140(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// stfs f13,144(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f12,168(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// stfs f11,172(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// stfs f6,128(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f10,196(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// stfs f9,200(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// stfs f5,132(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stfs f8,224(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// stfs f4,156(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// stfs f7,228(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// stfs f3,160(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// stfs f2,184(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// stfs f1,188(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// stfs f31,212(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// stfs f30,216(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// beq cr6,0x82124388
	if (ctx.cr6.eq) goto loc_82124388;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82172e00
	ctx.lr = 0x82123F78;
	sub_82172E00(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82124388
	if (ctx.cr6.eq) goto loc_82124388;
	// lwz r11,48(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82123f9c
	if (ctx.cr6.eq) goto loc_82123F9C;
	// bl 0x820b91d0
	ctx.lr = 0x82123F98;
	sub_820B91D0(ctx, base);
	// b 0x82123fb8
	goto loc_82123FB8;
loc_82123F9C:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82123fb0
	if (ctx.cr6.eq) goto loc_82123FB0;
	// lwz r29,88(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x82123fbc
	goto loc_82123FBC;
loc_82123FB0:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x82123FB8;
	sub_820B90A0(ctx, base);
loc_82123FB8:
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
loc_82123FBC:
	// cmplwi cr6,r29,0
	ctx.cr6.compare<uint32_t>(ctx.r29.u32, 0, ctx.xer);
	// beq cr6,0x82124388
	if (ctx.cr6.eq) goto loc_82124388;
	// lwz r11,2120(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2120);
	// cmpwi cr6,r11,8192
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 8192, ctx.xer);
	// beq cr6,0x82124038
	if (ctx.cr6.eq) goto loc_82124038;
	// li r11,12545
	ctx.r11.s64 = 12545;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r11,288(r31)
	PPC_STORE_U32(ctx.r31.u32 + 288, ctx.r11.u32);
	// li r3,100
	ctx.r3.s64 = 100;
	// bl 0x82111340
	ctx.lr = 0x82123FE4;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82111340
	ctx.lr = 0x82123FF0;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x82123FFC;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x82124008;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x82124014;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x82124020;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x82111340
	ctx.lr = 0x8212402C;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82124038;
	sub_821112B0(ctx, base);
loc_82124038:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82124044;
	sub_82111340(ctx, base);
	// lbz r11,52(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 52);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r4,r10,27,31,31
	ctx.r4.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// bl 0x8211a568
	ctx.lr = 0x82124058;
	sub_8211A568(ctx, base);
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82124088
	if (ctx.cr6.eq) goto loc_82124088;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// lwz r9,1152(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r9,r27,10,19,21
	ctx.r9.u64 = (rotl32(ctx.r27.u32, 10) & 0x1C00) | (ctx.r9.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r9,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r9.u32);
	// ld r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r7,r8,32768
	ctx.r7.u64 = ctx.r8.u64 | 2147483648;
	// std r7,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r7.u64);
	// stw r27,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r27.u32);
loc_82124088:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x821240b8
	if (ctx.cr6.eq) goto loc_821240B8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// lwz r9,1152(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r9,r27,13,16,18
	ctx.r9.u64 = (rotl32(ctx.r27.u32, 13) & 0xE000) | (ctx.r9.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r9,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r9.u32);
	// ld r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r7,r8,32768
	ctx.r7.u64 = ctx.r8.u64 | 2147483648;
	// std r7,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r7.u64);
	// stw r27,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r27.u32);
loc_821240B8:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821240dc
	if (ctx.cr6.eq) goto loc_821240DC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x821240D4;
	sub_8222C248(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r25,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r25.u32);
loc_821240DC:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82124100
	if (ctx.cr6.eq) goto loc_82124100;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x821240F8;
	sub_8222C0A0(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r25,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r25.u32);
loc_82124100:
	// lwz r11,20(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// lwz r10,2068(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// subfic r9,r11,1
	ctx.xer.ca = ctx.r11.u32 <= 1;
	ctx.r9.s64 = 1 - ctx.r11.s64;
	// subfe r11,r9,r9
	temp.u8 = (~ctx.r9.u32 + ctx.r9.u32 < ~ctx.r9.u32) | (~ctx.r9.u32 + ctx.r9.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r9.u64 + ctx.r9.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82124140
	if (ctx.cr6.eq) goto loc_82124140;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// lwz r8,1164(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1164);
	// rlwimi r8,r11,23,7,8
	ctx.r8.u64 = (rotl32(ctx.r11.u32, 23) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1164(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1164, ctx.r8.u32);
	// ld r7,24(r10)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r6.u64);
	// stw r11,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r11.u32);
loc_82124140:
	// lwz r3,100(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 100);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82124304
	if (ctx.cr6.eq) goto loc_82124304;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82172e00
	ctx.lr = 0x82124154;
	sub_82172E00(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82124304
	if (ctx.cr6.eq) goto loc_82124304;
	// lwz r11,100(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 100);
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82124178
	if (ctx.cr6.eq) goto loc_82124178;
	// bl 0x820b91d0
	ctx.lr = 0x82124174;
	sub_820B91D0(ctx, base);
	// b 0x82124194
	goto loc_82124194;
loc_82124178:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212418c
	if (ctx.cr6.eq) goto loc_8212418C;
	// lwz r11,88(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x82124198
	goto loc_82124198;
loc_8212418C:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x82124194;
	sub_820B90A0(ctx, base);
loc_82124194:
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82124198:
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,104(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 104);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,108(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lfs f12,112(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 112);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,116(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 116);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,120(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 120);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,124(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 124);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,128(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 128);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,132(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 132);
	ctx.f7.f64 = double(temp.f32);
	// stfs f0,148(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f13,152(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// stfs f12,176(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// stfs f11,180(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// stfs f10,204(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// stfs f9,208(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// stfs f8,232(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// stfs f7,236(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// bl 0x82111400
	ctx.lr = 0x821241E4;
	sub_82111400(ctx, base);
	// lwz r11,2292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2292);
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82124214
	if (ctx.cr6.eq) goto loc_82124214;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// lwz r9,1176(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r9,r27,10,19,21
	ctx.r9.u64 = (rotl32(ctx.r27.u32, 10) & 0x1C00) | (ctx.r9.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r9,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r9.u32);
	// ld r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r7,r8,16384
	ctx.r7.u64 = ctx.r8.u64 | 1073741824;
	// std r7,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r7.u64);
	// stw r27,2292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2292, ctx.r27.u32);
loc_82124214:
	// lwz r11,2308(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2308);
	// cmplw cr6,r11,r27
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r27.u32, ctx.xer);
	// beq cr6,0x82124244
	if (ctx.cr6.eq) goto loc_82124244;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// lwz r9,1176(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1176);
	// rlwimi r9,r27,13,16,18
	ctx.r9.u64 = (rotl32(ctx.r27.u32, 13) & 0xE000) | (ctx.r9.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r9,1176(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1176, ctx.r9.u32);
	// ld r8,24(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r7,r8,16384
	ctx.r7.u64 = ctx.r8.u64 | 1073741824;
	// std r7,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r7.u64);
	// stw r27,2308(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2308, ctx.r27.u32);
loc_82124244:
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82124268
	if (ctx.cr6.eq) goto loc_82124268;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x82124260;
	sub_8222C248(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r25,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r25.u32);
loc_82124268:
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212428c
	if (ctx.cr6.eq) goto loc_8212428C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x82124284;
	sub_8222C0A0(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r25,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r25.u32);
loc_8212428C:
	// lwz r11,2388(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2388);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x821242c0
	if (ctx.cr6.eq) goto loc_821242C0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// lwz r9,1164(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r9,r25,24,7,8
	ctx.r9.u64 = (rotl32(ctx.r25.u32, 24) & 0x1800000) | (ctx.r9.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r9,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r9.u32);
	// ld r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// oris r7,r8,16384
	ctx.r7.u64 = ctx.r8.u64 | 1073741824;
	// std r7,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r7.u64);
	// stw r10,2388(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2388, ctx.r10.u32);
loc_821242C0:
	// lwz r11,25852(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 25852);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r28)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r28.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r28)
	PPC_STORE_U64(ctx.r28.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x821242E4;
	sub_82238728(ctx, base);
	// lbz r7,52(r29)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r29.u32 + 52);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x821242fc
	if (ctx.cr6.eq) goto loc_821242FC;
	// lwz r11,25852(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 25852);
	// b 0x82124350
	goto loc_82124350;
loc_821242FC:
	// lwz r11,25868(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 25868);
	// b 0x82124350
	goto loc_82124350;
loc_82124304:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111400
	ctx.lr = 0x82124310;
	sub_82111400(ctx, base);
	// lwz r11,25844(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 25844);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r28)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r28.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r28)
	PPC_STORE_U64(ctx.r28.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82124334;
	sub_82238728(ctx, base);
	// lbz r7,52(r29)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r29.u32 + 52);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// beq cr6,0x8212434c
	if (ctx.cr6.eq) goto loc_8212434C;
	// lwz r11,25844(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 25844);
	// b 0x82124350
	goto loc_82124350;
loc_8212434C:
	// lwz r11,25856(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 25856);
loc_82124350:
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82124358;
	sub_82238380(ctx, base);
	// li r6,28
	ctx.r6.s64 = 28;
	// li r5,4
	ctx.r5.s64 = 4;
	// li r4,13
	ctx.r4.s64 = 13;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8222d600
	ctx.lr = 0x8212436C;
	sub_8222D600(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82124388
	if (ctx.cr6.eq) goto loc_82124388;
	// li r5,112
	ctx.r5.s64 = 112;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x8233e4e0
	ctx.lr = 0x82124380;
	sub_8233E4E0(ctx, base);
	// lwz r11,13828(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13828);
	// stw r11,48(r28)
	PPC_STORE_U32(ctx.r28.u32 + 48, ctx.r11.u32);
loc_82124388:
	// lwz r11,144(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 144);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821246f8
	if (ctx.cr6.eq) goto loc_821246F8;
	// lwz r3,136(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 136);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821246f8
	if (ctx.cr6.eq) goto loc_821246F8;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82172e00
	ctx.lr = 0x821243A8;
	sub_82172E00(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821246f8
	if (ctx.cr6.eq) goto loc_821246F8;
	// li r11,0
	ctx.r11.s64 = 0;
	// lwz r10,144(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 144);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r11.u32);
	// mulli r29,r10,112
	ctx.r29.s64 = ctx.r10.s64 * 112;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// bl 0x8210b178
	ctx.lr = 0x821243D8;
	sub_8210B178(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r4,140(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 140);
	// bl 0x8233e4e0
	ctx.lr = 0x821243E4;
	sub_8233E4E0(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x8210b488
	ctx.lr = 0x821243EC;
	sub_8210B488(ctx, base);
	// lwz r11,136(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 136);
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82124404
	if (ctx.cr6.eq) goto loc_82124404;
	// bl 0x820b91d0
	ctx.lr = 0x82124400;
	sub_820B91D0(ctx, base);
	// b 0x82124420
	goto loc_82124420;
loc_82124404:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82124418
	if (ctx.cr6.eq) goto loc_82124418;
	// lwz r29,88(r11)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x82124424
	goto loc_82124424;
loc_82124418:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x82124420;
	sub_820B90A0(ctx, base);
loc_82124420:
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
loc_82124424:
	// lbz r11,52(r29)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r29.u32 + 52);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// cntlzw r10,r11
	ctx.r10.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// rlwinm r4,r10,27,31,31
	ctx.r4.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// bl 0x8211a568
	ctx.lr = 0x82124438;
	sub_8211A568(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111390
	ctx.lr = 0x82124448;
	sub_82111390(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111390
	ctx.lr = 0x82124458;
	sub_82111390(ctx, base);
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x8212447c
	if (ctx.cr6.eq) goto loc_8212447C;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82124474;
	sub_8222C248(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r25,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r25.u32);
loc_8212447C:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821244a0
	if (ctx.cr6.eq) goto loc_821244A0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82124498;
	sub_8222C0A0(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r25,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r25.u32);
loc_821244A0:
	// lwz r11,20(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 20);
	// lwz r10,2068(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// subfic r9,r11,1
	ctx.xer.ca = ctx.r11.u32 <= 1;
	ctx.r9.s64 = 1 - ctx.r11.s64;
	// subfe r11,r9,r9
	temp.u8 = (~ctx.r9.u32 + ctx.r9.u32 < ~ctx.r9.u32) | (~ctx.r9.u32 + ctx.r9.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r9.u64 + ctx.r9.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x821244e0
	if (ctx.cr6.eq) goto loc_821244E0;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// lwz r8,1164(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1164);
	// rlwimi r8,r11,23,7,8
	ctx.r8.u64 = (rotl32(ctx.r11.u32, 23) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1164(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1164, ctx.r8.u32);
	// ld r7,24(r10)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r6.u64);
	// stw r11,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r11.u32);
loc_821244E0:
	// lwz r11,2120(r24)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r24.u32 + 2120);
	// cmpwi cr6,r11,8192
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 8192, ctx.xer);
	// beq cr6,0x82124504
	if (ctx.cr6.eq) goto loc_82124504;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x821244F8;
	sub_821112B0(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,12545
	ctx.r3.s64 = 12545;
	// bl 0x82113bc0
	ctx.lr = 0x82124504;
	sub_82113BC0(ctx, base);
loc_82124504:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82124510;
	sub_82111340(ctx, base);
	// lwz r3,100(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 100);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82124654
	if (ctx.cr6.eq) goto loc_82124654;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82172e00
	ctx.lr = 0x82124524;
	sub_82172E00(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82124654
	if (ctx.cr6.eq) goto loc_82124654;
	// lwz r11,100(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 100);
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82124548
	if (ctx.cr6.eq) goto loc_82124548;
	// bl 0x820b91d0
	ctx.lr = 0x82124544;
	sub_820B91D0(ctx, base);
	// b 0x82124564
	goto loc_82124564;
loc_82124548:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x8212455c
	if (ctx.cr6.eq) goto loc_8212455C;
	// lwz r11,88(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x82124568
	goto loc_82124568;
loc_8212455C:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x82124564;
	sub_820B90A0(ctx, base);
loc_82124564:
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
loc_82124568:
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// bl 0x82111400
	ctx.lr = 0x82124574;
	sub_82111400(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111390
	ctx.lr = 0x82124584;
	sub_82111390(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = ctx.r27.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111390
	ctx.lr = 0x82124594;
	sub_82111390(ctx, base);
	// lwz r11,2356(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2356);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821245b8
	if (ctx.cr6.eq) goto loc_821245B8;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c248
	ctx.lr = 0x821245B0;
	sub_8222C248(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r25,2356(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2356, ctx.r25.u32);
loc_821245B8:
	// lwz r11,2372(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2372);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821245dc
	if (ctx.cr6.eq) goto loc_821245DC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8222c0a0
	ctx.lr = 0x821245D4;
	sub_8222C0A0(ctx, base);
	// mr r11,r25
	ctx.r11.u64 = ctx.r25.u64;
	// stw r25,2372(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2372, ctx.r25.u32);
loc_821245DC:
	// lwz r11,2388(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2388);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82124610
	if (ctx.cr6.eq) goto loc_82124610;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// lwz r9,1164(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r9,r25,24,7,8
	ctx.r9.u64 = (rotl32(ctx.r25.u32, 24) & 0x1800000) | (ctx.r9.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r9,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r9.u32);
	// ld r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 0);
	// oris r7,r8,16384
	ctx.r7.u64 = ctx.r8.u64 | 1073741824;
	// std r7,0(r11)
	PPC_STORE_U64(ctx.r11.u32 + 0, ctx.r7.u64);
	// stw r10,2388(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2388, ctx.r10.u32);
loc_82124610:
	// lwz r11,25852(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 25852);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r28)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r28.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r28)
	PPC_STORE_U64(ctx.r28.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82124634;
	sub_82238728(ctx, base);
	// lbz r7,52(r29)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r29.u32 + 52);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// beq cr6,0x8212464c
	if (ctx.cr6.eq) goto loc_8212464C;
	// lwz r11,25852(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 25852);
	// b 0x821246a0
	goto loc_821246A0;
loc_8212464C:
	// lwz r11,25868(r21)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r21.u32 + 25868);
	// b 0x821246a0
	goto loc_821246A0;
loc_82124654:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82111400
	ctx.lr = 0x82124660;
	sub_82111400(ctx, base);
	// lwz r11,25844(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 25844);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r28)
	PPC_STORE_U32(ctx.r28.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r28)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r28.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r28)
	PPC_STORE_U64(ctx.r28.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82124684;
	sub_82238728(ctx, base);
	// lbz r7,52(r29)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r29.u32 + 52);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// beq cr6,0x8212469c
	if (ctx.cr6.eq) goto loc_8212469C;
	// lwz r11,25844(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 25844);
	// b 0x821246a0
	goto loc_821246A0;
loc_8212469C:
	// lwz r11,25856(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 25856);
loc_821246A0:
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x821246A8;
	sub_82238380(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r6,96(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r7,28
	ctx.r7.s64 = 28;
	// lwz r5,88(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8222cc48
	ctx.lr = 0x821246C4;
	sub_8222CC48(ctx, base);
	// lwz r11,144(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 144);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,13
	ctx.r4.s64 = 13;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// rlwinm r6,r11,2,0,29
	ctx.r6.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8222dfc8
	ctx.lr = 0x821246DC;
	sub_8222DFC8(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8222cc48
	ctx.lr = 0x821246F8;
	sub_8222CC48(ctx, base);
loc_821246F8:
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82124704;
	sub_82111340(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// lfd f30,-112(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// lfd f31,-104(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// b 0x8233e49c
	__restgprlr_21(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82124718"))) PPC_WEAK_FUNC(sub_82124718);
PPC_FUNC_IMPL(__imp__sub_82124718) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82124720;
	__restfpr_27(ctx, base);
	// stfd f30,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, ctx.f30.u64);
	// stfd f31,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, ctx.f31.u64);
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// mr r29,r5
	ctx.r29.u64 = ctx.r5.u64;
	// bl 0x82123ae0
	ctx.lr = 0x8212473C;
	sub_82123AE0(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212475c
	if (!ctx.cr6.eq) goto loc_8212475C;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// lfd f30,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f31,-56(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
loc_8212475C:
	// lwz r28,0(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// li r9,6
	ctx.r9.s64 = 6;
	// addi r11,r1,144
	ctx.r11.s64 = ctx.r1.s64 + 144;
	// addi r8,r1,112
	ctx.r8.s64 = ctx.r1.s64 + 112;
	// addi r10,r11,-4
	ctx.r10.s64 = ctx.r11.s64 + -4;
	// addi r11,r8,-4
	ctx.r11.s64 = ctx.r8.s64 + -4;
	// lfs f0,13008(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13008);
	ctx.f0.f64 = double(temp.f32);
	// mtctr r9
	ctx.ctr.u64 = ctx.r9.u64;
	// lfs f13,13012(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13012);
	ctx.f13.f64 = double(temp.f32);
	// fctidz f12,f0
	ctx.f12.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// lfs f11,13000(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13000);
	ctx.f11.f64 = double(temp.f32);
	// fctidz f10,f13
	ctx.f10.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// lfs f8,13004(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13004);
	ctx.f8.f64 = double(temp.f32);
	// fctidz f9,f11
	ctx.f9.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// stfd f12,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f12.u64);
	// lwz r9,92(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// stfd f10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f10.u64);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f9,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f9.u64);
	// stfd f7,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f7.u64);
	// lwz r7,92(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r6,84(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lfs f6,13016(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13016);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,13020(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 13020);
	ctx.f5.f64 = double(temp.f32);
	// stw r9,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r9.u32);
	// stfs f6,128(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stw r8,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r8.u32);
	// stfs f5,132(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stw r7,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r7.u32);
	// stw r6,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r6.u32);
loc_821247D8:
	// lwzu r9,4(r11)
	ea = 4 + ctx.r11.u32;
	ctx.r9.u64 = PPC_LOAD_U32(ea);
	ctx.r11.u32 = ea;
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// bdnz 0x821247d8
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_821247D8;
	// lis r11,-32182
	ctx.r11.s64 = -2109079552;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// addi r27,r11,-27800
	ctx.r27.s64 = ctx.r11.s64 + -27800;
	// addi r30,r10,31376
	ctx.r30.s64 = ctx.r10.s64 + 31376;
	// lwz r11,2120(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 2120);
	// lfs f30,36(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	ctx.f30.f64 = double(temp.f32);
	// cmpwi cr6,r11,8192
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 8192, ctx.xer);
	// beq cr6,0x82124840
	if (ctx.cr6.eq) goto loc_82124840;
	// clrldi r11,r29,32
	ctx.r11.u64 = ctx.r29.u64 & 0xFFFFFFFF;
	// lwz r9,76(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 76);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r11.u64);
	// lfd f0,80(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f0
	ctx.f13.f64 = double(ctx.f0.s64);
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lfd f12,80(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// frsp f11,f13
	ctx.f11.f64 = double(float(ctx.f13.f64));
	// fcfid f10,f12
	ctx.f10.f64 = double(ctx.f12.s64);
	// fdivs f9,f30,f11
	ctx.f9.f64 = double(float(ctx.f30.f64 / ctx.f11.f64));
	// frsp f8,f10
	ctx.f8.f64 = double(float(ctx.f10.f64));
	// fmuls f0,f8,f9
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f9.f64));
	// stfs f0,164(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// fadds f7,f0,f9
	ctx.f7.f64 = double(float(ctx.f0.f64 + ctx.f9.f64));
	// stfs f7,160(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
loc_82124840:
	// lfs f13,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// lfs f8,12(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 12);
	ctx.f8.f64 = double(temp.f32);
	// fctidz f10,f13
	ctx.f10.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f10,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.f10.u64);
	// stfd f7,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f7.u64);
	// lwz r11,84(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r8,100(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lfs f11,24(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 24);
	ctx.f11.f64 = double(temp.f32);
	// fctidz f9,f11
	ctx.f9.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// stfd f9,240(r1)
	PPC_STORE_U64(ctx.r1.u32 + 240, ctx.f9.u64);
	// lfs f0,20(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 20);
	ctx.f0.f64 = double(temp.f32);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// fctidz f12,f0
	ctx.f12.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// stfd f12,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f12.u64);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r29,r31,12
	ctx.r29.s64 = ctx.r31.s64 + 12;
	// stw r10,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, ctx.r10.u32);
	// lwz r9,244(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r11.u32);
	// stw r8,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r8.u32);
	// stw r9,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r9.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x821248A0;
	sub_8222CBC8(ctx, base);
	// lis r7,-32181
	ctx.r7.s64 = -2109014016;
	// lis r6,-32179
	ctx.r6.s64 = -2108882944;
	// lfs f2,36(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	ctx.f2.f64 = double(temp.f32);
	// addi r5,r7,-26328
	ctx.r5.s64 = ctx.r7.s64 + -26328;
	// lfs f11,40(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 40);
	ctx.f11.f64 = double(temp.f32);
	// lis r4,0
	ctx.r4.s64 = 0;
	// fdivs f10,f2,f11
	ctx.f10.f64 = double(float(ctx.f2.f64 / ctx.f11.f64));
	// addi r3,r6,20000
	ctx.r3.s64 = ctx.r6.s64 + 20000;
	// lfs f0,48(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// ori r9,r4,65520
	ctx.r9.u64 = ctx.r4.u64 | 65520;
	// lfs f1,48(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	ctx.cr6.compare(ctx.f1.f64, ctx.f0.f64);
	// lwz r8,8228(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8228);
	// lfsx f13,r3,r9
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + ctx.r9.u32);
	ctx.f13.f64 = double(temp.f32);
	// std r8,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r8.u64);
	// lfd f6,96(r1)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f3,f6
	ctx.f3.f64 = double(ctx.f6.s64);
	// lwz r7,8224(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8224);
	// frsp f9,f3
	ctx.f9.f64 = double(float(ctx.f3.f64));
	// std r7,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r7.u64);
	// lfd f5,96(r1)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f4,f5
	ctx.f4.f64 = double(ctx.f5.s64);
	// frsp f12,f4
	ctx.f12.f64 = double(float(ctx.f4.f64));
	// fdivs f8,f12,f9
	ctx.f8.f64 = double(float(ctx.f12.f64 / ctx.f9.f64));
	// fdivs f7,f13,f8
	ctx.f7.f64 = double(float(ctx.f13.f64 / ctx.f8.f64));
	// fmuls f31,f7,f10
	ctx.f31.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// bne cr6,0x8212495c
	if (!ctx.cr6.eq) goto loc_8212495C;
	// fdivs f10,f30,f31
	ctx.f10.f64 = double(float(ctx.f30.f64 / ctx.f31.f64));
	// lfs f13,56(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,948(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 948);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,952(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 952);
	ctx.f11.f64 = double(temp.f32);
	// stfs f0,220(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// stfs f0,212(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// stfs f0,208(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// stfs f0,204(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// stfs f0,200(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// stfs f0,192(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// stfs f0,188(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fdivs f9,f13,f10
	ctx.f9.f64 = double(float(ctx.f13.f64 / ctx.f10.f64));
	// stfs f0,184(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// stfs f0,180(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// stfs f13,176(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// stfs f12,216(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// stfs f11,232(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// stfs f30,236(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// stfs f9,196(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// b 0x82124970
	goto loc_82124970;
loc_8212495C:
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// lfs f4,40(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,88(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	ctx.f3.f64 = double(temp.f32);
	// fmr f2,f31
	ctx.f2.f64 = ctx.f31.f64;
	// bl 0x820b7070
	ctx.lr = 0x82124970;
	sub_820B7070(ctx, base);
loc_82124970:
	// lfs f0,64(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	ctx.f0.f64 = double(temp.f32);
	// mr r9,r29
	ctx.r9.u64 = ctx.r29.u64;
	// lfs f13,68(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	ctx.f13.f64 = double(temp.f32);
	// addi r8,r31,28
	ctx.r8.s64 = ctx.r31.s64 + 28;
	// stfs f0,224(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// addi r7,r31,52
	ctx.r7.s64 = ctx.r31.s64 + 52;
	// stfs f13,228(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// fmr f1,f31
	ctx.f1.f64 = ctx.f31.f64;
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// bl 0x8217c308
	ctx.lr = 0x821249A0;
	sub_8217C308(ctx, base);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// bl 0x821139a8
	ctx.lr = 0x821249AC;
	sub_821139A8(ctx, base);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x821229c0
	ctx.lr = 0x821249B4;
	sub_821229C0(ctx, base);
	// lwz r11,2120(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 2120);
	// cmpwi cr6,r11,8192
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 8192, ctx.xer);
	// beq cr6,0x821249d8
	if (ctx.cr6.eq) goto loc_821249D8;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,304
	ctx.r3.s64 = 304;
	// bl 0x82111340
	ctx.lr = 0x821249CC;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x821249D8;
	sub_821112B0(ctx, base);
loc_821249D8:
	// lwz r4,92(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 92);
	// addi r30,r31,92
	ctx.r30.s64 = ctx.r31.s64 + 92;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// stw r4,100(r31)
	PPC_STORE_U32(ctx.r31.u32 + 100, ctx.r4.u32);
	// beq cr6,0x82124a40
	if (ctx.cr6.eq) goto loc_82124A40;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// stw r11,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r11.u32);
loc_821249F4:
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// cmplwi cr6,r11,42
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 42, ctx.xer);
	// bne cr6,0x82124a0c
	if (!ctx.cr6.eq) goto loc_82124A0C;
	// addi r3,r27,8
	ctx.r3.s64 = ctx.r27.s64 + 8;
	// bl 0x82129148
	ctx.lr = 0x82124A08;
	sub_82129148(ctx, base);
	// b 0x82124a28
	goto loc_82124A28;
loc_82124A0C:
	// cmplwi cr6,r11,32
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 32, ctx.xer);
	// bne cr6,0x82124a20
	if (!ctx.cr6.eq) goto loc_82124A20;
	// addi r3,r27,20
	ctx.r3.s64 = ctx.r27.s64 + 20;
	// bl 0x82126710
	ctx.lr = 0x82124A1C;
	sub_82126710(ctx, base);
	// b 0x82124a28
	goto loc_82124A28;
loc_82124A20:
	// mr r3,r27
	ctx.r3.u64 = ctx.r27.u64;
	// bl 0x8211ce28
	ctx.lr = 0x82124A28;
	sub_8211CE28(ctx, base);
loc_82124A28:
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82124a40
	if (ctx.cr6.eq) goto loc_82124A40;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// stw r11,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r11.u32);
	// bne cr6,0x821249f4
	if (!ctx.cr6.eq) goto loc_821249F4;
loc_82124A40:
	// lwz r11,2120(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 2120);
	// cmpwi cr6,r11,8192
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 8192, ctx.xer);
	// beq cr6,0x82124a64
	if (ctx.cr6.eq) goto loc_82124A64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82124A58;
	sub_821112B0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,304
	ctx.r3.s64 = 304;
	// bl 0x82111340
	ctx.lr = 0x82124A64;
	sub_82111340(ctx, base);
loc_82124A64:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// bl 0x8222cbc8
	ctx.lr = 0x82124A70;
	sub_8222CBC8(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// lfd f30,-64(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f31,-56(r1)
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82124A84"))) PPC_WEAK_FUNC(sub_82124A84);
PPC_FUNC_IMPL(__imp__sub_82124A84) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82124A88"))) PPC_WEAK_FUNC(sub_82124A88);
PPC_FUNC_IMPL(__imp__sub_82124A88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x82124A90;
	__restfpr_29(ctx, base);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r31,r4
	ctx.r31.u64 = ctx.r4.u64;
	// bl 0x82123ae0
	ctx.lr = 0x82124AA0;
	sub_82123AE0(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82124ab8
	if (!ctx.cr6.eq) goto loc_82124AB8;
loc_82124AAC:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
loc_82124AB8:
	// lwz r4,56(r31)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r31.u32 + 56);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x82124aac
	if (ctx.cr6.eq) goto loc_82124AAC;
	// lbz r11,112(r31)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r31.u32 + 112);
	// addi r10,r31,116
	ctx.r10.s64 = ctx.r31.s64 + 116;
	// addi r9,r31,28
	ctx.r9.s64 = ctx.r31.s64 + 28;
	// lfs f5,108(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 108);
	ctx.f5.f64 = double(temp.f32);
	// addi r6,r31,100
	ctx.r6.s64 = ctx.r31.s64 + 100;
	// lfs f4,72(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 72);
	ctx.f4.f64 = double(temp.f32);
	// addi r5,r31,84
	ctx.r5.s64 = ctx.r31.s64 + 84;
	// lfs f3,68(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 68);
	ctx.f3.f64 = double(temp.f32);
	// addi r29,r31,76
	ctx.r29.s64 = ctx.r31.s64 + 76;
	// lwz r8,52(r31)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// lwz r7,48(r31)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r31.u32 + 48);
	// lfs f2,64(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 64);
	ctx.f2.f64 = double(temp.f32);
	// stw r10,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r10.u32);
	// lfs f1,60(r31)
	temp.u32 = PPC_LOAD_U32(ctx.r31.u32 + 60);
	ctx.f1.f64 = double(temp.f32);
	// stw r9,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r9.u32);
	// stb r11,119(r1)
	PPC_STORE_U8(ctx.r1.u32 + 119, ctx.r11.u8);
	// stw r6,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r6.u32);
	// stw r5,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r5.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// bl 0x82124b28
	ctx.lr = 0x82124B18;
	sub_82124B28(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82124B24"))) PPC_WEAK_FUNC(sub_82124B24);
PPC_FUNC_IMPL(__imp__sub_82124B24) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82124B28"))) PPC_WEAK_FUNC(sub_82124B28);
PPC_FUNC_IMPL(__imp__sub_82124B28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x82124B30;
	__restfpr_14(ctx, base);
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x8233fa00
	ctx.lr = 0x82124B38;
	sub_8233FA00(ctx, base);
	// stwu r1,-1280(r1)
	ea = -1280 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lbz r10,1399(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 1399);
	// lwz r9,116(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 116);
	// li r28,0
	ctx.r28.s64 = 0;
	// addi r30,r11,31376
	ctx.r30.s64 = ctx.r11.s64 + 31376;
	// lwz r17,0(r3)
	ctx.r17.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// stfs f5,1388(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 1388, temp.u32);
	// mr r14,r4
	ctx.r14.u64 = ctx.r4.u64;
	// fmr f30,f1
	ctx.f30.f64 = ctx.f1.f64;
	// mr r27,r7
	ctx.r27.u64 = ctx.r7.u64;
	// fmr f29,f2
	ctx.f29.f64 = ctx.f2.f64;
	// stw r7,1332(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1332, ctx.r7.u32);
	// mr r31,r8
	ctx.r31.u64 = ctx.r8.u64;
	// stw r8,1340(r1)
	PPC_STORE_U32(ctx.r1.u32 + 1340, ctx.r8.u32);
	// lfs f31,244(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 244);
	ctx.f31.f64 = double(temp.f32);
	// fmr f28,f3
	ctx.f28.f64 = ctx.f3.f64;
	// fmr f27,f4
	ctx.f27.f64 = ctx.f4.f64;
	// mr r11,r10
	ctx.r11.u64 = ctx.r10.u64;
	// fmr f26,f5
	ctx.f26.f64 = ctx.f5.f64;
	// stw r28,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r28.u32);
	// stw r28,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r28.u32);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// stw r10,268(r1)
	PPC_STORE_U32(ctx.r1.u32 + 268, ctx.r10.u32);
	// stw r9,224(r1)
	PPC_STORE_U32(ctx.r1.u32 + 224, ctx.r9.u32);
	// beq cr6,0x82124d68
	if (ctx.cr6.eq) goto loc_82124D68;
	// lwz r11,1412(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1412);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// rlwinm r6,r9,16,24,31
	ctx.r6.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0xFF;
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r5,12(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// rlwinm r8,r10,16,24,31
	ctx.r8.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFF;
	// rlwinm r3,r10,24,24,31
	ctx.r3.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF;
	// std r6,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r6.u64);
	// rlwinm r11,r10,8,24,31
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFF;
	// lfd f0,88(r1)
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// rlwinm r4,r9,24,24,31
	ctx.r4.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xFF;
	// std r8,296(r1)
	PPC_STORE_U64(ctx.r1.u32 + 296, ctx.r8.u64);
	// rlwinm r6,r9,8,24,31
	ctx.r6.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFF;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r11.u64);
	// std r3,280(r1)
	PPC_STORE_U64(ctx.r1.u32 + 280, ctx.r3.u64);
	// lfd f10,88(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// clrlwi r8,r9,24
	ctx.r8.u64 = ctx.r9.u32 & 0xFF;
	// std r4,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r4.u64);
	// rlwinm r3,r7,24,24,31
	ctx.r3.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 24) & 0xFF;
	// std r6,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r6.u64);
	// lfd f8,88(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// rlwinm r9,r7,8,24,31
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 8) & 0xFF;
	// lfd f13,120(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// std r8,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r8.u64);
	// std r3,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r3.u64);
	// lfd f6,88(r1)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// clrlwi r8,r10,24
	ctx.r8.u64 = ctx.r10.u32 & 0xFF;
	// std r9,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r9.u64);
	// lfd f4,88(r1)
	ctx.f4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// rlwinm r4,r7,16,24,31
	ctx.r4.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 16) & 0xFF;
	// std r8,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r8.u64);
	// lfd f3,88(r1)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// lfd f11,280(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 280);
	// clrlwi r11,r7,24
	ctx.r11.u64 = ctx.r7.u32 & 0xFF;
	// lfd f12,296(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 296);
	// fcfid f0,f0
	ctx.f0.f64 = double(ctx.f0.s64);
	// lfd f9,120(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// std r4,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r4.u64);
	// lfd f7,120(r1)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r11.u64);
	// lfd f5,120(r1)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// frsp f0,f0
	ctx.f0.f64 = double(float(ctx.f0.f64));
	// rlwinm r7,r5,16,24,31
	ctx.r7.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 16) & 0xFF;
	// rlwinm r6,r5,24,24,31
	ctx.r6.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 24) & 0xFF;
	// fcfid f8,f8
	ctx.f8.f64 = double(ctx.f8.s64);
	// std r7,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r7.u64);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcfid f6,f6
	ctx.f6.f64 = double(ctx.f6.s64);
	// fcfid f4,f4
	ctx.f4.f64 = double(ctx.f4.s64);
	// fcfid f2,f3
	ctx.f2.f64 = double(ctx.f3.s64);
	// fcfid f1,f11
	ctx.f1.f64 = double(ctx.f11.s64);
	// lfd f11,88(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f3,f12
	ctx.f3.f64 = double(ctx.f12.s64);
	// fcfid f12,f10
	ctx.f12.f64 = double(ctx.f10.s64);
	// fcfid f10,f9
	ctx.f10.f64 = double(ctx.f9.s64);
	// frsp f9,f2
	ctx.f9.f64 = double(float(ctx.f2.f64));
	// frsp f2,f1
	ctx.f2.f64 = double(float(ctx.f1.f64));
	// frsp f1,f3
	ctx.f1.f64 = double(float(ctx.f3.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fcfid f7,f7
	ctx.f7.f64 = double(ctx.f7.s64);
	// frsp f3,f12
	ctx.f3.f64 = double(float(ctx.f12.f64));
	// frsp f12,f10
	ctx.f12.f64 = double(float(ctx.f10.f64));
	// fcfid f5,f5
	ctx.f5.f64 = double(ctx.f5.s64);
	// fmuls f10,f9,f31
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// stfs f10,216(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// frsp f9,f8
	ctx.f9.f64 = double(float(ctx.f8.f64));
	// fmuls f8,f2,f31
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f31.f64));
	// stfs f8,212(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// fmuls f2,f1,f31
	ctx.f2.f64 = double(float(ctx.f1.f64 * ctx.f31.f64));
	// stfs f2,208(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f31.f64));
	// stfs f1,192(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fmuls f0,f13,f31
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// stfs f0,196(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// frsp f13,f7
	ctx.f13.f64 = double(float(ctx.f7.f64));
	// frsp f10,f6
	ctx.f10.f64 = double(float(ctx.f6.f64));
	// frsp f8,f5
	ctx.f8.f64 = double(float(ctx.f5.f64));
	// frsp f7,f4
	ctx.f7.f64 = double(float(ctx.f4.f64));
	// fmuls f20,f3,f31
	ctx.f20.f64 = double(float(ctx.f3.f64 * ctx.f31.f64));
	// fmuls f6,f12,f31
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f31.f64));
	// rlwinm r4,r5,8,24,31
	ctx.r4.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 8) & 0xFF;
	// std r6,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r6.u64);
	// lfd f3,88(r1)
	ctx.f3.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// clrlwi r3,r5,24
	ctx.r3.u64 = ctx.r5.u32 & 0xFF;
	// std r4,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r4.u64);
	// lfd f2,88(r1)
	ctx.f2.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r3,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r3.u64);
	// fmuls f4,f13,f31
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f31.f64));
	// fcfid f5,f11
	ctx.f5.f64 = double(ctx.f11.s64);
	// stfs f6,200(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f1,f10,f31
	ctx.f1.f64 = double(float(ctx.f10.f64 * ctx.f31.f64));
	// stfs f4,240(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fcfid f11,f3
	ctx.f11.f64 = double(ctx.f3.s64);
	// stfs f1,244(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f10,f2
	ctx.f10.f64 = double(ctx.f2.s64);
	// fcfid f12,f13
	ctx.f12.f64 = double(ctx.f13.s64);
	// fmuls f0,f8,f31
	ctx.f0.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// stfs f0,248(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// frsp f8,f5
	ctx.f8.f64 = double(float(ctx.f5.f64));
	// frsp f5,f11
	ctx.f5.f64 = double(float(ctx.f11.f64));
	// fmuls f19,f9,f31
	ctx.f19.f64 = double(float(ctx.f9.f64 * ctx.f31.f64));
	// fmuls f18,f7,f31
	ctx.f18.f64 = double(float(ctx.f7.f64 * ctx.f31.f64));
	// frsp f4,f10
	ctx.f4.f64 = double(float(ctx.f10.f64));
	// frsp f6,f12
	ctx.f6.f64 = double(float(ctx.f12.f64));
	// fmuls f3,f8,f31
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f31.f64));
	// stfs f3,176(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f1,f5,f31
	ctx.f1.f64 = double(float(ctx.f5.f64 * ctx.f31.f64));
	// stfs f1,180(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f17,f4,f31
	ctx.f17.f64 = double(float(ctx.f4.f64 * ctx.f31.f64));
	// fmuls f2,f6,f31
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f31.f64));
	// stfs f2,184(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// b 0x82124d78
	goto loc_82124D78;
loc_82124D68:
	// lfs f20,220(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f20.f64 = double(temp.f32);
	// lfs f19,204(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 204);
	ctx.f19.f64 = double(temp.f32);
	// lfs f18,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f18.f64 = double(temp.f32);
	// lfs f17,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f17.f64 = double(temp.f32);
loc_82124D78:
	// lis r11,-32197
	ctx.r11.s64 = -2110062592;
	// lwz r3,-27096(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + -27096);
	// bl 0x82388734
	ctx.lr = 0x82124D84;
	__imp__KeTlsGetValue(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82124d90
	if (!ctx.cr6.eq) goto loc_82124D90;
	// bl 0x821b3000
	ctx.lr = 0x82124D90;
	sub_821B3000(ctx, base);
loc_82124D90:
	// lwz r7,88(r27)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r27.u32 + 88);
	// addi r8,r3,20
	ctx.r8.s64 = ctx.r3.s64 + 20;
	// rlwinm r11,r7,2,0,29
	ctx.r11.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,312(r1)
	PPC_STORE_U32(ctx.r1.u32 + 312, ctx.r8.u32);
	// addi r9,r11,15
	ctx.r9.s64 = ctx.r11.s64 + 15;
	// stw r11,352(r1)
	PPC_STORE_U32(ctx.r1.u32 + 352, ctx.r11.u32);
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// rlwinm r11,r9,0,0,27
	ctx.r11.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFF0;
	// lwz r6,0(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// stw r7,272(r1)
	PPC_STORE_U32(ctx.r1.u32 + 272, ctx.r7.u32);
	// add r5,r11,r10
	ctx.r5.u64 = ctx.r11.u64 + ctx.r10.u64;
	// cmplw cr6,r5,r6
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, ctx.xer);
	// ble cr6,0x82124dd4
	if (!ctx.cr6.gt) goto loc_82124DD4;
	// lis r10,-13569
	ctx.r10.s64 = -889257984;
	// lis r9,-32250
	ctx.r9.s64 = -2113536000;
	// addi r6,r9,4492
	ctx.r6.s64 = ctx.r9.s64 + 4492;
	// stw r6,-13570(r10)
	PPC_STORE_U32(ctx.r10.u32 + -13570, ctx.r6.u32);
loc_82124DD4:
	// lwz r10,4(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// lwz r9,8(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// add r29,r9,r10
	ctx.r29.u64 = ctx.r9.u64 + ctx.r10.u64;
	// stw r11,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, ctx.r11.u32);
	// beq cr6,0x82124e04
	if (ctx.cr6.eq) goto loc_82124E04;
	// addi r11,r29,-4
	ctx.r11.s64 = ctx.r29.s64 + -4;
	// mtctr r7
	ctx.ctr.u64 = ctx.r7.u64;
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
loc_82124DFC:
	// stwu r10,4(r11)
	ea = 4 + ctx.r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	ctx.r11.u32 = ea;
	// bdnz 0x82124dfc
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82124DFC;
loc_82124E04:
	// mr r8,r28
	ctx.r8.u64 = ctx.r28.u64;
	// stw r28,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, ctx.r28.u32);
	// cmplwi cr6,r14,0
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 0, ctx.xer);
	// beq cr6,0x82124e50
	if (ctx.cr6.eq) goto loc_82124E50;
	// addi r11,r31,-20
	ctx.r11.s64 = ctx.r31.s64 + -20;
	// mtctr r14
	ctx.ctr.u64 = ctx.r14.u64;
loc_82124E1C:
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 24);
	// cmpwi cr6,r10,-1
	ctx.cr6.compare<int32_t>(ctx.r10.s32, -1, ctx.xer);
	// bne cr6,0x82124e34
	if (!ctx.cr6.eq) goto loc_82124E34;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r11,r11,24
	ctx.r11.s64 = ctx.r11.s64 + 24;
	// b 0x82124e48
	goto loc_82124E48;
loc_82124E34:
	// lwzu r10,24(r11)
	ea = 24 + ctx.r11.u32;
	ctx.r10.u64 = PPC_LOAD_U32(ea);
	ctx.r11.u32 = ea;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r10,r29
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r29.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r10,r29
	PPC_STORE_U32(ctx.r10.u32 + ctx.r29.u32, ctx.r9.u32);
loc_82124E48:
	// bdnz 0x82124e1c
	--ctx.ctr.u64;
	if (ctx.ctr.u32 != 0) goto loc_82124E1C;
	// stw r8,276(r1)
	PPC_STORE_U32(ctx.r1.u32 + 276, ctx.r8.u32);
loc_82124E50:
	// lwz r10,1364(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1364);
	// lfs f16,48(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	ctx.f16.f64 = double(temp.f32);
	// fmuls f28,f30,f28
	ctx.f28.f64 = double(float(ctx.f30.f64 * ctx.f28.f64));
	// stfs f28,264(r1)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// fmuls f29,f29,f27
	ctx.f29.f64 = double(float(ctx.f29.f64 * ctx.f27.f64));
	// stfs f29,228(r1)
	temp.f32 = float(ctx.f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// li r19,1
	ctx.r19.s64 = 1;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
	// lfs f0,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f16
	ctx.cr6.compare(ctx.f0.f64, ctx.f16.f64);
	// bne cr6,0x82124e88
	if (!ctx.cr6.eq) goto loc_82124E88;
	// lfs f0,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f16
	ctx.cr6.compare(ctx.f0.f64, ctx.f16.f64);
	// beq cr6,0x82124eb4
	if (ctx.cr6.eq) goto loc_82124EB4;
loc_82124E88:
	// ld r11,0(r10)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// fcmpu cr6,f26,f16
	ctx.fpscr.disableFlushMode();
	ctx.cr6.compare(ctx.f26.f64, ctx.f16.f64);
	// std r11,256(r1)
	PPC_STORE_U64(ctx.r1.u32 + 256, ctx.r11.u64);
	// beq cr6,0x82124eb0
	if (ctx.cr6.eq) goto loc_82124EB0;
	// stfs f16,160(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// stfs f16,164(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// fmr f1,f26
	ctx.f1.f64 = ctx.f26.f64;
	// bl 0x82183938
	ctx.lr = 0x82124EB0;
	sub_82183938(ctx, base);
loc_82124EB0:
	// mr r11,r19
	ctx.r11.u64 = ctx.r19.u64;
loc_82124EB4:
	// clrlwi r31,r11,24
	ctx.r31.u64 = ctx.r11.u32 & 0xFF;
	// stfs f16,168(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// cmplwi cr6,r31,0
	ctx.cr6.compare<uint32_t>(ctx.r31.u32, 0, ctx.xer);
	// beq cr6,0x82124ef8
	if (ctx.cr6.eq) goto loc_82124EF8;
	// lwz r11,1372(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1372);
	// addi r10,r1,368
	ctx.r10.s64 = ctx.r1.s64 + 368;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lfs f0,12(r11)
	temp.u32 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	ctx.f0.f64 = double(temp.f32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stfs f0,168(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// stw r6,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r6.u32);
	// stfs f16,380(r1)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
loc_82124EF8:
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r9,r10,-27800
	ctx.r9.s64 = ctx.r10.s64 + -27800;
	// addi r23,r11,28184
	ctx.r23.s64 = ctx.r11.s64 + 28184;
	// lwz r11,2120(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2120);
	// cmpwi cr6,r11,8192
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 8192, ctx.xer);
	// beq cr6,0x82124fb8
	if (ctx.cr6.eq) goto loc_82124FB8;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821112b0
	ctx.lr = 0x82124F20;
	sub_821112B0(ctx, base);
	// lbz r11,140(r27)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r27.u32 + 140);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82124f3c
	if (ctx.cr6.eq) goto loc_82124F3C;
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r4,144(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 144);
	// bl 0x82113bc0
	ctx.lr = 0x82124F38;
	sub_82113BC0(ctx, base);
	// b 0x82124fb8
	goto loc_82124FB8;
loc_82124F3C:
	// lwz r10,756(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 756);
	// li r11,12545
	ctx.r11.s64 = 12545;
	// stw r11,288(r23)
	PPC_STORE_U32(ctx.r23.u32 + 288, ctx.r11.u32);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// beq cr6,0x82124f70
	if (ctx.cr6.eq) goto loc_82124F70;
	// lwz r11,0(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	// mr r10,r19
	ctx.r10.u64 = ctx.r19.u64;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// stfs f31,10500(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r11.u32 + 10500, temp.u32);
	// ld r8,16(r11)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r11.u32 + 16);
	// oris r7,r8,2048
	ctx.r7.u64 = ctx.r8.u64 | 134217728;
	// std r7,16(r11)
	PPC_STORE_U64(ctx.r11.u32 + 16, ctx.r7.u64);
	// stw r19,756(r23)
	PPC_STORE_U32(ctx.r23.u32 + 756, ctx.r19.u32);
loc_82124F70:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,96
	ctx.r3.s64 = 96;
	// bl 0x82111340
	ctx.lr = 0x82124F7C;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,308
	ctx.r3.s64 = 308;
	// bl 0x82111340
	ctx.lr = 0x82124F88;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x82111340
	ctx.lr = 0x82124F94;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x82111340
	ctx.lr = 0x82124FA0;
	sub_82111340(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,72
	ctx.r3.s64 = 72;
	// bl 0x82111340
	ctx.lr = 0x82124FAC;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,76
	ctx.r3.s64 = 76;
	// bl 0x82111340
	ctx.lr = 0x82124FB8;
	sub_82111340(ctx, base);
loc_82124FB8:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82124FC4;
	sub_82111340(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111390
	ctx.lr = 0x82124FD4;
	sub_82111390(ctx, base);
	// lwz r11,1988(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82125008
	if (ctx.cr6.eq) goto loc_82125008;
	// lwz r11,0(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r9,r11
	ctx.r9.u64 = ctx.r11.u64;
	// lwz r8,1152(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r8,r19,14,16,18
	ctx.r8.u64 = (rotl32(ctx.r19.u32, 14) & 0xE000) | (ctx.r8.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r8,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r8.u32);
	// ld r7,24(r11)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r6.u64);
	// stw r10,1988(r23)
	PPC_STORE_U32(ctx.r23.u32 + 1988, ctx.r10.u32);
loc_82125008:
	// cntlzw r11,r31
	ctx.r11.u64 = ctx.r31.u32 == 0 ? 32 : __builtin_clz(ctx.r31.u32);
	// rlwinm r11,r11,27,31,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 27) & 0x1;
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r11.u32);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// bge cr6,0x8212641c
	if (!ctx.cr6.lt) goto loc_8212641C;
	// lis r11,255
	ctx.r11.s64 = 16711680;
	// lfs f0,260(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 260);
	ctx.f0.f64 = double(temp.f32);
	// lwz r25,1404(r1)
	ctx.r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1404);
	// lfs f29,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f29.f64 = double(temp.f32);
	// lfs f14,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f14.f64 = double(temp.f32);
	// ori r18,r11,65535
	ctx.r18.u64 = ctx.r11.u64 | 65535;
	// lfs f31,36(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// stfs f0,316(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
loc_8212503C:
	// lwz r11,148(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// li r12,1
	ctx.r12.s64 = 1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// rldicr r12,r12,36,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// bne cr6,0x82125074
	if (!ctx.cr6.eq) goto loc_82125074;
	// lfs f0,372(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,368(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 368);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,376(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 376);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,380(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	ctx.f11.f64 = double(temp.f32);
	// stfs f0,7748(r17)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r17.u32 + 7748, temp.u32);
	// stfs f13,7744(r17)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r17.u32 + 7744, temp.u32);
	// stfs f12,7752(r17)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r17.u32 + 7752, temp.u32);
	// stfs f11,7756(r17)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r17.u32 + 7756, temp.u32);
	// b 0x82125084
	goto loc_82125084;
loc_82125074:
	// stfs f16,7748(r17)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r17.u32 + 7748, temp.u32);
	// stfs f16,7744(r17)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r17.u32 + 7744, temp.u32);
	// stfs f16,7752(r17)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r17.u32 + 7752, temp.u32);
	// stfs f16,7756(r17)
	temp.f32 = float(ctx.f16.f64);
	PPC_STORE_U32(ctx.r17.u32 + 7756, temp.u32);
loc_82125084:
	// ld r11,8(r17)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r17.u32 + 8);
	// li r16,0
	ctx.r16.s64 = 0;
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// lwz r11,272(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// std r10,8(r17)
	PPC_STORE_U64(ctx.r17.u32 + 8, ctx.r10.u64);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82126400
	if (ctx.cr6.eq) goto loc_82126400;
loc_821250A0:
	// rlwinm r15,r16,2,0,29
	ctx.r15.u64 = rotl64(ctx.r16.u32 | (ctx.r16.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r15,r29
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r29.u32);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// blt cr6,0x821263f0
	if (ctx.cr6.lt) goto loc_821263F0;
	// lwz r11,224(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	// li r27,0
	ctx.r27.s64 = 0;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821263f0
	if (ctx.cr6.eq) goto loc_821263F0;
loc_821250C0:
	// lwzx r11,r15,r29
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r15.u32 + ctx.r29.u32);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// lwz r26,1340(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1340);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	ctx.r11.u64 = ctx.r11.u64 + ctx.r10.u64;
	// rlwinm r21,r11,4,0,27
	ctx.r21.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x8210b178
	ctx.lr = 0x821250E4;
	sub_8210B178(ctx, base);
	// mr r31,r3
	ctx.r31.u64 = ctx.r3.u64;
	// li r20,0
	ctx.r20.s64 = 0;
	// li r24,0
	ctx.r24.s64 = 0;
	// li r22,0
	ctx.r22.s64 = 0;
	// cmplwi cr6,r14,0
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 0, ctx.xer);
	// beq cr6,0x82126334
	if (ctx.cr6.eq) goto loc_82126334;
loc_821250FC:
	// lwz r11,4(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 4);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// ble cr6,0x82126318
	if (!ctx.cr6.gt) goto loc_82126318;
	// cmplw cr6,r11,r16
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r16.u32, ctx.xer);
	// bne cr6,0x82126318
	if (!ctx.cr6.eq) goto loc_82126318;
	// lwz r30,0(r26)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r4,r16
	ctx.r4.u64 = ctx.r16.u64;
	// lwz r3,1332(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1332);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x82126d28
	ctx.lr = 0x82125124;
	sub_82126D28(ctx, base);
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// bne cr6,0x82125138
	if (!ctx.cr6.eq) goto loc_82125138;
	// cmpwi cr6,r30,-1
	ctx.cr6.compare<int32_t>(ctx.r30.s32, -1, ctx.xer);
	// b 0x82126320
	goto loc_82126320;
loc_82125138:
	// lhz r11,36(r28)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r28.u32 + 36);
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// bne cr6,0x82126324
	if (!ctx.cr6.eq) goto loc_82126324;
	// clrlwi r11,r24,24
	ctx.r11.u64 = ctx.r24.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x8212524c
	if (!ctx.cr6.eq) goto loc_8212524C;
	// lwz r11,0(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 0);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82125238
	if (ctx.cr6.eq) goto loc_82125238;
	// lwz r3,96(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82125170
	if (ctx.cr6.eq) goto loc_82125170;
	// bl 0x820b91d0
	ctx.lr = 0x8212516C;
	sub_820B91D0(ctx, base);
	// b 0x8212518c
	goto loc_8212518C;
loc_82125170:
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x82125184
	if (ctx.cr6.eq) goto loc_82125184;
	// lwz r30,88(r11)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r11.u32 + 88);
	// b 0x82125190
	goto loc_82125190;
loc_82125184:
	// mr r3,r11
	ctx.r3.u64 = ctx.r11.u64;
	// bl 0x820b90a0
	ctx.lr = 0x8212518C;
	sub_820B90A0(ctx, base);
loc_8212518C:
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
loc_82125190:
	// lbz r11,52(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 52);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// cntlzw r9,r11
	ctx.r9.u64 = ctx.r11.u32 == 0 ? 32 : __builtin_clz(ctx.r11.u32);
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// rlwinm r4,r9,27,31,31
	ctx.r4.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// mr r19,r11
	ctx.r19.u64 = ctx.r11.u64;
	// bl 0x8211a568
	ctx.lr = 0x821251AC;
	sub_8211A568(ctx, base);
	// lwz r11,2036(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821251d0
	if (ctx.cr6.eq) goto loc_821251D0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r23)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x821251C8;
	sub_8222C248(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,2036(r23)
	PPC_STORE_U32(ctx.r23.u32 + 2036, ctx.r11.u32);
loc_821251D0:
	// lwz r11,2052(r23)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r23.u32 + 2052);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x821251f4
	if (ctx.cr6.eq) goto loc_821251F4;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r23)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x821251EC;
	sub_8222C0A0(ctx, base);
	// li r11,1
	ctx.r11.s64 = 1;
	// stw r11,2052(r23)
	PPC_STORE_U32(ctx.r23.u32 + 2052, ctx.r11.u32);
loc_821251F4:
	// lwz r11,20(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// lwz r10,2068(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 2068);
	// subfic r9,r11,1
	ctx.xer.ca = ctx.r11.u32 <= 1;
	ctx.r9.s64 = 1 - ctx.r11.s64;
	// subfe r11,r9,r9
	temp.u8 = (~ctx.r9.u32 + ctx.r9.u32 < ~ctx.r9.u32) | (~ctx.r9.u32 + ctx.r9.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r9.u64 + ctx.r9.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// addi r11,r11,2
	ctx.r11.s64 = ctx.r11.s64 + 2;
	// cmplw cr6,r10,r11
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82125248
	if (ctx.cr6.eq) goto loc_82125248;
	// lwz r10,0(r23)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r23.u32 + 0);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// lwz r8,1164(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1164);
	// rlwimi r8,r11,23,7,8
	ctx.r8.u64 = (rotl32(ctx.r11.u32, 23) & 0x1800000) | (ctx.r8.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r8,1164(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1164, ctx.r8.u32);
	// ld r7,24(r10)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r10.u32 + 24);
	// oris r6,r7,32768
	ctx.r6.u64 = ctx.r7.u64 | 2147483648;
	// std r6,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, ctx.r6.u64);
	// stw r11,2068(r23)
	PPC_STORE_U32(ctx.r23.u32 + 2068, ctx.r11.u32);
	// b 0x82125248
	goto loc_82125248;
loc_82125238:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// li r19,1
	ctx.r19.s64 = 1;
	// bl 0x82111400
	ctx.lr = 0x82125248;
	sub_82111400(ctx, base);
loc_82125248:
	// li r24,1
	ctx.r24.s64 = 1;
loc_8212524C:
	// lfs f13,16(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,12(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 12);
	ctx.f0.f64 = double(temp.f32);
	// fmr f27,f13
	ctx.f27.f64 = ctx.f13.f64;
	// lfs f12,24(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fmr f28,f0
	ctx.f28.f64 = ctx.f0.f64;
	// lfs f11,28(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	ctx.f11.f64 = double(temp.f32);
	// fmr f24,f13
	ctx.f24.f64 = ctx.f13.f64;
	// lfs f10,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f12,f12,f10,f0
	ctx.f12.f64 = double(std::fma(float(ctx.f12.f64), float(ctx.f10.f64), float(ctx.f0.f64)));
	// fmadds f11,f11,f9,f13
	ctx.f11.f64 = double(std::fma(float(ctx.f11.f64), float(ctx.f9.f64), float(ctx.f13.f64)));
	// lfs f8,1388(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 1388);
	ctx.f8.f64 = double(temp.f32);
	// lfs f30,20(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 20);
	ctx.f30.f64 = double(temp.f32);
	// fcmpu cr6,f8,f16
	ctx.cr6.compare(ctx.f8.f64, ctx.f16.f64);
	// lfs f15,8(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 8);
	ctx.f15.f64 = double(temp.f32);
	// lfs f26,12(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 12);
	ctx.f26.f64 = double(temp.f32);
	// lfs f23,16(r28)
	temp.u32 = PPC_LOAD_U32(ctx.r28.u32 + 16);
	ctx.f23.f64 = double(temp.f32);
	// stfs f0,288(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// stfs f13,292(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// stfs f13,308(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// stfs f0,152(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// stfs f30,320(r1)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// fmr f25,f12
	ctx.f25.f64 = ctx.f12.f64;
	// stfs f12,304(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// fmr f21,f11
	ctx.f21.f64 = ctx.f11.f64;
	// stfs f12,160(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmr f22,f12
	ctx.f22.f64 = ctx.f12.f64;
	// stfs f11,164(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stfs f11,156(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// beq cr6,0x8212536c
	if (ctx.cr6.eq) goto loc_8212536C;
	// lwz r30,1380(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1380);
	// addi r5,r1,280
	ctx.r5.s64 = ctx.r1.s64 + 280;
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// fmr f28,f8
	ctx.f28.f64 = ctx.f8.f64;
	// fmr f1,f8
	ctx.f1.f64 = ctx.f8.f64;
	// lfs f0,0(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,280(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// stfs f13,284(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// bl 0x82183938
	ctx.lr = 0x821252EC;
	sub_82183938(ctx, base);
	// lfs f12,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// addi r5,r1,296
	ctx.r5.s64 = ctx.r1.s64 + 296;
	// stfs f12,296(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// addi r3,r1,304
	ctx.r3.s64 = ctx.r1.s64 + 304;
	// stfs f11,300(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fmr f1,f28
	ctx.f1.f64 = ctx.f28.f64;
	// bl 0x82183938
	ctx.lr = 0x8212530C;
	sub_82183938(ctx, base);
	// lfs f10,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// stfs f10,120(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// stfs f9,124(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// fmr f1,f28
	ctx.f1.f64 = ctx.f28.f64;
	// bl 0x82183938
	ctx.lr = 0x8212532C;
	sub_82183938(ctx, base);
	// lfs f8,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,4(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// stfs f8,88(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// stfs f7,92(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fmr f1,f28
	ctx.f1.f64 = ctx.f28.f64;
	// bl 0x82183938
	ctx.lr = 0x8212534C;
	sub_82183938(ctx, base);
	// lfs f27,292(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f27.f64 = double(temp.f32);
	// lfs f28,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f28.f64 = double(temp.f32);
	// lfs f24,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	ctx.f24.f64 = double(temp.f32);
	// lfs f25,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f25.f64 = double(temp.f32);
	// lfs f21,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f21.f64 = double(temp.f32);
	// lfs f22,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f22.f64 = double(temp.f32);
	// lfs f0,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f0.f64 = double(temp.f32);
	// lfs f11,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f11.f64 = double(temp.f32);
loc_8212536C:
	// lwz r11,148(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// lwz r11,268(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// bne cr6,0x8212582c
	if (!ctx.cr6.eq) goto loc_8212582C;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x8212577c
	if (ctx.cr6.eq) goto loc_8212577C;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// lwz r4,20(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// bl 0x820c6b60
	ctx.lr = 0x82125390;
	sub_820C6B60(ctx, base);
	// lfs f0,0(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,8(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f28,f0
	ctx.f0.f64 = static_cast<float>(ctx.f28.f64 - ctx.f0.f64);
	// fdivs f13,f31,f13
	ctx.f13.f64 = double(float(ctx.f31.f64 / ctx.f13.f64));
	// lfs f9,348(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f9,f12
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// stfs f11,348(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// fmuls f10,f0,f13
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f10,f31
	ctx.cr6.compare(ctx.f10.f64, ctx.f31.f64);
	// bge cr6,0x821253c8
	if (!ctx.cr6.lt) goto loc_821253C8;
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f16
	ctx.cr6.compare(ctx.f12.f64, ctx.f16.f64);
	// ble cr6,0x821253e4
	if (!ctx.cr6.gt) goto loc_821253E4;
loc_821253C8:
	// fmuls f12,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x821253dc
	if (!ctx.cr6.lt) goto loc_821253DC;
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// b 0x821253e8
	goto loc_821253E8;
loc_821253DC:
	// fmr f12,f31
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = ctx.f31.f64;
	// b 0x821253e8
	goto loc_821253E8;
loc_821253E4:
	// fmr f12,f16
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = ctx.f16.f64;
loc_821253E8:
	// lfs f0,4(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,12(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f27,f0
	ctx.f0.f64 = static_cast<float>(ctx.f27.f64 - ctx.f0.f64);
	// fdivs f13,f31,f13
	ctx.f13.f64 = double(float(ctx.f31.f64 / ctx.f13.f64));
	// fmuls f10,f13,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f10,f31
	ctx.cr6.compare(ctx.f10.f64, ctx.f31.f64);
	// bge cr6,0x82125410
	if (!ctx.cr6.lt) goto loc_82125410;
	// fmuls f10,f13,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f10,f16
	ctx.cr6.compare(ctx.f10.f64, ctx.f16.f64);
	// ble cr6,0x8212542c
	if (!ctx.cr6.gt) goto loc_8212542C;
loc_82125410:
	// fmuls f10,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f10,f31
	ctx.cr6.compare(ctx.f10.f64, ctx.f31.f64);
	// bge cr6,0x82125424
	if (!ctx.cr6.lt) goto loc_82125424;
	// fmuls f0,f13,f0
	ctx.f0.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// b 0x82125430
	goto loc_82125430;
loc_82125424:
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64;
	// b 0x82125430
	goto loc_82125430;
loc_8212542C:
	// fmr f0,f16
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f16.f64;
loc_82125430:
	// fsubs f13,f31,f12
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = static_cast<float>(ctx.f31.f64 - ctx.f12.f64);
	// lfs f8,316(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f10,f31,f0
	ctx.f10.f64 = static_cast<float>(ctx.f31.f64 - ctx.f0.f64);
	// fmuls f9,f13,f17
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// fmuls f7,f13,f20
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f20.f64));
	// fmadds f6,f18,f12,f9
	ctx.f6.f64 = double(std::fma(float(ctx.f18.f64), float(ctx.f12.f64), float(ctx.f9.f64)));
	// fmadds f5,f19,f12,f7
	ctx.f5.f64 = double(std::fma(float(ctx.f19.f64), float(ctx.f12.f64), float(ctx.f7.f64)));
	// fmuls f4,f6,f0
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmadds f3,f5,f10,f4
	ctx.f3.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f10.f64), float(ctx.f4.f64)));
	// fmuls f2,f3,f11
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fadds f1,f2,f31
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f31.f64));
	// stfs f1,80(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fcmpu cr6,f2,f8
	ctx.cr6.compare(ctx.f2.f64, ctx.f8.f64);
	// blt cr6,0x82125470
	if (ctx.cr6.lt) goto loc_82125470;
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x82125478
	goto loc_82125478;
loc_82125470:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r11,r11,17,24,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 17) & 0xFF;
loc_82125478:
	// fadds f13,f29,f27
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// stfs f13,4(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 4, temp.u32);
	// stfs f26,16(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 16, temp.u32);
	// rlwinm r11,r11,24,0,7
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0xFF000000;
	// fadds f0,f14,f28
	ctx.f0.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// stfs f0,0(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// stfs f15,12(r31)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + 12, temp.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// lfs f10,8(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f13,f25,f12
	ctx.f13.f64 = static_cast<float>(ctx.f25.f64 - ctx.f12.f64);
	// fdivs f0,f31,f10
	ctx.f0.f64 = double(float(ctx.f31.f64 / ctx.f10.f64));
	// fmuls f9,f13,f0
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f9,f31
	ctx.cr6.compare(ctx.f9.f64, ctx.f31.f64);
	// bge cr6,0x821254c0
	if (!ctx.cr6.lt) goto loc_821254C0;
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f16
	ctx.cr6.compare(ctx.f12.f64, ctx.f16.f64);
	// ble cr6,0x821254dc
	if (!ctx.cr6.gt) goto loc_821254DC;
loc_821254C0:
	// fmuls f12,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x821254d4
	if (!ctx.cr6.lt) goto loc_821254D4;
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// b 0x821254e0
	goto loc_821254E0;
loc_821254D4:
	// fmr f12,f31
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = ctx.f31.f64;
	// b 0x821254e0
	goto loc_821254E0;
loc_821254DC:
	// fmr f12,f16
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = ctx.f16.f64;
loc_821254E0:
	// lfs f0,4(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,12(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f24,f0
	ctx.f0.f64 = static_cast<float>(ctx.f24.f64 - ctx.f0.f64);
	// fdivs f13,f31,f13
	ctx.f13.f64 = double(float(ctx.f31.f64 / ctx.f13.f64));
	// fmuls f10,f0,f13
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f10,f31
	ctx.cr6.compare(ctx.f10.f64, ctx.f31.f64);
	// bge cr6,0x82125508
	if (!ctx.cr6.lt) goto loc_82125508;
	// fmuls f10,f0,f13
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f10,f16
	ctx.cr6.compare(ctx.f10.f64, ctx.f16.f64);
	// ble cr6,0x82125524
	if (!ctx.cr6.gt) goto loc_82125524;
loc_82125508:
	// fmuls f10,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f10,f31
	ctx.cr6.compare(ctx.f10.f64, ctx.f31.f64);
	// bge cr6,0x8212551c
	if (!ctx.cr6.lt) goto loc_8212551C;
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// b 0x82125528
	goto loc_82125528;
loc_8212551C:
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64;
	// b 0x82125528
	goto loc_82125528;
loc_82125524:
	// fmr f0,f16
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f16.f64;
loc_82125528:
	// fsubs f13,f31,f12
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = static_cast<float>(ctx.f31.f64 - ctx.f12.f64);
	// fsubs f10,f31,f0
	ctx.f10.f64 = static_cast<float>(ctx.f31.f64 - ctx.f0.f64);
	// fmuls f9,f13,f17
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// fmuls f7,f13,f20
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f20.f64));
	// fmadds f6,f18,f12,f9
	ctx.f6.f64 = double(std::fma(float(ctx.f18.f64), float(ctx.f12.f64), float(ctx.f9.f64)));
	// fmadds f5,f19,f12,f7
	ctx.f5.f64 = double(std::fma(float(ctx.f19.f64), float(ctx.f12.f64), float(ctx.f7.f64)));
	// fmuls f4,f6,f0
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmadds f3,f5,f10,f4
	ctx.f3.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f10.f64), float(ctx.f4.f64)));
	// fmuls f2,f3,f11
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fadds f1,f2,f31
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f31.f64));
	// stfs f1,80(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fcmpu cr6,f2,f8
	ctx.cr6.compare(ctx.f2.f64, ctx.f8.f64);
	// blt cr6,0x82125564
	if (ctx.cr6.lt) goto loc_82125564;
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x8212556c
	goto loc_8212556C;
loc_82125564:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r11,r11,17,24,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 17) & 0xFF;
loc_8212556C:
	// rlwinm r11,r11,24,0,7
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0xFF000000;
	// fadds f0,f25,f14
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// fadds f13,f24,f29
	ctx.f13.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// stfs f0,20(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 20, temp.u32);
	// stfs f13,24(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 24, temp.u32);
	// stw r11,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r11.u32);
	// stfs f23,32(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 32, temp.u32);
	// stfs f26,36(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 36, temp.u32);
	// lfs f10,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,8(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fdivs f0,f31,f12
	ctx.f0.f64 = double(float(ctx.f31.f64 / ctx.f12.f64));
	// fsubs f13,f22,f10
	ctx.f13.f64 = static_cast<float>(ctx.f22.f64 - ctx.f10.f64);
	// fmuls f9,f13,f0
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f9,f31
	ctx.cr6.compare(ctx.f9.f64, ctx.f31.f64);
	// bge cr6,0x821255b4
	if (!ctx.cr6.lt) goto loc_821255B4;
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f16
	ctx.cr6.compare(ctx.f12.f64, ctx.f16.f64);
	// ble cr6,0x821255d0
	if (!ctx.cr6.gt) goto loc_821255D0;
loc_821255B4:
	// fmuls f12,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x821255c8
	if (!ctx.cr6.lt) goto loc_821255C8;
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// b 0x821255d4
	goto loc_821255D4;
loc_821255C8:
	// fmr f12,f31
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = ctx.f31.f64;
	// b 0x821255d4
	goto loc_821255D4;
loc_821255D0:
	// fmr f12,f16
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = ctx.f16.f64;
loc_821255D4:
	// lfs f0,4(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,12(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f21,f0
	ctx.f0.f64 = static_cast<float>(ctx.f21.f64 - ctx.f0.f64);
	// fdivs f13,f31,f13
	ctx.f13.f64 = double(float(ctx.f31.f64 / ctx.f13.f64));
	// fmuls f10,f0,f13
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f10,f31
	ctx.cr6.compare(ctx.f10.f64, ctx.f31.f64);
	// bge cr6,0x821255fc
	if (!ctx.cr6.lt) goto loc_821255FC;
	// fmuls f10,f0,f13
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f10,f16
	ctx.cr6.compare(ctx.f10.f64, ctx.f16.f64);
	// ble cr6,0x82125618
	if (!ctx.cr6.gt) goto loc_82125618;
loc_821255FC:
	// fmuls f10,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f10,f31
	ctx.cr6.compare(ctx.f10.f64, ctx.f31.f64);
	// bge cr6,0x82125610
	if (!ctx.cr6.lt) goto loc_82125610;
	// fmuls f0,f0,f13
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// b 0x8212561c
	goto loc_8212561C;
loc_82125610:
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64;
	// b 0x8212561c
	goto loc_8212561C;
loc_82125618:
	// fmr f0,f16
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f16.f64;
loc_8212561C:
	// fsubs f13,f31,f12
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = static_cast<float>(ctx.f31.f64 - ctx.f12.f64);
	// fsubs f10,f31,f0
	ctx.f10.f64 = static_cast<float>(ctx.f31.f64 - ctx.f0.f64);
	// fmuls f9,f13,f17
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f17.f64));
	// fmuls f7,f13,f20
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f20.f64));
	// fmadds f6,f18,f12,f9
	ctx.f6.f64 = double(std::fma(float(ctx.f18.f64), float(ctx.f12.f64), float(ctx.f9.f64)));
	// fmadds f5,f19,f12,f7
	ctx.f5.f64 = double(std::fma(float(ctx.f19.f64), float(ctx.f12.f64), float(ctx.f7.f64)));
	// fmuls f4,f6,f0
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f0.f64));
	// fmadds f3,f5,f10,f4
	ctx.f3.f64 = double(std::fma(float(ctx.f5.f64), float(ctx.f10.f64), float(ctx.f4.f64)));
	// fmuls f2,f3,f11
	ctx.f2.f64 = double(float(ctx.f3.f64 * ctx.f11.f64));
	// fadds f1,f2,f31
	ctx.f1.f64 = double(float(ctx.f2.f64 + ctx.f31.f64));
	// stfs f1,80(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fcmpu cr6,f2,f8
	ctx.cr6.compare(ctx.f2.f64, ctx.f8.f64);
	// blt cr6,0x82125658
	if (ctx.cr6.lt) goto loc_82125658;
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x82125660
	goto loc_82125660;
loc_82125658:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r11,r11,17,24,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 17) & 0xFF;
loc_82125660:
	// rlwinm r11,r11,24,0,7
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0xFF000000;
	// fadds f0,f22,f14
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// fadds f13,f21,f29
	ctx.f13.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// stfs f0,40(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 40, temp.u32);
	// stfs f13,44(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 44, temp.u32);
	// stw r11,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r11.u32);
	// stfs f23,52(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 52, temp.u32);
	// stfs f30,56(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 56, temp.u32);
	// lfs f9,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,8(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fdivs f0,f31,f12
	ctx.f0.f64 = double(float(ctx.f31.f64 / ctx.f12.f64));
	// fsubs f13,f9,f10
	ctx.f13.f64 = static_cast<float>(ctx.f9.f64 - ctx.f10.f64);
	// fmuls f7,f13,f0
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f7,f31
	ctx.cr6.compare(ctx.f7.f64, ctx.f31.f64);
	// bge cr6,0x821256ac
	if (!ctx.cr6.lt) goto loc_821256AC;
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f16
	ctx.cr6.compare(ctx.f12.f64, ctx.f16.f64);
	// ble cr6,0x821256c8
	if (!ctx.cr6.gt) goto loc_821256C8;
loc_821256AC:
	// fmuls f12,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x821256c0
	if (!ctx.cr6.lt) goto loc_821256C0;
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// b 0x821256cc
	goto loc_821256CC;
loc_821256C0:
	// fmr f13,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f31.f64;
	// b 0x821256cc
	goto loc_821256CC;
loc_821256C8:
	// fmr f13,f16
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f16.f64;
loc_821256CC:
	// lfs f0,4(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,12(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// fdivs f12,f31,f12
	ctx.f12.f64 = double(float(ctx.f31.f64 / ctx.f12.f64));
	// fsubs f0,f10,f0
	ctx.f0.f64 = static_cast<float>(ctx.f10.f64 - ctx.f0.f64);
	// fmuls f7,f0,f12
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fcmpu cr6,f7,f31
	ctx.cr6.compare(ctx.f7.f64, ctx.f31.f64);
	// bge cr6,0x821256f8
	if (!ctx.cr6.lt) goto loc_821256F8;
	// fmuls f7,f0,f12
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fcmpu cr6,f7,f16
	ctx.cr6.compare(ctx.f7.f64, ctx.f16.f64);
	// ble cr6,0x82125714
	if (!ctx.cr6.gt) goto loc_82125714;
loc_821256F8:
	// fmuls f7,f0,f12
	ctx.fpscr.disableFlushMode();
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// fcmpu cr6,f7,f31
	ctx.cr6.compare(ctx.f7.f64, ctx.f31.f64);
	// bge cr6,0x8212570c
	if (!ctx.cr6.lt) goto loc_8212570C;
	// fmuls f0,f0,f12
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f12.f64));
	// b 0x82125718
	goto loc_82125718;
loc_8212570C:
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f31.f64;
	// b 0x82125718
	goto loc_82125718;
loc_82125714:
	// fmr f0,f16
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = ctx.f16.f64;
loc_82125718:
	// fsubs f12,f31,f13
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = static_cast<float>(ctx.f31.f64 - ctx.f13.f64);
	// fsubs f7,f31,f0
	ctx.f7.f64 = static_cast<float>(ctx.f31.f64 - ctx.f0.f64);
	// fmuls f6,f12,f17
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f17.f64));
	// fmuls f5,f12,f20
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f20.f64));
	// fmadds f12,f18,f13,f6
	ctx.f12.f64 = double(std::fma(float(ctx.f18.f64), float(ctx.f13.f64), float(ctx.f6.f64)));
	// stfs f12,140(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// fmadds f4,f19,f13,f5
	ctx.f4.f64 = double(std::fma(float(ctx.f19.f64), float(ctx.f13.f64), float(ctx.f5.f64)));
	// fmuls f3,f12,f0
	ctx.f3.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// fmadds f2,f4,f7,f3
	ctx.f2.f64 = double(std::fma(float(ctx.f4.f64), float(ctx.f7.f64), float(ctx.f3.f64)));
	// fmuls f0,f2,f11
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f11.f64));
	// stfs f0,108(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fadds f1,f0,f31
	ctx.f1.f64 = double(float(ctx.f0.f64 + ctx.f31.f64));
	// stfs f1,80(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fcmpu cr6,f0,f8
	ctx.cr6.compare(ctx.f0.f64, ctx.f8.f64);
	// blt cr6,0x8212575c
	if (ctx.cr6.lt) goto loc_8212575C;
	// li r11,255
	ctx.r11.s64 = 255;
	// b 0x82125764
	goto loc_82125764;
loc_8212575C:
	// lwz r11,80(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r11,r11,17,24,31
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 17) & 0xFF;
loc_82125764:
	// rlwinm r11,r11,24,0,7
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 24) & 0xFF000000;
	// fadds f13,f10,f29
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f10.f64 + ctx.f29.f64));
	// stfs f13,64(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 64, temp.u32);
	// fadds f0,f9,f14
	ctx.f0.f64 = double(float(ctx.f9.f64 + ctx.f14.f64));
	// stw r11,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r11.u32);
	// b 0x82126300
	goto loc_82126300;
loc_8212577C:
	// lbz r11,20(r26)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r26.u32 + 20);
	// lfs f13,168(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f13.f64 = double(temp.f32);
	// fadds f2,f0,f14
	ctx.f2.f64 = double(float(ctx.f0.f64 + ctx.f14.f64));
	// stfs f15,12(r31)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + 12, temp.u32);
	// extsw r9,r11
	ctx.r9.s64 = ctx.r11.s32;
	// fadds f12,f14,f28
	ctx.f12.f64 = double(float(ctx.f14.f64 + ctx.f28.f64));
	// fadds f10,f29,f27
	ctx.f10.f64 = double(float(ctx.f29.f64 + ctx.f27.f64));
	// stfs f12,0(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// std r9,768(r1)
	PPC_STORE_U64(ctx.r1.u32 + 768, ctx.r9.u64);
	// stfs f10,4(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 4, temp.u32);
	// stfs f26,16(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 16, temp.u32);
	// fadds f9,f25,f14
	ctx.f9.f64 = double(float(ctx.f25.f64 + ctx.f14.f64));
	// fadds f8,f24,f29
	ctx.f8.f64 = double(float(ctx.f24.f64 + ctx.f29.f64));
	// mr r10,r11
	ctx.r10.u64 = ctx.r11.u64;
	// fadds f4,f22,f14
	ctx.f4.f64 = double(float(ctx.f22.f64 + ctx.f14.f64));
	// addi r20,r20,1
	ctx.r20.s64 = ctx.r20.s64 + 1;
	// fadds f3,f21,f29
	ctx.f3.f64 = double(float(ctx.f21.f64 + ctx.f29.f64));
	// fadds f1,f11,f29
	ctx.f1.f64 = double(float(ctx.f11.f64 + ctx.f29.f64));
	// lfd f7,768(r1)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 768);
	// fcfid f6,f7
	ctx.f6.f64 = double(ctx.f7.s64);
	// frsp f5,f6
	ctx.f5.f64 = double(float(ctx.f6.f64));
	// fmuls f0,f5,f13
	ctx.f0.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// fctidz f13,f0
	ctx.f13.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// stfd f13,320(r1)
	PPC_STORE_U64(ctx.r1.u32 + 320, ctx.f13.u64);
	// lwz r8,324(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 324);
	// rlwinm r7,r8,24,0,7
	ctx.r7.u64 = rotl64(ctx.r8.u32 | (ctx.r8.u64 << 32), 24) & 0xFF000000;
	// stw r7,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r7.u32);
	// stfs f9,20(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 20, temp.u32);
	// stfs f8,24(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 24, temp.u32);
	// stw r7,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r7.u32);
	// stfs f23,32(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 32, temp.u32);
	// stfs f26,36(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 36, temp.u32);
	// stw r7,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r7.u32);
	// stfs f4,40(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + 40, temp.u32);
	// stfs f3,44(r31)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + 44, temp.u32);
	// stfs f23,52(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 52, temp.u32);
	// stfs f30,56(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 56, temp.u32);
	// stw r7,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r7.u32);
	// stfs f2,60(r31)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + 60, temp.u32);
	// stfs f1,64(r31)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 64, temp.u32);
	// stfs f15,72(r31)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + 72, temp.u32);
	// stfs f30,76(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 76, temp.u32);
	// addi r31,r31,80
	ctx.r31.s64 = ctx.r31.s64 + 80;
	// b 0x82126324
	goto loc_82126324;
loc_8212582C:
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821262ac
	if (ctx.cr6.eq) goto loc_821262AC;
	// addi r3,r1,336
	ctx.r3.s64 = ctx.r1.s64 + 336;
	// lwz r4,20(r26)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// bl 0x820c6b60
	ctx.lr = 0x82125840;
	sub_820C6B60(ctx, base);
	// lfs f0,0(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,8(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f28,f0
	ctx.f0.f64 = static_cast<float>(ctx.f28.f64 - ctx.f0.f64);
	// fdivs f13,f31,f13
	ctx.f13.f64 = double(float(ctx.f31.f64 / ctx.f13.f64));
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x82125868
	if (!ctx.cr6.lt) goto loc_82125868;
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f16
	ctx.cr6.compare(ctx.f12.f64, ctx.f16.f64);
	// ble cr6,0x82125884
	if (!ctx.cr6.gt) goto loc_82125884;
loc_82125868:
	// fmuls f12,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x8212587c
	if (!ctx.cr6.lt) goto loc_8212587C;
	// fmuls f30,f0,f13
	ctx.f30.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// b 0x82125888
	goto loc_82125888;
loc_8212587C:
	// fmr f30,f31
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f31.f64;
	// b 0x82125888
	goto loc_82125888;
loc_82125884:
	// fmr f30,f16
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f16.f64;
loc_82125888:
	// lfs f0,4(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,12(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f27,f0
	ctx.f0.f64 = static_cast<float>(ctx.f27.f64 - ctx.f0.f64);
	// fdivs f13,f31,f13
	ctx.f13.f64 = double(float(ctx.f31.f64 / ctx.f13.f64));
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x821258b0
	if (!ctx.cr6.lt) goto loc_821258B0;
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f16
	ctx.cr6.compare(ctx.f12.f64, ctx.f16.f64);
	// ble cr6,0x821258cc
	if (!ctx.cr6.gt) goto loc_821258CC;
loc_821258B0:
	// fmuls f12,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x821258c4
	if (!ctx.cr6.lt) goto loc_821258C4;
	// fmuls f29,f13,f0
	ctx.f29.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// b 0x821258d0
	goto loc_821258D0;
loc_821258C4:
	// fmr f29,f31
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f31.f64;
	// b 0x821258d0
	goto loc_821258D0;
loc_821258CC:
	// fmr f29,f16
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f16.f64;
loc_821258D0:
	// fsubs f0,f31,f30
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = static_cast<float>(ctx.f31.f64 - ctx.f30.f64);
	// lfs f13,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f13,f30
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f10,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f30
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f8,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f30
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f6,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f19,f30
	ctx.f5.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// lfs f4,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f4.f64 = double(temp.f32);
	// addi r5,r1,592
	ctx.r5.s64 = ctx.r1.s64 + 592;
	// stfs f11,592(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 592, temp.u32);
	// addi r4,r1,384
	ctx.r4.s64 = ctx.r1.s64 + 384;
	// stfs f9,596(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// addi r3,r1,880
	ctx.r3.s64 = ctx.r1.s64 + 880;
	// stfs f7,600(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// stfs f5,604(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 604, temp.u32);
	// fmuls f3,f8,f0
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f3,384(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fmuls f2,f0,f6
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f2,388(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// fmuls f1,f0,f4
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// stfs f1,392(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fmuls f13,f0,f20
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f20.f64));
	// stfs f13,396(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// bl 0x82126c68
	ctx.lr = 0x82125940;
	sub_82126C68(ctx, base);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// lfs f8,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f18,f30
	ctx.f5.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// lfs f6,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f3,f8,f0
	ctx.f3.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// lfs f4,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f2,f0,f6
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// lfs f12,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f1,f0,f4
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f4.f64));
	// lfs f11,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f12,f30
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f14,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f14.f64 = double(temp.f32);
	// fmuls f9,f11,f30
	ctx.f9.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// fmuls f7,f14,f30
	ctx.f7.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// stfs f10,624(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 624, temp.u32);
	// fmuls f0,f0,f17
	ctx.f0.f64 = double(float(ctx.f0.f64 * ctx.f17.f64));
	// stfs f9,628(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 628, temp.u32);
	// stfs f7,632(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 632, temp.u32);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stfs f5,636(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 636, temp.u32);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// stfs f3,608(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// addi r5,r1,624
	ctx.r5.s64 = ctx.r1.s64 + 624;
	// stfs f2,612(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 612, temp.u32);
	// addi r4,r1,608
	ctx.r4.s64 = ctx.r1.s64 + 608;
	// stfs f1,616(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 616, temp.u32);
	// addi r3,r1,816
	ctx.r3.s64 = ctx.r1.s64 + 816;
	// stfs f0,620(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 620, temp.u32);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// stw r6,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r6.u32);
	// bl 0x82126c68
	ctx.lr = 0x821259D4;
	sub_82126C68(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// lfs f12,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f13,f31,f29
	ctx.f13.f64 = static_cast<float>(ctx.f31.f64 - ctx.f29.f64);
	// lfs f10,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f10.f64 = double(temp.f32);
	// addi r5,r1,736
	ctx.r5.s64 = ctx.r1.s64 + 736;
	// lfs f9,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f9.f64 = double(temp.f32);
	// addi r4,r1,480
	ctx.r4.s64 = ctx.r1.s64 + 480;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// addi r3,r1,944
	ctx.r3.s64 = ctx.r1.s64 + 944;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// fmuls f8,f12,f13
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stw r6,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r6.u32);
	// lfs f6,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f13,f11
	ctx.f5.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f7,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f4,f13,f10
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// stfs f8,480(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// fmuls f3,f13,f9
	ctx.f3.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// stfs f5,484(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// fmuls f0,f7,f29
	ctx.f0.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// stfs f4,488(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 488, temp.u32);
	// lfs f1,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f2,f6,f29
	ctx.f2.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// lfs f13,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f1,f29
	ctx.f12.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// fmuls f11,f13,f29
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f29.f64));
	// stfs f3,492(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// stfs f2,736(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 736, temp.u32);
	// stfs f0,740(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 740, temp.u32);
	// stfs f12,744(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 744, temp.u32);
	// stfs f11,748(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 748, temp.u32);
	// bl 0x82126c68
	ctx.lr = 0x82125A70;
	sub_82126C68(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// lwz r9,4(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// lwz r8,8(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwz r7,12(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
	// stw r7,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r7.u32);
	// bl 0x82126c20
	ctx.lr = 0x82125AA4;
	sub_82126C20(ctx, base);
	// lwz r6,8(r26)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// clrlwi r5,r6,31
	ctx.r5.u64 = ctx.r6.u32 & 0x1;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82125ac4
	if (ctx.cr6.eq) goto loc_82125AC4;
	// bl 0x820c6748
	ctx.lr = 0x82125ABC;
	sub_820C6748(ctx, base);
	// or r3,r3,r18
	ctx.r3.u64 = ctx.r3.u64 | ctx.r18.u64;
	// b 0x82125ac8
	goto loc_82125AC8;
loc_82125AC4:
	// bl 0x820c6748
	ctx.lr = 0x82125AC8;
	sub_820C6748(ctx, base);
loc_82125AC8:
	// stfs f15,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + 12, temp.u32);
	// stw r3,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r3.u32);
	// stfs f26,16(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 16, temp.u32);
	// stfs f28,0(r31)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// stfs f27,4(r31)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + 4, temp.u32);
	// lfs f0,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,8(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f13,f25,f0
	ctx.f13.f64 = static_cast<float>(ctx.f25.f64 - ctx.f0.f64);
	// fdivs f0,f31,f12
	ctx.f0.f64 = double(float(ctx.f31.f64 / ctx.f12.f64));
	// fmuls f11,f13,f0
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f11,f31
	ctx.cr6.compare(ctx.f11.f64, ctx.f31.f64);
	// bge cr6,0x82125b04
	if (!ctx.cr6.lt) goto loc_82125B04;
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f16
	ctx.cr6.compare(ctx.f12.f64, ctx.f16.f64);
	// ble cr6,0x82125b20
	if (!ctx.cr6.gt) goto loc_82125B20;
loc_82125B04:
	// fmuls f12,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x82125b18
	if (!ctx.cr6.lt) goto loc_82125B18;
	// fmuls f30,f13,f0
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// b 0x82125b24
	goto loc_82125B24;
loc_82125B18:
	// fmr f30,f31
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f31.f64;
	// b 0x82125b24
	goto loc_82125B24;
loc_82125B20:
	// fmr f30,f16
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f16.f64;
loc_82125B24:
	// lfs f0,4(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,12(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f24,f0
	ctx.f0.f64 = static_cast<float>(ctx.f24.f64 - ctx.f0.f64);
	// fdivs f13,f31,f13
	ctx.f13.f64 = double(float(ctx.f31.f64 / ctx.f13.f64));
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x82125b4c
	if (!ctx.cr6.lt) goto loc_82125B4C;
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f16
	ctx.cr6.compare(ctx.f12.f64, ctx.f16.f64);
	// ble cr6,0x82125b68
	if (!ctx.cr6.gt) goto loc_82125B68;
loc_82125B4C:
	// fmuls f12,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x82125b60
	if (!ctx.cr6.lt) goto loc_82125B60;
	// fmuls f29,f0,f13
	ctx.f29.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// b 0x82125b6c
	goto loc_82125B6C;
loc_82125B60:
	// fmr f29,f31
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f31.f64;
	// b 0x82125b6c
	goto loc_82125B6C;
loc_82125B68:
	// fmr f29,f16
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f16.f64;
loc_82125B6C:
	// fsubs f0,f31,f30
	ctx.fpscr.disableFlushMode();
	ctx.f0.f64 = static_cast<float>(ctx.f31.f64 - ctx.f30.f64);
	// lfs f13,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f13,f30
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f10,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f12,f30
	ctx.f9.f64 = double(float(ctx.f12.f64 * ctx.f30.f64));
	// lfs f8,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f10,f30
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f30.f64));
	// lfs f6,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f19,f30
	ctx.f5.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// lfs f28,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f28.f64 = double(temp.f32);
	// addi r5,r1,512
	ctx.r5.s64 = ctx.r1.s64 + 512;
	// stfs f11,512(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// addi r4,r1,640
	ctx.r4.s64 = ctx.r1.s64 + 640;
	// stfs f9,516(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// addi r3,r1,848
	ctx.r3.s64 = ctx.r1.s64 + 848;
	// stfs f7,520(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// stfs f5,524(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// fmuls f4,f0,f8
	ctx.f4.f64 = double(float(ctx.f0.f64 * ctx.f8.f64));
	// stfs f4,640(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 640, temp.u32);
	// fmuls f3,f0,f6
	ctx.f3.f64 = double(float(ctx.f0.f64 * ctx.f6.f64));
	// stfs f3,644(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 644, temp.u32);
	// fmuls f2,f0,f28
	ctx.f2.f64 = double(float(ctx.f0.f64 * ctx.f28.f64));
	// stfs f2,648(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 648, temp.u32);
	// fmuls f1,f0,f20
	ctx.f1.f64 = double(float(ctx.f0.f64 * ctx.f20.f64));
	// stfs f1,652(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 652, temp.u32);
	// stfs f0,80(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// bl 0x82126c68
	ctx.lr = 0x82125BDC;
	sub_82126C68(ctx, base);
	// lfs f0,240(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f0,f30
	ctx.f13.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// lfs f0,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f9,f14,f30
	ctx.f9.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// lfs f10,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f7,f18,f30
	ctx.f7.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// lfs f8,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f6,f12,f0
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f0.f64));
	// lfs f27,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f27.f64 = double(temp.f32);
	// fmuls f5,f10,f0
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f0.f64));
	// fmuls f11,f27,f30
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// stfs f13,544(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// fmuls f4,f8,f0
	ctx.f4.f64 = double(float(ctx.f8.f64 * ctx.f0.f64));
	// stfs f11,548(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 548, temp.u32);
	// fmuls f3,f17,f0
	ctx.f3.f64 = double(float(ctx.f17.f64 * ctx.f0.f64));
	// stfs f9,552(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// stfs f7,556(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 556, temp.u32);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stfs f6,704(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 704, temp.u32);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// stfs f5,708(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 708, temp.u32);
	// addi r5,r1,544
	ctx.r5.s64 = ctx.r1.s64 + 544;
	// stfs f4,712(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 712, temp.u32);
	// addi r4,r1,704
	ctx.r4.s64 = ctx.r1.s64 + 704;
	// stfs f3,716(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 716, temp.u32);
	// addi r3,r1,912
	ctx.r3.s64 = ctx.r1.s64 + 912;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// stw r6,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r6.u32);
	// bl 0x82126c68
	ctx.lr = 0x82125C6C;
	sub_82126C68(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// fsubs f2,f31,f29
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = static_cast<float>(ctx.f31.f64 - ctx.f29.f64);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// lfs f1,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f1.f64 = double(temp.f32);
	// addi r5,r1,672
	ctx.r5.s64 = ctx.r1.s64 + 672;
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f0.f64 = double(temp.f32);
	// addi r4,r1,576
	ctx.r4.s64 = ctx.r1.s64 + 576;
	// lfs f13,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// addi r3,r1,784
	ctx.r3.s64 = ctx.r1.s64 + 784;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lfs f12,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f12.f64 = double(temp.f32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// fmuls f11,f1,f2
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f2.f64));
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// fmuls f10,f0,f2
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f2.f64));
	// stw r6,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r6.u32);
	// fmuls f9,f13,f2
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f2.f64));
	// fmuls f8,f12,f2
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f2.f64));
	// stfs f11,576(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 576, temp.u32);
	// stfs f10,580(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// stfs f9,584(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// stfs f8,588(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// lfs f7,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f5,f7,f29
	ctx.f5.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// lfs f4,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f6,f29
	ctx.f3.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// lfs f2,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f2.f64 = double(temp.f32);
	// fmuls f1,f4,f29
	ctx.f1.f64 = double(float(ctx.f4.f64 * ctx.f29.f64));
	// fmuls f0,f2,f29
	ctx.f0.f64 = double(float(ctx.f2.f64 * ctx.f29.f64));
	// stfs f5,672(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 672, temp.u32);
	// stfs f3,676(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 676, temp.u32);
	// stfs f1,680(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 680, temp.u32);
	// stfs f0,684(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 684, temp.u32);
	// bl 0x82126c68
	ctx.lr = 0x82125D08;
	sub_82126C68(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// lwz r9,4(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// lwz r8,8(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwz r7,12(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
	// stw r7,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r7.u32);
	// bl 0x82126c20
	ctx.lr = 0x82125D3C;
	sub_82126C20(ctx, base);
	// lwz r6,8(r26)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// clrlwi r5,r6,31
	ctx.r5.u64 = ctx.r6.u32 & 0x1;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82125d5c
	if (ctx.cr6.eq) goto loc_82125D5C;
	// bl 0x820c6748
	ctx.lr = 0x82125D54;
	sub_820C6748(ctx, base);
	// or r3,r3,r18
	ctx.r3.u64 = ctx.r3.u64 | ctx.r18.u64;
	// b 0x82125d60
	goto loc_82125D60;
loc_82125D5C:
	// bl 0x820c6748
	ctx.lr = 0x82125D60;
	sub_820C6748(ctx, base);
loc_82125D60:
	// stfs f25,20(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r31.u32 + 20, temp.u32);
	// stw r3,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r3.u32);
	// stfs f24,24(r31)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + 24, temp.u32);
	// stfs f23,32(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 32, temp.u32);
	// stfs f26,36(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 36, temp.u32);
	// lfs f0,8(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f31,f0
	ctx.f0.f64 = double(float(ctx.f31.f64 / ctx.f0.f64));
	// fsubs f13,f22,f13
	ctx.f13.f64 = static_cast<float>(ctx.f22.f64 - ctx.f13.f64);
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x82125d9c
	if (!ctx.cr6.lt) goto loc_82125D9C;
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f16
	ctx.cr6.compare(ctx.f12.f64, ctx.f16.f64);
	// ble cr6,0x82125db8
	if (!ctx.cr6.gt) goto loc_82125DB8;
loc_82125D9C:
	// fmuls f12,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x82125db0
	if (!ctx.cr6.lt) goto loc_82125DB0;
	// fmuls f30,f13,f0
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// b 0x82125dbc
	goto loc_82125DBC;
loc_82125DB0:
	// fmr f30,f31
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f31.f64;
	// b 0x82125dbc
	goto loc_82125DBC;
loc_82125DB8:
	// fmr f30,f16
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f16.f64;
loc_82125DBC:
	// lfs f0,4(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,12(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f21,f0
	ctx.f0.f64 = static_cast<float>(ctx.f21.f64 - ctx.f0.f64);
	// fdivs f13,f31,f13
	ctx.f13.f64 = double(float(ctx.f31.f64 / ctx.f13.f64));
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x82125de4
	if (!ctx.cr6.lt) goto loc_82125DE4;
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f16
	ctx.cr6.compare(ctx.f12.f64, ctx.f16.f64);
	// ble cr6,0x82125e00
	if (!ctx.cr6.gt) goto loc_82125E00;
loc_82125DE4:
	// fmuls f12,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x82125df8
	if (!ctx.cr6.lt) goto loc_82125DF8;
	// fmuls f29,f0,f13
	ctx.f29.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// b 0x82125e04
	goto loc_82125E04;
loc_82125DF8:
	// fmr f29,f31
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f31.f64;
	// b 0x82125e04
	goto loc_82125E04;
loc_82125E00:
	// fmr f29,f16
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f16.f64;
loc_82125E04:
	// fsubs f26,f31,f30
	ctx.fpscr.disableFlushMode();
	ctx.f26.f64 = static_cast<float>(ctx.f31.f64 - ctx.f30.f64);
	// lfs f0,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f0,f30
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// lfs f11,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f13,f30
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f9,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f11,f30
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f7,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f19,f30
	ctx.f6.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// stfs f12,432(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// addi r5,r1,432
	ctx.r5.s64 = ctx.r1.s64 + 432;
	// stfs f10,436(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// addi r4,r1,464
	ctx.r4.s64 = ctx.r1.s64 + 464;
	// stfs f8,440(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// addi r3,r1,800
	ctx.r3.s64 = ctx.r1.s64 + 800;
	// stfs f6,444(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// fmuls f5,f9,f26
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f26.f64));
	// stfs f5,464(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// fmuls f4,f7,f26
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f26.f64));
	// stfs f4,468(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// fmuls f3,f28,f26
	ctx.f3.f64 = double(float(ctx.f28.f64 * ctx.f26.f64));
	// stfs f3,472(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// fmuls f2,f20,f26
	ctx.f2.f64 = double(float(ctx.f20.f64 * ctx.f26.f64));
	// stfs f2,476(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// bl 0x82126c68
	ctx.lr = 0x82125E6C;
	sub_82126C68(ctx, base);
	// lfs f1,240(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f1.f64 = double(temp.f32);
	// lfs f0,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f0.f64 = double(temp.f32);
	// fmuls f13,f1,f30
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f30.f64));
	// lfs f12,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f27,f30
	ctx.f11.f64 = double(float(ctx.f27.f64 * ctx.f30.f64));
	// lfs f10,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f14,f30
	ctx.f9.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// fmuls f8,f18,f30
	ctx.f8.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// stfs f13,496(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// fmuls f7,f0,f26
	ctx.f7.f64 = double(float(ctx.f0.f64 * ctx.f26.f64));
	// stfs f11,500(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// fmuls f6,f12,f26
	ctx.f6.f64 = double(float(ctx.f12.f64 * ctx.f26.f64));
	// stfs f9,504(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fmuls f5,f10,f26
	ctx.f5.f64 = double(float(ctx.f10.f64 * ctx.f26.f64));
	// stfs f8,508(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// fmuls f4,f17,f26
	ctx.f4.f64 = double(float(ctx.f17.f64 * ctx.f26.f64));
	// stfs f7,528(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// stfs f6,532(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stfs f5,536(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// stfs f4,540(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// addi r5,r1,496
	ctx.r5.s64 = ctx.r1.s64 + 496;
	// addi r4,r1,528
	ctx.r4.s64 = ctx.r1.s64 + 528;
	// addi r3,r1,832
	ctx.r3.s64 = ctx.r1.s64 + 832;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// stw r6,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r6.u32);
	// bl 0x82126c68
	ctx.lr = 0x82125EF4;
	sub_82126C68(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// fsubs f3,f31,f29
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = static_cast<float>(ctx.f31.f64 - ctx.f29.f64);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// lfs f2,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f2.f64 = double(temp.f32);
	// addi r5,r1,400
	ctx.r5.s64 = ctx.r1.s64 + 400;
	// lfs f1,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f1.f64 = double(temp.f32);
	// addi r4,r1,560
	ctx.r4.s64 = ctx.r1.s64 + 560;
	// lfs f0,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f0.f64 = double(temp.f32);
	// addi r3,r1,864
	ctx.r3.s64 = ctx.r1.s64 + 864;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// fmuls f12,f2,f3
	ctx.f12.f64 = double(float(ctx.f2.f64 * ctx.f3.f64));
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// fmuls f11,f1,f3
	ctx.f11.f64 = double(float(ctx.f1.f64 * ctx.f3.f64));
	// stw r6,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r6.u32);
	// fmuls f10,f0,f3
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f3.f64));
	// fmuls f8,f13,f3
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f3.f64));
	// lfs f9,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f9.f64 = double(temp.f32);
	// lfs f7,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f9,f29
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f29.f64));
	// lfs f5,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f7,f29
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f29.f64));
	// lfs f3,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f5,f29
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// fmuls f1,f3,f29
	ctx.f1.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// stfs f12,560(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 560, temp.u32);
	// stfs f11,564(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 564, temp.u32);
	// stfs f10,568(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// stfs f8,572(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// stfs f6,400(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// stfs f4,404(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// stfs f2,408(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// stfs f1,412(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// bl 0x82126c68
	ctx.lr = 0x82125F90;
	sub_82126C68(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// lwz r9,4(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// lwz r8,8(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwz r7,12(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
	// stw r7,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r7.u32);
	// bl 0x82126c20
	ctx.lr = 0x82125FC4;
	sub_82126C20(ctx, base);
	// lwz r6,8(r26)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// clrlwi r5,r6,31
	ctx.r5.u64 = ctx.r6.u32 & 0x1;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82125fe4
	if (ctx.cr6.eq) goto loc_82125FE4;
	// bl 0x820c6748
	ctx.lr = 0x82125FDC;
	sub_820C6748(ctx, base);
	// or r3,r3,r18
	ctx.r3.u64 = ctx.r3.u64 | ctx.r18.u64;
	// b 0x82125fe8
	goto loc_82125FE8;
loc_82125FE4:
	// bl 0x820c6748
	ctx.lr = 0x82125FE8;
	sub_820C6748(ctx, base);
loc_82125FE8:
	// lfs f26,320(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 320);
	ctx.f26.f64 = double(temp.f32);
	// stw r3,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r3.u32);
	// stfs f22,40(r31)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + 40, temp.u32);
	// stfs f21,44(r31)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r31.u32 + 44, temp.u32);
	// stfs f23,52(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 52, temp.u32);
	// stfs f26,56(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 56, temp.u32);
	// lfs f27,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f27.f64 = double(temp.f32);
	// lfs f0,8(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 8);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f31,f0
	ctx.f0.f64 = double(float(ctx.f31.f64 / ctx.f0.f64));
	// fsubs f13,f27,f13
	ctx.f13.f64 = static_cast<float>(ctx.f27.f64 - ctx.f13.f64);
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x8212602c
	if (!ctx.cr6.lt) goto loc_8212602C;
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f16
	ctx.cr6.compare(ctx.f12.f64, ctx.f16.f64);
	// ble cr6,0x82126048
	if (!ctx.cr6.gt) goto loc_82126048;
loc_8212602C:
	// fmuls f12,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x82126040
	if (!ctx.cr6.lt) goto loc_82126040;
	// fmuls f30,f13,f0
	ctx.f30.f64 = double(float(ctx.f13.f64 * ctx.f0.f64));
	// b 0x8212604c
	goto loc_8212604C;
loc_82126040:
	// fmr f30,f31
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f31.f64;
	// b 0x8212604c
	goto loc_8212604C;
loc_82126048:
	// fmr f30,f16
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f16.f64;
loc_8212604C:
	// lfs f0,4(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 4);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,12(r25)
	temp.u32 = PPC_LOAD_U32(ctx.r25.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// lfs f28,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f28.f64 = double(temp.f32);
	// fdivs f13,f31,f13
	ctx.f13.f64 = double(float(ctx.f31.f64 / ctx.f13.f64));
	// fsubs f0,f28,f0
	ctx.f0.f64 = static_cast<float>(ctx.f28.f64 - ctx.f0.f64);
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x82126078
	if (!ctx.cr6.lt) goto loc_82126078;
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f16
	ctx.cr6.compare(ctx.f12.f64, ctx.f16.f64);
	// ble cr6,0x82126094
	if (!ctx.cr6.gt) goto loc_82126094;
loc_82126078:
	// fmuls f12,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f31
	ctx.cr6.compare(ctx.f12.f64, ctx.f31.f64);
	// bge cr6,0x8212608c
	if (!ctx.cr6.lt) goto loc_8212608C;
	// fmuls f29,f0,f13
	ctx.f29.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// b 0x82126098
	goto loc_82126098;
loc_8212608C:
	// fmr f29,f31
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f31.f64;
	// b 0x82126098
	goto loc_82126098;
loc_82126094:
	// fmr f29,f16
	ctx.fpscr.disableFlushMode();
	ctx.f29.f64 = ctx.f16.f64;
loc_82126098:
	// fsubs f25,f31,f30
	ctx.fpscr.disableFlushMode();
	ctx.f25.f64 = static_cast<float>(ctx.f31.f64 - ctx.f30.f64);
	// lfs f0,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f0,f30
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// lfs f11,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f13,f30
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f9,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f11,f30
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f30.f64));
	// lfs f7,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f19,f30
	ctx.f6.f64 = double(float(ctx.f19.f64 * ctx.f30.f64));
	// lfs f5,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f5.f64 = double(temp.f32);
	// addi r5,r1,416
	ctx.r5.s64 = ctx.r1.s64 + 416;
	// stfs f12,416(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// addi r4,r1,656
	ctx.r4.s64 = ctx.r1.s64 + 656;
	// stfs f10,420(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// addi r3,r1,896
	ctx.r3.s64 = ctx.r1.s64 + 896;
	// stfs f8,424(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// stfs f6,428(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// fmuls f4,f9,f25
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// stfs f4,656(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 656, temp.u32);
	// fmuls f3,f7,f25
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// stfs f3,660(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 660, temp.u32);
	// fmuls f2,f5,f25
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f25.f64));
	// stfs f2,664(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 664, temp.u32);
	// fmuls f1,f20,f25
	ctx.f1.f64 = double(float(ctx.f20.f64 * ctx.f25.f64));
	// stfs f1,668(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 668, temp.u32);
	// bl 0x82126c68
	ctx.lr = 0x82126104;
	sub_82126C68(ctx, base);
	// lfs f0,240(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f0,f30
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f30.f64));
	// lfs f11,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f13,f30
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f30.f64));
	// lfs f9,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f8,f14,f30
	ctx.f8.f64 = double(float(ctx.f14.f64 * ctx.f30.f64));
	// lfs f7,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f18,f30
	ctx.f6.f64 = double(float(ctx.f18.f64 * ctx.f30.f64));
	// fmuls f5,f11,f25
	ctx.f5.f64 = double(float(ctx.f11.f64 * ctx.f25.f64));
	// stfs f12,688(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 688, temp.u32);
	// fmuls f4,f9,f25
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f25.f64));
	// stfs f10,692(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 692, temp.u32);
	// fmuls f3,f7,f25
	ctx.f3.f64 = double(float(ctx.f7.f64 * ctx.f25.f64));
	// stfs f8,696(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 696, temp.u32);
	// fmuls f2,f25,f17
	ctx.f2.f64 = double(float(ctx.f25.f64 * ctx.f17.f64));
	// stfs f6,700(r1)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r1.u32 + 700, temp.u32);
	// stfs f5,720(r1)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r1.u32 + 720, temp.u32);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// stfs f4,724(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 724, temp.u32);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// stfs f3,728(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 728, temp.u32);
	// addi r5,r1,688
	ctx.r5.s64 = ctx.r1.s64 + 688;
	// stfs f2,732(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 732, temp.u32);
	// addi r4,r1,720
	ctx.r4.s64 = ctx.r1.s64 + 720;
	// addi r3,r1,928
	ctx.r3.s64 = ctx.r1.s64 + 928;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// stw r6,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r6.u32);
	// bl 0x82126c68
	ctx.lr = 0x82126190;
	sub_82126C68(ctx, base);
	// mr r11,r3
	ctx.r11.u64 = ctx.r3.u64;
	// fsubs f1,f31,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = static_cast<float>(ctx.f31.f64 - ctx.f29.f64);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// addi r5,r1,448
	ctx.r5.s64 = ctx.r1.s64 + 448;
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// addi r4,r1,752
	ctx.r4.s64 = ctx.r1.s64 + 752;
	// lfs f12,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f12.f64 = double(temp.f32);
	// addi r3,r1,960
	ctx.r3.s64 = ctx.r1.s64 + 960;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// lfs f11,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f11.f64 = double(temp.f32);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r7,8(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// lwz r6,12(r11)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r11.u32 + 12);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// fmuls f10,f0,f1
	ctx.f10.f64 = double(float(ctx.f0.f64 * ctx.f1.f64));
	// stw r7,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r7.u32);
	// fmuls f9,f13,f1
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// stw r6,12(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12, ctx.r6.u32);
	// fmuls f8,f12,f1
	ctx.f8.f64 = double(float(ctx.f12.f64 * ctx.f1.f64));
	// fmuls f7,f1,f11
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// stfs f10,752(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 752, temp.u32);
	// stfs f9,756(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 756, temp.u32);
	// stfs f8,760(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 760, temp.u32);
	// stfs f7,764(r1)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r1.u32 + 764, temp.u32);
	// lfs f6,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f4,f6,f29
	ctx.f4.f64 = double(float(ctx.f6.f64 * ctx.f29.f64));
	// lfs f3,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f3.f64 = double(temp.f32);
	// fmuls f2,f5,f29
	ctx.f2.f64 = double(float(ctx.f5.f64 * ctx.f29.f64));
	// lfs f1,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f0,f3,f29
	ctx.f0.f64 = double(float(ctx.f3.f64 * ctx.f29.f64));
	// fmuls f13,f1,f29
	ctx.f13.f64 = double(float(ctx.f1.f64 * ctx.f29.f64));
	// stfs f4,448(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// stfs f2,452(r1)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// stfs f0,456(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// stfs f13,460(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// bl 0x82126c68
	ctx.lr = 0x8212622C;
	sub_82126C68(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r11,r1,96
	ctx.r11.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,336
	ctx.r4.s64 = ctx.r1.s64 + 336;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// lwz r9,4(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// lwz r8,8(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// lwz r7,12(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// stw r10,0(r11)
	PPC_STORE_U32(ctx.r11.u32 + 0, ctx.r10.u32);
	// stw r9,4(r11)
	PPC_STORE_U32(ctx.r11.u32 + 4, ctx.r9.u32);
	// stw r8,8(r11)
	PPC_STORE_U32(ctx.r11.u32 + 8, ctx.r8.u32);
	// stw r7,12(r11)
	PPC_STORE_U32(ctx.r11.u32 + 12, ctx.r7.u32);
	// bl 0x82126c20
	ctx.lr = 0x82126260;
	sub_82126C20(ctx, base);
	// lwz r6,8(r26)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r26.u32 + 8);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// clrlwi r5,r6,31
	ctx.r5.u64 = ctx.r6.u32 & 0x1;
	// cmplwi cr6,r5,0
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 0, ctx.xer);
	// beq cr6,0x82126280
	if (ctx.cr6.eq) goto loc_82126280;
	// bl 0x820c6748
	ctx.lr = 0x82126278;
	sub_820C6748(ctx, base);
	// or r3,r3,r18
	ctx.r3.u64 = ctx.r3.u64 | ctx.r18.u64;
	// b 0x82126284
	goto loc_82126284;
loc_82126280:
	// bl 0x820c6748
	ctx.lr = 0x82126284;
	sub_820C6748(ctx, base);
loc_82126284:
	// stfs f27,60(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + 60, temp.u32);
	// stw r3,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r3.u32);
	// stfs f28,64(r31)
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + 64, temp.u32);
	// addi r20,r20,1
	ctx.r20.s64 = ctx.r20.s64 + 1;
	// stfs f15,72(r31)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + 72, temp.u32);
	// stfs f26,76(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 76, temp.u32);
	// addi r31,r31,80
	ctx.r31.s64 = ctx.r31.s64 + 80;
	// lfs f14,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f14.f64 = double(temp.f32);
	// lfs f29,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f29.f64 = double(temp.f32);
	// b 0x82126324
	goto loc_82126324;
loc_821262AC:
	// lwz r11,20(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// stfs f28,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f28.f64);
	PPC_STORE_U32(ctx.r31.u32 + 0, temp.u32);
	// stfs f27,4(r31)
	temp.f32 = float(ctx.f27.f64);
	PPC_STORE_U32(ctx.r31.u32 + 4, temp.u32);
	// stfs f15,12(r31)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + 12, temp.u32);
	// stfs f26,16(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 16, temp.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(ctx.r31.u32 + 8, ctx.r11.u32);
	// lwz r10,20(r26)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// stfs f24,24(r31)
	temp.f32 = float(ctx.f24.f64);
	PPC_STORE_U32(ctx.r31.u32 + 24, temp.u32);
	// stfs f23,32(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 32, temp.u32);
	// stfs f25,20(r31)
	temp.f32 = float(ctx.f25.f64);
	PPC_STORE_U32(ctx.r31.u32 + 20, temp.u32);
	// stfs f26,36(r31)
	temp.f32 = float(ctx.f26.f64);
	PPC_STORE_U32(ctx.r31.u32 + 36, temp.u32);
	// stw r10,28(r31)
	PPC_STORE_U32(ctx.r31.u32 + 28, ctx.r10.u32);
	// lwz r9,20(r26)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// stfs f30,56(r31)
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 56, temp.u32);
	// stw r9,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r9.u32);
	// stfs f22,40(r31)
	temp.f32 = float(ctx.f22.f64);
	PPC_STORE_U32(ctx.r31.u32 + 40, temp.u32);
	// stfs f21,44(r31)
	temp.f32 = float(ctx.f21.f64);
	PPC_STORE_U32(ctx.r31.u32 + 44, temp.u32);
	// stfs f23,52(r31)
	temp.f32 = float(ctx.f23.f64);
	PPC_STORE_U32(ctx.r31.u32 + 52, temp.u32);
	// lwz r8,20(r26)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r26.u32 + 20);
	// stfs f11,64(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 64, temp.u32);
	// stw r8,68(r31)
	PPC_STORE_U32(ctx.r31.u32 + 68, ctx.r8.u32);
loc_82126300:
	// stfs f30,76(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f30.f64);
	PPC_STORE_U32(ctx.r31.u32 + 76, temp.u32);
	// addi r20,r20,1
	ctx.r20.s64 = ctx.r20.s64 + 1;
	// stfs f15,72(r31)
	temp.f32 = float(ctx.f15.f64);
	PPC_STORE_U32(ctx.r31.u32 + 72, temp.u32);
	// stfs f0,60(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 60, temp.u32);
	// addi r31,r31,80
	ctx.r31.s64 = ctx.r31.s64 + 80;
	// b 0x82126324
	goto loc_82126324;
loc_82126318:
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
loc_82126320:
	// beq cr6,0x82126334
	if (ctx.cr6.eq) goto loc_82126334;
loc_82126324:
	// addi r22,r22,1
	ctx.r22.s64 = ctx.r22.s64 + 1;
	// addi r26,r26,24
	ctx.r26.s64 = ctx.r26.s64 + 24;
	// cmplw cr6,r22,r14
	ctx.cr6.compare<uint32_t>(ctx.r22.u32, ctx.r14.u32, ctx.xer);
	// blt cr6,0x821250fc
	if (ctx.cr6.lt) goto loc_821250FC;
loc_82126334:
	// mr r3,r21
	ctx.r3.u64 = ctx.r21.u64;
	// bl 0x8210b488
	ctx.lr = 0x8212633C;
	sub_8210B488(ctx, base);
	// cmplwi cr6,r20,0
	ctx.cr6.compare<uint32_t>(ctx.r20.u32, 0, ctx.xer);
	// beq cr6,0x821263e0
	if (ctx.cr6.eq) goto loc_821263E0;
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r6,112(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// li r7,20
	ctx.r7.s64 = 20;
	// lwz r5,144(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x8222cc48
	ctx.lr = 0x82126360;
	sub_8222CC48(ctx, base);
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// lwz r11,25848(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25848);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r17)
	PPC_STORE_U32(ctx.r17.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r17)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r17.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r17)
	PPC_STORE_U64(ctx.r17.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82126388;
	sub_82238728(ctx, base);
	// clrlwi r7,r19,24
	ctx.r7.u64 = ctx.r19.u32 & 0xFF;
	// cmplwi cr6,r7,0
	ctx.cr6.compare<uint32_t>(ctx.r7.u32, 0, ctx.xer);
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// beq cr6,0x821263a0
	if (ctx.cr6.eq) goto loc_821263A0;
	// lwz r11,25848(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25848);
	// b 0x821263a8
	goto loc_821263A8;
loc_821263A0:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r11,25864(r11)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25864);
loc_821263A8:
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x821263B0;
	sub_82238380(ctx, base);
	// rlwinm r6,r20,2,0,29
	ctx.r6.u64 = rotl64(ctx.r20.u32 | (ctx.r20.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,13
	ctx.r4.s64 = 13;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x821263C4;
	sub_8222DFC8(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x8222cc48
	ctx.lr = 0x821263E0;
	sub_8222CC48(ctx, base);
loc_821263E0:
	// lwz r11,224(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// cmplw cr6,r27,r11
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x821250c0
	if (ctx.cr6.lt) goto loc_821250C0;
loc_821263F0:
	// lwz r11,272(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	// addi r16,r16,1
	ctx.r16.s64 = ctx.r16.s64 + 1;
	// cmplw cr6,r16,r11
	ctx.cr6.compare<uint32_t>(ctx.r16.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x821250a0
	if (ctx.cr6.lt) goto loc_821250A0;
loc_82126400:
	// lwz r11,148(r1)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	// addi r11,r11,1
	ctx.r11.s64 = ctx.r11.s64 + 1;
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r11.u32);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// blt cr6,0x8212503c
	if (ctx.cr6.lt) goto loc_8212503C;
	// lfs f28,264(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f28.f64 = double(temp.f32);
	// lfs f29,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f29.f64 = double(temp.f32);
loc_8212641C:
	// mr r5,r29
	ctx.r5.u64 = ctx.r29.u64;
	// lwz r4,352(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 352);
	// lwz r3,312(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 312);
	// bl 0x82082c20
	ctx.lr = 0x8212642C;
	sub_82082C20(ctx, base);
	// lwz r10,276(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// cmplwi cr6,r10,0
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 0, ctx.xer);
	// beq cr6,0x821265ac
	if (ctx.cr6.eq) goto loc_821265AC;
	// li r27,0
	ctx.r27.s64 = 0;
	// lwz r30,1340(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1340);
	// rlwinm r11,r10,1,0,30
	ctx.r11.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r27,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r27.u32);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// add r11,r10,r11
	ctx.r11.u64 = ctx.r10.u64 + ctx.r11.u64;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// rlwinm r3,r11,4,0,27
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r29,r27
	ctx.r29.u64 = ctx.r27.u64;
	// bl 0x8210b178
	ctx.lr = 0x82126460;
	sub_8210B178(ctx, base);
	// fmr f30,f16
	ctx.fpscr.disableFlushMode();
	ctx.f30.f64 = ctx.f16.f64;
	// fmr f31,f16
	ctx.f31.f64 = ctx.f16.f64;
	// cmplwi cr6,r14,0
	ctx.cr6.compare<uint32_t>(ctx.r14.u32, 0, ctx.xer);
	// beq cr6,0x8212650c
	if (ctx.cr6.eq) goto loc_8212650C;
	// lwz r26,1332(r1)
	ctx.r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 1332);
	// addi r31,r3,-4
	ctx.r31.s64 = ctx.r3.s64 + -4;
	// lis r28,-1
	ctx.r28.s64 = -65536;
loc_8212647C:
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// cmpwi cr6,r4,-1
	ctx.cr6.compare<int32_t>(ctx.r4.s32, -1, ctx.xer);
	// bne cr6,0x821264e0
	if (!ctx.cr6.eq) goto loc_821264E0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82111400
	ctx.lr = 0x82126494;
	sub_82111400(ctx, base);
	// lfs f0,12(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 12);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,16(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// stw r28,12(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12, ctx.r28.u32);
	// stfs f0,4(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 4, temp.u32);
	// fmadds f12,f30,f28,f0
	ctx.f12.f64 = double(std::fma(float(ctx.f30.f64), float(ctx.f28.f64), float(ctx.f0.f64)));
	// stfs f13,8(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 8, temp.u32);
	// stw r28,24(r31)
	PPC_STORE_U32(ctx.r31.u32 + 24, ctx.r28.u32);
	// stfs f12,16(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 16, temp.u32);
	// fmadds f11,f31,f29,f13
	ctx.f11.f64 = double(std::fma(float(ctx.f31.f64), float(ctx.f29.f64), float(ctx.f13.f64)));
	// stfs f13,20(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 20, temp.u32);
	// stw r28,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r28.u32);
	// stfs f12,28(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 28, temp.u32);
	// addi r29,r29,1
	ctx.r29.s64 = ctx.r29.s64 + 1;
	// stfs f11,32(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 32, temp.u32);
	// addi r30,r30,24
	ctx.r30.s64 = ctx.r30.s64 + 24;
	// stfs f0,40(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 40, temp.u32);
	// stfs f11,44(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 44, temp.u32);
	// stwu r28,48(r31)
	ea = 48 + ctx.r31.u32;
	PPC_STORE_U32(ea, ctx.r28.u32);
	ctx.r31.u32 = ea;
	// b 0x82126500
	goto loc_82126500;
loc_821264E0:
	// mr r3,r26
	ctx.r3.u64 = ctx.r26.u64;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// bl 0x82126d28
	ctx.lr = 0x821264EC;
	sub_82126D28(ctx, base);
	// lwzu r11,24(r30)
	ea = 24 + ctx.r30.u32;
	ctx.r11.u64 = PPC_LOAD_U32(ea);
	ctx.r30.u32 = ea;
	// lfs f31,28(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f31.f64 = double(temp.f32);
	// lfs f30,24(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f30.f64 = double(temp.f32);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x8212650c
	if (ctx.cr6.eq) goto loc_8212650C;
loc_82126500:
	// addi r27,r27,1
	ctx.r27.s64 = ctx.r27.s64 + 1;
	// cmplw cr6,r27,r14
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, ctx.r14.u32, ctx.xer);
	// blt cr6,0x8212647c
	if (ctx.cr6.lt) goto loc_8212647C;
loc_8212650C:
	// rlwinm r11,r29,1,0,30
	ctx.r11.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r29,r11
	ctx.r11.u64 = ctx.r29.u64 + ctx.r11.u64;
	// rlwinm r3,r11,4,0,27
	ctx.r3.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// bl 0x8210b488
	ctx.lr = 0x8212651C;
	sub_8210B488(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,12
	ctx.r7.s64 = 12;
	// lwz r6,112(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,144(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x8222cc48
	ctx.lr = 0x82126538;
	sub_8222CC48(ctx, base);
	// lis r31,-32178
	ctx.r31.s64 = -2108817408;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// lwz r11,25840(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25840);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r17)
	PPC_STORE_U32(ctx.r17.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r17)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r17.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r17)
	PPC_STORE_U64(ctx.r17.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82126560;
	sub_82238728(ctx, base);
	// lwz r11,25840(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 25840);
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82126570;
	sub_82238380(ctx, base);
	// rlwinm r6,r29,2,0,29
	ctx.r6.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,13
	ctx.r4.s64 = 13;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x82126584;
	sub_8222DFC8(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r17
	ctx.r3.u64 = ctx.r17.u64;
	// bl 0x8222cc48
	ctx.lr = 0x821265A0;
	sub_8222CC48(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x821265AC;
	sub_82111340(ctx, base);
loc_821265AC:
	// addi r1,r1,1280
	ctx.r1.s64 = ctx.r1.s64 + 1280;
	// addi r12,r1,-152
	ctx.r12.s64 = ctx.r1.s64 + -152;
	// bl 0x8233fa4c
	ctx.lr = 0x821265B8;
	__savefpr_14(ctx, base);
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821265BC"))) PPC_WEAK_FUNC(sub_821265BC);
PPC_FUNC_IMPL(__imp__sub_821265BC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_821265C0"))) PPC_WEAK_FUNC(sub_821265C0);
PPC_FUNC_IMPL(__imp__sub_821265C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x821265C8;
	__restfpr_28(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,24(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r28,r4
	ctx.r28.u64 = ctx.r4.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82126704
	if (ctx.cr6.eq) goto loc_82126704;
	// addic. r30,r4,12
	ctx.xer.ca = ctx.r4.u32 > 4294967283;
	ctx.r30.s64 = ctx.r4.s64 + 12;
	ctx.cr0.compare<int32_t>(ctx.r30.s32, 0, ctx.xer);
	// beq 0x82126704
	if (ctx.cr0.eq) goto loc_82126704;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// lwz r5,364(r31)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r31.u32 + 364);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x82126610
	if (ctx.cr6.eq) goto loc_82126610;
	// stw r5,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x82126610;
	sub_8222CDF8(ctx, base);
loc_82126610:
	// lwz r3,368(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 368);
	// bl 0x8210b080
	ctx.lr = 0x82126618;
	sub_8210B080(ctx, base);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r10,r11,31376
	ctx.r10.s64 = ctx.r11.s64 + 31376;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,16
	ctx.r3.s64 = 16;
	// lfs f1,48(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210afd8
	ctx.lr = 0x82126634;
	sub_8210AFD8(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,200
	ctx.r3.s64 = 200;
	// bl 0x82111340
	ctx.lr = 0x82126640;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,304
	ctx.r3.s64 = 304;
	// bl 0x82111340
	ctx.lr = 0x8212664C;
	sub_82111340(ctx, base);
	// lis r9,-32182
	ctx.r9.s64 = -2109079552;
	// lwz r4,28(r28)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r28.u32 + 28);
	// addi r3,r9,-27800
	ctx.r3.s64 = ctx.r9.s64 + -27800;
	// bl 0x8211fa50
	ctx.lr = 0x8212665C;
	sub_8211FA50(ctx, base);
	// lwz r4,0(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// stw r4,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r4.u32);
	// beq cr6,0x821266e0
	if (ctx.cr6.eq) goto loc_821266E0;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// stw r11,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r11.u32);
loc_82126674:
	// lwz r11,0(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r11,r11,-20
	ctx.r11.s64 = ctx.r11.s64 + -20;
	// cmplwi cr6,r11,3
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 3, ctx.xer);
	// bgt cr6,0x821266c8
	if (ctx.cr6.gt) goto loc_821266C8;
	// mtctr r11
	ctx.ctr.u64 = ctx.r11.u64;
	// cmpwi cr6,r11,0
	ctx.cr6.compare<int32_t>(ctx.r11.s32, 0, ctx.xer);
	// bdzf 4*cr6+eq,0x821266a4
	--ctx.ctr.u64;
	if (ctx.ctr.u32 == 0 && !ctx.cr6.eq) goto loc_821266A4;
	// bdzf 4*cr6+eq,0x821266c0
	--ctx.ctr.u64;
	if (ctx.ctr.u32 == 0 && !ctx.cr6.eq) goto loc_821266C0;
	// bne cr6,0x821266b0
	if (!ctx.cr6.eq) goto loc_821266B0;
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82123ba8
	ctx.lr = 0x821266A0;
	sub_82123BA8(ctx, base);
	// b 0x821266c8
	goto loc_821266C8;
loc_821266A4:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82123d78
	ctx.lr = 0x821266AC;
	sub_82123D78(ctx, base);
	// b 0x821266c8
	goto loc_821266C8;
loc_821266B0:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// lwz r5,24(r28)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r28.u32 + 24);
	// bl 0x82124718
	ctx.lr = 0x821266BC;
	sub_82124718(ctx, base);
	// b 0x821266c8
	goto loc_821266C8;
loc_821266C0:
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// bl 0x82124a88
	ctx.lr = 0x821266C8;
	sub_82124A88(ctx, base);
loc_821266C8:
	// lwz r4,8(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + 8);
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// beq cr6,0x821266e0
	if (ctx.cr6.eq) goto loc_821266E0;
	// lwz r11,4(r4)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// stw r11,8(r30)
	PPC_STORE_U32(ctx.r30.u32 + 8, ctx.r11.u32);
	// bne cr6,0x82126674
	if (!ctx.cr6.eq) goto loc_82126674;
loc_821266E0:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,200
	ctx.r3.s64 = 200;
	// bl 0x82111340
	ctx.lr = 0x821266EC;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,304
	ctx.r3.s64 = 304;
	// bl 0x82111340
	ctx.lr = 0x821266F8;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82126704;
	sub_821112B0(ctx, base);
loc_82126704:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8212670C"))) PPC_WEAK_FUNC(sub_8212670C);
PPC_FUNC_IMPL(__imp__sub_8212670C) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82126710"))) PPC_WEAK_FUNC(sub_82126710);
PPC_FUNC_IMPL(__imp__sub_82126710) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e430
	ctx.lr = 0x82126718;
	__restfpr_14(ctx, base);
	// stfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -160, ctx.f31.u64);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lwz r14,44(r4)
	ctx.r14.u64 = PPC_LOAD_U32(ctx.r4.u32 + 44);
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// lwz r22,24(r4)
	ctx.r22.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// addi r26,r11,31376
	ctx.r26.s64 = ctx.r11.s64 + 31376;
	// lwz r9,172(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 172);
	// lwz r8,168(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 168);
	// addi r11,r10,-27800
	ctx.r11.s64 = ctx.r10.s64 + -27800;
	// lwz r7,48(r4)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r4.u32 + 48);
	// li r28,0
	ctx.r28.s64 = 0;
	// addi r6,r11,2120
	ctx.r6.s64 = ctx.r11.s64 + 2120;
	// lbz r25,263(r14)
	ctx.r25.u64 = PPC_LOAD_U8(ctx.r14.u32 + 263);
	// li r5,-1
	ctx.r5.s64 = -1;
	// lwz r11,8(r22)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r22.u32 + 8);
	// lfs f0,36(r26)
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stw r9,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r9.u32);
	// stfs f0,120(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// stw r5,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r5.u32);
	// stw r7,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r7.u32);
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// stb r28,124(r1)
	PPC_STORE_U8(ctx.r1.u32 + 124, ctx.r28.u8);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// stw r8,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r8.u32);
	// stb r28,125(r1)
	PPC_STORE_U8(ctx.r1.u32 + 125, ctx.r28.u8);
	// stw r28,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r28.u32);
	// stw r28,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r28.u32);
	// stw r28,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r28.u32);
	// stw r6,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r6.u32);
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r3,r14
	ctx.r3.u64 = ctx.r14.u64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r11.u32);
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r28.u32);
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r28.u32);
	// bl 0x8210f908
	ctx.lr = 0x821267A8;
	sub_8210F908(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x821267B4;
	sub_82111340(ctx, base);
	// lfs f0,52(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 52);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,6288(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6288, temp.u32);
	// li r12,1
	ctx.r12.s64 = 1;
	// lfs f13,56(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stfs f13,6292(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6292, temp.u32);
	// rldicr r12,r12,59,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 59) & 0xFFFFFFFFFFFFFFFF;
	// lfs f12,60(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 60);
	ctx.f12.f64 = double(temp.f32);
	// rldicr r18,r10,63,63
	ctx.r18.u64 = rotl64(ctx.r10.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// stfs f12,6296(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6296, temp.u32);
	// lfs f11,64(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 64);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,6300(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6300, temp.u32);
	// ld r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r8,r9,r12
	ctx.r8.u64 = ctx.r9.u64 | ctx.r12.u64;
	// std r8,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r8.u64);
	// lwz r27,140(r29)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r29.u32 + 140);
	// cmplwi cr6,r27,0
	ctx.cr6.compare<uint32_t>(ctx.r27.u32, 0, ctx.xer);
	// beq cr6,0x82126840
	if (ctx.cr6.eq) goto loc_82126840;
	// addi r30,r29,72
	ctx.r30.s64 = ctx.r29.s64 + 72;
loc_82126800:
	// lwz r4,-4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r30.u32 + -4);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r6,4(r30)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r30.u32 + 4);
	// rlwinm r10,r4,30,2,31
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r30.u32 + 0);
	// add r11,r4,r6
	ctx.r11.u64 = ctx.r4.u64 + ctx.r6.u64;
	// addi r9,r11,-1
	ctx.r9.s64 = ctx.r11.s64 + -1;
	// rlwinm r8,r9,30,2,31
	ctx.r8.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
	// subf r7,r10,r8
	ctx.r7.s64 = ctx.r8.s64 - ctx.r10.s64;
	// clrldi r11,r7,32
	ctx.r11.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// srad r9,r18,r11
	temp.u64 = ctx.r11.u64 & 0x7F;
	if (temp.u64 > 0x3F) temp.u64 = 0x3F;
	ctx.xer.ca = (ctx.r18.s64 < 0) & (((ctx.r18.s64 >> temp.u64) << temp.u64) != ctx.r18.s64);
	ctx.r9.s64 = ctx.r18.s64 >> temp.u64;
	// srd r7,r9,r10
	ctx.r7.u64 = ctx.r10.u8 & 0x40 ? 0 : (ctx.r9.u64 >> (ctx.r10.u8 & 0x7F));
	// bl 0x82238120
	ctx.lr = 0x82126834;
	sub_82238120(ctx, base);
	// addic. r27,r27,-1
	ctx.xer.ca = ctx.r27.u32 > 0;
	ctx.r27.s64 = ctx.r27.s64 + -1;
	ctx.cr0.compare<int32_t>(ctx.r27.s32, 0, ctx.xer);
	// addi r30,r30,12
	ctx.r30.s64 = ctx.r30.s64 + 12;
	// bne 0x82126800
	if (!ctx.cr0.eq) goto loc_82126800;
loc_82126840:
	// mr r3,r14
	ctx.r3.u64 = ctx.r14.u64;
	// bl 0x8210fb60
	ctx.lr = 0x82126848;
	sub_8210FB60(ctx, base);
	// addi r3,r29,176
	ctx.r3.s64 = ctx.r29.s64 + 176;
	// bl 0x82113ab8
	ctx.lr = 0x82126850;
	sub_82113AB8(ctx, base);
	// lhz r11,32(r29)
	ctx.r11.u64 = PPC_LOAD_U16(ctx.r29.u32 + 32);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// lhz r17,34(r29)
	ctx.r17.u64 = PPC_LOAD_U16(ctx.r29.u32 + 34);
	// mullw r30,r11,r17
	ctx.r30.s64 = int64_t(ctx.r11.s32) * int64_t(ctx.r17.s32);
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x8210b178
	ctx.lr = 0x8212686C;
	sub_8210B178(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82126bcc
	if (ctx.cr6.eq) goto loc_82126BCC;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// lwz r4,28(r29)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r29.u32 + 28);
	// bl 0x8233e4e0
	ctx.lr = 0x82126880;
	sub_8233E4E0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// mr r10,r28
	ctx.r10.u64 = ctx.r28.u64;
	// addi r11,r11,27648
	ctx.r11.s64 = ctx.r11.s64 + 27648;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r8,r11,200
	ctx.r8.s64 = ctx.r11.s64 + 200;
	// lwz r9,268(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 268);
	// stb r28,264(r11)
	PPC_STORE_U8(ctx.r11.u32 + 264, ctx.r28.u8);
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,272(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 272);
	// add r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 + ctx.r30.u64;
	// addi r6,r10,31
	ctx.r6.s64 = ctx.r10.s64 + 31;
	// rlwinm r10,r6,0,0,26
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFE0;
	// stw r10,272(r11)
	PPC_STORE_U32(ctx.r11.u32 + 272, ctx.r10.u32);
	// lwzx r3,r7,r8
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r8.u32);
	// lwz r4,24(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r4,r4,0,0,29
	ctx.r4.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFC;
	// bl 0x8222ee68
	ctx.lr = 0x821268C4;
	sub_8222EE68(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// mr r7,r17
	ctx.r7.u64 = ctx.r17.u64;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x821268E0;
	sub_8222CC48(ctx, base);
	// addi r20,r31,6176
	ctx.r20.s64 = ctx.r31.s64 + 6176;
	// li r5,16
	ctx.r5.s64 = 16;
	// mr r4,r20
	ctx.r4.u64 = ctx.r20.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82247bf8
	ctx.lr = 0x821268F4;
	sub_82247BF8(ctx, base);
	// li r16,1
	ctx.r16.s64 = 1;
	// lfs f31,48(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r26.u32 + 48);
	ctx.f31.f64 = double(temp.f32);
	// lfs f0,56(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 56);
	ctx.f0.f64 = double(temp.f32);
	// mr r11,r16
	ctx.r11.u64 = ctx.r16.u64;
	// fcmpu cr6,f0,f31
	ctx.cr6.compare(ctx.f0.f64, ctx.f31.f64);
	// bgt cr6,0x82126910
	if (ctx.cr6.gt) goto loc_82126910;
	// mr r11,r28
	ctx.r11.u64 = ctx.r28.u64;
loc_82126910:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r15,r28
	ctx.r15.u64 = ctx.r28.u64;
	// rldicr r19,r10,61,63
	ctx.r19.u64 = rotl64(ctx.r10.u64, 61) & 0xFFFFFFFFFFFFFFFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82126974
	if (ctx.cr6.eq) goto loc_82126974;
	// lwz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	// lfs f0,44(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 44);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r20)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// li r3,208
	ctx.r3.s64 = 208;
	// lfs f13,48(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r15,r11,31,1,31
	ctx.r15.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 31) & 0x7FFFFFFF;
	// stfs f13,6180(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6180, temp.u32);
	// lfs f12,52(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 52);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,6184(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6184, temp.u32);
	// lfs f11,56(r22)
	temp.u32 = PPC_LOAD_U32(ctx.r22.u32 + 56);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,6188(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6188, temp.u32);
	// ld r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r9,r10,r19
	ctx.r9.u64 = ctx.r10.u64 | ctx.r19.u64;
	// std r9,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r9.u64);
	// lwz r4,28(r22)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r22.u32 + 28);
	// bl 0x82111340
	ctx.lr = 0x82126968;
	sub_82111340(ctx, base);
	// li r3,204
	ctx.r3.s64 = 204;
	// lwz r4,32(r22)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r22.u32 + 32);
	// bl 0x82111340
	ctx.lr = 0x82126974;
	sub_82111340(ctx, base);
loc_82126974:
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,48(r29)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r29.u32 + 48);
	// mr r3,r14
	ctx.r3.u64 = ctx.r14.u64;
	// bl 0x82110610
	ctx.lr = 0x82126984;
	sub_82110610(ctx, base);
	// lwz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	// mr r21,r28
	ctx.r21.u64 = ctx.r28.u64;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// ble cr6,0x82126b74
	if (!ctx.cr6.gt) goto loc_82126B74;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// addi r26,r11,28184
	ctx.r26.s64 = ctx.r11.s64 + 28184;
loc_8212699C:
	// cmplw cr6,r21,r15
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, ctx.r15.u32, ctx.xer);
	// bne cr6,0x821269f8
	if (!ctx.cr6.eq) goto loc_821269F8;
	// lfs f0,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,0(r20)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r20.u32 + 0, temp.u32);
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,6180(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6180, temp.u32);
	// lfs f12,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,6184(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6184, temp.u32);
	// lfs f11,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,6188(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 6188, temp.u32);
	// ld r11,8(r31)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r10,r11,r19
	ctx.r10.u64 = ctx.r11.u64 | ctx.r19.u64;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// lwz r4,20(r22)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r22.u32 + 20);
	// lwz r11,1188(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 1188);
	// cmplw cr6,r11,r4
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r4.u32, ctx.xer);
	// beq cr6,0x821269ec
	if (ctx.cr6.eq) goto loc_821269EC;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// bl 0x8222b3b0
	ctx.lr = 0x821269E8;
	sub_8222B3B0(ctx, base);
	// stw r4,1188(r26)
	PPC_STORE_U32(ctx.r26.u32 + 1188, ctx.r4.u32);
loc_821269EC:
	// li r3,204
	ctx.r3.s64 = 204;
	// lwz r4,24(r22)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r22.u32 + 24);
	// bl 0x82111340
	ctx.lr = 0x821269F8;
	sub_82111340(ctx, base);
loc_821269F8:
	// lwz r11,40(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 40);
	// twllei r17,0
	if (ctx.r17.u32 <= 0) __builtin_debugtrap();
	// add r11,r28,r11
	ctx.r11.u64 = ctx.r28.u64 + ctx.r11.u64;
	// lhz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U16(ctx.r11.u32 + 0);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// lwz r5,8(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// cmplwi cr6,r4,65535
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 65535, ctx.xer);
	// lhz r24,2(r11)
	ctx.r24.u64 = PPC_LOAD_U16(ctx.r11.u32 + 2);
	// divwu r23,r9,r17
	ctx.r23.u32 = ctx.r9.u32 / ctx.r17.u32;
	// beq cr6,0x82126b4c
	if (ctx.cr6.eq) goto loc_82126B4C;
	// cmpwi cr6,r5,-1
	ctx.cr6.compare<int32_t>(ctx.r5.s32, -1, ctx.xer);
	// beq cr6,0x82126b4c
	if (ctx.cr6.eq) goto loc_82126B4C;
	// lwz r3,88(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// bl 0x82126d28
	ctx.lr = 0x82126A30;
	sub_82126D28(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82126b4c
	if (ctx.cr6.eq) goto loc_82126B4C;
	// lwz r30,0(r3)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x82126b4c
	if (ctx.cr6.eq) goto loc_82126B4C;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x82172e00
	ctx.lr = 0x82126A50;
	sub_82172E00(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82126b4c
	if (ctx.cr6.eq) goto loc_82126B4C;
	// lwz r3,96(r30)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r30.u32 + 96);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82126a70
	if (ctx.cr6.eq) goto loc_82126A70;
	// bl 0x820b91d0
	ctx.lr = 0x82126A6C;
	sub_820B91D0(ctx, base);
	// b 0x82126a8c
	goto loc_82126A8C;
loc_82126A70:
	// lwz r11,88(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82126a84
	if (ctx.cr6.eq) goto loc_82126A84;
	// lwz r27,88(r30)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	// b 0x82126a90
	goto loc_82126A90;
loc_82126A84:
	// mr r3,r30
	ctx.r3.u64 = ctx.r30.u64;
	// bl 0x820b90a0
	ctx.lr = 0x82126A8C;
	sub_820B90A0(ctx, base);
loc_82126A8C:
	// mr r27,r3
	ctx.r27.u64 = ctx.r3.u64;
loc_82126A90:
	// mr r3,r25
	ctx.r3.u64 = ctx.r25.u64;
	// lwz r4,4(r27)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r27.u32 + 4);
	// bl 0x82111400
	ctx.lr = 0x82126A9C;
	sub_82111400(ctx, base);
	// rlwinm r11,r25,2,0,29
	ctx.r11.u64 = rotl64(ctx.r25.u32 | (ctx.r25.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r25,r11
	ctx.r11.u64 = ctx.r25.u64 + ctx.r11.u64;
	// rlwinm r11,r11,6,0,25
	ctx.r11.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 6) & 0xFFFFFFC0;
	// add r30,r11,r26
	ctx.r30.u64 = ctx.r11.u64 + ctx.r26.u64;
	// lwz r10,2052(r30)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2052);
	// cmplwi cr6,r10,1
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, 1, ctx.xer);
	// beq cr6,0x82126acc
	if (ctx.cr6.eq) goto loc_82126ACC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// bl 0x8222c0a0
	ctx.lr = 0x82126AC8;
	sub_8222C0A0(ctx, base);
	// stw r16,2052(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2052, ctx.r16.u32);
loc_82126ACC:
	// lwz r11,2036(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2036);
	// cmplwi cr6,r11,1
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 1, ctx.xer);
	// beq cr6,0x82126aec
	if (ctx.cr6.eq) goto loc_82126AEC;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,0(r26)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// mr r4,r25
	ctx.r4.u64 = ctx.r25.u64;
	// bl 0x8222c248
	ctx.lr = 0x82126AE8;
	sub_8222C248(ctx, base);
	// stw r16,2036(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2036, ctx.r16.u32);
loc_82126AEC:
	// lwz r11,20(r27)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r27.u32 + 20);
	// lwz r9,2068(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 2068);
	// subfic r8,r11,1
	ctx.xer.ca = ctx.r11.u32 <= 1;
	ctx.r8.s64 = 1 - ctx.r11.s64;
	// subfe r11,r8,r8
	temp.u8 = (~ctx.r8.u32 + ctx.r8.u32 < ~ctx.r8.u32) | (~ctx.r8.u32 + ctx.r8.u32 + ctx.xer.ca < ctx.xer.ca);
	ctx.r11.u64 = ~ctx.r8.u64 + ctx.r8.u64 + ctx.xer.ca;
	ctx.xer.ca = temp.u8;
	// addi r10,r11,2
	ctx.r10.s64 = ctx.r11.s64 + 2;
	// cmplw cr6,r9,r10
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, ctx.xer);
	// beq cr6,0x82126b4c
	if (ctx.cr6.eq) goto loc_82126B4C;
	// rlwinm r9,r25,1,0,30
	ctx.r9.u64 = rotl64(ctx.r25.u32 | (ctx.r25.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,0(r26)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r26.u32 + 0);
	// addi r8,r25,32
	ctx.r8.s64 = ctx.r25.s64 + 32;
	// add r7,r25,r9
	ctx.r7.u64 = ctx.r25.u64 + ctx.r9.u64;
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// rlwinm r9,r7,3,0,28
	ctx.r9.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// clrldi r5,r8,32
	ctx.r5.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// add r11,r9,r11
	ctx.r11.u64 = ctx.r9.u64 + ctx.r11.u64;
	// srd r4,r18,r5
	ctx.r4.u64 = ctx.r5.u8 & 0x40 ? 0 : (ctx.r18.u64 >> (ctx.r5.u8 & 0x7F));
	// lwz r3,1164(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// addi r9,r11,1164
	ctx.r9.s64 = ctx.r11.s64 + 1164;
	// rlwimi r3,r10,23,7,8
	ctx.r3.u64 = (rotl32(ctx.r10.u32, 23) & 0x1800000) | (ctx.r3.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r3,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r3.u32);
	// ld r11,24(r6)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r6.u32 + 24);
	// or r9,r4,r11
	ctx.r9.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r9,24(r6)
	PPC_STORE_U64(ctx.r6.u32 + 24, ctx.r9.u64);
	// stw r10,2068(r30)
	PPC_STORE_U32(ctx.r30.u32 + 2068, ctx.r10.u32);
loc_82126B4C:
	// rlwinm r6,r24,2,14,29
	ctx.r6.u64 = rotl64(ctx.r24.u32 | (ctx.r24.u64 << 32), 2) & 0x3FFFC;
	// mr r5,r23
	ctx.r5.u64 = ctx.r23.u64;
	// li r4,13
	ctx.r4.s64 = 13;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222dfc8
	ctx.lr = 0x82126B60;
	sub_8222DFC8(ctx, base);
	// lwz r11,36(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 36);
	// addi r21,r21,1
	ctx.r21.s64 = ctx.r21.s64 + 1;
	// addi r28,r28,12
	ctx.r28.s64 = ctx.r28.s64 + 12;
	// cmplw cr6,r21,r11
	ctx.cr6.compare<uint32_t>(ctx.r21.u32, ctx.r11.u32, ctx.xer);
	// blt cr6,0x8212699c
	if (ctx.cr6.lt) goto loc_8212699C;
loc_82126B74:
	// mr r3,r14
	ctx.r3.u64 = ctx.r14.u64;
	// bl 0x82110080
	ctx.lr = 0x82126B7C;
	sub_82110080(ctx, base);
	// mr r3,r14
	ctx.r3.u64 = ctx.r14.u64;
	// bl 0x821104c8
	ctx.lr = 0x82126B84;
	sub_821104C8(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82126B90;
	sub_82111340(ctx, base);
	// stfs f31,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// li r3,208
	ctx.r3.s64 = 208;
	// lwz r30,88(r1)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// bl 0x82111340
	ctx.lr = 0x82126BA4;
	sub_82111340(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// li r3,204
	ctx.r3.s64 = 204;
	// bl 0x82111340
	ctx.lr = 0x82126BB0;
	sub_82111340(ctx, base);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x8222cc48
	ctx.lr = 0x82126BCC;
	sub_8222CC48(ctx, base);
loc_82126BCC:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// lfd f31,-160(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x8233e480
	__restgprlr_14(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82126BD8"))) PPC_WEAK_FUNC(sub_82126BD8);
PPC_FUNC_IMPL(__imp__sub_82126BD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r11,0
	ctx.r11.s64 = 0;
	// addi r9,r10,31376
	ctx.r9.s64 = ctx.r10.s64 + 31376;
	// li r8,11
	ctx.r8.s64 = 11;
	// stb r11,12(r3)
	PPC_STORE_U8(ctx.r3.u32 + 12, ctx.r11.u8);
	// li r7,-1
	ctx.r7.s64 = -1;
	// stb r11,13(r3)
	PPC_STORE_U8(ctx.r3.u32 + 13, ctx.r11.u8);
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// stw r7,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r7.u32);
	// lfs f0,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r11.u32);
	// stfs f0,8(r3)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, ctx.r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, ctx.r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82126C20"))) PPC_WEAK_FUNC(sub_82126C20);
PPC_FUNC_IMPL(__imp__sub_82126C20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(ctx.f0.f64 * ctx.f13.f64));
	// lfs f11,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// stfs f12,0(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f10,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f9,f10,f11
	ctx.f9.f64 = double(float(ctx.f10.f64 * ctx.f11.f64));
	// lfs f8,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// stfs f9,4(r3)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// lfs f7,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f6,f7,f8
	ctx.f6.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f5,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// stfs f6,8(r3)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// lfs f4,12(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fmuls f3,f4,f5
	ctx.f3.f64 = double(float(ctx.f4.f64 * ctx.f5.f64));
	// stfs f3,12(r3)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82126C64"))) PPC_WEAK_FUNC(sub_82126C64);
PPC_FUNC_IMPL(__imp__sub_82126C64) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82126C68"))) PPC_WEAK_FUNC(sub_82126C68);
PPC_FUNC_IMPL(__imp__sub_82126C68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f0.f64 = double(temp.f32);
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fadds f11,f0,f13
	ctx.f11.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// lfs f10,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,8(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fadds f8,f12,f10
	ctx.f8.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// lfs f7,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,12(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// fadds f5,f9,f7
	ctx.f5.f64 = double(float(ctx.f9.f64 + ctx.f7.f64));
	// lfs f4,12(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	ctx.f4.f64 = double(temp.f32);
	// fadds f3,f6,f4
	ctx.f3.f64 = double(float(ctx.f6.f64 + ctx.f4.f64));
	// stfs f11,0(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f8,4(r3)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// stfs f5,8(r3)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// stfs f3,12(r3)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82126CAC"))) PPC_WEAK_FUNC(sub_82126CAC);
PPC_FUNC_IMPL(__imp__sub_82126CAC) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82126CB0"))) PPC_WEAK_FUNC(sub_82126CB0);
PPC_FUNC_IMPL(__imp__sub_82126CB0) {
	PPC_FUNC_PROLOGUE();
	// lwz r11,88(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 88);
	// cmplw cr6,r4,r11
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, ctx.r11.u32, ctx.xer);
	// bge cr6,0x82126cd4
	if (!ctx.cr6.lt) goto loc_82126CD4;
	// lwz r11,80(r3)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 80);
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r11.u32 + ctx.r10.u32);
	// li r11,1
	ctx.r11.s64 = 1;
	// cmplwi cr6,r9,0
	ctx.cr6.compare<uint32_t>(ctx.r9.u32, 0, ctx.xer);
	// bne cr6,0x82126cd8
	if (!ctx.cr6.eq) goto loc_82126CD8;
loc_82126CD4:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82126CD8:
	// clrlwi r11,r11,24
	ctx.r11.u64 = ctx.r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82126d1c
	if (ctx.cr6.eq) goto loc_82126D1C;
	// cmplwi cr6,r5,256
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, 256, ctx.xer);
	// bge cr6,0x82126d1c
	if (!ctx.cr6.lt) goto loc_82126D1C;
	// lwz r9,80(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 80);
	// rlwinm r11,r5,2,0,29
	ctx.r11.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r4,2,0,29
	ctx.r8.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r5,r11
	ctx.r7.u64 = ctx.r5.u64 + ctx.r11.u64;
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r11,r9,r8
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// add r6,r11,r10
	ctx.r6.u64 = ctx.r11.u64 + ctx.r10.u64;
	// li r11,1
	ctx.r11.s64 = 1;
	// lhz r5,38(r6)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r6.u32 + 38);
	// rlwinm r4,r5,0,0,16
	ctx.r4.u64 = rotl64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFFFF8000;
	// cmplwi cr6,r4,0
	ctx.cr6.compare<uint32_t>(ctx.r4.u32, 0, ctx.xer);
	// bne cr6,0x82126d20
	if (!ctx.cr6.eq) goto loc_82126D20;
loc_82126D1C:
	// li r11,0
	ctx.r11.s64 = 0;
loc_82126D20:
	// clrlwi r3,r11,24
	ctx.r3.u64 = ctx.r11.u32 & 0xFF;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82126D28"))) PPC_WEAK_FUNC(sub_82126D28);
PPC_FUNC_IMPL(__imp__sub_82126D28) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e46c
	ctx.lr = 0x82126D30;
	__restfpr_29(ctx, base);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	ctx.r30.u64 = ctx.r3.u64;
	// mr r29,r4
	ctx.r29.u64 = ctx.r4.u64;
	// mr r31,r5
	ctx.r31.u64 = ctx.r5.u64;
	// bl 0x82126cb0
	ctx.lr = 0x82126D44;
	sub_82126CB0(ctx, base);
	// clrlwi r11,r3,24
	ctx.r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// bne cr6,0x82126d5c
	if (!ctx.cr6.eq) goto loc_82126D5C;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
loc_82126D5C:
	// lwz r9,80(r30)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r30.u32 + 80);
	// rlwinm r11,r31,2,0,29
	ctx.r11.u64 = rotl64(ctx.r31.u32 | (ctx.r31.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r8,r29,2,0,29
	ctx.r8.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r31,r11
	ctx.r7.u64 = ctx.r31.u64 + ctx.r11.u64;
	// rlwinm r10,r7,3,0,28
	ctx.r10.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r11,r9,r8
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// add r3,r11,r10
	ctx.r3.u64 = ctx.r11.u64 + ctx.r10.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x8233e4bc
	__restgprlr_29(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82126D80"))) PPC_WEAK_FUNC(sub_82126D80);
PPC_FUNC_IMPL(__imp__sub_82126D80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82126D88;
	__restfpr_27(ctx, base);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r29,-32178
	ctx.r29.s64 = -2108817408;
	// lwz r31,0(r3)
	ctx.r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r30,r4
	ctx.r30.u64 = ctx.r4.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r11,25872(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25872);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r11.u32 + 4);
	// stw r10,12216(r31)
	PPC_STORE_U32(ctx.r31.u32 + 12216, ctx.r10.u32);
	// ld r9,16(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 16);
	// oris r8,r9,8
	ctx.r8.u64 = ctx.r9.u64 | 524288;
	// std r8,16(r31)
	PPC_STORE_U64(ctx.r31.u32 + 16, ctx.r8.u64);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 8);
	// bl 0x82238728
	ctx.lr = 0x82126DBC;
	sub_82238728(ctx, base);
	// lwz r11,25872(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 25872);
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r11.u32 + 0);
	// bl 0x82238380
	ctx.lr = 0x82126DCC;
	sub_82238380(ctx, base);
	// lfs f0,48(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,7744(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7744, temp.u32);
	// li r7,1
	ctx.r7.s64 = 1;
	// lfs f13,52(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// li r6,1
	ctx.r6.s64 = 1;
	// stfs f13,7748(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7748, temp.u32);
	// rldicr r10,r7,36,63
	ctx.r10.u64 = rotl64(ctx.r7.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// lfs f12,56(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 56);
	ctx.f12.f64 = double(temp.f32);
	// rldicr r11,r6,35,63
	ctx.r11.u64 = rotl64(ctx.r6.u64, 35) & 0xFFFFFFFFFFFFFFFF;
	// stfs f12,7752(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7752, temp.u32);
	// lfs f11,60(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	ctx.f11.f64 = double(temp.f32);
	// mr r5,r11
	ctx.r5.u64 = ctx.r11.u64;
	// stfs f11,7756(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7756, temp.u32);
	// ld r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r3,r4,r10
	ctx.r3.u64 = ctx.r4.u64 | ctx.r10.u64;
	// std r3,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r3.u64);
	// lfs f10,32(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 32);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,7760(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7760, temp.u32);
	// lfs f9,36(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,7764(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7764, temp.u32);
	// lfs f8,40(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 40);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,7768(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7768, temp.u32);
	// lfs f7,44(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 44);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,7772(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7772, temp.u32);
	// ld r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r8,r9,r10
	ctx.r8.u64 = ctx.r9.u64 | ctx.r10.u64;
	// std r8,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r8.u64);
	// lfs f6,64(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 64);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,7776(r31)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7776, temp.u32);
	// lfs f5,68(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 68);
	ctx.f5.f64 = double(temp.f32);
	// stfs f5,7780(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7780, temp.u32);
	// lfs f4,72(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 72);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,7784(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7784, temp.u32);
	// lfs f3,76(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 76);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,7788(r31)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7788, temp.u32);
	// ld r7,8(r31)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r6,r7,r10
	ctx.r6.u64 = ctx.r7.u64 | ctx.r10.u64;
	// std r6,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r6.u64);
	// lfs f2,80(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 80);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,7808(r31)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7808, temp.u32);
	// lfs f1,84(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 84);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,7812(r31)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7812, temp.u32);
	// lfs f0,88(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 88);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,7816(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7816, temp.u32);
	// lfs f13,92(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,7820(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7820, temp.u32);
	// ld r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r3,r4,r11
	ctx.r3.u64 = ctx.r4.u64 | ctx.r11.u64;
	// std r3,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r3.u64);
	// lfs f12,96(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,7792(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7792, temp.u32);
	// lfs f11,100(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 100);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,7796(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7796, temp.u32);
	// lfs f10,104(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 104);
	ctx.f10.f64 = double(temp.f32);
	// stfs f10,7800(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7800, temp.u32);
	// lfs f9,108(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 108);
	ctx.f9.f64 = double(temp.f32);
	// stfs f9,7804(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7804, temp.u32);
	// ld r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r8,r9,r10
	ctx.r8.u64 = ctx.r9.u64 | ctx.r10.u64;
	// std r8,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r8.u64);
	// lfs f8,112(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 112);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,7824(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7824, temp.u32);
	// lfs f7,116(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 116);
	ctx.f7.f64 = double(temp.f32);
	// stfs f7,7828(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7828, temp.u32);
	// lfs f6,120(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 120);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,7832(r31)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7832, temp.u32);
	// mr r6,r11
	ctx.r6.u64 = ctx.r11.u64;
	// lfs f5,124(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 124);
	ctx.f5.f64 = double(temp.f32);
	// mr r7,r11
	ctx.r7.u64 = ctx.r11.u64;
	// stfs f5,7836(r31)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7836, temp.u32);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// ld r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// lis r4,-32182
	ctx.r4.s64 = -2109079552;
	// addi r29,r11,28184
	ctx.r29.s64 = ctx.r11.s64 + 28184;
	// or r10,r3,r6
	ctx.r10.u64 = ctx.r3.u64 | ctx.r6.u64;
	// addi r9,r4,-27800
	ctx.r9.s64 = ctx.r4.s64 + -27800;
	// std r10,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r10.u64);
	// lfs f4,128(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 128);
	ctx.f4.f64 = double(temp.f32);
	// stfs f4,7840(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7840, temp.u32);
	// lfs f3,132(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 132);
	ctx.f3.f64 = double(temp.f32);
	// stfs f3,7844(r31)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7844, temp.u32);
	// lfs f2,136(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 136);
	ctx.f2.f64 = double(temp.f32);
	// stfs f2,7848(r31)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7848, temp.u32);
	// lfs f1,140(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 140);
	ctx.f1.f64 = double(temp.f32);
	// stfs f1,7852(r31)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7852, temp.u32);
	// ld r8,8(r31)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r7,r8,r7
	ctx.r7.u64 = ctx.r8.u64 | ctx.r7.u64;
	// std r7,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r7.u64);
	// lfs f0,144(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 144);
	ctx.f0.f64 = double(temp.f32);
	// stfs f0,7856(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7856, temp.u32);
	// lfs f13,148(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,7860(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7860, temp.u32);
	// lfs f12,152(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 152);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,7864(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7864, temp.u32);
	// lfs f11,156(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 156);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,7868(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 7868, temp.u32);
	// ld r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r31.u32 + 8);
	// or r4,r5,r6
	ctx.r4.u64 = ctx.r5.u64 | ctx.r6.u64;
	// std r4,8(r31)
	PPC_STORE_U64(ctx.r31.u32 + 8, ctx.r4.u64);
	// lwz r10,292(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 292);
	// lwz r11,2128(r9)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2128);
	// addi r28,r11,16
	ctx.r28.s64 = ctx.r11.s64 + 16;
	// cmplw cr6,r10,r28
	ctx.cr6.compare<uint32_t>(ctx.r10.u32, ctx.r28.u32, ctx.xer);
	// beq cr6,0x82126f88
	if (ctx.cr6.eq) goto loc_82126F88;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = ctx.r28.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x82126F84;
	sub_82237A38(ctx, base);
	// stw r28,292(r29)
	PPC_STORE_U32(ctx.r29.u32 + 292, ctx.r28.u32);
loc_82126F88:
	// lwz r11,2052(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82126fac
	if (ctx.cr6.eq) goto loc_82126FAC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82126FA4;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r29)
	PPC_STORE_U32(ctx.r29.u32 + 2052, ctx.r11.u32);
loc_82126FAC:
	// lwz r11,1972(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1972);
	// li r9,1
	ctx.r9.s64 = 1;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82126fe4
	if (ctx.cr6.eq) goto loc_82126FE4;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,11,19,21
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 11) & 0x1C00) | (ctx.r7.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1972(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1972, ctx.r10.u32);
loc_82126FE4:
	// lwz r11,1988(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 1988);
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82127018
	if (ctx.cr6.eq) goto loc_82127018;
	// lwz r11,0(r29)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r29.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,14,16,18
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 14) & 0xE000) | (ctx.r7.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1988(r29)
	PPC_STORE_U32(ctx.r29.u32 + 1988, ctx.r10.u32);
loc_82127018:
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,56
	ctx.r3.s64 = 56;
	// bl 0x82111340
	ctx.lr = 0x82127024;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x82127030;
	sub_821112B0(ctx, base);
	// lbz r11,160(r30)
	ctx.r11.u64 = PPC_LOAD_U8(ctx.r30.u32 + 160);
	// li r4,1
	ctx.r4.s64 = 1;
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// li r3,4353
	ctx.r3.s64 = 4353;
	// bne cr6,0x82127048
	if (!ctx.cr6.eq) goto loc_82127048;
	// li r3,12545
	ctx.r3.s64 = 12545;
loc_82127048:
	// bl 0x82113bc0
	ctx.lr = 0x8212704C;
	sub_82113BC0(ctx, base);
	// lwz r11,28(r30)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r30.u32 + 28);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// lwz r29,20(r30)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r30.u32 + 20);
	// lwz r28,24(r30)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r30.u32 + 24);
	// lwz r27,16(r30)
	ctx.r27.u64 = PPC_LOAD_U32(ctx.r30.u32 + 16);
	// add r30,r11,r10
	ctx.r30.u64 = ctx.r11.u64 + ctx.r10.u64;
	// mr r4,r29
	ctx.r4.u64 = ctx.r29.u64;
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// bl 0x8222dac0
	ctx.lr = 0x8212707C;
	sub_8222DAC0(ctx, base);
	// cmpwi cr6,r3,0
	ctx.cr6.compare<int32_t>(ctx.r3.s32, 0, ctx.xer);
	// bne cr6,0x821270bc
	if (!ctx.cr6.eq) goto loc_821270BC;
	// rlwinm r11,r29,3,0,28
	ctx.r11.u64 = rotl64(ctx.r29.u32 | (ctx.r29.u64 << 32), 3) & 0xFFFFFFF8;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r4,r27
	ctx.r4.u64 = ctx.r27.u64;
	// add r11,r29,r11
	ctx.r11.u64 = ctx.r29.u64 + ctx.r11.u64;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8233e4e0
	ctx.lr = 0x8212709C;
	sub_8233E4E0(ctx, base);
	// rlwinm r11,r30,1,0,30
	ctx.r11.u64 = rotl64(ctx.r30.u32 | (ctx.r30.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r4,r28
	ctx.r4.u64 = ctx.r28.u64;
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r10,r11,3
	ctx.r10.s64 = ctx.r11.s64 + 3;
	// rlwinm r5,r10,0,0,29
	ctx.r5.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFC;
	// bl 0x8233e4e0
	ctx.lr = 0x821270B4;
	sub_8233E4E0(ctx, base);
	// lwz r9,13828(r31)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r31.u32 + 13828);
	// stw r9,48(r31)
	PPC_STORE_U32(ctx.r31.u32 + 48, ctx.r9.u32);
loc_821270BC:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,52
	ctx.r3.s64 = 52;
	// bl 0x82111340
	ctx.lr = 0x821270C8;
	sub_82111340(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,12545
	ctx.r3.s64 = 12545;
	// bl 0x82113bc0
	ctx.lr = 0x821270D4;
	sub_82113BC0(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x821270E0;
	sub_821112B0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821270E8"))) PPC_WEAK_FUNC(sub_821270E8);
PPC_FUNC_IMPL(__imp__sub_821270E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e460
	ctx.lr = 0x821270F0;
	__restfpr_26(ctx, base);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// addi r9,r11,31376
	ctx.r9.s64 = ctx.r11.s64 + 31376;
	// addi r8,r10,-25648
	ctx.r8.s64 = ctx.r10.s64 + -25648;
	// lis r7,42
	ctx.r7.s64 = 2752512;
	// li r29,0
	ctx.r29.s64 = 0;
	// ori r6,r7,9145
	ctx.r6.u64 = ctx.r7.u64 | 9145;
	// lfs f0,36(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 36);
	ctx.f0.f64 = double(temp.f32);
	// stb r29,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, ctx.r29.u8);
	// lfs f13,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// lfs f12,32(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// li r4,2
	ctx.r4.s64 = 2;
	// stfs f12,-25648(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + -25648, temp.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stfs f0,4(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 4, temp.u32);
	// stfs f13,8(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 8, temp.u32);
	// stfs f13,12(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 12, temp.u32);
	// stfs f0,16(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 16, temp.u32);
	// stfs f0,20(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 20, temp.u32);
	// stfs f0,24(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 24, temp.u32);
	// stfs f13,28(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 28, temp.u32);
	// stfs f12,32(r8)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + 32, temp.u32);
	// stfs f12,36(r8)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + 36, temp.u32);
	// stfs f13,40(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 40, temp.u32);
	// stfs f0,44(r8)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 44, temp.u32);
	// bl 0x821160a8
	ctx.lr = 0x82127160;
	sub_821160A8(ctx, base);
	// lis r5,44
	ctx.r5.s64 = 2883584;
	// li r4,5
	ctx.r4.s64 = 5;
	// stb r29,121(r1)
	PPC_STORE_U8(ctx.r1.u32 + 121, ctx.r29.u8);
	// ori r11,r5,9125
	ctx.r11.u64 = ctx.r5.u64 | 9125;
	// stb r4,133(r1)
	PPC_STORE_U8(ctx.r1.u32 + 133, ctx.r4.u8);
	// li r4,3
	ctx.r4.s64 = 3;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r11.u32);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r11.u32);
	// bl 0x821160a8
	ctx.lr = 0x82127188;
	sub_821160A8(ctx, base);
	// bl 0x82116360
	ctx.lr = 0x8212718C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821271b8
	if (ctx.cr6.eq) goto loc_821271B8;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,25440
	ctx.r6.s64 = ctx.r11.s64 + 25440;
	// addi r5,r10,25856
	ctx.r5.s64 = ctx.r10.s64 + 25856;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x821271AC;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25876(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25876, ctx.r3.u32);
	// b 0x821271c4
	goto loc_821271C4;
loc_821271B8:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25876(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25876, ctx.r29.u32);
loc_821271C4:
	// bl 0x82116360
	ctx.lr = 0x821271C8;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821271f4
	if (ctx.cr6.eq) goto loc_821271F4;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,27088
	ctx.r6.s64 = ctx.r11.s64 + 27088;
	// addi r5,r10,27720
	ctx.r5.s64 = ctx.r10.s64 + 27720;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c770
	ctx.lr = 0x821271E8;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25880(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25880, ctx.r3.u32);
	// b 0x82127200
	goto loc_82127200;
loc_821271F4:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25880(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25880, ctx.r29.u32);
loc_82127200:
	// bl 0x82116360
	ctx.lr = 0x82127204;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82127230
	if (ctx.cr6.eq) goto loc_82127230;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,29088
	ctx.r6.s64 = ctx.r11.s64 + 29088;
	// addi r5,r10,29704
	ctx.r5.s64 = ctx.r10.s64 + 29704;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x8211c770
	ctx.lr = 0x82127224;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25884(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25884, ctx.r3.u32);
	// b 0x8212723c
	goto loc_8212723C;
loc_82127230:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25884(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25884, ctx.r29.u32);
loc_8212723C:
	// bl 0x82116360
	ctx.lr = 0x82127240;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212726c
	if (ctx.cr6.eq) goto loc_8212726C;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,30032
	ctx.r6.s64 = ctx.r11.s64 + 30032;
	// addi r5,r10,30624
	ctx.r5.s64 = ctx.r10.s64 + 30624;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x8211c770
	ctx.lr = 0x82127260;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25888(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25888, ctx.r3.u32);
	// b 0x82127278
	goto loc_82127278;
loc_8212726C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25888(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25888, ctx.r29.u32);
loc_82127278:
	// bl 0x82116360
	ctx.lr = 0x8212727C;
	sub_82116360(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821272a8
	if (ctx.cr6.eq) goto loc_821272A8;
	// lis r11,-32252
	ctx.r11.s64 = -2113667072;
	// lis r10,-32252
	ctx.r10.s64 = -2113667072;
	// addi r6,r11,30952
	ctx.r6.s64 = ctx.r11.s64 + 30952;
	// addi r5,r10,31312
	ctx.r5.s64 = ctx.r10.s64 + 31312;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x8211c770
	ctx.lr = 0x8212729C;
	sub_8211C770(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r3,25892(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25892, ctx.r3.u32);
	// b 0x821272b4
	goto loc_821272B4;
loc_821272A8:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// mr r11,r29
	ctx.r11.u64 = ctx.r29.u64;
	// stw r29,25892(r10)
	PPC_STORE_U32(ctx.r10.u32 + 25892, ctx.r29.u32);
loc_821272B4:
	// lis r11,-32179
	ctx.r11.s64 = -2108882944;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r29.u32);
	// lis r10,0
	ctx.r10.s64 = 0;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r29.u32);
	// addi r9,r11,20000
	ctx.r9.s64 = ctx.r11.s64 + 20000;
	// ori r7,r10,65512
	ctx.r7.u64 = ctx.r10.u64 | 65512;
	// lis r5,0
	ctx.r5.s64 = 0;
	// li r6,80
	ctx.r6.s64 = 80;
	// ori r4,r5,65516
	ctx.r4.u64 = ctx.r5.u64 | 65516;
	// li r3,1
	ctx.r3.s64 = 1;
	// lwzx r11,r9,r7
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// li r8,5120
	ctx.r8.s64 = 5120;
	// stw r3,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r3.u32);
	// lis r5,6688
	ctx.r5.s64 = 438304768;
	// addi r7,r11,79
	ctx.r7.s64 = ctx.r11.s64 + 79;
	// lwzx r10,r9,r4
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r4.u32);
	// rlwinm r31,r11,29,3,31
	ctx.r31.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 29) & 0x1FFFFFFF;
	// divwu r9,r7,r6
	ctx.r9.u32 = ctx.r7.u32 / ctx.r6.u32;
	// addi r4,r10,15
	ctx.r4.s64 = ctx.r10.s64 + 15;
	// rlwinm r7,r9,2,0,29
	ctx.r7.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r3,r4,28,4,31
	ctx.r3.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 28) & 0xFFFFFFF;
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// rlwinm r7,r3,4,0,27
	ctx.r7.u64 = rotl64(ctx.r3.u32 | (ctx.r3.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r4,r9,4,0,27
	ctx.r4.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r28,r31,79
	ctx.r28.s64 = ctx.r31.s64 + 79;
	// mullw r9,r7,r4
	ctx.r9.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r4.s32);
	// mullw r7,r7,r4
	ctx.r7.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r4.s32);
	// rlwinm r4,r9,2,0,29
	ctx.r4.u64 = rotl64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r7,r7,3,0,28
	ctx.r7.u64 = rotl64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// divwu r9,r4,r8
	ctx.r9.u32 = ctx.r4.u32 / ctx.r8.u32;
	// divwu r7,r7,r8
	ctx.r7.u32 = ctx.r7.u32 / ctx.r8.u32;
	// rlwinm r30,r10,29,3,31
	ctx.r30.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// add r27,r7,r9
	ctx.r27.u64 = ctx.r7.u64 + ctx.r9.u64;
	// divwu r10,r28,r6
	ctx.r10.u32 = ctx.r28.u32 / ctx.r6.u32;
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r27.u32);
	// addi r4,r11,31
	ctx.r4.s64 = ctx.r11.s64 + 31;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = rotl64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r30,15
	ctx.r6.s64 = ctx.r30.s64 + 15;
	// add r11,r10,r9
	ctx.r11.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r6,0,0,27
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFF0;
	// rlwinm r9,r11,4,0,27
	ctx.r9.u64 = rotl64(ctx.r11.u32 | (ctx.r11.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r7,r4,27,5,31
	ctx.r7.u64 = rotl64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// mullw r6,r10,r9
	ctx.r6.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// mullw r11,r7,r3
	ctx.r11.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r3.s32);
	// rlwinm r10,r6,3,0,28
	ctx.r10.u64 = rotl64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,0
	ctx.r6.s64 = 0;
	// ori r5,r5,43861
	ctx.r5.u64 = ctx.r5.u64 | 43861;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// clrlwi r26,r11,9
	ctx.r26.u64 = ctx.r11.u32 & 0x7FFFFF;
	// divwu r28,r10,r8
	ctx.r28.u32 = ctx.r10.u32 / ctx.r8.u32;
	// bl 0x82237798
	ctx.lr = 0x82127388;
	sub_82237798(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// stw r29,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r29.u32);
	// lis r5,6184
	ctx.r5.s64 = 405274624;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,0
	ctx.r6.s64 = 0;
	// ori r5,r5,390
	ctx.r5.u64 = ctx.r5.u64 | 390;
	// stw r3,25900(r9)
	PPC_STORE_U32(ctx.r9.u32 + 25900, ctx.r3.u32);
	// li r4,128
	ctx.r4.s64 = 128;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82237798
	ctx.lr = 0x821273B0;
	sub_82237798(ctx, base);
	// lis r8,-32178
	ctx.r8.s64 = -2108817408;
	// lis r5,11552
	ctx.r5.s64 = 757071872;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,0
	ctx.r6.s64 = 0;
	// ori r5,r5,406
	ctx.r5.u64 = ctx.r5.u64 | 406;
	// stw r3,25908(r8)
	PPC_STORE_U32(ctx.r8.u32 + 25908, ctx.r3.u32);
	// li r4,128
	ctx.r4.s64 = 128;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82237798
	ctx.lr = 0x821273D4;
	sub_82237798(ctx, base);
	// lis r7,-32178
	ctx.r7.s64 = -2108817408;
	// cmplwi cr6,r28,16
	ctx.cr6.compare<uint32_t>(ctx.r28.u32, 16, ctx.xer);
	// stw r3,25904(r7)
	PPC_STORE_U32(ctx.r7.u32 + 25904, ctx.r3.u32);
	// bgt cr6,0x821273e8
	if (ctx.cr6.gt) goto loc_821273E8;
	// li r28,16
	ctx.r28.s64 = 16;
loc_821273E8:
	// add r11,r28,r27
	ctx.r11.u64 = ctx.r28.u64 + ctx.r27.u64;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r26.u32);
	// lis r5,6690
	ctx.r5.s64 = 438435840;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r11.u32);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// li r6,0
	ctx.r6.s64 = 0;
	// ori r5,r5,407
	ctx.r5.u64 = ctx.r5.u64 | 407;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82237798
	ctx.lr = 0x82127410;
	sub_82237798(ctx, base);
	// lis r7,-32178
	ctx.r7.s64 = -2108817408;
	// lis r8,6690
	ctx.r8.s64 = 438435840;
	// li r10,3
	ctx.r10.s64 = 3;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r8,r8,344
	ctx.r8.u64 = ctx.r8.u64 | 344;
	// stw r3,25896(r7)
	PPC_STORE_U32(ctx.r7.u32 + 25896, ctx.r3.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// mr r3,r31
	ctx.r3.u64 = ctx.r31.u64;
	// bl 0x82237678
	ctx.lr = 0x82127440;
	sub_82237678(ctx, base);
	// lis r6,-32178
	ctx.r6.s64 = -2108817408;
	// li r5,13
	ctx.r5.s64 = 13;
	// lis r8,11552
	ctx.r8.s64 = 757071872;
	// li r10,3
	ctx.r10.s64 = 3;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r3,25912(r6)
	PPC_STORE_U32(ctx.r6.u32 + 25912, ctx.r3.u32);
	// ori r8,r8,406
	ctx.r8.u64 = ctx.r8.u64 | 406;
	// lwz r4,40(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// rlwimi r4,r5,15,13,18
	ctx.r4.u64 = (rotl32(ctx.r5.u32, 15) & 0x7E000) | (ctx.r4.u64 & 0xFFFFFFFFFFF81FFF);
	// stw r4,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r4.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,128
	ctx.r4.s64 = 128;
	// li r3,128
	ctx.r3.s64 = 128;
	// bl 0x82237678
	ctx.lr = 0x82127480;
	sub_82237678(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// stw r3,25916(r11)
	PPC_STORE_U32(ctx.r11.u32 + 25916, ctx.r3.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x8233e4b0
	__restgprlr_26(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82127490"))) PPC_WEAK_FUNC(sub_82127490);
PPC_FUNC_IMPL(__imp__sub_82127490) {
	PPC_FUNC_PROLOGUE();
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25876(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25876);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821274b0
	if (ctx.cr6.eq) goto loc_821274B0;
	// bl 0x8211af20
	ctx.lr = 0x821274B0;
	sub_8211AF20(ctx, base);
loc_821274B0:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25880(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25880);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821274c4
	if (ctx.cr6.eq) goto loc_821274C4;
	// bl 0x8211af20
	ctx.lr = 0x821274C4;
	sub_8211AF20(ctx, base);
loc_821274C4:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25884(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25884);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821274d8
	if (ctx.cr6.eq) goto loc_821274D8;
	// bl 0x8211af20
	ctx.lr = 0x821274D8;
	sub_8211AF20(ctx, base);
loc_821274D8:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25888(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25888);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x821274ec
	if (ctx.cr6.eq) goto loc_821274EC;
	// bl 0x8211af20
	ctx.lr = 0x821274EC;
	sub_8211AF20(ctx, base);
loc_821274EC:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25892(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25892);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x82127500
	if (ctx.cr6.eq) goto loc_82127500;
	// bl 0x8211af20
	ctx.lr = 0x82127500;
	sub_8211AF20(ctx, base);
loc_82127500:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25900(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25900);
	// bl 0x8222f0f8
	ctx.lr = 0x8212750C;
	sub_8222F0F8(ctx, base);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// lwz r3,25896(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 25896);
	// bl 0x8222f0f8
	ctx.lr = 0x82127518;
	sub_8222F0F8(ctx, base);
	// lis r9,-32178
	ctx.r9.s64 = -2108817408;
	// lwz r3,25904(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25904);
	// bl 0x8222f0f8
	ctx.lr = 0x82127524;
	sub_8222F0F8(ctx, base);
	// lis r8,-32178
	ctx.r8.s64 = -2108817408;
	// lwz r3,25908(r8)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + 25908);
	// bl 0x8222f0f8
	ctx.lr = 0x82127530;
	sub_8222F0F8(ctx, base);
	// lis r7,-32178
	ctx.r7.s64 = -2108817408;
	// lwz r3,25912(r7)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r7.u32 + 25912);
	// bl 0x8222f0f8
	ctx.lr = 0x8212753C;
	sub_8222F0F8(ctx, base);
	// lis r6,-32178
	ctx.r6.s64 = -2108817408;
	// lwz r3,25916(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 25916);
	// bl 0x8222f0f8
	ctx.lr = 0x82127548;
	sub_8222F0F8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	ctx.r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	ctx.lr = ctx.r12.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82127558"))) PPC_WEAK_FUNC(sub_82127558);
PPC_FUNC_IMPL(__imp__sub_82127558) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e464
	ctx.lr = 0x82127560;
	__restfpr_27(ctx, base);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r28,0(r3)
	ctx.r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// mr r29,r3
	ctx.r29.u64 = ctx.r3.u64;
	// mr r27,r4
	ctx.r27.u64 = ctx.r4.u64;
	// lwz r5,25908(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 25908);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x8212759c
	if (ctx.cr6.eq) goto loc_8212759C;
	// stw r5,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x8212759C;
	sub_8222CDF8(ctx, base);
loc_8212759C:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// lwz r11,52(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// lwz r30,25904(r10)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 25904);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x821275cc
	if (ctx.cr6.eq) goto loc_821275CC;
	// stw r30,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r30.u32);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222d188
	ctx.lr = 0x821275C0;
	sub_8222D188(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x821275cc
	if (ctx.cr6.eq) goto loc_821275CC;
	// bl 0x82113790
	ctx.lr = 0x821275CC;
	sub_82113790(ctx, base);
loc_821275CC:
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x821275D8;
	sub_821112B0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x821275E4;
	sub_82113BC0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,384
	ctx.r3.s64 = 384;
	// bl 0x82111340
	ctx.lr = 0x821275F0;
	sub_82111340(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,388
	ctx.r3.s64 = 388;
	// bl 0x82111340
	ctx.lr = 0x821275FC;
	sub_82111340(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x82127608;
	sub_82111340(ctx, base);
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lwz r3,25888(r11)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25888);
	// bl 0x8211c5f0
	ctx.lr = 0x82127614;
	sub_8211C5F0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r29.u32 + 4);
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// addi r30,r10,172
	ctx.r30.s64 = ctx.r10.s64 + 172;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x8212764c
	if (ctx.cr6.eq) goto loc_8212764C;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x82127648;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_8212764C:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// li r9,3
	ctx.r9.s64 = 3;
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82127684
	if (ctx.cr6.eq) goto loc_82127684;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,11,19,21
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 11) & 0x1C00) | (ctx.r7.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_82127684:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x821276b8
	if (ctx.cr6.eq) goto loc_821276B8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,14,16,18
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 14) & 0xE000) | (ctx.r7.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_821276B8:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x821276dc
	if (ctx.cr6.eq) goto loc_821276DC;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x821276D4;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r11.u32);
loc_821276DC:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82127700
	if (ctx.cr6.eq) goto loc_82127700;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x821276F8;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
loc_82127700:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// li r9,1
	ctx.r9.s64 = 1;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82127738
	if (ctx.cr6.eq) goto loc_82127738;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1164(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r7,r9,24,7,8
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 24) & 0x1800000) | (ctx.r7.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r7,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r10.u32);
loc_82127738:
	// lwz r11,2020(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2020);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x8212776c
	if (ctx.cr6.eq) goto loc_8212776C;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1172(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// rlwimi r7,r9,0,30,31
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 0) & 0x3) | (ctx.r7.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r7,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2020, ctx.r10.u32);
loc_8212776C:
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f0,1084(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 1084);
	ctx.f0.f64 = double(temp.f32);
	// lfs f12,1080(r27)
	temp.u32 = PPC_LOAD_U32(ctx.r27.u32 + 1080);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32182
	ctx.r10.s64 = -2109079552;
	// addi r30,r11,31376
	ctx.r30.s64 = ctx.r11.s64 + 31376;
	// addi r31,r10,-25648
	ctx.r31.s64 = ctx.r10.s64 + -25648;
	// li r12,1
	ctx.r12.s64 = 1;
	// li r6,16
	ctx.r6.s64 = 16;
	// rldicr r12,r12,36,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// lfs f13,148(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// li r5,3
	ctx.r5.s64 = 3;
	// fadds f11,f0,f13
	ctx.f11.f64 = double(float(ctx.f0.f64 + ctx.f13.f64));
	// lfs f0,60(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 60);
	ctx.f0.f64 = double(temp.f32);
	// fadds f8,f12,f13
	ctx.f8.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f13,1472(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 1472);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,536(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 536);
	ctx.f10.f64 = double(temp.f32);
	// li r4,8
	ctx.r4.s64 = 8;
	// lfs f9,1476(r30)
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 1476);
	ctx.f9.f64 = double(temp.f32);
	// mr r3,r28
	ctx.r3.u64 = ctx.r28.u64;
	// fsubs f7,f11,f0
	ctx.f7.f64 = static_cast<float>(ctx.f11.f64 - ctx.f0.f64);
	// fsubs f6,f8,f0
	ctx.f6.f64 = static_cast<float>(ctx.f8.f64 - ctx.f0.f64);
	// fsubs f12,f7,f13
	ctx.f12.f64 = static_cast<float>(ctx.f7.f64 - ctx.f13.f64);
	// stfs f12,12(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 12, temp.u32);
	// fsubs f11,f6,f13
	ctx.f11.f64 = static_cast<float>(ctx.f6.f64 - ctx.f13.f64);
	// stfs f11,8(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 8, temp.u32);
	// stfs f12,28(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r31.u32 + 28, temp.u32);
	// stfs f11,40(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r31.u32 + 40, temp.u32);
	// fadds f5,f12,f0
	ctx.f5.f64 = double(float(ctx.f12.f64 + ctx.f0.f64));
	// fadds f4,f11,f0
	ctx.f4.f64 = double(float(ctx.f11.f64 + ctx.f0.f64));
	// fsubs f0,f5,f13
	ctx.f0.f64 = static_cast<float>(ctx.f5.f64 - ctx.f13.f64);
	// stfs f0,44(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 44, temp.u32);
	// fsubs f0,f4,f13
	ctx.f0.f64 = static_cast<float>(ctx.f4.f64 - ctx.f13.f64);
	// stfs f0,24(r31)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r31.u32 + 24, temp.u32);
	// stfs f10,7744(r28)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + 7744, temp.u32);
	// stfs f9,7748(r28)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r28.u32 + 7748, temp.u32);
	// stfs f10,7752(r28)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + 7752, temp.u32);
	// stfs f10,7756(r28)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r28.u32 + 7756, temp.u32);
	// ld r11,8(r28)
	ctx.r11.u64 = PPC_LOAD_U64(ctx.r28.u32 + 8);
	// or r10,r11,r12
	ctx.r10.u64 = ctx.r11.u64 | ctx.r12.u64;
	// std r10,8(r28)
	PPC_STORE_U64(ctx.r28.u32 + 8, ctx.r10.u64);
	// bl 0x8222d600
	ctx.lr = 0x82127810;
	sub_8222D600(ctx, base);
	// cmplwi cr6,r3,0
	ctx.cr6.compare<uint32_t>(ctx.r3.u32, 0, ctx.xer);
	// beq cr6,0x8212782c
	if (ctx.cr6.eq) goto loc_8212782C;
	// mr r4,r31
	ctx.r4.u64 = ctx.r31.u64;
	// li r5,48
	ctx.r5.s64 = 48;
	// bl 0x8233e4e0
	ctx.lr = 0x82127824;
	sub_8233E4E0(ctx, base);
	// lwz r11,13828(r28)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r28.u32 + 13828);
	// stw r11,48(r28)
	PPC_STORE_U32(ctx.r28.u32 + 48, ctx.r11.u32);
loc_8212782C:
	// lis r11,-32178
	ctx.r11.s64 = -2108817408;
	// lfs f1,36(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r30.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,4
	ctx.r3.s64 = 4;
	// lwz r5,25916(r11)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r11.u32 + 25916);
	// bl 0x8210af50
	ctx.lr = 0x82127850;
	sub_8210AF50(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8212785C;
	sub_821112B0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x8233e4b4
	__restgprlr_27(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82127864"))) PPC_WEAK_FUNC(sub_82127864);
PPC_FUNC_IMPL(__imp__sub_82127864) {
	PPC_FUNC_PROLOGUE();
	// .long 0x0
}

__attribute__((alias("__imp__sub_82127868"))) PPC_WEAK_FUNC(sub_82127868);
PPC_FUNC_IMPL(__imp__sub_82127868) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	ctx.r12.u64 = ctx.lr;
	// bl 0x8233e468
	ctx.lr = 0x82127870;
	__restfpr_28(ctx, base);
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, ctx.f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r29,0(r3)
	ctx.r29.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// addi r31,r11,27648
	ctx.r31.s64 = ctx.r11.s64 + 27648;
	// mr r28,r3
	ctx.r28.u64 = ctx.r3.u64;
	// lwz r5,25900(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 25900);
	// lwz r11,36(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 36);
	// cmplw cr6,r5,r11
	ctx.cr6.compare<uint32_t>(ctx.r5.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x821278ac
	if (ctx.cr6.eq) goto loc_821278AC;
	// stw r5,36(r31)
	PPC_STORE_U32(ctx.r31.u32 + 36, ctx.r5.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222cdf8
	ctx.lr = 0x821278AC;
	sub_8222CDF8(ctx, base);
loc_821278AC:
	// lis r10,-32178
	ctx.r10.s64 = -2108817408;
	// lwz r11,52(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 52);
	// lwz r30,25896(r10)
	ctx.r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 25896);
	// cmplw cr6,r30,r11
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, ctx.r11.u32, ctx.xer);
	// beq cr6,0x821278dc
	if (ctx.cr6.eq) goto loc_821278DC;
	// stw r30,52(r31)
	PPC_STORE_U32(ctx.r31.u32 + 52, ctx.r30.u32);
	// mr r4,r30
	ctx.r4.u64 = ctx.r30.u64;
	// lwz r3,188(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 188);
	// bl 0x8222d188
	ctx.lr = 0x821278D0;
	sub_8222D188(ctx, base);
	// cmplwi cr6,r30,0
	ctx.cr6.compare<uint32_t>(ctx.r30.u32, 0, ctx.xer);
	// beq cr6,0x821278dc
	if (ctx.cr6.eq) goto loc_821278DC;
	// bl 0x82113790
	ctx.lr = 0x821278DC;
	sub_82113790(ctx, base);
loc_821278DC:
	// lfs f0,13008(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 13008);
	ctx.f0.f64 = double(temp.f32);
	// lis r11,-32250
	ctx.r11.s64 = -2113536000;
	// lfs f13,13012(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 13012);
	ctx.f13.f64 = double(temp.f32);
	// fctidz f12,f0
	ctx.f12.s64 = (ctx.f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f0.f64);
	// lfs f11,13000(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 13000);
	ctx.f11.f64 = double(temp.f32);
	// fctidz f10,f13
	ctx.f10.s64 = (ctx.f13.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f13.f64);
	// lfs f8,13004(r29)
	temp.u32 = PPC_LOAD_U32(ctx.r29.u32 + 13004);
	ctx.f8.f64 = double(temp.f32);
	// fctidz f9,f11
	ctx.f9.s64 = (ctx.f11.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f11.f64);
	// stfd f12,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f12.u64);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stfd f10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f10.u64);
	// lwz r9,92(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// fctidz f7,f8
	ctx.f7.s64 = (ctx.f8.f64 > double(LLONG_MAX)) ? LLONG_MAX : simd::truncate_f64_to_i64(ctx.f8.f64);
	// stfd f9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.f9.u64);
	// stfd f7,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.f7.u64);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r6,92(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r7,r11,31376
	ctx.r7.s64 = ctx.r11.s64 + 31376;
	// stw r10,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r10.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lfs f0,48(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 48);
	ctx.f0.f64 = double(temp.f32);
	// stw r9,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r9.u32);
	// lfs f31,36(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 36);
	ctx.f31.f64 = double(temp.f32);
	// mr r3,r29
	ctx.r3.u64 = ctx.r29.u64;
	// stfs f31,112(r1)
	temp.f32 = float(ctx.f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stw r8,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r8.u32);
	// stfs f0,116(r1)
	temp.f32 = float(ctx.f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stw r6,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r6.u32);
	// bl 0x8222cbc8
	ctx.lr = 0x82127950;
	sub_8222CBC8(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x821112b0
	ctx.lr = 0x8212795C;
	sub_821112B0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82113bc0
	ctx.lr = 0x82127968;
	sub_82113BC0(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x82111340
	ctx.lr = 0x82127974;
	sub_82111340(ctx, base);
	// lis r5,-32178
	ctx.r5.s64 = -2108817408;
	// lwz r3,25884(r5)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + 25884);
	// bl 0x8211c5f0
	ctx.lr = 0x82127980;
	sub_8211C5F0(ctx, base);
	// lis r11,-32183
	ctx.r11.s64 = -2109145088;
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r28.u32 + 4);
	// addi r31,r11,28184
	ctx.r31.s64 = ctx.r11.s64 + 28184;
	// addi r30,r10,16
	ctx.r30.s64 = ctx.r10.s64 + 16;
	// lwz r11,292(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 292);
	// cmplw cr6,r11,r30
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, ctx.r30.u32, ctx.xer);
	// beq cr6,0x821279b8
	if (ctx.cr6.eq) goto loc_821279B8;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// mr r5,r30
	ctx.r5.u64 = ctx.r30.u64;
	// oris r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 2147483648;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82237a38
	ctx.lr = 0x821279B4;
	sub_82237A38(ctx, base);
	// stw r30,292(r31)
	PPC_STORE_U32(ctx.r31.u32 + 292, ctx.r30.u32);
loc_821279B8:
	// lwz r11,1972(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1972);
	// li r9,3
	ctx.r9.s64 = 3;
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x821279f0
	if (ctx.cr6.eq) goto loc_821279F0;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,11,19,21
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 11) & 0x1C00) | (ctx.r7.u64 & 0xFFFFFFFFFFFFE3FF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1972(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1972, ctx.r10.u32);
loc_821279F0:
	// lwz r11,1988(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 1988);
	// cmplwi cr6,r11,6
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 6, ctx.xer);
	// beq cr6,0x82127a24
	if (ctx.cr6.eq) goto loc_82127A24;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,6
	ctx.r10.s64 = 6;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1152(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1152);
	// rlwimi r7,r9,14,16,18
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 14) & 0xE000) | (ctx.r7.u64 & 0xFFFFFFFFFFFF1FFF);
	// stw r7,1152(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1152, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,1988(r31)
	PPC_STORE_U32(ctx.r31.u32 + 1988, ctx.r10.u32);
loc_82127A24:
	// lwz r11,2036(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2036);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82127a48
	if (ctx.cr6.eq) goto loc_82127A48;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c248
	ctx.lr = 0x82127A40;
	sub_8222C248(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2036(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2036, ctx.r11.u32);
loc_82127A48:
	// lwz r11,2052(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2052);
	// cmplwi cr6,r11,0
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 0, ctx.xer);
	// beq cr6,0x82127a6c
	if (ctx.cr6.eq) goto loc_82127A6C;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8222c0a0
	ctx.lr = 0x82127A64;
	sub_8222C0A0(ctx, base);
	// li r11,0
	ctx.r11.s64 = 0;
	// stw r11,2052(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2052, ctx.r11.u32);
loc_82127A6C:
	// lwz r11,2068(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2068);
	// li r9,1
	ctx.r9.s64 = 1;
	// cmplwi cr6,r11,2
	ctx.cr6.compare<uint32_t>(ctx.r11.u32, 2, ctx.xer);
	// beq cr6,0x82127aa4
	if (ctx.cr6.eq) goto loc_82127AA4;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1164(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1164);
	// rlwimi r7,r9,24,7,8
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 24) & 0x1800000) | (ctx.r7.u64 & 0xFFFFFFFFFE7FFFFF);
	// stw r7,1164(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1164, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2068(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2068, ctx.r10.u32);
loc_82127AA4:
	// lwz r11,2020(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 2020);
	// cmpwi cr6,r11,-1
	ctx.cr6.compare<int32_t>(ctx.r11.s32, -1, ctx.xer);
	// beq cr6,0x82127ad8
	if (ctx.cr6.eq) goto loc_82127AD8;
	// lwz r11,0(r31)
	ctx.r11.u64 = PPC_LOAD_U32(ctx.r31.u32 + 0);
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r8,r11
	ctx.r8.u64 = ctx.r11.u64;
	// lwz r7,1172(r11)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r11.u32 + 1172);
	// rlwimi r7,r9,0,30,31
	ctx.r7.u64 = (rotl32(ctx.r9.u32, 0) & 0x3) | (ctx.r7.u64 & 0xFFFFFFFFFFFFFFFC);
	// stw r7,1172(r11)
	PPC_STORE_U32(ctx.r11.u32 + 1172, ctx.r7.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r11.u32 + 24);
	// oris r5,r6,32768
	ctx.r5.u64 = ctx.r6.u64 | 2147483648;
	// std r5,24(r11)
	PPC_STORE_U64(ctx.r11.u32 + 24, ctx.r5.u64);
	// stw r10,2020(r31)
	PPC_STORE_U32(ctx.r31.u32 + 2020, ctx.r10.u32);
loc_82127AD8:
	// lis r11,-32179
	ctx.r11.s64 = -2108882944;
	// lis r10,0
	ctx.r10.s64 = 0;
	// lis r7,0
	ctx.r7.s64 = 0;
	// addi r9,r11,20000
	ctx.r9.s64 = ctx.r11.s64 + 20000;
	// ori r8,r10,65516
	ctx.r8.u64 = ctx.r10.u64 | 65516;
	// ori r6,r7,65512
	ctx.r6.u64 = ctx.r7.u64 | 65512;
	// li r12,1
	ctx.r12.s64 = 1;
	// rldicr r12,r12,36,63
	ctx.r12.u64 = rotl64(ctx.r12.u64, 36) & 0xFFFFFFFFFFFFFFFF;
	// lwzx r5,r9,r8
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// lwzx r4,r9,r6
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// std r5,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r5.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r4,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r4.u64);
	// lfd f12,88(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f0
	ctx.f13.f64 = double(ctx.f0.s64);
	// fcfid f11,f12
	ctx.f11.f64 = double(ctx.f12.s64);
	// frsp f9,f13
	ctx.f9.f64 = double(float(ctx.f13.f64));
	// frsp f10,f11
	ctx.f10.f64 = double(float(ctx.f11.f64));
	// fdivs f7,f31,f9
	ctx.f7.f64 = double(float(ctx.f31.f64 / ctx.f9.f64));
	// stfs f7,7752(r29)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r29.u32 + 7752, temp.u32);
	// fdivs f8,f31,f10
	ctx.f8.f64 = double(float(ctx.f31.f64 / ctx.f10.f64));
	// stfs f8,7744(r29)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r29.u32 + 7744, temp.u32);
	// fneg f5,f7
	ctx.f5.u64 = ctx.f7.u64 ^ 0x8000000000000000;
	// stfs f5,7756(r29)
	temp.f32 = float(ctx.f5.f64);
	PPC_STORE_U32(ctx.r29.u32 + 7756, temp.u32);
	// fneg f6,f8
	ctx.f6.u64 = ctx.f8.u64 ^ 0x8000000000000000;
	// stfs f6,7748(r29)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r29.u32 + 7748, temp.u32);
	// ld r3,8(r29)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r29.u32 + 8);
	// or r11,r3,r12
	ctx.r11.u64 = ctx.r3.u64 | ctx.r12.u64;
	// std r11,8(r29)
	PPC_STORE_U64(ctx.r29.u32 + 8, ctx.r11.u64);
	// bl 0x8210b0d8
	ctx.lr = 0x82127B50;
	sub_8210B0D8(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x8233e4b8
	__restgprlr_28(ctx, base);
	return;
}

